{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Semi-Supervised Architope - for Reviews\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"PC-NNs\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1-(1/24)\n",
    "min_width = 100\n",
    "min_epochs = 100\n",
    "# Ablation Finess\n",
    "N_plot_finess = 8\n",
    "# min_parts_threshold = .001; max_parts_threshold = 0.9\n",
    "N_min_parts = 1; N_max_plots = 8\n",
    "Tied_Neurons_Q = True\n",
    "# Partition with Inputs (determine parts with domain) or outputs (determine parts with image)\n",
    "Partition_using_Inputs = True\n",
    "# Cuttoff Level\n",
    "gamma = .5\n",
    "# Softmax Layer instead of sigmoid\n",
    "softmax_layer = False #<- Just out of curiosity...but it doesn't perform many better IRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 10**4\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return np.exp(-x)\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# exec(open('Prepare_Data_California_Housing.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]\n",
    "sns.set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Partion Builder:\n",
    "Implements exactly Algorithm 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(X_in,\n",
    "                               y_in,\n",
    "                               N_parts_to_get=4):\n",
    "\n",
    "    # Compute Size of each part\n",
    "    size_part_reference = int(round(X_in.shape[0]/N_parts_to_get))\n",
    "\n",
    "    # Apply random bijection #\n",
    "    #------------------------#\n",
    "    ## Get random bijection indices\n",
    "    random_bijection_indices = np.random.choice(range(X_in.shape[0]),size=X_in.shape[0], replace=False)\n",
    "    ## Apply random bijections\n",
    "    X_in_shuffled = X_in[random_bijection_indices,:]\n",
    "    y_in_shuffled = y_in[random_bijection_indices,:]\n",
    "\n",
    "    # Initialize Lists #\n",
    "    #------------------#\n",
    "    X_parts = []\n",
    "    y_parts = []\n",
    "\n",
    "    for i_th_part_to_get in range(N_parts_to_get):\n",
    "        # Build random balls #\n",
    "        #--------------------#\n",
    "        ## Sample random radius\n",
    "        size_part = int(np.maximum(1,np.round(size_part_reference*np.random.uniform(low=.5,high=1.5,size=1)[0])))\n",
    "        ## Sample random point\n",
    "        X_center_loop_index = np.random.choice(range(X_in_shuffled.shape[0]),size=1, replace=False)\n",
    "        X_center_loop = X_in_shuffled[X_center_loop_index,:]\n",
    "        ## Compute Typical Distances from Center\n",
    "        distances_loop = X_center_loop-X_in_shuffled\n",
    "        distances_loop = np.linalg.norm(distances_loop, axis=1)\n",
    "\n",
    "        # Remove Random Ball from Dataset\n",
    "        if size_part <= len(distances_loop):\n",
    "            ## Identify indices\n",
    "            indices_smallest_to_random_ball = np.argsort(distances_loop)[:size_part]\n",
    "        else:\n",
    "            print('Final Loop')\n",
    "            indices_smallest_to_random_ball = np.array(range(X_in_shuffled.shape[0]))\n",
    "        ## Extract Parts\n",
    "        X_current_part_loop = X_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        y_current_part_loop = y_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        ## Append to List of Parts\n",
    "        X_parts.append(X_current_part_loop)\n",
    "        y_parts.append(y_current_part_loop)\n",
    "\n",
    "        # Remove Selected Entries From Array #\n",
    "        #------------------------------------#\n",
    "        X_in_shuffled = np.delete(X_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "        y_in_shuffled = np.delete(y_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "\n",
    "        # Failsafe if procedure has terminated\n",
    "        if X_in_shuffled.shape[0] == 0:\n",
    "            print('breaking early')\n",
    "            break\n",
    "    # Count Number of Parts Generated        \n",
    "    N_parts_generated = len(X_parts)\n",
    "    # Output Parts\n",
    "    return X_parts, y_parts, N_parts_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCNNs(N_parts,X_train,y_train,X_test,y_test):\n",
    "\n",
    "    # Initialization(s) #\n",
    "    #-------------------#\n",
    "    N_neurons = 0\n",
    "    L_timer = 0\n",
    "    P_timer = 0\n",
    "    Mean_Width_Subnetworks = 0\n",
    "\n",
    "    # Partitioner Begin #\n",
    "    #-------------------#\n",
    "    import time\n",
    "    partitioning_time_begin = time.time()\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Randomly Initialized Parts - Via Randomized Algorithm 2')\n",
    "    print('-------------------------------------------------------')\n",
    "    if Partition_using_Inputs == True:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(X_train.to_numpy(),\n",
    "                                                                                             y_train.reshape(-1,1),\n",
    "                                                                                             N_parts)\n",
    "    else:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(y_train.reshape(-1,1),\n",
    "                                                                                             X_train.to_numpy(),\n",
    "                                                                                             N_parts)\n",
    "    partitioning_time = time.time() - partitioning_time_begin\n",
    "    print('The_parts_listhe number of parts are: ' + str(N_parts_Generated_by_Algo_2)+'.')\n",
    "    ############# Partitioner End ########\n",
    "\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Training Sub-Networks on Each Randomly Generated Part')\n",
    "    print('-----------------------------------------------------')\n",
    "    # Time-Elapse (Start) for Training on Each Part #\n",
    "    PCNN_timer = time.time(); PCNN_timer = -math.inf; N_params_Architope = 0; N_params_tally = 0\n",
    "    # Remove Eager Execution Error(s)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Automatically Initialize Correct Input/Output Dimension(s)\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]; param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    # Decide if/or not to tie neuron numbers of sub-patterns together\n",
    "    if Tied_Neurons_Q == True:\n",
    "        param_grid_Vanilla_Nets['height'] = [int(np.maximum(round(param_grid_Vanilla_Nets['height'][0]/N_parts),min_width))]\n",
    "        param_grid_Vanilla_Nets['epochs'] = [int(np.maximum(round(param_grid_Vanilla_Nets['epochs'][0]/int(round(np.sqrt(N_parts)))),min_epochs))]\n",
    "#         param_grid_Deep_Classifier['height'] = [int(np.maximum(round(param_grid_Deep_Classifier['height'][0]/N_parts),min_width))]\n",
    "\n",
    "    for current_part in range(N_parts_Generated_by_Algo_2):\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('-----------------------------------------------------------')\n",
    "        print('Currently Training Part: '+str(current_part)+'/'+str(N_parts_Generated_by_Algo_2 )+'Total Parts.')\n",
    "        print('-----------------------------------------------------------')\n",
    "\n",
    "        # Timer for Part\n",
    "        part_training_timer = time.time()\n",
    "        # Get Data for Sub-Pattern\n",
    "        X_loop = pd.DataFrame(X_parts_list[current_part])\n",
    "        y_loop = (y_parts_list[current_part]).reshape(-1,)\n",
    "        # Train ffNN\n",
    "        y_hat_part_loop, y_hat_part_loop_test, N_neurons_PCNN_loop = build_ffNN(n_folds = 4, \n",
    "                                                                              n_jobs = n_jobs,\n",
    "                                                                              n_iter = n_iter, \n",
    "                                                                              param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                              X_train= X_loop, \n",
    "                                                                              y_train=y_loop,\n",
    "                                                                              X_test_partial=X_train,\n",
    "                                                                              X_test=X_test,\n",
    "                                                                              NOCV=True)\n",
    "        # Reshape y\n",
    "        ## Training\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop.shape = (y_hat_part_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        ## Testing\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop_test.shape = (y_hat_part_loop_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_part_loop-y_train)).reshape(y_hat_part_loop.shape[0],1)\n",
    "\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_part_loop.reshape(y_hat_part_loop.shape[0],1)\n",
    "            predictions_test = y_hat_part_loop_test.reshape(y_hat_part_loop_test.shape[0],1)\n",
    "\n",
    "\n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "        # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_part_loop.reshape(predictions_train.shape[0],1)\n",
    "            predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "            y_hat_test_loop = y_hat_part_loop_test.reshape(predictions_test.shape[0],1)\n",
    "            predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "\n",
    "        #==============================#\n",
    "        # Update Performance Metric(s) #\n",
    "        #==============================#\n",
    "        part_training_timer = time.time() - part_training_timer\n",
    "        # L-Time\n",
    "        L_timer += partitioning_time\n",
    "        # P-Time\n",
    "        P_timer = max(P_timer,part_training_timer)\n",
    "        # N. Params\n",
    "        N_neurons += N_neurons_PCNN_loop\n",
    "        # Mean Width for Sub-Network(s)\n",
    "        Mean_Width_Subnetworks += param_grid_Vanilla_Nets['height'][0]\n",
    "\n",
    "    # Take Mean of Width(s)\n",
    "    Mean_Width_Subnetworks = Mean_Width_Subnetworks/N_parts_Generated_by_Algo_2\n",
    "    print('-----------------------')\n",
    "    print('Training Deep Zero-Sets')\n",
    "    print('-----------------------')\n",
    "\n",
    "\n",
    "    # Time Elapsed for Training Deep Zero-Sets\n",
    "    Deep_Zero_Sets_timer = time.time()\n",
    "\n",
    "    ## Initialize Classes Labels\n",
    "    if softmax_layer == False:\n",
    "        # No pooling (classical)\n",
    "        partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "    else:\n",
    "        # Max Pooling\n",
    "#         partition_labels_training_integers = (training_quality == training_quality.min(axis=1)[:,None]).astype(int)\n",
    "        partition_labels_training_integers = np.apply_along_axis(softminn, 1, training_quality).astype(int)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    ## Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    ## Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    ## Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train.values, \n",
    "                                                                                                        y_train = partition_labels_training.values,\n",
    "                                                                                                        X_test = X_test.values)\n",
    "    # Get Binary Classes (Discontinuous Unit)\n",
    "    ## Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>gamma)*1).astype(int)\n",
    "    ## Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > gamma)*1).astype(int)\n",
    "    # Get PC-NN Prediction(s)\n",
    "    ## Train\n",
    "    PCNN_prediction_y_train = (predictions_train*predicted_classes_train).sum(axis=1)\n",
    "    ## Test\n",
    "    PCNN_prediction_y_test = (predictions_test*predicted_classes_test).sum(axis=1)\n",
    "\n",
    "    # End Timer\n",
    "    Deep_Zero_Sets_timer = time.time() - Deep_Zero_Sets_timer\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print('Computing Final Performance Metrics')\n",
    "    print('-----------------------------------')\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "\n",
    "    # Update Times\n",
    "    L_timer +=Deep_Zero_Sets_timer\n",
    "    P_timer +=Deep_Zero_Sets_timer\n",
    "    # Update Number of Neurons Used\n",
    "    N_neurons_subPatterns = N_neurons\n",
    "    N_neurons_deep_Zero_Sets = (param_grid_Deep_Classifier['height'][0])*(param_grid_Deep_Classifier['depth'][0])\n",
    "    N_neurons = N_neurons_deep_Zero_Sets + N_neurons_subPatterns\n",
    "\n",
    "\n",
    "\n",
    "    # Compute Peformance\n",
    "    performance_PCNN = reporter(y_train_hat_in=PCNN_prediction_y_train,y_test_hat_in=PCNN_prediction_y_test,\n",
    "                                y_train_in=y_train,\n",
    "                                y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_PCNN.to_latex((results_tables_path+\"PCNN_full_performance.tex\"))\n",
    "\n",
    "    # Update User\n",
    "    print(performance_PCNN)\n",
    "\n",
    "    ### Model Complexity/Efficiency Metrics\n",
    "    # Build AIC-like Metric #\n",
    "    #-----------------------#\n",
    "    AIC_like = 2*(N_neurons - np.log((performance_PCNN['test']['MAE'])))\n",
    "    AIC_like = np.round(AIC_like,3)\n",
    "    Efficiency = np.log(N_neurons) *(performance_PCNN['test']['MAE'])\n",
    "    Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "    # Build Table #\n",
    "    #-------------#\n",
    "    PCNN_Model_Complexity = pd.DataFrame({'L-time': [L_timer],\n",
    "                                               'P-time':[P_timer],\n",
    "                                               'N_params_expt': [N_neurons],\n",
    "                                               'AIC-like': [AIC_like],\n",
    "                                               'Eff': [Efficiency],\n",
    "                                               'N. Parts':[N_parts_Generated_by_Algo_2]})\n",
    "\n",
    "\n",
    "    # Write Required Training Time(s)\n",
    "    PCNN_Model_Complexity.to_latex((results_tables_path+\"PCNN_full_model_complexities.tex\"))\n",
    "\n",
    "    #--------------======---------------#\n",
    "    # Display Required Training Time(s) #\n",
    "    #--------------======---------------#\n",
    "    print(PCNN_Model_Complexity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    print('# ---- Getting Benchmarks ---- #')\n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training_begin = time.time()\n",
    "    \n",
    "    if N_parts > 1:\n",
    "        parameters = {'penalty': ['none'], 'C': [0.1]}\n",
    "        lr = LogisticRegression(random_state=2020)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=CV_folds, \n",
    "                                     n_repeats=n_iter, random_state=0)\n",
    "        classifier = RandomizedSearchCV(lr, \n",
    "                                        parameters, \n",
    "                                        random_state=2020)\n",
    "\n",
    "        # Initialize Classes Labels\n",
    "        partition_labels_training = np.argmin(training_quality,axis=-1)\n",
    "\n",
    "        # Train logistic Classifier\n",
    "        print(\"Training classifier and generating partition!\")\n",
    "\n",
    "        # Train Logistic Classifier #\n",
    "        #---------------------------#\n",
    "        # Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Train Classifier\n",
    "        classifier.fit(X_train, partition_labels_training)\n",
    "    if N_parts >1 :\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "        Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "        # Testing Set\n",
    "        predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "        Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, \n",
    "                                                                     predicted_classes_test_logistic_BM[:,None], \n",
    "                                                                     axis=1)\n",
    "    else:\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        Architope_prediction_y_train_logistic_BM = predictions_train\n",
    "\n",
    "        # Testing Set\n",
    "        Architope_prediction_y_test_logistic_BM = predictions_test\n",
    "        \n",
    "    # Extract Number of Parameters Logistic Regressor\n",
    "    if N_parts > 1:\n",
    "        N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)\n",
    "    else:\n",
    "        N_params_best_logistic = 1\n",
    "    N_params_best_logistic = N_params_best_logistic + N_neurons_subPatterns*N_parts\n",
    "        \n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin\n",
    "\n",
    "    #### Compute Performance\n",
    "    # Compute Peformance\n",
    "    performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                        y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                        y_train_in=y_train,\n",
    "                                        y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "    \n",
    "    # Return Output(s)\n",
    "    return performance_PCNN, PCNN_Model_Complexity, N_parts_Generated_by_Algo_2, N_neurons, N_neurons_subPatterns,N_neurons_deep_Zero_Sets, Mean_Width_Subnetworks, performance_architope_ffNN_logistic, N_params_best_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform Ablation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.0\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 1.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/1Total Parts.\n",
      "-----------------------------------------------------------\n",
      "WARNING:tensorflow:From /Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 299 samples\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 0s 2ms/sample - loss: 0.5899 - mse: 0.3635 - mae: 0.5899 - mape: 108.5401\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 758us/sample - loss: 0.5555 - mse: 0.3244 - mae: 0.5555 - mape: 101.7945\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 568us/sample - loss: 0.5210 - mse: 0.2880 - mae: 0.5210 - mape: 95.0097\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 460us/sample - loss: 0.4866 - mse: 0.2534 - mae: 0.4866 - mape: 88.3480\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 429us/sample - loss: 0.4521 - mse: 0.2214 - mae: 0.4521 - mape: 81.5984\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 501us/sample - loss: 0.4174 - mse: 0.1918 - mae: 0.4174 - mape: 74.8161\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 510us/sample - loss: 0.3827 - mse: 0.1646 - mae: 0.3827 - mape: 67.9736\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 419us/sample - loss: 0.3478 - mse: 0.1397 - mae: 0.3478 - mape: 61.1155\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 413us/sample - loss: 0.3126 - mse: 0.1170 - mae: 0.3126 - mape: 54.2483\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 552us/sample - loss: 0.2773 - mse: 0.0970 - mae: 0.2773 - mape: 47.2749\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 487us/sample - loss: 0.2417 - mse: 0.0790 - mae: 0.2417 - mape: 40.3298\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 440us/sample - loss: 0.2086 - mse: 0.0637 - mae: 0.2086 - mape: 34.0298\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 346us/sample - loss: 0.1866 - mse: 0.0522 - mae: 0.1866 - mape: 30.4410\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 398us/sample - loss: 0.1721 - mse: 0.0439 - mae: 0.1721 - mape: 28.4347\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.1616 - mse: 0.0382 - mae: 0.1616 - mape: 27.1090\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 401us/sample - loss: 0.1533 - mse: 0.0338 - mae: 0.1533 - mape: 26.1602\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 491us/sample - loss: 0.1458 - mse: 0.0304 - mae: 0.1458 - mape: 25.3569\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 474us/sample - loss: 0.1396 - mse: 0.0278 - mae: 0.1396 - mape: 24.7223\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 536us/sample - loss: 0.1348 - mse: 0.0258 - mae: 0.1348 - mape: 24.2470\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 490us/sample - loss: 0.1315 - mse: 0.0245 - mae: 0.1315 - mape: 24.0559\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 439us/sample - loss: 0.1287 - mse: 0.0233 - mae: 0.1287 - mape: 23.9017\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 376us/sample - loss: 0.1265 - mse: 0.0225 - mae: 0.1265 - mape: 23.7904\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 416us/sample - loss: 0.1247 - mse: 0.0219 - mae: 0.1247 - mape: 23.6501\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 416us/sample - loss: 0.1233 - mse: 0.0215 - mae: 0.1233 - mape: 23.5580\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 419us/sample - loss: 0.1220 - mse: 0.0210 - mae: 0.1220 - mape: 23.4443\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 434us/sample - loss: 0.1208 - mse: 0.0206 - mae: 0.1208 - mape: 23.2812\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 429us/sample - loss: 0.1197 - mse: 0.0203 - mae: 0.1197 - mape: 23.1209\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 391us/sample - loss: 0.1186 - mse: 0.0199 - mae: 0.1186 - mape: 22.9552\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 471us/sample - loss: 0.1174 - mse: 0.0196 - mae: 0.1174 - mape: 22.7052\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 511us/sample - loss: 0.1162 - mse: 0.0193 - mae: 0.1162 - mape: 22.4295\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 385us/sample - loss: 0.1151 - mse: 0.0190 - mae: 0.1151 - mape: 22.1908\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 378us/sample - loss: 0.1139 - mse: 0.0186 - mae: 0.1139 - mape: 21.9635\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 374us/sample - loss: 0.1127 - mse: 0.0183 - mae: 0.1127 - mape: 21.7205\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 486us/sample - loss: 0.1115 - mse: 0.0180 - mae: 0.1115 - mape: 21.4594\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 471us/sample - loss: 0.1102 - mse: 0.0177 - mae: 0.1102 - mape: 21.2002\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 575us/sample - loss: 0.1090 - mse: 0.0174 - mae: 0.1090 - mape: 20.9814\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 553us/sample - loss: 0.1078 - mse: 0.0171 - mae: 0.1078 - mape: 20.7235\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 538us/sample - loss: 0.1066 - mse: 0.0168 - mae: 0.1066 - mape: 20.5381\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 566us/sample - loss: 0.1055 - mse: 0.0165 - mae: 0.1055 - mape: 20.3713\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 503us/sample - loss: 0.1042 - mse: 0.0163 - mae: 0.1042 - mape: 20.0946\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 525us/sample - loss: 0.1030 - mse: 0.0160 - mae: 0.1030 - mape: 19.8202\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 550us/sample - loss: 0.1017 - mse: 0.0158 - mae: 0.1017 - mape: 19.5477\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 465us/sample - loss: 0.1004 - mse: 0.0155 - mae: 0.1004 - mape: 19.3201\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 520us/sample - loss: 0.0993 - mse: 0.0152 - mae: 0.0993 - mape: 19.1911\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 575us/sample - loss: 0.0980 - mse: 0.0150 - mae: 0.0980 - mape: 18.9452\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 599us/sample - loss: 0.0967 - mse: 0.0148 - mae: 0.0967 - mape: 18.5805\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 566us/sample - loss: 0.0955 - mse: 0.0146 - mae: 0.0955 - mape: 18.3036\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 550us/sample - loss: 0.0941 - mse: 0.0143 - mae: 0.0941 - mape: 18.0936\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 527us/sample - loss: 0.0929 - mse: 0.0141 - mae: 0.0929 - mape: 17.9280\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 481us/sample - loss: 0.0917 - mse: 0.0138 - mae: 0.0917 - mape: 17.7286\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 500us/sample - loss: 0.0903 - mse: 0.0137 - mae: 0.0903 - mape: 17.4020\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 452us/sample - loss: 0.0890 - mse: 0.0135 - mae: 0.0890 - mape: 17.0711\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 499us/sample - loss: 0.0877 - mse: 0.0134 - mae: 0.0877 - mape: 16.7942\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 394us/sample - loss: 0.0864 - mse: 0.0132 - mae: 0.0864 - mape: 16.5522\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 447us/sample - loss: 0.0851 - mse: 0.0130 - mae: 0.0851 - mape: 16.3345\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 492us/sample - loss: 0.0837 - mse: 0.0128 - mae: 0.0837 - mape: 16.0615\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 417us/sample - loss: 0.0825 - mse: 0.0127 - mae: 0.0825 - mape: 15.8142\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 363us/sample - loss: 0.0811 - mse: 0.0125 - mae: 0.0811 - mape: 15.5433\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 462us/sample - loss: 0.0799 - mse: 0.0124 - mae: 0.0799 - mape: 15.2855\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 448us/sample - loss: 0.0787 - mse: 0.0123 - mae: 0.0787 - mape: 15.0924\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 392us/sample - loss: 0.0772 - mse: 0.0122 - mae: 0.0772 - mape: 14.7828\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 444us/sample - loss: 0.0760 - mse: 0.0122 - mae: 0.0760 - mape: 14.4333\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 484us/sample - loss: 0.0747 - mse: 0.0121 - mae: 0.0747 - mape: 14.1960\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.0734 - mse: 0.0119 - mae: 0.0734 - mape: 13.9853\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 400us/sample - loss: 0.0720 - mse: 0.0118 - mae: 0.0720 - mape: 13.7570\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 387us/sample - loss: 0.0707 - mse: 0.0117 - mae: 0.0707 - mape: 13.5085\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 464us/sample - loss: 0.0693 - mse: 0.0117 - mae: 0.0693 - mape: 13.2224\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 495us/sample - loss: 0.0680 - mse: 0.0116 - mae: 0.0680 - mape: 12.9700\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 528us/sample - loss: 0.0666 - mse: 0.0116 - mae: 0.0666 - mape: 12.6587\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 426us/sample - loss: 0.0652 - mse: 0.0116 - mae: 0.0652 - mape: 12.3770\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 485us/sample - loss: 0.0638 - mse: 0.0116 - mae: 0.0638 - mape: 12.1300\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 509us/sample - loss: 0.0625 - mse: 0.0116 - mae: 0.0625 - mape: 11.8878\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 431us/sample - loss: 0.0611 - mse: 0.0116 - mae: 0.0611 - mape: 11.6278\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 364us/sample - loss: 0.0598 - mse: 0.0116 - mae: 0.0598 - mape: 11.3067\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 463us/sample - loss: 0.0585 - mse: 0.0116 - mae: 0.0585 - mape: 11.0935\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 403us/sample - loss: 0.0571 - mse: 0.0116 - mae: 0.0571 - mape: 10.8633\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 463us/sample - loss: 0.0556 - mse: 0.0117 - mae: 0.0556 - mape: 10.5862\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 465us/sample - loss: 0.0542 - mse: 0.0117 - mae: 0.0542 - mape: 10.3576\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 393us/sample - loss: 0.0528 - mse: 0.0117 - mae: 0.0528 - mape: 10.1053\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 481us/sample - loss: 0.0514 - mse: 0.0118 - mae: 0.0514 - mape: 9.8345\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 425us/sample - loss: 0.0501 - mse: 0.0119 - mae: 0.0501 - mape: 9.5881\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.0489 - mse: 0.0119 - mae: 0.0489 - mape: 9.4213\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 435us/sample - loss: 0.0479 - mse: 0.0120 - mae: 0.0479 - mape: 9.3239\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 427us/sample - loss: 0.0475 - mse: 0.0120 - mae: 0.0475 - mape: 9.3243\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 527us/sample - loss: 0.0471 - mse: 0.0121 - mae: 0.0471 - mape: 9.2662\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 396us/sample - loss: 0.0468 - mse: 0.0122 - mae: 0.0468 - mape: 9.2558\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 388us/sample - loss: 0.0468 - mse: 0.0122 - mae: 0.0468 - mape: 9.3167\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 447us/sample - loss: 0.0466 - mse: 0.0123 - mae: 0.0466 - mape: 9.2773\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 462us/sample - loss: 0.0466 - mse: 0.0122 - mae: 0.0466 - mape: 9.3378\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 443us/sample - loss: 0.0465 - mse: 0.0123 - mae: 0.0465 - mape: 9.3126\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 424us/sample - loss: 0.0466 - mse: 0.0123 - mae: 0.0466 - mape: 9.3739\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 405us/sample - loss: 0.0465 - mse: 0.0124 - mae: 0.0465 - mape: 9.3405\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 374us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.3494\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 381us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.3617\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 370us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.3472\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 377us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.3964\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 403us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.3834\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 376us/sample - loss: 0.0462 - mse: 0.0124 - mae: 0.0462 - mape: 9.4004\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 379us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.4367\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 347us/sample - loss: 0.0461 - mse: 0.0125 - mae: 0.0461 - mape: 9.3935\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 791us/sample - loss: 0.4716 - accuracy: 1.0000\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "          train       test\n",
      "MAE    0.114492   0.121137\n",
      "MSE    0.056836   0.061505\n",
      "MAPE  16.276739  17.498144\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.123646  16.80413           2400  4804.222  0.943         1\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.1\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 3.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 112 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.4603 - mse: 0.2293 - mae: 0.4603 - mape: 90.5468\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.4584 - mse: 0.2276 - mae: 0.4584 - mape: 90.1472\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.4565 - mse: 0.2259 - mae: 0.4565 - mape: 89.7470\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.4546 - mse: 0.2241 - mae: 0.4546 - mape: 89.3498\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.4527 - mse: 0.2224 - mae: 0.4527 - mape: 88.9497\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.4508 - mse: 0.2207 - mae: 0.4508 - mape: 88.5530\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 0.4489 - mse: 0.2190 - mae: 0.4489 - mape: 88.1536\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.4470 - mse: 0.2173 - mae: 0.4470 - mape: 87.7485\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.4451 - mse: 0.2156 - mae: 0.4451 - mape: 87.3507\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.4431 - mse: 0.2139 - mae: 0.4431 - mape: 86.9480\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.4412 - mse: 0.2122 - mae: 0.4412 - mape: 86.5493\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.4393 - mse: 0.2105 - mae: 0.4393 - mape: 86.1485\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.4374 - mse: 0.2089 - mae: 0.4374 - mape: 85.7470\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.4355 - mse: 0.2072 - mae: 0.4355 - mape: 85.3430\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.4335 - mse: 0.2055 - mae: 0.4335 - mape: 84.9411\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.4316 - mse: 0.2039 - mae: 0.4316 - mape: 84.5387\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.4297 - mse: 0.2022 - mae: 0.4297 - mape: 84.1360\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.4278 - mse: 0.2006 - mae: 0.4278 - mape: 83.7313\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.4258 - mse: 0.1989 - mae: 0.4258 - mape: 83.3237\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.4239 - mse: 0.1973 - mae: 0.4239 - mape: 82.9219\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.4220 - mse: 0.1956 - mae: 0.4220 - mape: 82.5177\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.4200 - mse: 0.1940 - mae: 0.4200 - mape: 82.1086\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 207us/sample - loss: 0.4181 - mse: 0.1924 - mae: 0.4181 - mape: 81.6982\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.4161 - mse: 0.1908 - mae: 0.4161 - mape: 81.2936\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.4142 - mse: 0.1892 - mae: 0.4142 - mape: 80.8821\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.4122 - mse: 0.1876 - mae: 0.4122 - mape: 80.4752\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.4102 - mse: 0.1860 - mae: 0.4102 - mape: 80.0651\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.4083 - mse: 0.1844 - mae: 0.4083 - mape: 79.6528\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.4063 - mse: 0.1828 - mae: 0.4063 - mape: 79.2416\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.4043 - mse: 0.1812 - mae: 0.4043 - mape: 78.8277\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.4024 - mse: 0.1796 - mae: 0.4024 - mape: 78.4086\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.4004 - mse: 0.1780 - mae: 0.4004 - mape: 77.9994\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.3984 - mse: 0.1765 - mae: 0.3984 - mape: 77.5805\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.3964 - mse: 0.1749 - mae: 0.3964 - mape: 77.1700\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.3944 - mse: 0.1733 - mae: 0.3944 - mape: 76.7475\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.3924 - mse: 0.1717 - mae: 0.3924 - mape: 76.3321\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 0.3904 - mse: 0.1702 - mae: 0.3904 - mape: 75.9114\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.3884 - mse: 0.1686 - mae: 0.3884 - mape: 75.4872\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.3864 - mse: 0.1671 - mae: 0.3864 - mape: 75.0685\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.3844 - mse: 0.1655 - mae: 0.3844 - mape: 74.6438\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.3824 - mse: 0.1640 - mae: 0.3824 - mape: 74.2208\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.3803 - mse: 0.1625 - mae: 0.3803 - mape: 73.7961\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.3783 - mse: 0.1609 - mae: 0.3783 - mape: 73.3783\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 0.3763 - mse: 0.1594 - mae: 0.3763 - mape: 72.9468\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.3742 - mse: 0.1579 - mae: 0.3742 - mape: 72.5127\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.3722 - mse: 0.1563 - mae: 0.3722 - mape: 72.0862\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.3701 - mse: 0.1548 - mae: 0.3701 - mape: 71.6546\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.3680 - mse: 0.1533 - mae: 0.3680 - mape: 71.2267\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.3660 - mse: 0.1518 - mae: 0.3660 - mape: 70.7943\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.3639 - mse: 0.1503 - mae: 0.3639 - mape: 70.3560\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 0.3618 - mse: 0.1488 - mae: 0.3618 - mape: 69.9168\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 587us/sample - loss: 0.3597 - mse: 0.1473 - mae: 0.3597 - mape: 69.4829\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.3576 - mse: 0.1458 - mae: 0.3576 - mape: 69.0421\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 361us/sample - loss: 0.3555 - mse: 0.1443 - mae: 0.3555 - mape: 68.6071\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 516us/sample - loss: 0.3534 - mse: 0.1428 - mae: 0.3534 - mape: 68.1595\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.3513 - mse: 0.1414 - mae: 0.3513 - mape: 67.7163\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.3492 - mse: 0.1399 - mae: 0.3492 - mape: 67.2742\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.3470 - mse: 0.1384 - mae: 0.3470 - mape: 66.8334\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.3449 - mse: 0.1369 - mae: 0.3449 - mape: 66.3789\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.3428 - mse: 0.1354 - mae: 0.3428 - mape: 65.9347\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.3406 - mse: 0.1340 - mae: 0.3406 - mape: 65.4820\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.3385 - mse: 0.1325 - mae: 0.3385 - mape: 65.0298\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 183us/sample - loss: 0.3363 - mse: 0.1311 - mae: 0.3363 - mape: 64.5760\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.3341 - mse: 0.1296 - mae: 0.3341 - mape: 64.1192\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.3319 - mse: 0.1282 - mae: 0.3319 - mape: 63.6644\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.3297 - mse: 0.1267 - mae: 0.3297 - mape: 63.2061\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.3275 - mse: 0.1253 - mae: 0.3275 - mape: 62.7434\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.3253 - mse: 0.1239 - mae: 0.3253 - mape: 62.2850\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.3231 - mse: 0.1224 - mae: 0.3231 - mape: 61.8211\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 0.3209 - mse: 0.1211 - mae: 0.3209 - mape: 61.3442\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.3187 - mse: 0.1196 - mae: 0.3187 - mape: 60.8781\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.3164 - mse: 0.1182 - mae: 0.3164 - mape: 60.4150\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3142 - mse: 0.1168 - mae: 0.3142 - mape: 59.9453\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 0.3119 - mse: 0.1153 - mae: 0.3119 - mape: 59.4738\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.3096 - mse: 0.1140 - mae: 0.3096 - mape: 58.9949\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.3073 - mse: 0.1126 - mae: 0.3073 - mape: 58.5126\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.3051 - mse: 0.1112 - mae: 0.3051 - mape: 58.0378\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.3028 - mse: 0.1098 - mae: 0.3028 - mape: 57.5628\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.3005 - mse: 0.1084 - mae: 0.3005 - mape: 57.0700\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.2981 - mse: 0.1071 - mae: 0.2981 - mape: 56.5862\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.2958 - mse: 0.1057 - mae: 0.2958 - mape: 56.1031\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.2935 - mse: 0.1043 - mae: 0.2935 - mape: 55.6159\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.2911 - mse: 0.1030 - mae: 0.2911 - mape: 55.1182\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.2888 - mse: 0.1016 - mae: 0.2888 - mape: 54.6300\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.2864 - mse: 0.1003 - mae: 0.2864 - mape: 54.1320\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.2840 - mse: 0.0989 - mae: 0.2840 - mape: 53.6374\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.2817 - mse: 0.0976 - mae: 0.2817 - mape: 53.1345\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.2793 - mse: 0.0962 - mae: 0.2793 - mape: 52.6356\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.2769 - mse: 0.0949 - mae: 0.2769 - mape: 52.1325\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 0.2744 - mse: 0.0936 - mae: 0.2744 - mape: 51.6240\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.2720 - mse: 0.0923 - mae: 0.2720 - mape: 51.1182\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.2696 - mse: 0.0910 - mae: 0.2696 - mape: 50.6051\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.2671 - mse: 0.0897 - mae: 0.2671 - mape: 50.0937\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.2647 - mse: 0.0884 - mae: 0.2647 - mape: 49.5812\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.2622 - mse: 0.0871 - mae: 0.2622 - mape: 49.0644\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.2597 - mse: 0.0858 - mae: 0.2597 - mape: 48.5388\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.2572 - mse: 0.0845 - mae: 0.2572 - mape: 48.0152\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.2547 - mse: 0.0833 - mae: 0.2547 - mape: 47.4931\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.2522 - mse: 0.0820 - mae: 0.2522 - mape: 46.9699\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.2497 - mse: 0.0807 - mae: 0.2497 - mape: 46.4411\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 89 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 0s 3ms/sample - loss: 0.5875 - mse: 0.3881 - mae: 0.5875 - mape: 105.9410\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 148us/sample - loss: 0.5862 - mse: 0.3866 - mae: 0.5862 - mape: 105.6566\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 144us/sample - loss: 0.5849 - mse: 0.3851 - mae: 0.5849 - mape: 105.3819\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 156us/sample - loss: 0.5836 - mse: 0.3836 - mae: 0.5836 - mape: 105.1001\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 146us/sample - loss: 0.5823 - mse: 0.3821 - mae: 0.5823 - mape: 104.8191\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 153us/sample - loss: 0.5810 - mse: 0.3806 - mae: 0.5810 - mape: 104.5417\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 217us/sample - loss: 0.5797 - mse: 0.3791 - mae: 0.5797 - mape: 104.2556\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 198us/sample - loss: 0.5784 - mse: 0.3776 - mae: 0.5784 - mape: 103.9799\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 211us/sample - loss: 0.5771 - mse: 0.3761 - mae: 0.5771 - mape: 103.7052\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 176us/sample - loss: 0.5758 - mse: 0.3746 - mae: 0.5758 - mape: 103.4285\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 162us/sample - loss: 0.5746 - mse: 0.3731 - mae: 0.5746 - mape: 103.1444\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 155us/sample - loss: 0.5733 - mse: 0.3717 - mae: 0.5733 - mape: 102.8593\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 167us/sample - loss: 0.5720 - mse: 0.3701 - mae: 0.5720 - mape: 102.5925\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 156us/sample - loss: 0.5707 - mse: 0.3687 - mae: 0.5707 - mape: 102.3099\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 161us/sample - loss: 0.5694 - mse: 0.3672 - mae: 0.5694 - mape: 102.0341\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 181us/sample - loss: 0.5681 - mse: 0.3657 - mae: 0.5681 - mape: 101.7523\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 249us/sample - loss: 0.5668 - mse: 0.3642 - mae: 0.5668 - mape: 101.4750\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 182us/sample - loss: 0.5655 - mse: 0.3628 - mae: 0.5655 - mape: 101.1982\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 233us/sample - loss: 0.5642 - mse: 0.3613 - mae: 0.5642 - mape: 100.9193\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 195us/sample - loss: 0.5629 - mse: 0.3598 - mae: 0.5629 - mape: 100.6400\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 174us/sample - loss: 0.5616 - mse: 0.3584 - mae: 0.5616 - mape: 100.3570\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 172us/sample - loss: 0.5604 - mse: 0.3569 - mae: 0.5604 - mape: 100.0830\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 182us/sample - loss: 0.5591 - mse: 0.3555 - mae: 0.5591 - mape: 99.8002\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 213us/sample - loss: 0.5578 - mse: 0.3540 - mae: 0.5578 - mape: 99.5212\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 236us/sample - loss: 0.5565 - mse: 0.3526 - mae: 0.5565 - mape: 99.2407\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 185us/sample - loss: 0.5552 - mse: 0.3511 - mae: 0.5552 - mape: 98.9614\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 191us/sample - loss: 0.5539 - mse: 0.3497 - mae: 0.5539 - mape: 98.6851\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 178us/sample - loss: 0.5526 - mse: 0.3482 - mae: 0.5526 - mape: 98.4074\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 191us/sample - loss: 0.5513 - mse: 0.3468 - mae: 0.5513 - mape: 98.1176\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 172us/sample - loss: 0.5500 - mse: 0.3454 - mae: 0.5500 - mape: 97.8378\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 213us/sample - loss: 0.5487 - mse: 0.3440 - mae: 0.5487 - mape: 97.5567\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 225us/sample - loss: 0.5474 - mse: 0.3425 - mae: 0.5474 - mape: 97.2775\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 214us/sample - loss: 0.5461 - mse: 0.3411 - mae: 0.5461 - mape: 96.9960\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 182us/sample - loss: 0.5448 - mse: 0.3397 - mae: 0.5448 - mape: 96.7165\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 174us/sample - loss: 0.5435 - mse: 0.3382 - mae: 0.5435 - mape: 96.4355\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 164us/sample - loss: 0.5422 - mse: 0.3368 - mae: 0.5422 - mape: 96.1485\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 160us/sample - loss: 0.5408 - mse: 0.3354 - mae: 0.5408 - mape: 95.8692\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 165us/sample - loss: 0.5395 - mse: 0.3340 - mae: 0.5395 - mape: 95.5824\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 160us/sample - loss: 0.5382 - mse: 0.3326 - mae: 0.5382 - mape: 95.3072\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5369 - mse: 0.3312 - mae: 0.5369 - mape: 95.0165\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 204us/sample - loss: 0.5356 - mse: 0.3297 - mae: 0.5356 - mape: 94.7344\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 163us/sample - loss: 0.5343 - mse: 0.3283 - mae: 0.5343 - mape: 94.4508\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5330 - mse: 0.3269 - mae: 0.5330 - mape: 94.1610\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 170us/sample - loss: 0.5316 - mse: 0.3255 - mae: 0.5316 - mape: 93.8847\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 164us/sample - loss: 0.5303 - mse: 0.3241 - mae: 0.5303 - mape: 93.6027\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 196us/sample - loss: 0.5290 - mse: 0.3227 - mae: 0.5290 - mape: 93.3117\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 227us/sample - loss: 0.5277 - mse: 0.3213 - mae: 0.5277 - mape: 93.0210\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 188us/sample - loss: 0.5264 - mse: 0.3199 - mae: 0.5264 - mape: 92.7379\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 194us/sample - loss: 0.5250 - mse: 0.3185 - mae: 0.5250 - mape: 92.4530\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 158us/sample - loss: 0.5237 - mse: 0.3171 - mae: 0.5237 - mape: 92.1646\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 238us/sample - loss: 0.5224 - mse: 0.3157 - mae: 0.5224 - mape: 91.8736\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 281us/sample - loss: 0.5210 - mse: 0.3143 - mae: 0.5210 - mape: 91.5905\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 171us/sample - loss: 0.5197 - mse: 0.3129 - mae: 0.5197 - mape: 91.3056\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 202us/sample - loss: 0.5184 - mse: 0.3115 - mae: 0.5184 - mape: 91.0129\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 212us/sample - loss: 0.5170 - mse: 0.3101 - mae: 0.5170 - mape: 90.7255\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 195us/sample - loss: 0.5157 - mse: 0.3087 - mae: 0.5157 - mape: 90.4349\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 230us/sample - loss: 0.5143 - mse: 0.3074 - mae: 0.5143 - mape: 90.1391\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 243us/sample - loss: 0.5130 - mse: 0.3060 - mae: 0.5130 - mape: 89.8485\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 175us/sample - loss: 0.5116 - mse: 0.3046 - mae: 0.5116 - mape: 89.5672\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 228us/sample - loss: 0.5103 - mse: 0.3032 - mae: 0.5103 - mape: 89.2665\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 191us/sample - loss: 0.5089 - mse: 0.3018 - mae: 0.5089 - mape: 88.9749\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 185us/sample - loss: 0.5076 - mse: 0.3004 - mae: 0.5076 - mape: 88.6822\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 165us/sample - loss: 0.5062 - mse: 0.2991 - mae: 0.5062 - mape: 88.3885\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 157us/sample - loss: 0.5049 - mse: 0.2977 - mae: 0.5049 - mape: 88.0939\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 162us/sample - loss: 0.5035 - mse: 0.2963 - mae: 0.5035 - mape: 87.8072\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 164us/sample - loss: 0.5021 - mse: 0.2949 - mae: 0.5021 - mape: 87.5205\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 169us/sample - loss: 0.5008 - mse: 0.2935 - mae: 0.5008 - mape: 87.2127\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 166us/sample - loss: 0.4994 - mse: 0.2922 - mae: 0.4994 - mape: 86.9200\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 269us/sample - loss: 0.4980 - mse: 0.2908 - mae: 0.4980 - mape: 86.6217\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 188us/sample - loss: 0.4966 - mse: 0.2894 - mae: 0.4966 - mape: 86.3259\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 176us/sample - loss: 0.4953 - mse: 0.2880 - mae: 0.4953 - mape: 86.0299\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 167us/sample - loss: 0.4939 - mse: 0.2867 - mae: 0.4939 - mape: 85.7300\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 162us/sample - loss: 0.4925 - mse: 0.2853 - mae: 0.4925 - mape: 85.4343\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 162us/sample - loss: 0.4911 - mse: 0.2839 - mae: 0.4911 - mape: 85.1289\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 235us/sample - loss: 0.4897 - mse: 0.2826 - mae: 0.4897 - mape: 84.8299\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 212us/sample - loss: 0.4883 - mse: 0.2812 - mae: 0.4883 - mape: 84.5222\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 212us/sample - loss: 0.4869 - mse: 0.2798 - mae: 0.4869 - mape: 84.2264\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 209us/sample - loss: 0.4855 - mse: 0.2784 - mae: 0.4855 - mape: 83.9307\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 196us/sample - loss: 0.4841 - mse: 0.2771 - mae: 0.4841 - mape: 83.6227\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 263us/sample - loss: 0.4827 - mse: 0.2757 - mae: 0.4827 - mape: 83.3198\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 229us/sample - loss: 0.4813 - mse: 0.2744 - mae: 0.4813 - mape: 83.0150\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 265us/sample - loss: 0.4799 - mse: 0.2730 - mae: 0.4799 - mape: 82.7098\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 217us/sample - loss: 0.4785 - mse: 0.2717 - mae: 0.4785 - mape: 82.3967\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 207us/sample - loss: 0.4771 - mse: 0.2703 - mae: 0.4771 - mape: 82.1015\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 341us/sample - loss: 0.4756 - mse: 0.2689 - mae: 0.4756 - mape: 81.7944\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 368us/sample - loss: 0.4742 - mse: 0.2676 - mae: 0.4742 - mape: 81.4880\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 217us/sample - loss: 0.4728 - mse: 0.2662 - mae: 0.4728 - mape: 81.1804\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 197us/sample - loss: 0.4714 - mse: 0.2649 - mae: 0.4714 - mape: 80.8699\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.4699 - mse: 0.2635 - mae: 0.4699 - mape: 80.5591\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 188us/sample - loss: 0.4685 - mse: 0.2622 - mae: 0.4685 - mape: 80.2411\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 167us/sample - loss: 0.4670 - mse: 0.2608 - mae: 0.4670 - mape: 79.9378\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 166us/sample - loss: 0.4656 - mse: 0.2594 - mae: 0.4656 - mape: 79.6286\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 210us/sample - loss: 0.4642 - mse: 0.2581 - mae: 0.4642 - mape: 79.3137\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 226us/sample - loss: 0.4627 - mse: 0.2567 - mae: 0.4627 - mape: 79.0033\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 194us/sample - loss: 0.4612 - mse: 0.2554 - mae: 0.4612 - mape: 78.6875\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 0s 176us/sample - loss: 0.4598 - mse: 0.2541 - mae: 0.4598 - mape: 78.3669\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 174us/sample - loss: 0.4583 - mse: 0.2527 - mae: 0.4583 - mape: 78.0573\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 194us/sample - loss: 0.4569 - mse: 0.2514 - mae: 0.4569 - mape: 77.7369\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 211us/sample - loss: 0.4554 - mse: 0.2500 - mae: 0.4554 - mape: 77.4210\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 216us/sample - loss: 0.4539 - mse: 0.2487 - mae: 0.4539 - mape: 77.1058\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 131 samples\n",
      "Epoch 1/100\n",
      "131/131 [==============================] - 0s 3ms/sample - loss: 0.5381 - mse: 0.2978 - mae: 0.5381 - mape: 97.6870\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 223us/sample - loss: 0.5354 - mse: 0.2950 - mae: 0.5354 - mape: 97.1796\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 186us/sample - loss: 0.5328 - mse: 0.2922 - mae: 0.5328 - mape: 96.6736\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 193us/sample - loss: 0.5301 - mse: 0.2894 - mae: 0.5301 - mape: 96.1702\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 182us/sample - loss: 0.5274 - mse: 0.2866 - mae: 0.5274 - mape: 95.6556\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 176us/sample - loss: 0.5247 - mse: 0.2838 - mae: 0.5247 - mape: 95.1530\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 164us/sample - loss: 0.5221 - mse: 0.2810 - mae: 0.5221 - mape: 94.6488\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 190us/sample - loss: 0.5194 - mse: 0.2783 - mae: 0.5194 - mape: 94.1385\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 231us/sample - loss: 0.5167 - mse: 0.2756 - mae: 0.5167 - mape: 93.6258\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 224us/sample - loss: 0.5140 - mse: 0.2728 - mae: 0.5140 - mape: 93.1231\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 190us/sample - loss: 0.5114 - mse: 0.2701 - mae: 0.5114 - mape: 92.6142\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 171us/sample - loss: 0.5087 - mse: 0.2674 - mae: 0.5087 - mape: 92.1075\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 195us/sample - loss: 0.5060 - mse: 0.2647 - mae: 0.5060 - mape: 91.5991\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 201us/sample - loss: 0.5033 - mse: 0.2621 - mae: 0.5033 - mape: 91.0821\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 239us/sample - loss: 0.5006 - mse: 0.2594 - mae: 0.5006 - mape: 90.5792\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 195us/sample - loss: 0.4979 - mse: 0.2567 - mae: 0.4979 - mape: 90.0661\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 207us/sample - loss: 0.4952 - mse: 0.2541 - mae: 0.4952 - mape: 89.5520\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 252us/sample - loss: 0.4925 - mse: 0.2514 - mae: 0.4925 - mape: 89.0335\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 0s 264us/sample - loss: 0.4898 - mse: 0.2488 - mae: 0.4898 - mape: 88.5227\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 0s 239us/sample - loss: 0.4871 - mse: 0.2462 - mae: 0.4871 - mape: 87.9994\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 0s 210us/sample - loss: 0.4843 - mse: 0.2435 - mae: 0.4843 - mape: 87.4796\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 164us/sample - loss: 0.4816 - mse: 0.2409 - mae: 0.4816 - mape: 86.9582\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 194us/sample - loss: 0.4788 - mse: 0.2383 - mae: 0.4788 - mape: 86.4428\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 172us/sample - loss: 0.4761 - mse: 0.2357 - mae: 0.4761 - mape: 85.9203\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 169us/sample - loss: 0.4733 - mse: 0.2332 - mae: 0.4733 - mape: 85.3944\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 154us/sample - loss: 0.4706 - mse: 0.2306 - mae: 0.4706 - mape: 84.8750\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 0s 150us/sample - loss: 0.4678 - mse: 0.2281 - mae: 0.4678 - mape: 84.3522\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 0s 154us/sample - loss: 0.4651 - mse: 0.2255 - mae: 0.4651 - mape: 83.8315\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 0s 175us/sample - loss: 0.4623 - mse: 0.2230 - mae: 0.4623 - mape: 83.3033\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 0s 181us/sample - loss: 0.4595 - mse: 0.2205 - mae: 0.4595 - mape: 82.7758\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 0s 180us/sample - loss: 0.4567 - mse: 0.2179 - mae: 0.4567 - mape: 82.2468\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 0s 161us/sample - loss: 0.4539 - mse: 0.2154 - mae: 0.4539 - mape: 81.7210\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 0s 152us/sample - loss: 0.4511 - mse: 0.2129 - mae: 0.4511 - mape: 81.1822\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 0s 150us/sample - loss: 0.4483 - mse: 0.2104 - mae: 0.4483 - mape: 80.6543\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 0s 151us/sample - loss: 0.4455 - mse: 0.2079 - mae: 0.4455 - mape: 80.1138\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 0s 155us/sample - loss: 0.4427 - mse: 0.2055 - mae: 0.4427 - mape: 79.5758\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 0s 200us/sample - loss: 0.4398 - mse: 0.2030 - mae: 0.4398 - mape: 79.0345\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 0s 160us/sample - loss: 0.4370 - mse: 0.2006 - mae: 0.4370 - mape: 78.4918\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 0s 170us/sample - loss: 0.4341 - mse: 0.1981 - mae: 0.4341 - mape: 77.9500\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 0s 158us/sample - loss: 0.4312 - mse: 0.1956 - mae: 0.4312 - mape: 77.4072\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 0s 173us/sample - loss: 0.4283 - mse: 0.1932 - mae: 0.4283 - mape: 76.8613\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 0s 174us/sample - loss: 0.4254 - mse: 0.1908 - mae: 0.4254 - mape: 76.3078\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 0s 233us/sample - loss: 0.4225 - mse: 0.1884 - mae: 0.4225 - mape: 75.7596\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 0s 191us/sample - loss: 0.4196 - mse: 0.1859 - mae: 0.4196 - mape: 75.2045\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 0s 200us/sample - loss: 0.4167 - mse: 0.1835 - mae: 0.4167 - mape: 74.6461\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 0s 167us/sample - loss: 0.4137 - mse: 0.1811 - mae: 0.4137 - mape: 74.0878\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 0s 162us/sample - loss: 0.4108 - mse: 0.1787 - mae: 0.4108 - mape: 73.5249\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s 156us/sample - loss: 0.4078 - mse: 0.1763 - mae: 0.4078 - mape: 72.9560\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 0s 223us/sample - loss: 0.4048 - mse: 0.1739 - mae: 0.4048 - mape: 72.3888\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 0s 185us/sample - loss: 0.4018 - mse: 0.1715 - mae: 0.4018 - mape: 71.8206\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 0s 180us/sample - loss: 0.3988 - mse: 0.1692 - mae: 0.3988 - mape: 71.2516\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 0s 167us/sample - loss: 0.3958 - mse: 0.1668 - mae: 0.3958 - mape: 70.6735\n",
      "Epoch 53/100\n",
      "131/131 [==============================] - 0s 195us/sample - loss: 0.3927 - mse: 0.1645 - mae: 0.3927 - mape: 70.0963\n",
      "Epoch 54/100\n",
      "131/131 [==============================] - 0s 295us/sample - loss: 0.3896 - mse: 0.1621 - mae: 0.3896 - mape: 69.5089\n",
      "Epoch 55/100\n",
      "131/131 [==============================] - 0s 190us/sample - loss: 0.3865 - mse: 0.1598 - mae: 0.3865 - mape: 68.9183\n",
      "Epoch 56/100\n",
      "131/131 [==============================] - 0s 190us/sample - loss: 0.3834 - mse: 0.1574 - mae: 0.3834 - mape: 68.3326\n",
      "Epoch 57/100\n",
      "131/131 [==============================] - 0s 168us/sample - loss: 0.3803 - mse: 0.1551 - mae: 0.3803 - mape: 67.7387\n",
      "Epoch 58/100\n",
      "131/131 [==============================] - 0s 188us/sample - loss: 0.3772 - mse: 0.1528 - mae: 0.3772 - mape: 67.1398\n",
      "Epoch 59/100\n",
      "131/131 [==============================] - 0s 198us/sample - loss: 0.3741 - mse: 0.1505 - mae: 0.3741 - mape: 66.5468\n",
      "Epoch 60/100\n",
      "131/131 [==============================] - 0s 184us/sample - loss: 0.3709 - mse: 0.1482 - mae: 0.3709 - mape: 65.9507\n",
      "Epoch 61/100\n",
      "131/131 [==============================] - 0s 181us/sample - loss: 0.3678 - mse: 0.1459 - mae: 0.3678 - mape: 65.3494\n",
      "Epoch 62/100\n",
      "131/131 [==============================] - 0s 165us/sample - loss: 0.3646 - mse: 0.1436 - mae: 0.3646 - mape: 64.7493\n",
      "Epoch 63/100\n",
      "131/131 [==============================] - 0s 222us/sample - loss: 0.3614 - mse: 0.1414 - mae: 0.3614 - mape: 64.1448\n",
      "Epoch 64/100\n",
      "131/131 [==============================] - 0s 209us/sample - loss: 0.3582 - mse: 0.1391 - mae: 0.3582 - mape: 63.5386\n",
      "Epoch 65/100\n",
      "131/131 [==============================] - 0s 199us/sample - loss: 0.3550 - mse: 0.1369 - mae: 0.3550 - mape: 62.9271\n",
      "Epoch 66/100\n",
      "131/131 [==============================] - 0s 177us/sample - loss: 0.3518 - mse: 0.1346 - mae: 0.3518 - mape: 62.3243\n",
      "Epoch 67/100\n",
      "131/131 [==============================] - 0s 182us/sample - loss: 0.3485 - mse: 0.1324 - mae: 0.3485 - mape: 61.6949\n",
      "Epoch 68/100\n",
      "131/131 [==============================] - 0s 296us/sample - loss: 0.3453 - mse: 0.1302 - mae: 0.3453 - mape: 61.0789\n",
      "Epoch 69/100\n",
      "131/131 [==============================] - 0s 177us/sample - loss: 0.3420 - mse: 0.1280 - mae: 0.3420 - mape: 60.4622\n",
      "Epoch 70/100\n",
      "131/131 [==============================] - 0s 185us/sample - loss: 0.3387 - mse: 0.1258 - mae: 0.3387 - mape: 59.8389\n",
      "Epoch 71/100\n",
      "131/131 [==============================] - 0s 167us/sample - loss: 0.3354 - mse: 0.1237 - mae: 0.3354 - mape: 59.2032\n",
      "Epoch 72/100\n",
      "131/131 [==============================] - 0s 223us/sample - loss: 0.3321 - mse: 0.1215 - mae: 0.3321 - mape: 58.5783\n",
      "Epoch 73/100\n",
      "131/131 [==============================] - 0s 206us/sample - loss: 0.3287 - mse: 0.1193 - mae: 0.3287 - mape: 57.9426\n",
      "Epoch 74/100\n",
      "131/131 [==============================] - 0s 215us/sample - loss: 0.3254 - mse: 0.1172 - mae: 0.3254 - mape: 57.3043\n",
      "Epoch 75/100\n",
      "131/131 [==============================] - 0s 170us/sample - loss: 0.3220 - mse: 0.1150 - mae: 0.3220 - mape: 56.6637\n",
      "Epoch 76/100\n",
      "131/131 [==============================] - 0s 196us/sample - loss: 0.3186 - mse: 0.1129 - mae: 0.3186 - mape: 56.0098\n",
      "Epoch 77/100\n",
      "131/131 [==============================] - 0s 175us/sample - loss: 0.3152 - mse: 0.1108 - mae: 0.3152 - mape: 55.3652\n",
      "Epoch 78/100\n",
      "131/131 [==============================] - 0s 216us/sample - loss: 0.3117 - mse: 0.1087 - mae: 0.3117 - mape: 54.7151\n",
      "Epoch 79/100\n",
      "131/131 [==============================] - 0s 173us/sample - loss: 0.3083 - mse: 0.1066 - mae: 0.3083 - mape: 54.0623\n",
      "Epoch 80/100\n",
      "131/131 [==============================] - 0s 172us/sample - loss: 0.3048 - mse: 0.1045 - mae: 0.3048 - mape: 53.4060\n",
      "Epoch 81/100\n",
      "131/131 [==============================] - 0s 150us/sample - loss: 0.3013 - mse: 0.1025 - mae: 0.3013 - mape: 52.7387\n",
      "Epoch 82/100\n",
      "131/131 [==============================] - 0s 153us/sample - loss: 0.2978 - mse: 0.1005 - mae: 0.2978 - mape: 52.0709\n",
      "Epoch 83/100\n",
      "131/131 [==============================] - 0s 202us/sample - loss: 0.2943 - mse: 0.0984 - mae: 0.2943 - mape: 51.4012\n",
      "Epoch 84/100\n",
      "131/131 [==============================] - 0s 211us/sample - loss: 0.2907 - mse: 0.0964 - mae: 0.2907 - mape: 50.7233\n",
      "Epoch 85/100\n",
      "131/131 [==============================] - 0s 160us/sample - loss: 0.2872 - mse: 0.0944 - mae: 0.2872 - mape: 50.0411\n",
      "Epoch 86/100\n",
      "131/131 [==============================] - 0s 159us/sample - loss: 0.2836 - mse: 0.0924 - mae: 0.2836 - mape: 49.3631\n",
      "Epoch 87/100\n",
      "131/131 [==============================] - 0s 249us/sample - loss: 0.2799 - mse: 0.0904 - mae: 0.2799 - mape: 48.6704\n",
      "Epoch 88/100\n",
      "131/131 [==============================] - 0s 168us/sample - loss: 0.2763 - mse: 0.0885 - mae: 0.2763 - mape: 47.9815\n",
      "Epoch 89/100\n",
      "131/131 [==============================] - 0s 182us/sample - loss: 0.2727 - mse: 0.0866 - mae: 0.2727 - mape: 47.2847\n",
      "Epoch 90/100\n",
      "131/131 [==============================] - 0s 172us/sample - loss: 0.2690 - mse: 0.0846 - mae: 0.2690 - mape: 46.5940\n",
      "Epoch 91/100\n",
      "131/131 [==============================] - 0s 158us/sample - loss: 0.2653 - mse: 0.0827 - mae: 0.2653 - mape: 45.8949\n",
      "Epoch 92/100\n",
      "131/131 [==============================] - 0s 215us/sample - loss: 0.2616 - mse: 0.0808 - mae: 0.2616 - mape: 45.1887\n",
      "Epoch 93/100\n",
      "131/131 [==============================] - 0s 197us/sample - loss: 0.2579 - mse: 0.0789 - mae: 0.2579 - mape: 44.4722\n",
      "Epoch 94/100\n",
      "131/131 [==============================] - 0s 210us/sample - loss: 0.2541 - mse: 0.0771 - mae: 0.2541 - mape: 43.7583\n",
      "Epoch 95/100\n",
      "131/131 [==============================] - 0s 168us/sample - loss: 0.2503 - mse: 0.0753 - mae: 0.2503 - mape: 43.0373\n",
      "Epoch 96/100\n",
      "131/131 [==============================] - 0s 297us/sample - loss: 0.2465 - mse: 0.0734 - mae: 0.2465 - mape: 42.3275\n",
      "Epoch 97/100\n",
      "131/131 [==============================] - 0s 164us/sample - loss: 0.2427 - mse: 0.0717 - mae: 0.2427 - mape: 41.5941\n",
      "Epoch 98/100\n",
      "131/131 [==============================] - 0s 283us/sample - loss: 0.2389 - mse: 0.0699 - mae: 0.2389 - mape: 40.8690\n",
      "Epoch 99/100\n",
      "131/131 [==============================] - 0s 203us/sample - loss: 0.2352 - mse: 0.0681 - mae: 0.2352 - mape: 40.1658\n",
      "Epoch 100/100\n",
      "131/131 [==============================] - 0s 177us/sample - loss: 0.2316 - mse: 0.0664 - mae: 0.2316 - mape: 39.5109\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 1ms/sample - loss: 0.6569 - accuracy: 0.6410\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.480826  6.206444           2402  4805.158  4.363         3\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.2\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 5.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/5Total Parts.\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 7ms/sample - loss: 0.6489 - mse: 0.4420 - mae: 0.6489 - mape: 102.0893\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 159us/sample - loss: 0.6487 - mse: 0.4417 - mae: 0.6487 - mape: 102.0494\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 161us/sample - loss: 0.6485 - mse: 0.4414 - mae: 0.6485 - mape: 102.0107\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 210us/sample - loss: 0.6482 - mse: 0.4411 - mae: 0.6482 - mape: 101.9702\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 408us/sample - loss: 0.6480 - mse: 0.4408 - mae: 0.6480 - mape: 101.9319\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 970us/sample - loss: 0.6478 - mse: 0.4405 - mae: 0.6478 - mape: 101.8913\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 192us/sample - loss: 0.6475 - mse: 0.4402 - mae: 0.6475 - mape: 101.8519\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 183us/sample - loss: 0.6473 - mse: 0.4399 - mae: 0.6473 - mape: 101.8132\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 164us/sample - loss: 0.6471 - mse: 0.4396 - mae: 0.6471 - mape: 101.7727\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 152us/sample - loss: 0.6469 - mse: 0.4393 - mae: 0.6469 - mape: 101.7339\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 150us/sample - loss: 0.6466 - mse: 0.4390 - mae: 0.6466 - mape: 101.6944\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 176us/sample - loss: 0.6464 - mse: 0.4387 - mae: 0.6464 - mape: 101.6542\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 177us/sample - loss: 0.6462 - mse: 0.4384 - mae: 0.6462 - mape: 101.6151\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 242us/sample - loss: 0.6459 - mse: 0.4381 - mae: 0.6459 - mape: 101.5765\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 154us/sample - loss: 0.6457 - mse: 0.4379 - mae: 0.6457 - mape: 101.5373\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 142us/sample - loss: 0.6455 - mse: 0.4376 - mae: 0.6455 - mape: 101.4975\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 179us/sample - loss: 0.6453 - mse: 0.4373 - mae: 0.6453 - mape: 101.4576\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 187us/sample - loss: 0.6450 - mse: 0.4370 - mae: 0.6450 - mape: 101.4181\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 151us/sample - loss: 0.6448 - mse: 0.4367 - mae: 0.6448 - mape: 101.3783\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 145us/sample - loss: 0.6446 - mse: 0.4364 - mae: 0.6446 - mape: 101.3387\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 137us/sample - loss: 0.6443 - mse: 0.4361 - mae: 0.6443 - mape: 101.2996\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 142us/sample - loss: 0.6441 - mse: 0.4358 - mae: 0.6441 - mape: 101.2593\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 140us/sample - loss: 0.6439 - mse: 0.4355 - mae: 0.6439 - mape: 101.2206\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 149us/sample - loss: 0.6437 - mse: 0.4352 - mae: 0.6437 - mape: 101.1815\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 159us/sample - loss: 0.6434 - mse: 0.4349 - mae: 0.6434 - mape: 101.1420\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 154us/sample - loss: 0.6432 - mse: 0.4346 - mae: 0.6432 - mape: 101.1025\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 188us/sample - loss: 0.6430 - mse: 0.4343 - mae: 0.6430 - mape: 101.0629\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 167us/sample - loss: 0.6427 - mse: 0.4340 - mae: 0.6427 - mape: 101.0233\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 165us/sample - loss: 0.6425 - mse: 0.4337 - mae: 0.6425 - mape: 100.9833\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 236us/sample - loss: 0.6423 - mse: 0.4334 - mae: 0.6423 - mape: 100.9439\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 173us/sample - loss: 0.6420 - mse: 0.4331 - mae: 0.6420 - mape: 100.9043\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 169us/sample - loss: 0.6418 - mse: 0.4328 - mae: 0.6418 - mape: 100.8647\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 164us/sample - loss: 0.6416 - mse: 0.4325 - mae: 0.6416 - mape: 100.8250\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 157us/sample - loss: 0.6414 - mse: 0.4322 - mae: 0.6414 - mape: 100.7855\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 172us/sample - loss: 0.6411 - mse: 0.4319 - mae: 0.6411 - mape: 100.7449\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 171us/sample - loss: 0.6409 - mse: 0.4316 - mae: 0.6409 - mape: 100.7059\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 153us/sample - loss: 0.6407 - mse: 0.4314 - mae: 0.6407 - mape: 100.6662\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 166us/sample - loss: 0.6404 - mse: 0.4311 - mae: 0.6404 - mape: 100.6270\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 160us/sample - loss: 0.6402 - mse: 0.4308 - mae: 0.6402 - mape: 100.5877\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 170us/sample - loss: 0.6400 - mse: 0.4305 - mae: 0.6400 - mape: 100.5481\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 157us/sample - loss: 0.6397 - mse: 0.4302 - mae: 0.6397 - mape: 100.5072\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 197us/sample - loss: 0.6395 - mse: 0.4299 - mae: 0.6395 - mape: 100.4690\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 298us/sample - loss: 0.6393 - mse: 0.4296 - mae: 0.6393 - mape: 100.4281\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 194us/sample - loss: 0.6391 - mse: 0.4293 - mae: 0.6391 - mape: 100.3893\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 176us/sample - loss: 0.6388 - mse: 0.4290 - mae: 0.6388 - mape: 100.3486\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 189us/sample - loss: 0.6386 - mse: 0.4287 - mae: 0.6386 - mape: 100.3086\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 219us/sample - loss: 0.6384 - mse: 0.4284 - mae: 0.6384 - mape: 100.2691\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 177us/sample - loss: 0.6381 - mse: 0.4281 - mae: 0.6381 - mape: 100.2301\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 167us/sample - loss: 0.6379 - mse: 0.4278 - mae: 0.6379 - mape: 100.1900\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 139us/sample - loss: 0.6377 - mse: 0.4275 - mae: 0.6377 - mape: 100.1502\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 117us/sample - loss: 0.6374 - mse: 0.4272 - mae: 0.6374 - mape: 100.1099\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 130us/sample - loss: 0.6372 - mse: 0.4269 - mae: 0.6372 - mape: 100.0701\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 119us/sample - loss: 0.6370 - mse: 0.4266 - mae: 0.6370 - mape: 100.0298\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 134us/sample - loss: 0.6367 - mse: 0.4263 - mae: 0.6367 - mape: 99.9912\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 134us/sample - loss: 0.6365 - mse: 0.4260 - mae: 0.6365 - mape: 99.9505\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 214us/sample - loss: 0.6363 - mse: 0.4257 - mae: 0.6363 - mape: 99.9114\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 177us/sample - loss: 0.6360 - mse: 0.4255 - mae: 0.6360 - mape: 99.8707\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 154us/sample - loss: 0.6358 - mse: 0.4252 - mae: 0.6358 - mape: 99.8306\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 164us/sample - loss: 0.6356 - mse: 0.4249 - mae: 0.6356 - mape: 99.7916\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 175us/sample - loss: 0.6353 - mse: 0.4246 - mae: 0.6353 - mape: 99.7508\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 171us/sample - loss: 0.6351 - mse: 0.4243 - mae: 0.6351 - mape: 99.7116\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 167us/sample - loss: 0.6349 - mse: 0.4240 - mae: 0.6349 - mape: 99.6707\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 123us/sample - loss: 0.6347 - mse: 0.4237 - mae: 0.6347 - mape: 99.6307\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 145us/sample - loss: 0.6344 - mse: 0.4234 - mae: 0.6344 - mape: 99.5910\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 168us/sample - loss: 0.6342 - mse: 0.4231 - mae: 0.6342 - mape: 99.5506\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 184us/sample - loss: 0.6340 - mse: 0.4228 - mae: 0.6340 - mape: 99.5113\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 243us/sample - loss: 0.6337 - mse: 0.4225 - mae: 0.6337 - mape: 99.4716\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 168us/sample - loss: 0.6335 - mse: 0.4222 - mae: 0.6335 - mape: 99.4310\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 156us/sample - loss: 0.6333 - mse: 0.4219 - mae: 0.6333 - mape: 99.3902\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 133us/sample - loss: 0.6330 - mse: 0.4216 - mae: 0.6330 - mape: 99.3511\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 141us/sample - loss: 0.6328 - mse: 0.4213 - mae: 0.6328 - mape: 99.3101\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 142us/sample - loss: 0.6326 - mse: 0.4210 - mae: 0.6326 - mape: 99.2707\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 125us/sample - loss: 0.6323 - mse: 0.4207 - mae: 0.6323 - mape: 99.2305\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 115us/sample - loss: 0.6321 - mse: 0.4204 - mae: 0.6321 - mape: 99.1890\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 133us/sample - loss: 0.6319 - mse: 0.4201 - mae: 0.6319 - mape: 99.1492\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 165us/sample - loss: 0.6316 - mse: 0.4198 - mae: 0.6316 - mape: 99.1096\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 160us/sample - loss: 0.6314 - mse: 0.4195 - mae: 0.6314 - mape: 99.0677\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 125us/sample - loss: 0.6312 - mse: 0.4192 - mae: 0.6312 - mape: 99.0277\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 142us/sample - loss: 0.6309 - mse: 0.4189 - mae: 0.6309 - mape: 98.9877\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 138us/sample - loss: 0.6307 - mse: 0.4187 - mae: 0.6307 - mape: 98.9469\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 184us/sample - loss: 0.6304 - mse: 0.4184 - mae: 0.6304 - mape: 98.9070\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 176us/sample - loss: 0.6302 - mse: 0.4181 - mae: 0.6302 - mape: 98.8674\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 119us/sample - loss: 0.6300 - mse: 0.4178 - mae: 0.6300 - mape: 98.8261\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 131us/sample - loss: 0.6297 - mse: 0.4175 - mae: 0.6297 - mape: 98.7856\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 141us/sample - loss: 0.6295 - mse: 0.4172 - mae: 0.6295 - mape: 98.7442\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 130us/sample - loss: 0.6293 - mse: 0.4169 - mae: 0.6293 - mape: 98.7041\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 138us/sample - loss: 0.6290 - mse: 0.4166 - mae: 0.6290 - mape: 98.6644\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 118us/sample - loss: 0.6288 - mse: 0.4163 - mae: 0.6288 - mape: 98.6229\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 128us/sample - loss: 0.6286 - mse: 0.4160 - mae: 0.6286 - mape: 98.5828\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 116us/sample - loss: 0.6283 - mse: 0.4157 - mae: 0.6283 - mape: 98.5422\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 119us/sample - loss: 0.6281 - mse: 0.4154 - mae: 0.6281 - mape: 98.5015\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 113us/sample - loss: 0.6279 - mse: 0.4151 - mae: 0.6279 - mape: 98.4613\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 126us/sample - loss: 0.6276 - mse: 0.4148 - mae: 0.6276 - mape: 98.4202\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 122us/sample - loss: 0.6274 - mse: 0.4145 - mae: 0.6274 - mape: 98.3794\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 133us/sample - loss: 0.6271 - mse: 0.4142 - mae: 0.6271 - mape: 98.3390\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5873 - mse: 0.3746 - mae: 0.5873 - mape: 98.128 - 0s 153us/sample - loss: 0.6269 - mse: 0.4139 - mae: 0.6269 - mape: 98.2991\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 136us/sample - loss: 0.6267 - mse: 0.4136 - mae: 0.6267 - mape: 98.2574\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 188us/sample - loss: 0.6264 - mse: 0.4133 - mae: 0.6264 - mape: 98.2149\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 204us/sample - loss: 0.6262 - mse: 0.4130 - mae: 0.6262 - mape: 98.1744\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 156us/sample - loss: 0.6260 - mse: 0.4127 - mae: 0.6260 - mape: 98.1344\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 80 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 4ms/sample - loss: 0.5865 - mse: 0.3463 - mae: 0.5865 - mape: 98.6334\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5862 - mse: 0.3460 - mae: 0.5862 - mape: 98.5803\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.5859 - mse: 0.3456 - mae: 0.5859 - mape: 98.5271\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.5855 - mse: 0.3452 - mae: 0.5855 - mape: 98.4737\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5852 - mse: 0.3449 - mae: 0.5852 - mape: 98.4206\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5849 - mse: 0.3445 - mae: 0.5849 - mape: 98.3672\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5846 - mse: 0.3441 - mae: 0.5846 - mape: 98.3136\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5843 - mse: 0.3438 - mae: 0.5843 - mape: 98.2607\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.5840 - mse: 0.3434 - mae: 0.5840 - mape: 98.2073\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5837 - mse: 0.3430 - mae: 0.5837 - mape: 98.1538\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 0.5833 - mse: 0.3427 - mae: 0.5833 - mape: 98.1008\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5830 - mse: 0.3423 - mae: 0.5830 - mape: 98.0472\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5827 - mse: 0.3419 - mae: 0.5827 - mape: 97.9943\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.5824 - mse: 0.3416 - mae: 0.5824 - mape: 97.9409\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5821 - mse: 0.3412 - mae: 0.5821 - mape: 97.8877\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.5818 - mse: 0.3408 - mae: 0.5818 - mape: 97.8343\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.5815 - mse: 0.3405 - mae: 0.5815 - mape: 97.7811\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.5811 - mse: 0.3401 - mae: 0.5811 - mape: 97.7280\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.5808 - mse: 0.3397 - mae: 0.5808 - mape: 97.6744\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.5805 - mse: 0.3394 - mae: 0.5805 - mape: 97.6211\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 0.5802 - mse: 0.3390 - mae: 0.5802 - mape: 97.5680\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5799 - mse: 0.3387 - mae: 0.5799 - mape: 97.5146\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.5796 - mse: 0.3383 - mae: 0.5796 - mape: 97.4613\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5793 - mse: 0.3379 - mae: 0.5793 - mape: 97.4081\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 166us/sample - loss: 0.5789 - mse: 0.3376 - mae: 0.5789 - mape: 97.3547\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.5786 - mse: 0.3372 - mae: 0.5786 - mape: 97.3013\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.5783 - mse: 0.3368 - mae: 0.5783 - mape: 97.2479\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5780 - mse: 0.3365 - mae: 0.5780 - mape: 97.1947\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.5777 - mse: 0.3361 - mae: 0.5777 - mape: 97.1412\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.5774 - mse: 0.3357 - mae: 0.5774 - mape: 97.0879\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.5770 - mse: 0.3354 - mae: 0.5770 - mape: 97.0344\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.5767 - mse: 0.3350 - mae: 0.5767 - mape: 96.9811\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 220us/sample - loss: 0.5764 - mse: 0.3347 - mae: 0.5764 - mape: 96.9275\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 235us/sample - loss: 0.5761 - mse: 0.3343 - mae: 0.5761 - mape: 96.8742\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.5758 - mse: 0.3339 - mae: 0.5758 - mape: 96.8208\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.5755 - mse: 0.3336 - mae: 0.5755 - mape: 96.7672\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5752 - mse: 0.3332 - mae: 0.5752 - mape: 96.7137\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.5748 - mse: 0.3328 - mae: 0.5748 - mape: 96.6597\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5745 - mse: 0.3325 - mae: 0.5745 - mape: 96.6066\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5742 - mse: 0.3321 - mae: 0.5742 - mape: 96.5531\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.5739 - mse: 0.3318 - mae: 0.5739 - mape: 96.4994\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.5736 - mse: 0.3314 - mae: 0.5736 - mape: 96.4456\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.5733 - mse: 0.3310 - mae: 0.5733 - mape: 96.3920\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.5729 - mse: 0.3307 - mae: 0.5729 - mape: 96.3383\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.5726 - mse: 0.3303 - mae: 0.5726 - mape: 96.2845\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.5723 - mse: 0.3299 - mae: 0.5723 - mape: 96.2308\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5720 - mse: 0.3296 - mae: 0.5720 - mape: 96.1769\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.5717 - mse: 0.3292 - mae: 0.5717 - mape: 96.1231\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.5714 - mse: 0.3289 - mae: 0.5714 - mape: 96.0690\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.5710 - mse: 0.3285 - mae: 0.5710 - mape: 96.0152\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.5707 - mse: 0.3281 - mae: 0.5707 - mape: 95.9613\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.5704 - mse: 0.3278 - mae: 0.5704 - mape: 95.9073\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.5701 - mse: 0.3274 - mae: 0.5701 - mape: 95.8533\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.5698 - mse: 0.3270 - mae: 0.5698 - mape: 95.7993\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5694 - mse: 0.3267 - mae: 0.5694 - mape: 95.7450\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5691 - mse: 0.3263 - mae: 0.5691 - mape: 95.6910\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5688 - mse: 0.3259 - mae: 0.5688 - mape: 95.6368\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.5685 - mse: 0.3256 - mae: 0.5685 - mape: 95.5824\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.5682 - mse: 0.3252 - mae: 0.5682 - mape: 95.5280\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5678 - mse: 0.3249 - mae: 0.5678 - mape: 95.4737\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.5675 - mse: 0.3245 - mae: 0.5675 - mape: 95.4195\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 214us/sample - loss: 0.5672 - mse: 0.3241 - mae: 0.5672 - mape: 95.3649\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5669 - mse: 0.3238 - mae: 0.5669 - mape: 95.3106\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.5666 - mse: 0.3234 - mae: 0.5666 - mape: 95.2558\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.5662 - mse: 0.3230 - mae: 0.5662 - mape: 95.2011\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5659 - mse: 0.3227 - mae: 0.5659 - mape: 95.1468\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.5656 - mse: 0.3223 - mae: 0.5656 - mape: 95.0922\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.5653 - mse: 0.3219 - mae: 0.5653 - mape: 95.0372\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5649 - mse: 0.3216 - mae: 0.5649 - mape: 94.9825\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 0.5646 - mse: 0.3212 - mae: 0.5646 - mape: 94.9277\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.5643 - mse: 0.3208 - mae: 0.5643 - mape: 94.8728\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.5640 - mse: 0.3205 - mae: 0.5640 - mape: 94.8175\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 179us/sample - loss: 0.5636 - mse: 0.3201 - mae: 0.5636 - mape: 94.7624\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5633 - mse: 0.3197 - mae: 0.5633 - mape: 94.7077\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.5630 - mse: 0.3194 - mae: 0.5630 - mape: 94.6525\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.5627 - mse: 0.3190 - mae: 0.5627 - mape: 94.5973\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5623 - mse: 0.3186 - mae: 0.5623 - mape: 94.5419\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5620 - mse: 0.3183 - mae: 0.5620 - mape: 94.4865\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5617 - mse: 0.3179 - mae: 0.5617 - mape: 94.4315\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.5614 - mse: 0.3175 - mae: 0.5614 - mape: 94.3760\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.5610 - mse: 0.3172 - mae: 0.5610 - mape: 94.3202\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.5607 - mse: 0.3168 - mae: 0.5607 - mape: 94.2648\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.5604 - mse: 0.3164 - mae: 0.5604 - mape: 94.2089\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5601 - mse: 0.3161 - mae: 0.5601 - mape: 94.1531\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.5597 - mse: 0.3157 - mae: 0.5597 - mape: 94.0975\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.5594 - mse: 0.3153 - mae: 0.5594 - mape: 94.0419\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5591 - mse: 0.3150 - mae: 0.5591 - mape: 93.9859\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 144us/sample - loss: 0.5587 - mse: 0.3146 - mae: 0.5587 - mape: 93.9296\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 205us/sample - loss: 0.5584 - mse: 0.3142 - mae: 0.5584 - mape: 93.8738\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.5581 - mse: 0.3139 - mae: 0.5581 - mape: 93.8174\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 195us/sample - loss: 0.5577 - mse: 0.3135 - mae: 0.5577 - mape: 93.7614\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.5574 - mse: 0.3131 - mae: 0.5574 - mape: 93.7052\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 189us/sample - loss: 0.5571 - mse: 0.3128 - mae: 0.5571 - mape: 93.6486\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5567 - mse: 0.3124 - mae: 0.5567 - mape: 93.5922\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.5564 - mse: 0.3120 - mae: 0.5564 - mape: 93.5358\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.5561 - mse: 0.3116 - mae: 0.5561 - mape: 93.4793\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 0.5557 - mse: 0.3113 - mae: 0.5557 - mape: 93.4226\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 194us/sample - loss: 0.5554 - mse: 0.3109 - mae: 0.5554 - mape: 93.3655\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.5551 - mse: 0.3105 - mae: 0.5551 - mape: 93.3093\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 178us/sample - loss: 0.5547 - mse: 0.3102 - mae: 0.5547 - mape: 93.2518\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 61 samples\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 5ms/sample - loss: 0.6588 - mse: 0.6111 - mae: 0.6588 - mape: 553.6426\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 142us/sample - loss: 0.6586 - mse: 0.6108 - mae: 0.6586 - mape: 552.6095\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 139us/sample - loss: 0.6585 - mse: 0.6105 - mae: 0.6585 - mape: 551.6112\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 100us/sample - loss: 0.6583 - mse: 0.6103 - mae: 0.6583 - mape: 550.6312\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 185us/sample - loss: 0.6581 - mse: 0.6100 - mae: 0.6581 - mape: 549.9523\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 132us/sample - loss: 0.6579 - mse: 0.6098 - mae: 0.6579 - mape: 548.9178\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 140us/sample - loss: 0.6577 - mse: 0.6095 - mae: 0.6577 - mape: 547.9265\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 122us/sample - loss: 0.6575 - mse: 0.6093 - mae: 0.6575 - mape: 546.9462\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 108us/sample - loss: 0.6573 - mse: 0.6090 - mae: 0.6573 - mape: 545.5609\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 108us/sample - loss: 0.6571 - mse: 0.6087 - mae: 0.6571 - mape: 544.9358\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 105us/sample - loss: 0.6569 - mse: 0.6085 - mae: 0.6569 - mape: 543.8984\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 116us/sample - loss: 0.6567 - mse: 0.6082 - mae: 0.6567 - mape: 542.8514\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 114us/sample - loss: 0.6565 - mse: 0.6080 - mae: 0.6565 - mape: 541.5172\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 108us/sample - loss: 0.6563 - mse: 0.6077 - mae: 0.6563 - mape: 540.4917\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 117us/sample - loss: 0.6561 - mse: 0.6075 - mae: 0.6561 - mape: 539.8499\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 134us/sample - loss: 0.6559 - mse: 0.6072 - mae: 0.6559 - mape: 538.8193\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 131us/sample - loss: 0.6557 - mse: 0.6070 - mae: 0.6557 - mape: 537.4592\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 188us/sample - loss: 0.6555 - mse: 0.6067 - mae: 0.6555 - mape: 536.4418\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 164us/sample - loss: 0.6554 - mse: 0.6065 - mae: 0.6554 - mape: 535.7763\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 135us/sample - loss: 0.6552 - mse: 0.6062 - mae: 0.6552 - mape: 534.7707\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 104us/sample - loss: 0.6550 - mse: 0.6060 - mae: 0.6550 - mape: 533.3705\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 145us/sample - loss: 0.6548 - mse: 0.6057 - mae: 0.6548 - mape: 532.7515\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6546 - mse: 0.6054 - mae: 0.6546 - mape: 531.7119\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 123us/sample - loss: 0.6544 - mse: 0.6052 - mae: 0.6544 - mape: 530.3577\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 116us/sample - loss: 0.6542 - mse: 0.6049 - mae: 0.6542 - mape: 529.3549\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 105us/sample - loss: 0.6540 - mse: 0.6047 - mae: 0.6540 - mape: 528.6721\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 121us/sample - loss: 0.6538 - mse: 0.6044 - mae: 0.6538 - mape: 527.6466\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 182us/sample - loss: 0.6536 - mse: 0.6042 - mae: 0.6536 - mape: 526.3104\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 163us/sample - loss: 0.6534 - mse: 0.6039 - mae: 0.6534 - mape: 525.2632\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 123us/sample - loss: 0.6532 - mse: 0.6037 - mae: 0.6532 - mape: 524.6038\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 120us/sample - loss: 0.6530 - mse: 0.6034 - mae: 0.6530 - mape: 523.2411\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 114us/sample - loss: 0.6528 - mse: 0.6031 - mae: 0.6528 - mape: 522.5906\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 136us/sample - loss: 0.6526 - mse: 0.6029 - mae: 0.6526 - mape: 521.5618\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6524 - mse: 0.6026 - mae: 0.6524 - mape: 520.2173\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 110us/sample - loss: 0.6522 - mse: 0.6024 - mae: 0.6522 - mape: 519.1833\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6521 - mse: 0.6021 - mae: 0.6521 - mape: 518.5211\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 150us/sample - loss: 0.6519 - mse: 0.6019 - mae: 0.6519 - mape: 517.1310\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 249us/sample - loss: 0.6517 - mse: 0.6016 - mae: 0.6517 - mape: 516.1381\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 169us/sample - loss: 0.6515 - mse: 0.6014 - mae: 0.6515 - mape: 515.4666\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 163us/sample - loss: 0.6513 - mse: 0.6011 - mae: 0.6513 - mape: 514.0946\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 146us/sample - loss: 0.6511 - mse: 0.6009 - mae: 0.6511 - mape: 513.4380\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 124us/sample - loss: 0.6509 - mse: 0.6006 - mae: 0.6509 - mape: 512.3998\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6507 - mse: 0.6004 - mae: 0.6507 - mape: 511.0383\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 121us/sample - loss: 0.6505 - mse: 0.6001 - mae: 0.6505 - mape: 510.3569\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 124us/sample - loss: 0.6503 - mse: 0.5998 - mae: 0.6503 - mape: 509.0145\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 113us/sample - loss: 0.6501 - mse: 0.5996 - mae: 0.6501 - mape: 508.3357\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 133us/sample - loss: 0.6499 - mse: 0.5993 - mae: 0.6499 - mape: 507.2729\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 111us/sample - loss: 0.6497 - mse: 0.5991 - mae: 0.6497 - mape: 505.9456\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6495 - mse: 0.5988 - mae: 0.6495 - mape: 504.9217\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 113us/sample - loss: 0.6493 - mse: 0.5986 - mae: 0.6493 - mape: 504.2334\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 120us/sample - loss: 0.6491 - mse: 0.5983 - mae: 0.6491 - mape: 503.1846\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 145us/sample - loss: 0.6489 - mse: 0.5981 - mae: 0.6489 - mape: 501.8662\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 197us/sample - loss: 0.6487 - mse: 0.5978 - mae: 0.6487 - mape: 500.8078\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 160us/sample - loss: 0.6485 - mse: 0.5975 - mae: 0.6485 - mape: 500.1764\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 119us/sample - loss: 0.6483 - mse: 0.5973 - mae: 0.6483 - mape: 499.1283\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 139us/sample - loss: 0.6481 - mse: 0.5970 - mae: 0.6481 - mape: 497.7444\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 134us/sample - loss: 0.6479 - mse: 0.5968 - mae: 0.6479 - mape: 496.7404\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 111us/sample - loss: 0.6478 - mse: 0.5965 - mae: 0.6478 - mape: 495.7187\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 110us/sample - loss: 0.6476 - mse: 0.5963 - mae: 0.6476 - mape: 494.6994\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 94us/sample - loss: 0.6474 - mse: 0.5960 - mae: 0.6474 - mape: 493.6447\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 96us/sample - loss: 0.6472 - mse: 0.5958 - mae: 0.6472 - mape: 492.5797\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 103us/sample - loss: 0.6470 - mse: 0.5955 - mae: 0.6470 - mape: 491.9083\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 123us/sample - loss: 0.6468 - mse: 0.5952 - mae: 0.6468 - mape: 490.8931\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 97us/sample - loss: 0.6466 - mse: 0.5950 - mae: 0.6466 - mape: 489.8737\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 110us/sample - loss: 0.6464 - mse: 0.5947 - mae: 0.6464 - mape: 488.8454\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 160us/sample - loss: 0.6462 - mse: 0.5945 - mae: 0.6462 - mape: 487.8242\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 208us/sample - loss: 0.6460 - mse: 0.5942 - mae: 0.6460 - mape: 486.4414\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 152us/sample - loss: 0.6458 - mse: 0.5940 - mae: 0.6458 - mape: 485.7823\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 123us/sample - loss: 0.6456 - mse: 0.5937 - mae: 0.6456 - mape: 484.7566\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 322us/sample - loss: 0.6454 - mse: 0.5935 - mae: 0.6454 - mape: 483.6936\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 137us/sample - loss: 0.6452 - mse: 0.5932 - mae: 0.6452 - mape: 482.6490\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 125us/sample - loss: 0.6450 - mse: 0.5929 - mae: 0.6450 - mape: 481.2813\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 133us/sample - loss: 0.6448 - mse: 0.5927 - mae: 0.6448 - mape: 480.5963\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 116us/sample - loss: 0.6446 - mse: 0.5924 - mae: 0.6446 - mape: 479.2145\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 134us/sample - loss: 0.6444 - mse: 0.5922 - mae: 0.6444 - mape: 478.2018\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 128us/sample - loss: 0.6442 - mse: 0.5919 - mae: 0.6442 - mape: 477.5098\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 101us/sample - loss: 0.6440 - mse: 0.5917 - mae: 0.6440 - mape: 476.0747\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 134us/sample - loss: 0.6438 - mse: 0.5914 - mae: 0.6438 - mape: 475.3859\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 126us/sample - loss: 0.6436 - mse: 0.5911 - mae: 0.6436 - mape: 474.3961\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 139us/sample - loss: 0.6434 - mse: 0.5909 - mae: 0.6434 - mape: 473.0070\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 195us/sample - loss: 0.6432 - mse: 0.5906 - mae: 0.6432 - mape: 471.9385\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 198us/sample - loss: 0.6430 - mse: 0.5904 - mae: 0.6430 - mape: 470.9442\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 157us/sample - loss: 0.6428 - mse: 0.5901 - mae: 0.6428 - mape: 469.9009\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 153us/sample - loss: 0.6426 - mse: 0.5899 - mae: 0.6426 - mape: 469.1821\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 153us/sample - loss: 0.6424 - mse: 0.5896 - mae: 0.6424 - mape: 468.1833\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 149us/sample - loss: 0.6422 - mse: 0.5894 - mae: 0.6422 - mape: 466.7546\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 115us/sample - loss: 0.6420 - mse: 0.5891 - mae: 0.6420 - mape: 465.7044\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 116us/sample - loss: 0.6418 - mse: 0.5888 - mae: 0.6418 - mape: 465.0364\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 156us/sample - loss: 0.6416 - mse: 0.5886 - mae: 0.6416 - mape: 463.6221\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 141us/sample - loss: 0.6414 - mse: 0.5883 - mae: 0.6414 - mape: 462.9369\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 196us/sample - loss: 0.6412 - mse: 0.5880 - mae: 0.6412 - mape: 461.5385\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 131us/sample - loss: 0.6410 - mse: 0.5878 - mae: 0.6410 - mape: 460.8138\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 127us/sample - loss: 0.6408 - mse: 0.5875 - mae: 0.6408 - mape: 459.4402\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 124us/sample - loss: 0.6406 - mse: 0.5873 - mae: 0.6406 - mape: 458.3937\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 170us/sample - loss: 0.6404 - mse: 0.5870 - mae: 0.6404 - mape: 457.6849\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 108us/sample - loss: 0.6402 - mse: 0.5868 - mae: 0.6402 - mape: 456.2926\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 121us/sample - loss: 0.6400 - mse: 0.5865 - mae: 0.6400 - mape: 455.5888\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 144us/sample - loss: 0.6398 - mse: 0.5863 - mae: 0.6398 - mape: 454.1798\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 216us/sample - loss: 0.6396 - mse: 0.5860 - mae: 0.6396 - mape: 453.5079\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 183us/sample - loss: 0.6394 - mse: 0.5857 - mae: 0.6394 - mape: 452.1078\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 3/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 89 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 0s 4ms/sample - loss: 0.5401 - mse: 0.3014 - mae: 0.5401 - mape: 97.4282\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 111us/sample - loss: 0.5397 - mse: 0.3010 - mae: 0.5397 - mape: 97.3664\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 103us/sample - loss: 0.5394 - mse: 0.3007 - mae: 0.5394 - mape: 97.3040\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 107us/sample - loss: 0.5391 - mse: 0.3003 - mae: 0.5391 - mape: 97.2422\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 125us/sample - loss: 0.5387 - mse: 0.2999 - mae: 0.5387 - mape: 97.1800\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 110us/sample - loss: 0.5384 - mse: 0.2996 - mae: 0.5384 - mape: 97.1174\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 138us/sample - loss: 0.5380 - mse: 0.2992 - mae: 0.5380 - mape: 97.0555\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 235us/sample - loss: 0.5377 - mse: 0.2989 - mae: 0.5377 - mape: 96.9932\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5374 - mse: 0.2985 - mae: 0.5374 - mape: 96.9309\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5370 - mse: 0.2981 - mae: 0.5370 - mape: 96.8687\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5367 - mse: 0.2978 - mae: 0.5367 - mape: 96.8064\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5364 - mse: 0.2974 - mae: 0.5364 - mape: 96.7440\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 111us/sample - loss: 0.5360 - mse: 0.2970 - mae: 0.5360 - mape: 96.6822\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 113us/sample - loss: 0.5357 - mse: 0.2967 - mae: 0.5357 - mape: 96.6200\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 115us/sample - loss: 0.5354 - mse: 0.2963 - mae: 0.5354 - mape: 96.5575\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 118us/sample - loss: 0.5350 - mse: 0.2960 - mae: 0.5350 - mape: 96.4951\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 116us/sample - loss: 0.5347 - mse: 0.2956 - mae: 0.5347 - mape: 96.4332\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 116us/sample - loss: 0.5343 - mse: 0.2952 - mae: 0.5343 - mape: 96.3710\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5340 - mse: 0.2949 - mae: 0.5340 - mape: 96.3088\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 199us/sample - loss: 0.5337 - mse: 0.2945 - mae: 0.5337 - mape: 96.2461\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5333 - mse: 0.2942 - mae: 0.5333 - mape: 96.1840\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 136us/sample - loss: 0.5330 - mse: 0.2938 - mae: 0.5330 - mape: 96.1217\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 148us/sample - loss: 0.5327 - mse: 0.2934 - mae: 0.5327 - mape: 96.0595\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 135us/sample - loss: 0.5323 - mse: 0.2931 - mae: 0.5323 - mape: 95.9973\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5320 - mse: 0.2927 - mae: 0.5320 - mape: 95.9348\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 151us/sample - loss: 0.5317 - mse: 0.2924 - mae: 0.5317 - mape: 95.8729\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 224us/sample - loss: 0.5313 - mse: 0.2920 - mae: 0.5313 - mape: 95.8103\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 339us/sample - loss: 0.5310 - mse: 0.2917 - mae: 0.5310 - mape: 95.7478\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 265us/sample - loss: 0.5306 - mse: 0.2913 - mae: 0.5306 - mape: 95.6852\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 291us/sample - loss: 0.5303 - mse: 0.2909 - mae: 0.5303 - mape: 95.6236\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 178us/sample - loss: 0.5300 - mse: 0.2906 - mae: 0.5300 - mape: 95.5603\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 208us/sample - loss: 0.5296 - mse: 0.2902 - mae: 0.5296 - mape: 95.4976\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 162us/sample - loss: 0.5293 - mse: 0.2899 - mae: 0.5293 - mape: 95.4358\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 152us/sample - loss: 0.5290 - mse: 0.2895 - mae: 0.5290 - mape: 95.3732\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5286 - mse: 0.2891 - mae: 0.5286 - mape: 95.3111\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 391us/sample - loss: 0.5283 - mse: 0.2888 - mae: 0.5283 - mape: 95.2479\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 170us/sample - loss: 0.5279 - mse: 0.2884 - mae: 0.5279 - mape: 95.1857\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 241us/sample - loss: 0.5276 - mse: 0.2881 - mae: 0.5276 - mape: 95.1227\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 166us/sample - loss: 0.5273 - mse: 0.2877 - mae: 0.5273 - mape: 95.0604\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 142us/sample - loss: 0.5269 - mse: 0.2873 - mae: 0.5269 - mape: 94.9980\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 200us/sample - loss: 0.5266 - mse: 0.2870 - mae: 0.5266 - mape: 94.9352\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 270us/sample - loss: 0.5262 - mse: 0.2866 - mae: 0.5262 - mape: 94.8719\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5259 - mse: 0.2863 - mae: 0.5259 - mape: 94.8094\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 138us/sample - loss: 0.5256 - mse: 0.2859 - mae: 0.5256 - mape: 94.7462\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 168us/sample - loss: 0.5252 - mse: 0.2856 - mae: 0.5252 - mape: 94.6834\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5249 - mse: 0.2852 - mae: 0.5249 - mape: 94.6203\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 127us/sample - loss: 0.5245 - mse: 0.2848 - mae: 0.5245 - mape: 94.5582\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 121us/sample - loss: 0.5242 - mse: 0.2845 - mae: 0.5242 - mape: 94.4944\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 110us/sample - loss: 0.5239 - mse: 0.2841 - mae: 0.5239 - mape: 94.4314\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 113us/sample - loss: 0.5235 - mse: 0.2838 - mae: 0.5235 - mape: 94.3685\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 120us/sample - loss: 0.5232 - mse: 0.2834 - mae: 0.5232 - mape: 94.3050\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5228 - mse: 0.2831 - mae: 0.5228 - mape: 94.2417\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 144us/sample - loss: 0.5225 - mse: 0.2827 - mae: 0.5225 - mape: 94.1788\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 195us/sample - loss: 0.5222 - mse: 0.2823 - mae: 0.5222 - mape: 94.1152\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 161us/sample - loss: 0.5218 - mse: 0.2820 - mae: 0.5218 - mape: 94.0519\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 150us/sample - loss: 0.5215 - mse: 0.2816 - mae: 0.5215 - mape: 93.9889\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 153us/sample - loss: 0.5211 - mse: 0.2813 - mae: 0.5211 - mape: 93.9253\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5208 - mse: 0.2809 - mae: 0.5208 - mape: 93.8610\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 134us/sample - loss: 0.5204 - mse: 0.2805 - mae: 0.5204 - mape: 93.7978\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 128us/sample - loss: 0.5201 - mse: 0.2802 - mae: 0.5201 - mape: 93.7340\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 104us/sample - loss: 0.5197 - mse: 0.2798 - mae: 0.5197 - mape: 93.6697\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 117us/sample - loss: 0.5194 - mse: 0.2795 - mae: 0.5194 - mape: 93.6063\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 135us/sample - loss: 0.5191 - mse: 0.2791 - mae: 0.5191 - mape: 93.5428\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 197us/sample - loss: 0.5187 - mse: 0.2788 - mae: 0.5187 - mape: 93.4783\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5184 - mse: 0.2784 - mae: 0.5184 - mape: 93.4144\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5180 - mse: 0.2780 - mae: 0.5180 - mape: 93.3505\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5177 - mse: 0.2777 - mae: 0.5177 - mape: 93.2861\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 140us/sample - loss: 0.5173 - mse: 0.2773 - mae: 0.5173 - mape: 93.2220\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5170 - mse: 0.2770 - mae: 0.5170 - mape: 93.1583\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 129us/sample - loss: 0.5166 - mse: 0.2766 - mae: 0.5166 - mape: 93.0936\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 122us/sample - loss: 0.5163 - mse: 0.2762 - mae: 0.5163 - mape: 93.0292\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 107us/sample - loss: 0.5159 - mse: 0.2759 - mae: 0.5159 - mape: 92.9646\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 109us/sample - loss: 0.5156 - mse: 0.2755 - mae: 0.5156 - mape: 92.9001\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5152 - mse: 0.2752 - mae: 0.5152 - mape: 92.8359\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 134us/sample - loss: 0.5149 - mse: 0.2748 - mae: 0.5149 - mape: 92.7708\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 150us/sample - loss: 0.5145 - mse: 0.2744 - mae: 0.5145 - mape: 92.7064\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 216us/sample - loss: 0.5142 - mse: 0.2741 - mae: 0.5142 - mape: 92.6410\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 242us/sample - loss: 0.5138 - mse: 0.2737 - mae: 0.5138 - mape: 92.5763\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 169us/sample - loss: 0.5135 - mse: 0.2734 - mae: 0.5135 - mape: 92.5114\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 179us/sample - loss: 0.5131 - mse: 0.2730 - mae: 0.5131 - mape: 92.4465\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 172us/sample - loss: 0.5128 - mse: 0.2726 - mae: 0.5128 - mape: 92.3814\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 172us/sample - loss: 0.5124 - mse: 0.2723 - mae: 0.5124 - mape: 92.3159\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 218us/sample - loss: 0.5121 - mse: 0.2719 - mae: 0.5121 - mape: 92.2506\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 165us/sample - loss: 0.5117 - mse: 0.2715 - mae: 0.5117 - mape: 92.1853\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5114 - mse: 0.2712 - mae: 0.5114 - mape: 92.1201\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 163us/sample - loss: 0.5110 - mse: 0.2708 - mae: 0.5110 - mape: 92.0547\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 0s 145us/sample - loss: 0.5107 - mse: 0.2705 - mae: 0.5107 - mape: 91.9891\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 170us/sample - loss: 0.5103 - mse: 0.2701 - mae: 0.5103 - mape: 91.9229\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 228us/sample - loss: 0.5099 - mse: 0.2697 - mae: 0.5099 - mape: 91.8575\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 173us/sample - loss: 0.5096 - mse: 0.2694 - mae: 0.5096 - mape: 91.7923\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 155us/sample - loss: 0.5092 - mse: 0.2690 - mae: 0.5092 - mape: 91.7264\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 190us/sample - loss: 0.5089 - mse: 0.2686 - mae: 0.5089 - mape: 91.6595\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 222us/sample - loss: 0.5085 - mse: 0.2683 - mae: 0.5085 - mape: 91.5940\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 168us/sample - loss: 0.5082 - mse: 0.2679 - mae: 0.5082 - mape: 91.5272\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 146us/sample - loss: 0.5078 - mse: 0.2675 - mae: 0.5078 - mape: 91.4616\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 0s 188us/sample - loss: 0.5074 - mse: 0.2672 - mae: 0.5074 - mape: 91.3944\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 155us/sample - loss: 0.5071 - mse: 0.2668 - mae: 0.5071 - mape: 91.3279\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 142us/sample - loss: 0.5067 - mse: 0.2664 - mae: 0.5067 - mape: 91.2623\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 145us/sample - loss: 0.5064 - mse: 0.2661 - mae: 0.5064 - mape: 91.1952\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5060 - mse: 0.2657 - mae: 0.5060 - mape: 91.1286\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 4/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 121 samples\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 0s 3ms/sample - loss: 0.5306 - mse: 0.3174 - mae: 0.5306 - mape: 114.7797\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s 170us/sample - loss: 0.5301 - mse: 0.3169 - mae: 0.5301 - mape: 114.6740\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s 121us/sample - loss: 0.5297 - mse: 0.3164 - mae: 0.5297 - mape: 114.5663\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s 129us/sample - loss: 0.5293 - mse: 0.3160 - mae: 0.5293 - mape: 114.4603\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s 141us/sample - loss: 0.5288 - mse: 0.3155 - mae: 0.5288 - mape: 114.3519\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s 127us/sample - loss: 0.5284 - mse: 0.3151 - mae: 0.5284 - mape: 114.2454\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s 120us/sample - loss: 0.5279 - mse: 0.3146 - mae: 0.5279 - mape: 114.1384\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s 178us/sample - loss: 0.5275 - mse: 0.3141 - mae: 0.5275 - mape: 114.0335\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s 152us/sample - loss: 0.5271 - mse: 0.3137 - mae: 0.5271 - mape: 113.9234\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s 151us/sample - loss: 0.5266 - mse: 0.3132 - mae: 0.5266 - mape: 113.8171\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s 136us/sample - loss: 0.5262 - mse: 0.3128 - mae: 0.5262 - mape: 113.7098\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s 121us/sample - loss: 0.5257 - mse: 0.3123 - mae: 0.5257 - mape: 113.6038\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s 152us/sample - loss: 0.5253 - mse: 0.3118 - mae: 0.5253 - mape: 113.4976\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s 124us/sample - loss: 0.5249 - mse: 0.3114 - mae: 0.5249 - mape: 113.3891\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s 145us/sample - loss: 0.5244 - mse: 0.3109 - mae: 0.5244 - mape: 113.2832\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s 144us/sample - loss: 0.5240 - mse: 0.3105 - mae: 0.5240 - mape: 113.1765\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s 178us/sample - loss: 0.5235 - mse: 0.3100 - mae: 0.5235 - mape: 113.0674\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s 201us/sample - loss: 0.5231 - mse: 0.3096 - mae: 0.5231 - mape: 112.9616\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s 180us/sample - loss: 0.5227 - mse: 0.3091 - mae: 0.5227 - mape: 112.8547\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s 158us/sample - loss: 0.5222 - mse: 0.3086 - mae: 0.5222 - mape: 112.7483\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s 147us/sample - loss: 0.5218 - mse: 0.3082 - mae: 0.5218 - mape: 112.6386\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s 142us/sample - loss: 0.5213 - mse: 0.3077 - mae: 0.5213 - mape: 112.5322\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s 129us/sample - loss: 0.5209 - mse: 0.3073 - mae: 0.5209 - mape: 112.4241\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s 159us/sample - loss: 0.5204 - mse: 0.3068 - mae: 0.5204 - mape: 112.3163\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s 210us/sample - loss: 0.5200 - mse: 0.3064 - mae: 0.5200 - mape: 112.2099\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s 144us/sample - loss: 0.5196 - mse: 0.3059 - mae: 0.5196 - mape: 112.1024\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s 163us/sample - loss: 0.5191 - mse: 0.3054 - mae: 0.5191 - mape: 111.9943\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 0s 159us/sample - loss: 0.5187 - mse: 0.3050 - mae: 0.5187 - mape: 111.8873\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 0s 157us/sample - loss: 0.5182 - mse: 0.3045 - mae: 0.5182 - mape: 111.7793\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 0s 182us/sample - loss: 0.5178 - mse: 0.3041 - mae: 0.5178 - mape: 111.6689\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 0s 175us/sample - loss: 0.5173 - mse: 0.3036 - mae: 0.5173 - mape: 111.5624\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 0s 206us/sample - loss: 0.5169 - mse: 0.3032 - mae: 0.5169 - mape: 111.4530\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 0s 157us/sample - loss: 0.5165 - mse: 0.3027 - mae: 0.5165 - mape: 111.3462\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 165us/sample - loss: 0.5160 - mse: 0.3023 - mae: 0.5160 - mape: 111.2378\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 0s 165us/sample - loss: 0.5156 - mse: 0.3018 - mae: 0.5156 - mape: 111.1294\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 0s 204us/sample - loss: 0.5151 - mse: 0.3013 - mae: 0.5151 - mape: 111.0208\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 0s 161us/sample - loss: 0.5147 - mse: 0.3009 - mae: 0.5147 - mape: 110.9095\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 0s 180us/sample - loss: 0.5142 - mse: 0.3004 - mae: 0.5142 - mape: 110.8022\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 0s 129us/sample - loss: 0.5138 - mse: 0.3000 - mae: 0.5138 - mape: 110.6936\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 0s 136us/sample - loss: 0.5133 - mse: 0.2995 - mae: 0.5133 - mape: 110.5851\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 0s 187us/sample - loss: 0.5129 - mse: 0.2991 - mae: 0.5129 - mape: 110.4750\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 0s 152us/sample - loss: 0.5124 - mse: 0.2986 - mae: 0.5124 - mape: 110.3651\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 0s 207us/sample - loss: 0.5120 - mse: 0.2981 - mae: 0.5120 - mape: 110.2578\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 0s 198us/sample - loss: 0.5115 - mse: 0.2977 - mae: 0.5115 - mape: 110.1465\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 0s 147us/sample - loss: 0.5111 - mse: 0.2972 - mae: 0.5111 - mape: 110.0385\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 0s 162us/sample - loss: 0.5106 - mse: 0.2968 - mae: 0.5106 - mape: 109.9272\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 0s 264us/sample - loss: 0.5102 - mse: 0.2963 - mae: 0.5102 - mape: 109.8163\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 0s 146us/sample - loss: 0.5097 - mse: 0.2959 - mae: 0.5097 - mape: 109.7066\n",
      "Epoch 49/100\n",
      "121/121 [==============================] - 0s 155us/sample - loss: 0.5093 - mse: 0.2954 - mae: 0.5093 - mape: 109.5960\n",
      "Epoch 50/100\n",
      "121/121 [==============================] - 0s 161us/sample - loss: 0.5088 - mse: 0.2949 - mae: 0.5088 - mape: 109.4856\n",
      "Epoch 51/100\n",
      "121/121 [==============================] - 0s 158us/sample - loss: 0.5083 - mse: 0.2945 - mae: 0.5083 - mape: 109.3740\n",
      "Epoch 52/100\n",
      "121/121 [==============================] - 0s 320us/sample - loss: 0.5079 - mse: 0.2940 - mae: 0.5079 - mape: 109.2650\n",
      "Epoch 53/100\n",
      "121/121 [==============================] - 0s 184us/sample - loss: 0.5074 - mse: 0.2936 - mae: 0.5074 - mape: 109.1520\n",
      "Epoch 54/100\n",
      "121/121 [==============================] - 0s 178us/sample - loss: 0.5070 - mse: 0.2931 - mae: 0.5070 - mape: 109.0428\n",
      "Epoch 55/100\n",
      "121/121 [==============================] - 0s 152us/sample - loss: 0.5065 - mse: 0.2926 - mae: 0.5065 - mape: 108.9318\n",
      "Epoch 56/100\n",
      "121/121 [==============================] - 0s 153us/sample - loss: 0.5061 - mse: 0.2922 - mae: 0.5061 - mape: 108.8210\n",
      "Epoch 57/100\n",
      "121/121 [==============================] - 0s 222us/sample - loss: 0.5056 - mse: 0.2917 - mae: 0.5056 - mape: 108.7077\n",
      "Epoch 58/100\n",
      "121/121 [==============================] - 0s 323us/sample - loss: 0.5051 - mse: 0.2913 - mae: 0.5051 - mape: 108.5950\n",
      "Epoch 59/100\n",
      "121/121 [==============================] - 0s 192us/sample - loss: 0.5047 - mse: 0.2908 - mae: 0.5047 - mape: 108.4846\n",
      "Epoch 60/100\n",
      "121/121 [==============================] - 0s 183us/sample - loss: 0.5042 - mse: 0.2903 - mae: 0.5042 - mape: 108.3712\n",
      "Epoch 61/100\n",
      "121/121 [==============================] - 0s 133us/sample - loss: 0.5038 - mse: 0.2899 - mae: 0.5038 - mape: 108.2595\n",
      "Epoch 62/100\n",
      "121/121 [==============================] - 0s 158us/sample - loss: 0.5033 - mse: 0.2894 - mae: 0.5033 - mape: 108.1460\n",
      "Epoch 63/100\n",
      "121/121 [==============================] - 0s 207us/sample - loss: 0.5028 - mse: 0.2890 - mae: 0.5028 - mape: 108.0327\n",
      "Epoch 64/100\n",
      "121/121 [==============================] - 0s 125us/sample - loss: 0.5024 - mse: 0.2885 - mae: 0.5024 - mape: 107.9180\n",
      "Epoch 65/100\n",
      "121/121 [==============================] - 0s 161us/sample - loss: 0.5019 - mse: 0.2880 - mae: 0.5019 - mape: 107.8059\n",
      "Epoch 66/100\n",
      "121/121 [==============================] - 0s 144us/sample - loss: 0.5014 - mse: 0.2876 - mae: 0.5014 - mape: 107.6916\n",
      "Epoch 67/100\n",
      "121/121 [==============================] - 0s 141us/sample - loss: 0.5010 - mse: 0.2871 - mae: 0.5010 - mape: 107.5801\n",
      "Epoch 68/100\n",
      "121/121 [==============================] - 0s 131us/sample - loss: 0.5005 - mse: 0.2866 - mae: 0.5005 - mape: 107.4659\n",
      "Epoch 69/100\n",
      "121/121 [==============================] - 0s 141us/sample - loss: 0.5000 - mse: 0.2862 - mae: 0.5000 - mape: 107.3524\n",
      "Epoch 70/100\n",
      "121/121 [==============================] - 0s 174us/sample - loss: 0.4996 - mse: 0.2857 - mae: 0.4996 - mape: 107.2363\n",
      "Epoch 71/100\n",
      "121/121 [==============================] - 0s 212us/sample - loss: 0.4991 - mse: 0.2853 - mae: 0.4991 - mape: 107.1210\n",
      "Epoch 72/100\n",
      "121/121 [==============================] - 0s 147us/sample - loss: 0.4986 - mse: 0.2848 - mae: 0.4986 - mape: 107.0063\n",
      "Epoch 73/100\n",
      "121/121 [==============================] - 0s 136us/sample - loss: 0.4981 - mse: 0.2843 - mae: 0.4981 - mape: 106.8917\n",
      "Epoch 74/100\n",
      "121/121 [==============================] - 0s 129us/sample - loss: 0.4977 - mse: 0.2839 - mae: 0.4977 - mape: 106.7765\n",
      "Epoch 75/100\n",
      "121/121 [==============================] - 0s 117us/sample - loss: 0.4972 - mse: 0.2834 - mae: 0.4972 - mape: 106.6605\n",
      "Epoch 76/100\n",
      "121/121 [==============================] - 0s 128us/sample - loss: 0.4967 - mse: 0.2829 - mae: 0.4967 - mape: 106.5468\n",
      "Epoch 77/100\n",
      "121/121 [==============================] - 0s 113us/sample - loss: 0.4962 - mse: 0.2825 - mae: 0.4962 - mape: 106.4286\n",
      "Epoch 78/100\n",
      "121/121 [==============================] - 0s 135us/sample - loss: 0.4958 - mse: 0.2820 - mae: 0.4958 - mape: 106.3129\n",
      "Epoch 79/100\n",
      "121/121 [==============================] - 0s 155us/sample - loss: 0.4953 - mse: 0.2815 - mae: 0.4953 - mape: 106.1956\n",
      "Epoch 80/100\n",
      "121/121 [==============================] - 0s 121us/sample - loss: 0.4948 - mse: 0.2810 - mae: 0.4948 - mape: 106.0801\n",
      "Epoch 81/100\n",
      "121/121 [==============================] - 0s 122us/sample - loss: 0.4943 - mse: 0.2806 - mae: 0.4943 - mape: 105.9623\n",
      "Epoch 82/100\n",
      "121/121 [==============================] - 0s 127us/sample - loss: 0.4938 - mse: 0.2801 - mae: 0.4938 - mape: 105.8458\n",
      "Epoch 83/100\n",
      "121/121 [==============================] - 0s 99us/sample - loss: 0.4934 - mse: 0.2796 - mae: 0.4934 - mape: 105.7285\n",
      "Epoch 84/100\n",
      "121/121 [==============================] - 0s 124us/sample - loss: 0.4929 - mse: 0.2792 - mae: 0.4929 - mape: 105.6108\n",
      "Epoch 85/100\n",
      "121/121 [==============================] - 0s 161us/sample - loss: 0.4924 - mse: 0.2787 - mae: 0.4924 - mape: 105.4944\n",
      "Epoch 86/100\n",
      "121/121 [==============================] - 0s 117us/sample - loss: 0.4919 - mse: 0.2782 - mae: 0.4919 - mape: 105.3739\n",
      "Epoch 87/100\n",
      "121/121 [==============================] - 0s 114us/sample - loss: 0.4914 - mse: 0.2777 - mae: 0.4914 - mape: 105.2581\n",
      "Epoch 88/100\n",
      "121/121 [==============================] - 0s 118us/sample - loss: 0.4909 - mse: 0.2773 - mae: 0.4909 - mape: 105.1371\n",
      "Epoch 89/100\n",
      "121/121 [==============================] - 0s 97us/sample - loss: 0.4904 - mse: 0.2768 - mae: 0.4904 - mape: 105.0178\n",
      "Epoch 90/100\n",
      "121/121 [==============================] - 0s 111us/sample - loss: 0.4899 - mse: 0.2763 - mae: 0.4899 - mape: 104.8996\n",
      "Epoch 91/100\n",
      "121/121 [==============================] - 0s 104us/sample - loss: 0.4895 - mse: 0.2758 - mae: 0.4895 - mape: 104.7791\n",
      "Epoch 92/100\n",
      "121/121 [==============================] - 0s 106us/sample - loss: 0.4890 - mse: 0.2754 - mae: 0.4890 - mape: 104.6581\n",
      "Epoch 93/100\n",
      "121/121 [==============================] - 0s 181us/sample - loss: 0.4885 - mse: 0.2749 - mae: 0.4885 - mape: 104.5373\n",
      "Epoch 94/100\n",
      "121/121 [==============================] - 0s 105us/sample - loss: 0.4880 - mse: 0.2744 - mae: 0.4880 - mape: 104.4191\n",
      "Epoch 95/100\n",
      "121/121 [==============================] - 0s 124us/sample - loss: 0.4875 - mse: 0.2739 - mae: 0.4875 - mape: 104.2979\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 104us/sample - loss: 0.4870 - mse: 0.2734 - mae: 0.4870 - mape: 104.1752\n",
      "Epoch 97/100\n",
      "121/121 [==============================] - 0s 101us/sample - loss: 0.4865 - mse: 0.2730 - mae: 0.4865 - mape: 104.0548\n",
      "Epoch 98/100\n",
      "121/121 [==============================] - 0s 96us/sample - loss: 0.4860 - mse: 0.2725 - mae: 0.4860 - mape: 103.9326\n",
      "Epoch 99/100\n",
      "121/121 [==============================] - 0s 91us/sample - loss: 0.4855 - mse: 0.2720 - mae: 0.4855 - mape: 103.8112\n",
      "Epoch 100/100\n",
      "121/121 [==============================] - 0s 107us/sample - loss: 0.4850 - mse: 0.2715 - mae: 0.4850 - mape: 103.6878\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 1ms/sample - loss: 0.5930 - accuracy: 0.7538\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time   P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.982531  6.52965           1800  3601.158  4.201         5\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.3\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "Final Loop\n",
      "breaking early\n",
      "The_parts_listhe number of parts are: 6.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 77 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 5ms/sample - loss: 0.5149 - mse: 0.2657 - mae: 0.5149 - mape: 94.5521\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 109us/sample - loss: 0.5146 - mse: 0.2654 - mae: 0.5146 - mape: 94.4942\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 127us/sample - loss: 0.5143 - mse: 0.2651 - mae: 0.5143 - mape: 94.4363\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 160us/sample - loss: 0.5140 - mse: 0.2648 - mae: 0.5140 - mape: 94.3784\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 139us/sample - loss: 0.5137 - mse: 0.2644 - mae: 0.5137 - mape: 94.3205\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 131us/sample - loss: 0.5134 - mse: 0.2641 - mae: 0.5134 - mape: 94.2624\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 130us/sample - loss: 0.5130 - mse: 0.2638 - mae: 0.5130 - mape: 94.2046\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 136us/sample - loss: 0.5127 - mse: 0.2635 - mae: 0.5127 - mape: 94.1464\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 124us/sample - loss: 0.5124 - mse: 0.2632 - mae: 0.5124 - mape: 94.0884\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 112us/sample - loss: 0.5121 - mse: 0.2628 - mae: 0.5121 - mape: 94.0304\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 125us/sample - loss: 0.5118 - mse: 0.2625 - mae: 0.5118 - mape: 93.9724\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 133us/sample - loss: 0.5115 - mse: 0.2622 - mae: 0.5115 - mape: 93.9144\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 219us/sample - loss: 0.5112 - mse: 0.2619 - mae: 0.5112 - mape: 93.8563\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 170us/sample - loss: 0.5108 - mse: 0.2615 - mae: 0.5108 - mape: 93.7981\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 208us/sample - loss: 0.5105 - mse: 0.2612 - mae: 0.5105 - mape: 93.7398\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 321us/sample - loss: 0.5102 - mse: 0.2609 - mae: 0.5102 - mape: 93.6818\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 169us/sample - loss: 0.5099 - mse: 0.2606 - mae: 0.5099 - mape: 93.6236\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 197us/sample - loss: 0.5096 - mse: 0.2602 - mae: 0.5096 - mape: 93.5655\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 250us/sample - loss: 0.5093 - mse: 0.2599 - mae: 0.5093 - mape: 93.5071\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 162us/sample - loss: 0.5089 - mse: 0.2596 - mae: 0.5089 - mape: 93.4489\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 162us/sample - loss: 0.5086 - mse: 0.2593 - mae: 0.5086 - mape: 93.3904\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 176us/sample - loss: 0.5083 - mse: 0.2590 - mae: 0.5083 - mape: 93.3322\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 155us/sample - loss: 0.5080 - mse: 0.2586 - mae: 0.5080 - mape: 93.2737\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 131us/sample - loss: 0.5077 - mse: 0.2583 - mae: 0.5077 - mape: 93.2152\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 151us/sample - loss: 0.5074 - mse: 0.2580 - mae: 0.5074 - mape: 93.1568\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 150us/sample - loss: 0.5070 - mse: 0.2577 - mae: 0.5070 - mape: 93.0983\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 144us/sample - loss: 0.5067 - mse: 0.2573 - mae: 0.5067 - mape: 93.0396\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 159us/sample - loss: 0.5064 - mse: 0.2570 - mae: 0.5064 - mape: 92.9809\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.5061 - mse: 0.2567 - mae: 0.5061 - mape: 92.9223\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 203us/sample - loss: 0.5058 - mse: 0.2564 - mae: 0.5058 - mape: 92.8636\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 189us/sample - loss: 0.5054 - mse: 0.2561 - mae: 0.5054 - mape: 92.8049\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 145us/sample - loss: 0.5051 - mse: 0.2557 - mae: 0.5051 - mape: 92.7460\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 148us/sample - loss: 0.5048 - mse: 0.2554 - mae: 0.5048 - mape: 92.6872\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 168us/sample - loss: 0.5045 - mse: 0.2551 - mae: 0.5045 - mape: 92.6282\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.5042 - mse: 0.2548 - mae: 0.5042 - mape: 92.5693\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 138us/sample - loss: 0.5038 - mse: 0.2544 - mae: 0.5038 - mape: 92.5103\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.5035 - mse: 0.2541 - mae: 0.5035 - mape: 92.4514\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 240us/sample - loss: 0.5032 - mse: 0.2538 - mae: 0.5032 - mape: 92.3923\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 151us/sample - loss: 0.5029 - mse: 0.2535 - mae: 0.5029 - mape: 92.3331\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 164us/sample - loss: 0.5026 - mse: 0.2531 - mae: 0.5026 - mape: 92.2739\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 146us/sample - loss: 0.5022 - mse: 0.2528 - mae: 0.5022 - mape: 92.2146\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 121us/sample - loss: 0.5019 - mse: 0.2525 - mae: 0.5019 - mape: 92.1551\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 111us/sample - loss: 0.5016 - mse: 0.2522 - mae: 0.5016 - mape: 92.0957\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 128us/sample - loss: 0.5013 - mse: 0.2519 - mae: 0.5013 - mape: 92.0364\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 136us/sample - loss: 0.5009 - mse: 0.2515 - mae: 0.5009 - mape: 91.9769\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 171us/sample - loss: 0.5006 - mse: 0.2512 - mae: 0.5006 - mape: 91.9173\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 178us/sample - loss: 0.5003 - mse: 0.2509 - mae: 0.5003 - mape: 91.8576\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 124us/sample - loss: 0.5000 - mse: 0.2506 - mae: 0.5000 - mape: 91.7980\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 139us/sample - loss: 0.4996 - mse: 0.2502 - mae: 0.4996 - mape: 91.7380\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.4993 - mse: 0.2499 - mae: 0.4993 - mape: 91.6783\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 124us/sample - loss: 0.4990 - mse: 0.2496 - mae: 0.4990 - mape: 91.6183\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 129us/sample - loss: 0.4987 - mse: 0.2493 - mae: 0.4987 - mape: 91.5583\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 154us/sample - loss: 0.4983 - mse: 0.2489 - mae: 0.4983 - mape: 91.4984\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.4980 - mse: 0.2486 - mae: 0.4980 - mape: 91.4380\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 125us/sample - loss: 0.4977 - mse: 0.2483 - mae: 0.4977 - mape: 91.3781\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 127us/sample - loss: 0.4974 - mse: 0.2480 - mae: 0.4974 - mape: 91.3177\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 150us/sample - loss: 0.4970 - mse: 0.2476 - mae: 0.4970 - mape: 91.2574\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 131us/sample - loss: 0.4967 - mse: 0.2473 - mae: 0.4967 - mape: 91.1973\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 132us/sample - loss: 0.4964 - mse: 0.2470 - mae: 0.4964 - mape: 91.1366\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 137us/sample - loss: 0.4960 - mse: 0.2467 - mae: 0.4960 - mape: 91.0760\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 248us/sample - loss: 0.4957 - mse: 0.2463 - mae: 0.4957 - mape: 91.0155\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 133us/sample - loss: 0.4954 - mse: 0.2460 - mae: 0.4954 - mape: 90.9547\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 162us/sample - loss: 0.4951 - mse: 0.2457 - mae: 0.4951 - mape: 90.8940\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 148us/sample - loss: 0.4947 - mse: 0.2453 - mae: 0.4947 - mape: 90.8329\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 130us/sample - loss: 0.4944 - mse: 0.2450 - mae: 0.4944 - mape: 90.7720\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.4941 - mse: 0.2447 - mae: 0.4941 - mape: 90.7111\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 154us/sample - loss: 0.4937 - mse: 0.2444 - mae: 0.4937 - mape: 90.6500\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 237us/sample - loss: 0.4934 - mse: 0.2440 - mae: 0.4934 - mape: 90.5889\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.4931 - mse: 0.2437 - mae: 0.4931 - mape: 90.5275\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 151us/sample - loss: 0.4927 - mse: 0.2434 - mae: 0.4927 - mape: 90.4662\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 148us/sample - loss: 0.4924 - mse: 0.2430 - mae: 0.4924 - mape: 90.4048\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 152us/sample - loss: 0.4921 - mse: 0.2427 - mae: 0.4921 - mape: 90.3432\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 132us/sample - loss: 0.4917 - mse: 0.2424 - mae: 0.4917 - mape: 90.2817\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 144us/sample - loss: 0.4914 - mse: 0.2421 - mae: 0.4914 - mape: 90.2199\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.4911 - mse: 0.2417 - mae: 0.4911 - mape: 90.1580\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 152us/sample - loss: 0.4907 - mse: 0.2414 - mae: 0.4907 - mape: 90.0963\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 212us/sample - loss: 0.4904 - mse: 0.2411 - mae: 0.4904 - mape: 90.0342\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 162us/sample - loss: 0.4900 - mse: 0.2407 - mae: 0.4900 - mape: 89.9722\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 187us/sample - loss: 0.4897 - mse: 0.2404 - mae: 0.4897 - mape: 89.9100\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 165us/sample - loss: 0.4894 - mse: 0.2401 - mae: 0.4894 - mape: 89.8479\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 143us/sample - loss: 0.4890 - mse: 0.2397 - mae: 0.4890 - mape: 89.7856\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 118us/sample - loss: 0.4887 - mse: 0.2394 - mae: 0.4887 - mape: 89.7231\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 0s 112us/sample - loss: 0.4884 - mse: 0.2391 - mae: 0.4884 - mape: 89.6605\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 126us/sample - loss: 0.4880 - mse: 0.2388 - mae: 0.4880 - mape: 89.5980\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 125us/sample - loss: 0.4877 - mse: 0.2384 - mae: 0.4877 - mape: 89.5352\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 124us/sample - loss: 0.4873 - mse: 0.2381 - mae: 0.4873 - mape: 89.4724\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 111us/sample - loss: 0.4870 - mse: 0.2378 - mae: 0.4870 - mape: 89.4095\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 144us/sample - loss: 0.4866 - mse: 0.2374 - mae: 0.4866 - mape: 89.3465\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 203us/sample - loss: 0.4863 - mse: 0.2371 - mae: 0.4863 - mape: 89.2833\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 194us/sample - loss: 0.4860 - mse: 0.2368 - mae: 0.4860 - mape: 89.2202\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 168us/sample - loss: 0.4856 - mse: 0.2364 - mae: 0.4856 - mape: 89.1571\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 164us/sample - loss: 0.4853 - mse: 0.2361 - mae: 0.4853 - mape: 89.0936\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 122us/sample - loss: 0.4849 - mse: 0.2358 - mae: 0.4849 - mape: 89.0299\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 142us/sample - loss: 0.4846 - mse: 0.2354 - mae: 0.4846 - mape: 88.9666\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 175us/sample - loss: 0.4842 - mse: 0.2351 - mae: 0.4842 - mape: 88.9029\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 195us/sample - loss: 0.4839 - mse: 0.2347 - mae: 0.4839 - mape: 88.8391\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 158us/sample - loss: 0.4835 - mse: 0.2344 - mae: 0.4835 - mape: 88.7753\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 150us/sample - loss: 0.4832 - mse: 0.2341 - mae: 0.4832 - mape: 88.7111\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 186us/sample - loss: 0.4828 - mse: 0.2337 - mae: 0.4828 - mape: 88.6470\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 158us/sample - loss: 0.4825 - mse: 0.2334 - mae: 0.4825 - mape: 88.5830\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 5ms/sample - loss: 0.5434 - mse: 0.3134 - mae: 0.5434 - mape: 96.7725\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 159us/sample - loss: 0.5430 - mse: 0.3130 - mae: 0.5430 - mape: 96.7031\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 182us/sample - loss: 0.5426 - mse: 0.3126 - mae: 0.5426 - mape: 96.6340\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 238us/sample - loss: 0.5423 - mse: 0.3122 - mae: 0.5423 - mape: 96.5654\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 177us/sample - loss: 0.5419 - mse: 0.3118 - mae: 0.5419 - mape: 96.4959\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 152us/sample - loss: 0.5415 - mse: 0.3115 - mae: 0.5415 - mape: 96.4260\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 172us/sample - loss: 0.5411 - mse: 0.3110 - mae: 0.5411 - mape: 96.3571\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 199us/sample - loss: 0.5408 - mse: 0.3107 - mae: 0.5408 - mape: 96.2876\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 133us/sample - loss: 0.5404 - mse: 0.3102 - mae: 0.5404 - mape: 96.2191\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 131us/sample - loss: 0.5400 - mse: 0.3099 - mae: 0.5400 - mape: 96.1492\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 142us/sample - loss: 0.5397 - mse: 0.3094 - mae: 0.5397 - mape: 96.0811\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 128us/sample - loss: 0.5393 - mse: 0.3090 - mae: 0.5393 - mape: 96.0116\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 133us/sample - loss: 0.5389 - mse: 0.3087 - mae: 0.5389 - mape: 95.9425\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 122us/sample - loss: 0.5386 - mse: 0.3083 - mae: 0.5386 - mape: 95.8734\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 132us/sample - loss: 0.5382 - mse: 0.3079 - mae: 0.5382 - mape: 95.8031\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 143us/sample - loss: 0.5378 - mse: 0.3075 - mae: 0.5378 - mape: 95.7347\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 195us/sample - loss: 0.5374 - mse: 0.3071 - mae: 0.5374 - mape: 95.6653\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 134us/sample - loss: 0.5371 - mse: 0.3067 - mae: 0.5371 - mape: 95.5962\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 207us/sample - loss: 0.5367 - mse: 0.3063 - mae: 0.5367 - mape: 95.5267\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 142us/sample - loss: 0.5363 - mse: 0.3059 - mae: 0.5363 - mape: 95.4577\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 126us/sample - loss: 0.5360 - mse: 0.3055 - mae: 0.5360 - mape: 95.3885\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 118us/sample - loss: 0.5356 - mse: 0.3051 - mae: 0.5356 - mape: 95.3188\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 145us/sample - loss: 0.5352 - mse: 0.3047 - mae: 0.5352 - mape: 95.2493\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 130us/sample - loss: 0.5349 - mse: 0.3043 - mae: 0.5349 - mape: 95.1805\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 119us/sample - loss: 0.5345 - mse: 0.3039 - mae: 0.5345 - mape: 95.1105\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 130us/sample - loss: 0.5341 - mse: 0.3035 - mae: 0.5341 - mape: 95.0419\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 188us/sample - loss: 0.5337 - mse: 0.3031 - mae: 0.5337 - mape: 94.9724\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 167us/sample - loss: 0.5334 - mse: 0.3027 - mae: 0.5334 - mape: 94.9023\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 134us/sample - loss: 0.5330 - mse: 0.3023 - mae: 0.5330 - mape: 94.8329\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 153us/sample - loss: 0.5326 - mse: 0.3019 - mae: 0.5326 - mape: 94.7628\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 140us/sample - loss: 0.5323 - mse: 0.3015 - mae: 0.5323 - mape: 94.6929\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 118us/sample - loss: 0.5319 - mse: 0.3011 - mae: 0.5319 - mape: 94.6246\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 132us/sample - loss: 0.5315 - mse: 0.3007 - mae: 0.5315 - mape: 94.5538\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 149us/sample - loss: 0.5311 - mse: 0.3003 - mae: 0.5311 - mape: 94.4851\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 177us/sample - loss: 0.5308 - mse: 0.2999 - mae: 0.5308 - mape: 94.4154\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 144us/sample - loss: 0.5304 - mse: 0.2995 - mae: 0.5304 - mape: 94.3447\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 133us/sample - loss: 0.5300 - mse: 0.2991 - mae: 0.5300 - mape: 94.2747\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 187us/sample - loss: 0.5296 - mse: 0.2987 - mae: 0.5296 - mape: 94.2045\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 118us/sample - loss: 0.5293 - mse: 0.2983 - mae: 0.5293 - mape: 94.1347\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 116us/sample - loss: 0.5289 - mse: 0.2979 - mae: 0.5289 - mape: 94.0645\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 170us/sample - loss: 0.5285 - mse: 0.2975 - mae: 0.5285 - mape: 93.9949\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 209us/sample - loss: 0.5282 - mse: 0.2971 - mae: 0.5282 - mape: 93.9243\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 144us/sample - loss: 0.5278 - mse: 0.2968 - mae: 0.5278 - mape: 93.8541\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 156us/sample - loss: 0.5274 - mse: 0.2964 - mae: 0.5274 - mape: 93.7841\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 147us/sample - loss: 0.5270 - mse: 0.2960 - mae: 0.5270 - mape: 93.7137\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 131us/sample - loss: 0.5267 - mse: 0.2956 - mae: 0.5267 - mape: 93.6430\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 149us/sample - loss: 0.5263 - mse: 0.2952 - mae: 0.5263 - mape: 93.5729\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 341us/sample - loss: 0.5259 - mse: 0.2948 - mae: 0.5259 - mape: 93.5026\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 173us/sample - loss: 0.5255 - mse: 0.2944 - mae: 0.5255 - mape: 93.4313\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 183us/sample - loss: 0.5251 - mse: 0.2940 - mae: 0.5251 - mape: 93.3610\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 201us/sample - loss: 0.5248 - mse: 0.2936 - mae: 0.5248 - mape: 93.2901\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 169us/sample - loss: 0.5244 - mse: 0.2932 - mae: 0.5244 - mape: 93.2197\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 175us/sample - loss: 0.5240 - mse: 0.2928 - mae: 0.5240 - mape: 93.1486\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 238us/sample - loss: 0.5236 - mse: 0.2924 - mae: 0.5236 - mape: 93.0776\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 166us/sample - loss: 0.5233 - mse: 0.2920 - mae: 0.5233 - mape: 93.0073\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 203us/sample - loss: 0.5229 - mse: 0.2916 - mae: 0.5229 - mape: 92.9362\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 180us/sample - loss: 0.5225 - mse: 0.2912 - mae: 0.5225 - mape: 92.8659\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 184us/sample - loss: 0.5221 - mse: 0.2908 - mae: 0.5221 - mape: 92.7937\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 165us/sample - loss: 0.5217 - mse: 0.2904 - mae: 0.5217 - mape: 92.7227\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 444us/sample - loss: 0.5214 - mse: 0.2900 - mae: 0.5214 - mape: 92.6516\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 168us/sample - loss: 0.5210 - mse: 0.2896 - mae: 0.5210 - mape: 92.5796\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 161us/sample - loss: 0.5206 - mse: 0.2892 - mae: 0.5206 - mape: 92.5090\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 154us/sample - loss: 0.5202 - mse: 0.2888 - mae: 0.5202 - mape: 92.4378\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 152us/sample - loss: 0.5198 - mse: 0.2884 - mae: 0.5198 - mape: 92.3664\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 131us/sample - loss: 0.5194 - mse: 0.2880 - mae: 0.5194 - mape: 92.2947\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 154us/sample - loss: 0.5191 - mse: 0.2876 - mae: 0.5191 - mape: 92.2224\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 160us/sample - loss: 0.5187 - mse: 0.2872 - mae: 0.5187 - mape: 92.1512\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 187us/sample - loss: 0.5183 - mse: 0.2868 - mae: 0.5183 - mape: 92.0788\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 185us/sample - loss: 0.5179 - mse: 0.2864 - mae: 0.5179 - mape: 92.0075\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 136us/sample - loss: 0.5175 - mse: 0.2860 - mae: 0.5175 - mape: 91.9355\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 141us/sample - loss: 0.5171 - mse: 0.2856 - mae: 0.5171 - mape: 91.8635\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 132us/sample - loss: 0.5168 - mse: 0.2852 - mae: 0.5168 - mape: 91.7912\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 118us/sample - loss: 0.5164 - mse: 0.2848 - mae: 0.5164 - mape: 91.7188\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 119us/sample - loss: 0.5160 - mse: 0.2844 - mae: 0.5160 - mape: 91.6460\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 112us/sample - loss: 0.5156 - mse: 0.2840 - mae: 0.5156 - mape: 91.5738\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 116us/sample - loss: 0.5152 - mse: 0.2836 - mae: 0.5152 - mape: 91.5018\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 119us/sample - loss: 0.5148 - mse: 0.2832 - mae: 0.5148 - mape: 91.4297\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 121us/sample - loss: 0.5144 - mse: 0.2828 - mae: 0.5144 - mape: 91.3554\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 137us/sample - loss: 0.5140 - mse: 0.2824 - mae: 0.5140 - mape: 91.2831\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 213us/sample - loss: 0.5137 - mse: 0.2820 - mae: 0.5137 - mape: 91.2094\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 137us/sample - loss: 0.5133 - mse: 0.2816 - mae: 0.5133 - mape: 91.1369\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 147us/sample - loss: 0.5129 - mse: 0.2812 - mae: 0.5129 - mape: 91.0639\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 145us/sample - loss: 0.5125 - mse: 0.2808 - mae: 0.5125 - mape: 90.9903\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 132us/sample - loss: 0.5121 - mse: 0.2804 - mae: 0.5121 - mape: 90.9178\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 134us/sample - loss: 0.5117 - mse: 0.2800 - mae: 0.5117 - mape: 90.8442\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 151us/sample - loss: 0.5113 - mse: 0.2796 - mae: 0.5113 - mape: 90.7707\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 213us/sample - loss: 0.5109 - mse: 0.2792 - mae: 0.5109 - mape: 90.6967\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 134us/sample - loss: 0.5105 - mse: 0.2788 - mae: 0.5105 - mape: 90.6240\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 118us/sample - loss: 0.5101 - mse: 0.2784 - mae: 0.5101 - mape: 90.5503\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 137us/sample - loss: 0.5097 - mse: 0.2780 - mae: 0.5097 - mape: 90.4756\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 136us/sample - loss: 0.5093 - mse: 0.2776 - mae: 0.5093 - mape: 90.4025\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 131us/sample - loss: 0.5089 - mse: 0.2772 - mae: 0.5089 - mape: 90.3279\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 125us/sample - loss: 0.5086 - mse: 0.2768 - mae: 0.5086 - mape: 90.2538\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 115us/sample - loss: 0.5082 - mse: 0.2764 - mae: 0.5082 - mape: 90.1794\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 159us/sample - loss: 0.5078 - mse: 0.2760 - mae: 0.5078 - mape: 90.1050\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 205us/sample - loss: 0.5074 - mse: 0.2756 - mae: 0.5074 - mape: 90.0309\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 161us/sample - loss: 0.5070 - mse: 0.2752 - mae: 0.5070 - mape: 89.9565\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 147us/sample - loss: 0.5066 - mse: 0.2748 - mae: 0.5066 - mape: 89.8820\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 161us/sample - loss: 0.5062 - mse: 0.2744 - mae: 0.5062 - mape: 89.8071\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 129us/sample - loss: 0.5058 - mse: 0.2740 - mae: 0.5058 - mape: 89.7321\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 80 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 5ms/sample - loss: 0.6214 - mse: 0.5072 - mae: 0.6214 - mape: 94.8127\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6213 - mse: 0.5068 - mae: 0.6213 - mape: 95.0512\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6211 - mse: 0.5065 - mae: 0.6211 - mape: 95.2267\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6209 - mse: 0.5062 - mae: 0.6209 - mape: 95.4614\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6208 - mse: 0.5058 - mae: 0.6208 - mape: 95.6550\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6206 - mse: 0.5055 - mae: 0.6206 - mape: 95.8682\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6205 - mse: 0.5051 - mae: 0.6205 - mape: 96.0697\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 0.6203 - mse: 0.5047 - mae: 0.6203 - mape: 96.2625\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 251us/sample - loss: 0.6202 - mse: 0.5044 - mae: 0.6202 - mape: 96.4949\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 227us/sample - loss: 0.6200 - mse: 0.5040 - mae: 0.6200 - mape: 96.6941\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 173us/sample - loss: 0.6199 - mse: 0.5037 - mae: 0.6199 - mape: 96.9053\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.6197 - mse: 0.5033 - mae: 0.6197 - mape: 97.1194\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6196 - mse: 0.5030 - mae: 0.6196 - mape: 97.3365\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6194 - mse: 0.5027 - mae: 0.6194 - mape: 97.5539\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6193 - mse: 0.5023 - mae: 0.6193 - mape: 97.7548\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6192 - mse: 0.5020 - mae: 0.6192 - mape: 97.9724\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.6190 - mse: 0.5016 - mae: 0.6190 - mape: 98.1935\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6189 - mse: 0.5013 - mae: 0.6189 - mape: 98.4028\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.6187 - mse: 0.5010 - mae: 0.6187 - mape: 98.6411\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 215us/sample - loss: 0.6186 - mse: 0.5006 - mae: 0.6186 - mape: 98.8415\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.6185 - mse: 0.5003 - mae: 0.6185 - mape: 99.0410\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.6183 - mse: 0.4999 - mae: 0.6183 - mape: 99.2741\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.6182 - mse: 0.4996 - mae: 0.6182 - mape: 99.4895\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 214us/sample - loss: 0.6180 - mse: 0.4992 - mae: 0.6180 - mape: 99.7119\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.6179 - mse: 0.4989 - mae: 0.6179 - mape: 99.9152\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6177 - mse: 0.4986 - mae: 0.6177 - mape: 100.1226\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.6176 - mse: 0.4982 - mae: 0.6176 - mape: 100.3634\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 293us/sample - loss: 0.6175 - mse: 0.4979 - mae: 0.6175 - mape: 100.5753\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 204us/sample - loss: 0.6173 - mse: 0.4975 - mae: 0.6173 - mape: 100.7984\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.6172 - mse: 0.4972 - mae: 0.6172 - mape: 101.0031\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6170 - mse: 0.4968 - mae: 0.6170 - mape: 101.2212\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6169 - mse: 0.4965 - mae: 0.6169 - mape: 101.4742\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 176us/sample - loss: 0.6167 - mse: 0.4961 - mae: 0.6167 - mape: 101.6945\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 203us/sample - loss: 0.6166 - mse: 0.4958 - mae: 0.6166 - mape: 101.8706\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.6165 - mse: 0.4955 - mae: 0.6165 - mape: 102.1002\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6163 - mse: 0.4951 - mae: 0.6163 - mape: 102.3398\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.6162 - mse: 0.4948 - mae: 0.6162 - mape: 102.5123\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6160 - mse: 0.4944 - mae: 0.6160 - mape: 102.7160\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6159 - mse: 0.4941 - mae: 0.6159 - mape: 102.9699\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.6157 - mse: 0.4938 - mae: 0.6157 - mape: 103.1675\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6156 - mse: 0.4934 - mae: 0.6156 - mape: 103.3926\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6155 - mse: 0.4931 - mae: 0.6155 - mape: 103.6377\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6153 - mse: 0.4927 - mae: 0.6153 - mape: 103.8249\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6152 - mse: 0.4924 - mae: 0.6152 - mape: 104.0429\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6150 - mse: 0.4921 - mae: 0.6150 - mape: 104.2839\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6149 - mse: 0.4917 - mae: 0.6149 - mape: 104.4976\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.6147 - mse: 0.4914 - mae: 0.6147 - mape: 104.7271\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.6146 - mse: 0.4910 - mae: 0.6146 - mape: 104.9419\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6144 - mse: 0.4907 - mae: 0.6144 - mape: 105.1762\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6143 - mse: 0.4903 - mae: 0.6143 - mape: 105.4002\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6142 - mse: 0.4900 - mae: 0.6142 - mape: 105.6381\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6140 - mse: 0.4896 - mae: 0.6140 - mape: 105.8113\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6139 - mse: 0.4893 - mae: 0.6139 - mape: 106.0479\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.6137 - mse: 0.4890 - mae: 0.6137 - mape: 106.2612\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6136 - mse: 0.4886 - mae: 0.6136 - mape: 106.4681\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6134 - mse: 0.4883 - mae: 0.6134 - mape: 106.6860\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.6133 - mse: 0.4879 - mae: 0.6133 - mape: 106.8994\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6132 - mse: 0.4876 - mae: 0.6132 - mape: 107.1409\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6130 - mse: 0.4873 - mae: 0.6130 - mape: 107.3503\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6129 - mse: 0.4869 - mae: 0.6129 - mape: 107.5606\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 202us/sample - loss: 0.6127 - mse: 0.4866 - mae: 0.6127 - mape: 107.7468\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6126 - mse: 0.4863 - mae: 0.6126 - mape: 107.9833\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6124 - mse: 0.4859 - mae: 0.6124 - mape: 108.2255\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6123 - mse: 0.4856 - mae: 0.6123 - mape: 108.4296\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6121 - mse: 0.4852 - mae: 0.6121 - mape: 108.6597\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6120 - mse: 0.4849 - mae: 0.6120 - mape: 108.8866\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.6118 - mse: 0.4845 - mae: 0.6118 - mape: 109.0985\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.6117 - mse: 0.4842 - mae: 0.6117 - mape: 109.3543\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6115 - mse: 0.4838 - mae: 0.6115 - mape: 109.5527\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.6114 - mse: 0.4835 - mae: 0.6114 - mape: 109.7429\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.6113 - mse: 0.4831 - mae: 0.6113 - mape: 110.0134\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6111 - mse: 0.4828 - mae: 0.6111 - mape: 110.2255\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.6109 - mse: 0.4824 - mae: 0.6109 - mape: 110.4895\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6108 - mse: 0.4821 - mae: 0.6108 - mape: 110.6935\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6106 - mse: 0.4817 - mae: 0.6106 - mape: 110.9065\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6105 - mse: 0.4814 - mae: 0.6105 - mape: 111.1335\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6104 - mse: 0.4810 - mae: 0.6104 - mape: 111.3744\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6102 - mse: 0.4807 - mae: 0.6102 - mape: 111.5741\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.6100 - mse: 0.4803 - mae: 0.6100 - mape: 111.7951\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6099 - mse: 0.4800 - mae: 0.6099 - mape: 112.0629\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6097 - mse: 0.4796 - mae: 0.6097 - mape: 112.3061\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6096 - mse: 0.4792 - mae: 0.6096 - mape: 112.4982\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6094 - mse: 0.4789 - mae: 0.6094 - mape: 112.7878\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6093 - mse: 0.4785 - mae: 0.6093 - mape: 113.0050\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6091 - mse: 0.4782 - mae: 0.6091 - mape: 113.2659\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 243us/sample - loss: 0.6090 - mse: 0.4778 - mae: 0.6090 - mape: 113.4628\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6088 - mse: 0.4775 - mae: 0.6088 - mape: 113.6846\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.6087 - mse: 0.4771 - mae: 0.6087 - mape: 113.8696\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6085 - mse: 0.4768 - mae: 0.6085 - mape: 114.1183\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6084 - mse: 0.4764 - mae: 0.6084 - mape: 114.3433\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6082 - mse: 0.4761 - mae: 0.6082 - mape: 114.5636\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6081 - mse: 0.4758 - mae: 0.6081 - mape: 114.8080\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.6080 - mse: 0.4754 - mae: 0.6080 - mape: 115.0294\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 190us/sample - loss: 0.6078 - mse: 0.4751 - mae: 0.6078 - mape: 115.2402\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6077 - mse: 0.4747 - mae: 0.6077 - mape: 115.4795\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6075 - mse: 0.4744 - mae: 0.6075 - mape: 115.6520\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6074 - mse: 0.4740 - mae: 0.6074 - mape: 115.9395\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6072 - mse: 0.4737 - mae: 0.6072 - mape: 116.1241\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6071 - mse: 0.4733 - mae: 0.6071 - mape: 116.3660\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.6069 - mse: 0.4730 - mae: 0.6069 - mape: 116.6127\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 3/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 82 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 5ms/sample - loss: 0.4689 - mse: 0.2318 - mae: 0.4689 - mape: 100.6475\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 119us/sample - loss: 0.4685 - mse: 0.2315 - mae: 0.4685 - mape: 100.5713\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 124us/sample - loss: 0.4682 - mse: 0.2312 - mae: 0.4682 - mape: 100.4936\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 108us/sample - loss: 0.4679 - mse: 0.2309 - mae: 0.4679 - mape: 100.4166\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 104us/sample - loss: 0.4675 - mse: 0.2306 - mae: 0.4675 - mape: 100.3403\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 108us/sample - loss: 0.4672 - mse: 0.2303 - mae: 0.4672 - mape: 100.2637\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 112us/sample - loss: 0.4669 - mse: 0.2300 - mae: 0.4669 - mape: 100.1862\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 131us/sample - loss: 0.4665 - mse: 0.2296 - mae: 0.4665 - mape: 100.1091\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4662 - mse: 0.2293 - mae: 0.4662 - mape: 100.0323\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 126us/sample - loss: 0.4658 - mse: 0.2290 - mae: 0.4658 - mape: 99.9556\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 132us/sample - loss: 0.4655 - mse: 0.2287 - mae: 0.4655 - mape: 99.8783\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.4652 - mse: 0.2284 - mae: 0.4652 - mape: 99.8002\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 110us/sample - loss: 0.4648 - mse: 0.2281 - mae: 0.4648 - mape: 99.7237\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 106us/sample - loss: 0.4645 - mse: 0.2278 - mae: 0.4645 - mape: 99.6466\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 106us/sample - loss: 0.4642 - mse: 0.2275 - mae: 0.4642 - mape: 99.5688\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 112us/sample - loss: 0.4638 - mse: 0.2272 - mae: 0.4638 - mape: 99.4921\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 113us/sample - loss: 0.4635 - mse: 0.2269 - mae: 0.4635 - mape: 99.4150\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 115us/sample - loss: 0.4631 - mse: 0.2266 - mae: 0.4631 - mape: 99.3376\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 108us/sample - loss: 0.4628 - mse: 0.2262 - mae: 0.4628 - mape: 99.2603\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 111us/sample - loss: 0.4625 - mse: 0.2259 - mae: 0.4625 - mape: 99.1827\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 135us/sample - loss: 0.4621 - mse: 0.2256 - mae: 0.4621 - mape: 99.1048\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 191us/sample - loss: 0.4618 - mse: 0.2253 - mae: 0.4618 - mape: 99.0283\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 142us/sample - loss: 0.4614 - mse: 0.2250 - mae: 0.4614 - mape: 98.9497\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 147us/sample - loss: 0.4611 - mse: 0.2247 - mae: 0.4611 - mape: 98.8726\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.4608 - mse: 0.2244 - mae: 0.4608 - mape: 98.7941\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 114us/sample - loss: 0.4604 - mse: 0.2241 - mae: 0.4604 - mape: 98.7176\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 109us/sample - loss: 0.4601 - mse: 0.2238 - mae: 0.4601 - mape: 98.6401\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4597 - mse: 0.2235 - mae: 0.4597 - mape: 98.5620\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 239us/sample - loss: 0.4594 - mse: 0.2232 - mae: 0.4594 - mape: 98.4844\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.4591 - mse: 0.2228 - mae: 0.4591 - mape: 98.4062\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.4587 - mse: 0.2225 - mae: 0.4587 - mape: 98.3288\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 149us/sample - loss: 0.4584 - mse: 0.2222 - mae: 0.4584 - mape: 98.2509\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 109us/sample - loss: 0.4580 - mse: 0.2219 - mae: 0.4580 - mape: 98.1732\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4577 - mse: 0.2216 - mae: 0.4577 - mape: 98.0949\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.4573 - mse: 0.2213 - mae: 0.4573 - mape: 98.0171\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.4570 - mse: 0.2210 - mae: 0.4570 - mape: 97.9383\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4567 - mse: 0.2207 - mae: 0.4567 - mape: 97.8607\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 152us/sample - loss: 0.4563 - mse: 0.2204 - mae: 0.4563 - mape: 97.7819\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.4560 - mse: 0.2201 - mae: 0.4560 - mape: 97.7052\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4556 - mse: 0.2198 - mae: 0.4556 - mape: 97.6264\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 110us/sample - loss: 0.4553 - mse: 0.2195 - mae: 0.4553 - mape: 97.5470\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 121us/sample - loss: 0.4549 - mse: 0.2192 - mae: 0.4549 - mape: 97.4684\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 137us/sample - loss: 0.4546 - mse: 0.2188 - mae: 0.4546 - mape: 97.3911\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 138us/sample - loss: 0.4542 - mse: 0.2185 - mae: 0.4542 - mape: 97.3112\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 189us/sample - loss: 0.4539 - mse: 0.2182 - mae: 0.4539 - mape: 97.2332\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 224us/sample - loss: 0.4536 - mse: 0.2179 - mae: 0.4536 - mape: 97.1550\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 235us/sample - loss: 0.4532 - mse: 0.2176 - mae: 0.4532 - mape: 97.0761\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 165us/sample - loss: 0.4529 - mse: 0.2173 - mae: 0.4529 - mape: 96.9967\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 151us/sample - loss: 0.4525 - mse: 0.2170 - mae: 0.4525 - mape: 96.9174\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.4522 - mse: 0.2167 - mae: 0.4522 - mape: 96.8380\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 140us/sample - loss: 0.4518 - mse: 0.2164 - mae: 0.4518 - mape: 96.7589\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 216us/sample - loss: 0.4515 - mse: 0.2161 - mae: 0.4515 - mape: 96.6794\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 168us/sample - loss: 0.4511 - mse: 0.2158 - mae: 0.4511 - mape: 96.6003\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 174us/sample - loss: 0.4508 - mse: 0.2154 - mae: 0.4508 - mape: 96.5209\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 163us/sample - loss: 0.4504 - mse: 0.2151 - mae: 0.4504 - mape: 96.4419\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 137us/sample - loss: 0.4501 - mse: 0.2148 - mae: 0.4501 - mape: 96.3616\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 143us/sample - loss: 0.4497 - mse: 0.2145 - mae: 0.4497 - mape: 96.2816\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 149us/sample - loss: 0.4494 - mse: 0.2142 - mae: 0.4494 - mape: 96.2019\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 217us/sample - loss: 0.4490 - mse: 0.2139 - mae: 0.4490 - mape: 96.1220\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 149us/sample - loss: 0.4487 - mse: 0.2136 - mae: 0.4487 - mape: 96.0423\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.4483 - mse: 0.2133 - mae: 0.4483 - mape: 95.9619\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 185us/sample - loss: 0.4480 - mse: 0.2130 - mae: 0.4480 - mape: 95.8826\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.4476 - mse: 0.2127 - mae: 0.4476 - mape: 95.8016\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 120us/sample - loss: 0.4473 - mse: 0.2124 - mae: 0.4473 - mape: 95.7206\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 114us/sample - loss: 0.4469 - mse: 0.2120 - mae: 0.4469 - mape: 95.6408\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 115us/sample - loss: 0.4466 - mse: 0.2117 - mae: 0.4466 - mape: 95.5596\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 125us/sample - loss: 0.4462 - mse: 0.2114 - mae: 0.4462 - mape: 95.4793\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 118us/sample - loss: 0.4459 - mse: 0.2111 - mae: 0.4459 - mape: 95.3985\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 113us/sample - loss: 0.4455 - mse: 0.2108 - mae: 0.4455 - mape: 95.3164\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 138us/sample - loss: 0.4451 - mse: 0.2105 - mae: 0.4451 - mape: 95.2362\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.4448 - mse: 0.2102 - mae: 0.4448 - mape: 95.1550\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 143us/sample - loss: 0.4444 - mse: 0.2099 - mae: 0.4444 - mape: 95.0744\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.4441 - mse: 0.2096 - mae: 0.4441 - mape: 94.9916\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 142us/sample - loss: 0.4437 - mse: 0.2092 - mae: 0.4437 - mape: 94.9105\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 118us/sample - loss: 0.4434 - mse: 0.2089 - mae: 0.4434 - mape: 94.8289\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 117us/sample - loss: 0.4430 - mse: 0.2086 - mae: 0.4430 - mape: 94.7464\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4426 - mse: 0.2083 - mae: 0.4426 - mape: 94.6649\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 197us/sample - loss: 0.4423 - mse: 0.2080 - mae: 0.4423 - mape: 94.5832\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 130us/sample - loss: 0.4419 - mse: 0.2077 - mae: 0.4419 - mape: 94.5004\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 151us/sample - loss: 0.4416 - mse: 0.2074 - mae: 0.4416 - mape: 94.4185\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 127us/sample - loss: 0.4412 - mse: 0.2071 - mae: 0.4412 - mape: 94.3358\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 118us/sample - loss: 0.4408 - mse: 0.2067 - mae: 0.4408 - mape: 94.2532\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 112us/sample - loss: 0.4405 - mse: 0.2064 - mae: 0.4405 - mape: 94.1700\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 123us/sample - loss: 0.4401 - mse: 0.2061 - mae: 0.4401 - mape: 94.0880\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 182us/sample - loss: 0.4397 - mse: 0.2058 - mae: 0.4397 - mape: 94.0039\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 161us/sample - loss: 0.4394 - mse: 0.2055 - mae: 0.4394 - mape: 93.9209\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 122us/sample - loss: 0.4390 - mse: 0.2052 - mae: 0.4390 - mape: 93.8382\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 136us/sample - loss: 0.4387 - mse: 0.2049 - mae: 0.4387 - mape: 93.7541\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 122us/sample - loss: 0.4383 - mse: 0.2045 - mae: 0.4383 - mape: 93.6704\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 127us/sample - loss: 0.4379 - mse: 0.2042 - mae: 0.4379 - mape: 93.5874\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 177us/sample - loss: 0.4376 - mse: 0.2039 - mae: 0.4376 - mape: 93.5030\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 266us/sample - loss: 0.4372 - mse: 0.2036 - mae: 0.4372 - mape: 93.4197\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 147us/sample - loss: 0.4368 - mse: 0.2033 - mae: 0.4368 - mape: 93.3350\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 155us/sample - loss: 0.4364 - mse: 0.2030 - mae: 0.4364 - mape: 93.2509\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 138us/sample - loss: 0.4361 - mse: 0.2026 - mae: 0.4361 - mape: 93.1667\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 115us/sample - loss: 0.4357 - mse: 0.2023 - mae: 0.4357 - mape: 93.0809\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 138us/sample - loss: 0.4353 - mse: 0.2020 - mae: 0.4353 - mape: 92.9966\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 113us/sample - loss: 0.4350 - mse: 0.2017 - mae: 0.4350 - mape: 92.9122\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 116us/sample - loss: 0.4346 - mse: 0.2014 - mae: 0.4346 - mape: 92.8251\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 108us/sample - loss: 0.4342 - mse: 0.2011 - mae: 0.4342 - mape: 92.7411\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 4/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 72 samples\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 6ms/sample - loss: 0.5757 - mse: 0.3574 - mae: 0.5757 - mape: 94.3353\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 167us/sample - loss: 0.5754 - mse: 0.3570 - mae: 0.5754 - mape: 94.2756\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 263us/sample - loss: 0.5751 - mse: 0.3567 - mae: 0.5751 - mape: 94.2177\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 186us/sample - loss: 0.5748 - mse: 0.3563 - mae: 0.5748 - mape: 94.1589\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 170us/sample - loss: 0.5745 - mse: 0.3559 - mae: 0.5745 - mape: 94.0993\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 232us/sample - loss: 0.5742 - mse: 0.3556 - mae: 0.5742 - mape: 94.0417\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 176us/sample - loss: 0.5738 - mse: 0.3552 - mae: 0.5738 - mape: 93.9814\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 161us/sample - loss: 0.5735 - mse: 0.3548 - mae: 0.5735 - mape: 93.9247\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 158us/sample - loss: 0.5732 - mse: 0.3545 - mae: 0.5732 - mape: 93.8647\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 148us/sample - loss: 0.5729 - mse: 0.3541 - mae: 0.5729 - mape: 93.8055\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 179us/sample - loss: 0.5726 - mse: 0.3537 - mae: 0.5726 - mape: 93.7485\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 145us/sample - loss: 0.5722 - mse: 0.3534 - mae: 0.5722 - mape: 93.6888\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 169us/sample - loss: 0.5719 - mse: 0.3530 - mae: 0.5719 - mape: 93.6297\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 203us/sample - loss: 0.5716 - mse: 0.3527 - mae: 0.5716 - mape: 93.5720\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5713 - mse: 0.3523 - mae: 0.5713 - mape: 93.5123\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 170us/sample - loss: 0.5710 - mse: 0.3519 - mae: 0.5710 - mape: 93.4534\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 150us/sample - loss: 0.5707 - mse: 0.3516 - mae: 0.5707 - mape: 93.3956\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 155us/sample - loss: 0.5703 - mse: 0.3512 - mae: 0.5703 - mape: 93.3356\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 146us/sample - loss: 0.5700 - mse: 0.3508 - mae: 0.5700 - mape: 93.2768\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 160us/sample - loss: 0.5697 - mse: 0.3505 - mae: 0.5697 - mape: 93.2192\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 217us/sample - loss: 0.5694 - mse: 0.3501 - mae: 0.5694 - mape: 93.1583\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 141us/sample - loss: 0.5691 - mse: 0.3497 - mae: 0.5691 - mape: 93.0999\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5687 - mse: 0.3494 - mae: 0.5687 - mape: 93.0409\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5684 - mse: 0.3490 - mae: 0.5684 - mape: 92.9813\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 143us/sample - loss: 0.5681 - mse: 0.3487 - mae: 0.5681 - mape: 92.9226\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 134us/sample - loss: 0.5678 - mse: 0.3483 - mae: 0.5678 - mape: 92.8645\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 169us/sample - loss: 0.5675 - mse: 0.3479 - mae: 0.5675 - mape: 92.8038\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 216us/sample - loss: 0.5672 - mse: 0.3476 - mae: 0.5672 - mape: 92.7441\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 163us/sample - loss: 0.5668 - mse: 0.3472 - mae: 0.5668 - mape: 92.6856\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 136us/sample - loss: 0.5665 - mse: 0.3468 - mae: 0.5665 - mape: 92.6275\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 155us/sample - loss: 0.5662 - mse: 0.3465 - mae: 0.5662 - mape: 92.5665\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 151us/sample - loss: 0.5659 - mse: 0.3461 - mae: 0.5659 - mape: 92.5079\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 122us/sample - loss: 0.5655 - mse: 0.3457 - mae: 0.5655 - mape: 92.4499\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 167us/sample - loss: 0.5652 - mse: 0.3454 - mae: 0.5652 - mape: 92.3888\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 143us/sample - loss: 0.5649 - mse: 0.3450 - mae: 0.5649 - mape: 92.3307\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 229us/sample - loss: 0.5646 - mse: 0.3446 - mae: 0.5646 - mape: 92.2708\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 148us/sample - loss: 0.5643 - mse: 0.3443 - mae: 0.5643 - mape: 92.2104\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 158us/sample - loss: 0.5639 - mse: 0.3439 - mae: 0.5639 - mape: 92.1496\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5636 - mse: 0.3436 - mae: 0.5636 - mape: 92.0892\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 148us/sample - loss: 0.5633 - mse: 0.3432 - mae: 0.5633 - mape: 92.0311\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 128us/sample - loss: 0.5630 - mse: 0.3428 - mae: 0.5630 - mape: 91.9719\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 244us/sample - loss: 0.5626 - mse: 0.3425 - mae: 0.5626 - mape: 91.9115\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 276us/sample - loss: 0.5623 - mse: 0.3421 - mae: 0.5623 - mape: 91.8510\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 174us/sample - loss: 0.5620 - mse: 0.3417 - mae: 0.5620 - mape: 91.7917\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 202us/sample - loss: 0.5617 - mse: 0.3414 - mae: 0.5617 - mape: 91.7313\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 174us/sample - loss: 0.5614 - mse: 0.3410 - mae: 0.5614 - mape: 91.6722\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 162us/sample - loss: 0.5610 - mse: 0.3406 - mae: 0.5610 - mape: 91.6122\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5607 - mse: 0.3403 - mae: 0.5607 - mape: 91.5504\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 167us/sample - loss: 0.5604 - mse: 0.3399 - mae: 0.5604 - mape: 91.4904\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 165us/sample - loss: 0.5601 - mse: 0.3395 - mae: 0.5601 - mape: 91.4305\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 189us/sample - loss: 0.5597 - mse: 0.3392 - mae: 0.5597 - mape: 91.3706\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 196us/sample - loss: 0.5594 - mse: 0.3388 - mae: 0.5594 - mape: 91.3106\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 196us/sample - loss: 0.5591 - mse: 0.3384 - mae: 0.5591 - mape: 91.2490\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 210us/sample - loss: 0.5587 - mse: 0.3381 - mae: 0.5587 - mape: 91.1874\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 269us/sample - loss: 0.5584 - mse: 0.3377 - mae: 0.5584 - mape: 91.1281\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 174us/sample - loss: 0.5581 - mse: 0.3374 - mae: 0.5581 - mape: 91.0665\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 168us/sample - loss: 0.5578 - mse: 0.3370 - mae: 0.5578 - mape: 91.0059\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 182us/sample - loss: 0.5574 - mse: 0.3366 - mae: 0.5574 - mape: 90.9451\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 286us/sample - loss: 0.5571 - mse: 0.3362 - mae: 0.5571 - mape: 90.8850\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 187us/sample - loss: 0.5568 - mse: 0.3359 - mae: 0.5568 - mape: 90.8225\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 159us/sample - loss: 0.5564 - mse: 0.3355 - mae: 0.5564 - mape: 90.7631\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 158us/sample - loss: 0.5561 - mse: 0.3351 - mae: 0.5561 - mape: 90.7020\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 158us/sample - loss: 0.5558 - mse: 0.3348 - mae: 0.5558 - mape: 90.6412\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 125us/sample - loss: 0.5555 - mse: 0.3344 - mae: 0.5555 - mape: 90.5804\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 158us/sample - loss: 0.5551 - mse: 0.3340 - mae: 0.5551 - mape: 90.5193\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 205us/sample - loss: 0.5548 - mse: 0.3337 - mae: 0.5548 - mape: 90.4567\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 160us/sample - loss: 0.5545 - mse: 0.3333 - mae: 0.5545 - mape: 90.3959\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 141us/sample - loss: 0.5541 - mse: 0.3329 - mae: 0.5541 - mape: 90.3343\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 154us/sample - loss: 0.5538 - mse: 0.3326 - mae: 0.5538 - mape: 90.2723\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 151us/sample - loss: 0.5535 - mse: 0.3322 - mae: 0.5535 - mape: 90.2105\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 138us/sample - loss: 0.5531 - mse: 0.3318 - mae: 0.5531 - mape: 90.1486\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 151us/sample - loss: 0.5528 - mse: 0.3315 - mae: 0.5528 - mape: 90.0862\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 220us/sample - loss: 0.5525 - mse: 0.3311 - mae: 0.5525 - mape: 90.0255\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 162us/sample - loss: 0.5521 - mse: 0.3307 - mae: 0.5521 - mape: 89.9639\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 148us/sample - loss: 0.5518 - mse: 0.3304 - mae: 0.5518 - mape: 89.9001\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 144us/sample - loss: 0.5515 - mse: 0.3300 - mae: 0.5515 - mape: 89.8392\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 156us/sample - loss: 0.5511 - mse: 0.3296 - mae: 0.5511 - mape: 89.7763\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 118us/sample - loss: 0.5508 - mse: 0.3292 - mae: 0.5508 - mape: 89.7144\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 122us/sample - loss: 0.5504 - mse: 0.3289 - mae: 0.5504 - mape: 89.6519\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 151us/sample - loss: 0.5501 - mse: 0.3285 - mae: 0.5501 - mape: 89.5890\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 219us/sample - loss: 0.5498 - mse: 0.3281 - mae: 0.5498 - mape: 89.5282\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 148us/sample - loss: 0.5494 - mse: 0.3277 - mae: 0.5494 - mape: 89.4651\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 150us/sample - loss: 0.5491 - mse: 0.3274 - mae: 0.5491 - mape: 89.4022\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 219us/sample - loss: 0.5488 - mse: 0.3270 - mae: 0.5488 - mape: 89.3394\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 132us/sample - loss: 0.5484 - mse: 0.3266 - mae: 0.5484 - mape: 89.2768\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 139us/sample - loss: 0.5481 - mse: 0.3262 - mae: 0.5481 - mape: 89.2144\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 204us/sample - loss: 0.5477 - mse: 0.3259 - mae: 0.5477 - mape: 89.1500\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 162us/sample - loss: 0.5474 - mse: 0.3255 - mae: 0.5474 - mape: 89.0878\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 205us/sample - loss: 0.5471 - mse: 0.3251 - mae: 0.5471 - mape: 89.0235\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 217us/sample - loss: 0.5467 - mse: 0.3248 - mae: 0.5467 - mape: 88.9589\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 189us/sample - loss: 0.5464 - mse: 0.3244 - mae: 0.5464 - mape: 88.8967\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 182us/sample - loss: 0.5460 - mse: 0.3240 - mae: 0.5460 - mape: 88.8328\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 309us/sample - loss: 0.5457 - mse: 0.3236 - mae: 0.5457 - mape: 88.7695\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 243us/sample - loss: 0.5453 - mse: 0.3233 - mae: 0.5453 - mape: 88.7045\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 188us/sample - loss: 0.5450 - mse: 0.3229 - mae: 0.5450 - mape: 88.6418\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 202us/sample - loss: 0.5446 - mse: 0.3225 - mae: 0.5446 - mape: 88.5763\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 168us/sample - loss: 0.5443 - mse: 0.3221 - mae: 0.5443 - mape: 88.5135\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 170us/sample - loss: 0.5440 - mse: 0.3217 - mae: 0.5440 - mape: 88.4503\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 184us/sample - loss: 0.5436 - mse: 0.3214 - mae: 0.5436 - mape: 88.3862\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 271us/sample - loss: 0.5433 - mse: 0.3210 - mae: 0.5433 - mape: 88.3213\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 5/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 32 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 13ms/sample - loss: 0.4958 - mse: 0.3308 - mae: 0.4958 - mape: 399.0706\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 141us/sample - loss: 0.4957 - mse: 0.3307 - mae: 0.4957 - mape: 398.2661\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 110us/sample - loss: 0.4956 - mse: 0.3306 - mae: 0.4956 - mape: 397.4608\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 101us/sample - loss: 0.4955 - mse: 0.3305 - mae: 0.4955 - mape: 396.6553\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 111us/sample - loss: 0.4954 - mse: 0.3304 - mae: 0.4954 - mape: 395.8495\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 101us/sample - loss: 0.4953 - mse: 0.3303 - mae: 0.4953 - mape: 395.0435\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 155us/sample - loss: 0.4952 - mse: 0.3302 - mae: 0.4952 - mape: 394.2374\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.4951 - mse: 0.3301 - mae: 0.4951 - mape: 393.4312\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 151us/sample - loss: 0.4950 - mse: 0.3300 - mae: 0.4950 - mape: 392.6250\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 208us/sample - loss: 0.4949 - mse: 0.3299 - mae: 0.4949 - mape: 391.8186\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 204us/sample - loss: 0.4948 - mse: 0.3298 - mae: 0.4948 - mape: 391.0121\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 128us/sample - loss: 0.4947 - mse: 0.3297 - mae: 0.4947 - mape: 390.2056\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 113us/sample - loss: 0.4946 - mse: 0.3296 - mae: 0.4946 - mape: 389.3990\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 127us/sample - loss: 0.4945 - mse: 0.3295 - mae: 0.4945 - mape: 388.5923\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.4943 - mse: 0.3294 - mae: 0.4943 - mape: 387.7855\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 158us/sample - loss: 0.4942 - mse: 0.3293 - mae: 0.4942 - mape: 386.9787\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 116us/sample - loss: 0.4941 - mse: 0.3292 - mae: 0.4941 - mape: 386.1718\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 105us/sample - loss: 0.4940 - mse: 0.3291 - mae: 0.4940 - mape: 385.3648\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 107us/sample - loss: 0.4939 - mse: 0.3290 - mae: 0.4939 - mape: 384.5578\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 120us/sample - loss: 0.4938 - mse: 0.3289 - mae: 0.4938 - mape: 383.7507\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 159us/sample - loss: 0.4937 - mse: 0.3288 - mae: 0.4937 - mape: 382.9435\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.4936 - mse: 0.3287 - mae: 0.4936 - mape: 382.1362\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 203us/sample - loss: 0.4935 - mse: 0.3286 - mae: 0.4935 - mape: 381.3289\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 178us/sample - loss: 0.4934 - mse: 0.3285 - mae: 0.4934 - mape: 380.5214\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 174us/sample - loss: 0.4933 - mse: 0.3284 - mae: 0.4933 - mape: 379.7139\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.4932 - mse: 0.3283 - mae: 0.4932 - mape: 378.9063\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 164us/sample - loss: 0.4931 - mse: 0.3282 - mae: 0.4931 - mape: 378.0986\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.4930 - mse: 0.3281 - mae: 0.4930 - mape: 377.2909\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 212us/sample - loss: 0.4929 - mse: 0.3280 - mae: 0.4929 - mape: 376.4830\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 230us/sample - loss: 0.4928 - mse: 0.3279 - mae: 0.4928 - mape: 375.6751\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 146us/sample - loss: 0.4927 - mse: 0.3278 - mae: 0.4927 - mape: 374.8671\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 166us/sample - loss: 0.4926 - mse: 0.3277 - mae: 0.4926 - mape: 374.0590\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 184us/sample - loss: 0.4925 - mse: 0.3276 - mae: 0.4925 - mape: 373.2507\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 135us/sample - loss: 0.4924 - mse: 0.3275 - mae: 0.4924 - mape: 372.4424\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 0.4923 - mse: 0.3274 - mae: 0.4923 - mape: 371.6341\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 170us/sample - loss: 0.4922 - mse: 0.3273 - mae: 0.4922 - mape: 370.8256\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 129us/sample - loss: 0.4921 - mse: 0.3272 - mae: 0.4921 - mape: 370.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 149us/sample - loss: 0.4920 - mse: 0.3271 - mae: 0.4920 - mape: 369.2083\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 194us/sample - loss: 0.4919 - mse: 0.3270 - mae: 0.4919 - mape: 368.3995\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 145us/sample - loss: 0.4918 - mse: 0.3269 - mae: 0.4918 - mape: 367.5906\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 184us/sample - loss: 0.4917 - mse: 0.3268 - mae: 0.4917 - mape: 366.7816\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 444us/sample - loss: 0.4916 - mse: 0.3267 - mae: 0.4916 - mape: 365.9725\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 281us/sample - loss: 0.4915 - mse: 0.3265 - mae: 0.4915 - mape: 365.1633\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 224us/sample - loss: 0.4914 - mse: 0.3264 - mae: 0.4914 - mape: 364.3540\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 172us/sample - loss: 0.4913 - mse: 0.3263 - mae: 0.4913 - mape: 363.5446\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 193us/sample - loss: 0.4912 - mse: 0.3262 - mae: 0.4912 - mape: 362.7351\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 283us/sample - loss: 0.4911 - mse: 0.3261 - mae: 0.4911 - mape: 361.9255\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 164us/sample - loss: 0.4910 - mse: 0.3260 - mae: 0.4910 - mape: 361.1158\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 194us/sample - loss: 0.4908 - mse: 0.3259 - mae: 0.4908 - mape: 360.3059\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 208us/sample - loss: 0.4907 - mse: 0.3258 - mae: 0.4907 - mape: 359.4960\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 196us/sample - loss: 0.4906 - mse: 0.3257 - mae: 0.4906 - mape: 358.6860\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 160us/sample - loss: 0.4905 - mse: 0.3256 - mae: 0.4905 - mape: 357.8758\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.4904 - mse: 0.3255 - mae: 0.4904 - mape: 357.0656\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 130us/sample - loss: 0.4903 - mse: 0.3254 - mae: 0.4903 - mape: 356.2552\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.4902 - mse: 0.3253 - mae: 0.4902 - mape: 355.4447\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 99us/sample - loss: 0.4901 - mse: 0.3252 - mae: 0.4901 - mape: 354.6340\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 144us/sample - loss: 0.4900 - mse: 0.3251 - mae: 0.4900 - mape: 353.8233\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 162us/sample - loss: 0.4899 - mse: 0.3250 - mae: 0.4899 - mape: 353.0125\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 153us/sample - loss: 0.4898 - mse: 0.3249 - mae: 0.4898 - mape: 352.2014\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 153us/sample - loss: 0.4897 - mse: 0.3248 - mae: 0.4897 - mape: 351.3903\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 222us/sample - loss: 0.4896 - mse: 0.3247 - mae: 0.4896 - mape: 350.5791\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 127us/sample - loss: 0.4895 - mse: 0.3246 - mae: 0.4895 - mape: 349.7677\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 297us/sample - loss: 0.4894 - mse: 0.3245 - mae: 0.4894 - mape: 348.9562\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 166us/sample - loss: 0.4893 - mse: 0.3244 - mae: 0.4893 - mape: 348.1446\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 194us/sample - loss: 0.4892 - mse: 0.3243 - mae: 0.4892 - mape: 347.3328\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 227us/sample - loss: 0.4891 - mse: 0.3242 - mae: 0.4891 - mape: 346.5208\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 224us/sample - loss: 0.4890 - mse: 0.3241 - mae: 0.4890 - mape: 345.7088\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 173us/sample - loss: 0.4889 - mse: 0.3240 - mae: 0.4889 - mape: 344.8966\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 174us/sample - loss: 0.4888 - mse: 0.3239 - mae: 0.4888 - mape: 344.0844\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 199us/sample - loss: 0.4887 - mse: 0.3238 - mae: 0.4887 - mape: 343.2718\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 166us/sample - loss: 0.4886 - mse: 0.3237 - mae: 0.4886 - mape: 342.4592\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 266us/sample - loss: 0.4885 - mse: 0.3236 - mae: 0.4885 - mape: 341.6465\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 182us/sample - loss: 0.4884 - mse: 0.3235 - mae: 0.4884 - mape: 340.8335\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 201us/sample - loss: 0.4883 - mse: 0.3234 - mae: 0.4883 - mape: 340.0205\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 192us/sample - loss: 0.4882 - mse: 0.3233 - mae: 0.4882 - mape: 339.2073\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 460us/sample - loss: 0.4881 - mse: 0.3232 - mae: 0.4881 - mape: 338.3939\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 220us/sample - loss: 0.4880 - mse: 0.3231 - mae: 0.4880 - mape: 337.5804\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 236us/sample - loss: 0.4879 - mse: 0.3230 - mae: 0.4879 - mape: 336.7667\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.4877 - mse: 0.3229 - mae: 0.4877 - mape: 335.9529\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 131us/sample - loss: 0.4876 - mse: 0.3228 - mae: 0.4876 - mape: 335.1389\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 165us/sample - loss: 0.4875 - mse: 0.3227 - mae: 0.4875 - mape: 334.3248\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 143us/sample - loss: 0.4874 - mse: 0.3226 - mae: 0.4874 - mape: 333.5106\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 199us/sample - loss: 0.4873 - mse: 0.3225 - mae: 0.4873 - mape: 332.6961\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 0.4872 - mse: 0.3224 - mae: 0.4872 - mape: 331.8815\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 116us/sample - loss: 0.4871 - mse: 0.3223 - mae: 0.4871 - mape: 331.0667\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.4870 - mse: 0.3222 - mae: 0.4870 - mape: 330.2517\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 155us/sample - loss: 0.4869 - mse: 0.3221 - mae: 0.4869 - mape: 329.4366\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 154us/sample - loss: 0.4868 - mse: 0.3220 - mae: 0.4868 - mape: 328.6213\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 141us/sample - loss: 0.4867 - mse: 0.3219 - mae: 0.4867 - mape: 327.8059\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 177us/sample - loss: 0.4866 - mse: 0.3218 - mae: 0.4866 - mape: 326.9903\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 158us/sample - loss: 0.4865 - mse: 0.3217 - mae: 0.4865 - mape: 326.1745\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 148us/sample - loss: 0.4864 - mse: 0.3216 - mae: 0.4864 - mape: 325.3586\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 315us/sample - loss: 0.4863 - mse: 0.3215 - mae: 0.4863 - mape: 324.5424\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 123us/sample - loss: 0.4862 - mse: 0.3214 - mae: 0.4862 - mape: 323.7261\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 146us/sample - loss: 0.4861 - mse: 0.3213 - mae: 0.4861 - mape: 322.9096\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 263us/sample - loss: 0.4860 - mse: 0.3212 - mae: 0.4860 - mape: 322.0930\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.4859 - mse: 0.3211 - mae: 0.4859 - mape: 321.2762\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 160us/sample - loss: 0.4858 - mse: 0.3210 - mae: 0.4858 - mape: 320.4591\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.4857 - mse: 0.3209 - mae: 0.4857 - mape: 319.6419\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 141us/sample - loss: 0.4856 - mse: 0.3208 - mae: 0.4856 - mape: 318.8246\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/416 [==============================] - 0s 1ms/sample - loss: 0.5810 - accuracy: 0.7821\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like   Eff  N. Parts\n",
      "0  2.570027  6.983446           2000  4001.158  4.26         6\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.4\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 9.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/9Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 32 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 14ms/sample - loss: 0.7426 - mse: 0.5517 - mae: 0.7426 - mape: 104.9342\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 120us/sample - loss: 0.7425 - mse: 0.5516 - mae: 0.7425 - mape: 104.9211\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 152us/sample - loss: 0.7424 - mse: 0.5514 - mae: 0.7424 - mape: 104.9081\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 114us/sample - loss: 0.7423 - mse: 0.5513 - mae: 0.7423 - mape: 104.8951\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.7422 - mse: 0.5512 - mae: 0.7422 - mape: 104.8820\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 111us/sample - loss: 0.7422 - mse: 0.5510 - mae: 0.7422 - mape: 104.8690\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 102us/sample - loss: 0.7421 - mse: 0.5509 - mae: 0.7421 - mape: 104.8559\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 123us/sample - loss: 0.7420 - mse: 0.5508 - mae: 0.7420 - mape: 104.8428\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 100us/sample - loss: 0.7419 - mse: 0.5506 - mae: 0.7419 - mape: 104.8298\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 129us/sample - loss: 0.7418 - mse: 0.5505 - mae: 0.7418 - mape: 104.8168\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 109us/sample - loss: 0.7417 - mse: 0.5503 - mae: 0.7417 - mape: 104.8037\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 143us/sample - loss: 0.7416 - mse: 0.5502 - mae: 0.7416 - mape: 104.7906\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 104us/sample - loss: 0.7415 - mse: 0.5501 - mae: 0.7415 - mape: 104.7776\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 169us/sample - loss: 0.7414 - mse: 0.5499 - mae: 0.7414 - mape: 104.7645\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 123us/sample - loss: 0.7413 - mse: 0.5498 - mae: 0.7413 - mape: 104.7515\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 222us/sample - loss: 0.7412 - mse: 0.5497 - mae: 0.7412 - mape: 104.7384\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 200us/sample - loss: 0.7411 - mse: 0.5495 - mae: 0.7411 - mape: 104.7254\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.7410 - mse: 0.5494 - mae: 0.7410 - mape: 104.7123\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 189us/sample - loss: 0.7410 - mse: 0.5493 - mae: 0.7410 - mape: 104.6993\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 113us/sample - loss: 0.7409 - mse: 0.5491 - mae: 0.7409 - mape: 104.6862\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 117us/sample - loss: 0.7408 - mse: 0.5490 - mae: 0.7408 - mape: 104.6732\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 161us/sample - loss: 0.7407 - mse: 0.5488 - mae: 0.7407 - mape: 104.6601\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 128us/sample - loss: 0.7406 - mse: 0.5487 - mae: 0.7406 - mape: 104.6470\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 127us/sample - loss: 0.7405 - mse: 0.5486 - mae: 0.7405 - mape: 104.6340\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 126us/sample - loss: 0.7404 - mse: 0.5484 - mae: 0.7404 - mape: 104.6209\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 143us/sample - loss: 0.7403 - mse: 0.5483 - mae: 0.7403 - mape: 104.6079\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 117us/sample - loss: 0.7402 - mse: 0.5482 - mae: 0.7402 - mape: 104.5948\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 186us/sample - loss: 0.7401 - mse: 0.5480 - mae: 0.7401 - mape: 104.5818\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 129us/sample - loss: 0.7400 - mse: 0.5479 - mae: 0.7400 - mape: 104.5687\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 174us/sample - loss: 0.7399 - mse: 0.5477 - mae: 0.7399 - mape: 104.5556\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 187us/sample - loss: 0.7398 - mse: 0.5476 - mae: 0.7398 - mape: 104.5426\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 0.7398 - mse: 0.5475 - mae: 0.7398 - mape: 104.5295\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.7397 - mse: 0.5473 - mae: 0.7397 - mape: 104.5165\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 114us/sample - loss: 0.7396 - mse: 0.5472 - mae: 0.7396 - mape: 104.5034\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 112us/sample - loss: 0.7395 - mse: 0.5471 - mae: 0.7395 - mape: 104.4904\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 157us/sample - loss: 0.7394 - mse: 0.5469 - mae: 0.7394 - mape: 104.4773\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 161us/sample - loss: 0.7393 - mse: 0.5468 - mae: 0.7393 - mape: 104.4642\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 146us/sample - loss: 0.7392 - mse: 0.5467 - mae: 0.7392 - mape: 104.4512\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 159us/sample - loss: 0.7391 - mse: 0.5465 - mae: 0.7391 - mape: 104.4381\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 123us/sample - loss: 0.7390 - mse: 0.5464 - mae: 0.7390 - mape: 104.4250\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 149us/sample - loss: 0.7389 - mse: 0.5462 - mae: 0.7389 - mape: 104.4120\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 115us/sample - loss: 0.7388 - mse: 0.5461 - mae: 0.7388 - mape: 104.3989\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 106us/sample - loss: 0.7387 - mse: 0.5460 - mae: 0.7387 - mape: 104.3858\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 140us/sample - loss: 0.7386 - mse: 0.5458 - mae: 0.7386 - mape: 104.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 120us/sample - loss: 0.7386 - mse: 0.5457 - mae: 0.7386 - mape: 104.3597\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 139us/sample - loss: 0.7385 - mse: 0.5456 - mae: 0.7385 - mape: 104.3467\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 106us/sample - loss: 0.7384 - mse: 0.5454 - mae: 0.7384 - mape: 104.3336\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 149us/sample - loss: 0.7383 - mse: 0.5453 - mae: 0.7383 - mape: 104.3205\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 112us/sample - loss: 0.7382 - mse: 0.5452 - mae: 0.7382 - mape: 104.3075\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 162us/sample - loss: 0.7381 - mse: 0.5450 - mae: 0.7381 - mape: 104.2944\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 201us/sample - loss: 0.7380 - mse: 0.5449 - mae: 0.7380 - mape: 104.2813\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 144us/sample - loss: 0.7379 - mse: 0.5447 - mae: 0.7379 - mape: 104.2682\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 208us/sample - loss: 0.7378 - mse: 0.5446 - mae: 0.7378 - mape: 104.2552\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 136us/sample - loss: 0.7377 - mse: 0.5445 - mae: 0.7377 - mape: 104.2421\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 107us/sample - loss: 0.7376 - mse: 0.5443 - mae: 0.7376 - mape: 104.2290\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 155us/sample - loss: 0.7375 - mse: 0.5442 - mae: 0.7375 - mape: 104.2160\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 125us/sample - loss: 0.7374 - mse: 0.5441 - mae: 0.7374 - mape: 104.2029\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 258us/sample - loss: 0.7373 - mse: 0.5439 - mae: 0.7373 - mape: 104.1898\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 144us/sample - loss: 0.7373 - mse: 0.5438 - mae: 0.7373 - mape: 104.1767\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 0.7372 - mse: 0.5437 - mae: 0.7372 - mape: 104.1637\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.7371 - mse: 0.5435 - mae: 0.7371 - mape: 104.1506\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 156us/sample - loss: 0.7370 - mse: 0.5434 - mae: 0.7370 - mape: 104.1375\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 211us/sample - loss: 0.7369 - mse: 0.5432 - mae: 0.7369 - mape: 104.1244\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 110us/sample - loss: 0.7368 - mse: 0.5431 - mae: 0.7368 - mape: 104.1113\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 176us/sample - loss: 0.7367 - mse: 0.5430 - mae: 0.7367 - mape: 104.0982\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 319us/sample - loss: 0.7366 - mse: 0.5428 - mae: 0.7366 - mape: 104.0852\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 175us/sample - loss: 0.7365 - mse: 0.5427 - mae: 0.7365 - mape: 104.0721\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 139us/sample - loss: 0.7364 - mse: 0.5426 - mae: 0.7364 - mape: 104.0590\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 163us/sample - loss: 0.7363 - mse: 0.5424 - mae: 0.7363 - mape: 104.0459\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 227us/sample - loss: 0.7362 - mse: 0.5423 - mae: 0.7362 - mape: 104.0328\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 183us/sample - loss: 0.7361 - mse: 0.5422 - mae: 0.7361 - mape: 104.0197\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 124us/sample - loss: 0.7361 - mse: 0.5420 - mae: 0.7361 - mape: 104.0066\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 150us/sample - loss: 0.7360 - mse: 0.5419 - mae: 0.7360 - mape: 103.9935\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 111us/sample - loss: 0.7359 - mse: 0.5417 - mae: 0.7359 - mape: 103.9804\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 0.7358 - mse: 0.5416 - mae: 0.7358 - mape: 103.9673\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 113us/sample - loss: 0.7357 - mse: 0.5415 - mae: 0.7357 - mape: 103.9543\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 136us/sample - loss: 0.7356 - mse: 0.5413 - mae: 0.7356 - mape: 103.9412\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 108us/sample - loss: 0.7355 - mse: 0.5412 - mae: 0.7355 - mape: 103.9281\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 144us/sample - loss: 0.7354 - mse: 0.5411 - mae: 0.7354 - mape: 103.9150\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 129us/sample - loss: 0.7353 - mse: 0.5409 - mae: 0.7353 - mape: 103.9019\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 125us/sample - loss: 0.7352 - mse: 0.5408 - mae: 0.7352 - mape: 103.8888\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 177us/sample - loss: 0.7351 - mse: 0.5407 - mae: 0.7351 - mape: 103.8757\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 132us/sample - loss: 0.7350 - mse: 0.5405 - mae: 0.7350 - mape: 103.8625\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 191us/sample - loss: 0.7349 - mse: 0.5404 - mae: 0.7349 - mape: 103.8494\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 184us/sample - loss: 0.7348 - mse: 0.5402 - mae: 0.7348 - mape: 103.8363\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 128us/sample - loss: 0.7348 - mse: 0.5401 - mae: 0.7348 - mape: 103.8232\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 165us/sample - loss: 0.7347 - mse: 0.5400 - mae: 0.7347 - mape: 103.8101\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 122us/sample - loss: 0.7346 - mse: 0.5398 - mae: 0.7346 - mape: 103.7970\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 153us/sample - loss: 0.7345 - mse: 0.5397 - mae: 0.7345 - mape: 103.7839\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 178us/sample - loss: 0.7344 - mse: 0.5396 - mae: 0.7344 - mape: 103.7708\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 127us/sample - loss: 0.7343 - mse: 0.5394 - mae: 0.7343 - mape: 103.7576\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 160us/sample - loss: 0.7342 - mse: 0.5393 - mae: 0.7342 - mape: 103.7445\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 123us/sample - loss: 0.7341 - mse: 0.5392 - mae: 0.7341 - mape: 103.7314\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 147us/sample - loss: 0.7340 - mse: 0.5390 - mae: 0.7340 - mape: 103.7183\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 152us/sample - loss: 0.7339 - mse: 0.5389 - mae: 0.7339 - mape: 103.7052\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 191us/sample - loss: 0.7338 - mse: 0.5387 - mae: 0.7338 - mape: 103.6920\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 166us/sample - loss: 0.7337 - mse: 0.5386 - mae: 0.7337 - mape: 103.6789\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 185us/sample - loss: 0.7336 - mse: 0.5385 - mae: 0.7336 - mape: 103.6658\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 166us/sample - loss: 0.7335 - mse: 0.5383 - mae: 0.7335 - mape: 103.6526\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 121us/sample - loss: 0.7335 - mse: 0.5382 - mae: 0.7335 - mape: 103.6395\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/9Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 34 samples\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 14ms/sample - loss: 0.4781 - mse: 0.2287 - mae: 0.4781 - mape: 96.9571\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 216us/sample - loss: 0.4779 - mse: 0.2285 - mae: 0.4779 - mape: 96.9126\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 221us/sample - loss: 0.4777 - mse: 0.2283 - mae: 0.4777 - mape: 96.8680\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 194us/sample - loss: 0.4775 - mse: 0.2281 - mae: 0.4775 - mape: 96.8235\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 271us/sample - loss: 0.4772 - mse: 0.2279 - mae: 0.4772 - mape: 96.7790\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 265us/sample - loss: 0.4770 - mse: 0.2277 - mae: 0.4770 - mape: 96.7344\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 302us/sample - loss: 0.4768 - mse: 0.2275 - mae: 0.4768 - mape: 96.6899\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 283us/sample - loss: 0.4766 - mse: 0.2272 - mae: 0.4766 - mape: 96.6453\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 203us/sample - loss: 0.4764 - mse: 0.2270 - mae: 0.4764 - mape: 96.6007\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 208us/sample - loss: 0.4761 - mse: 0.2268 - mae: 0.4761 - mape: 96.5562\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 295us/sample - loss: 0.4759 - mse: 0.2266 - mae: 0.4759 - mape: 96.5116\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 311us/sample - loss: 0.4757 - mse: 0.2264 - mae: 0.4757 - mape: 96.4670\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 298us/sample - loss: 0.4755 - mse: 0.2262 - mae: 0.4755 - mape: 96.4224\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 216us/sample - loss: 0.4753 - mse: 0.2260 - mae: 0.4753 - mape: 96.3778\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 186us/sample - loss: 0.4750 - mse: 0.2258 - mae: 0.4750 - mape: 96.3332\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 263us/sample - loss: 0.4748 - mse: 0.2256 - mae: 0.4748 - mape: 96.2886\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 255us/sample - loss: 0.4746 - mse: 0.2254 - mae: 0.4746 - mape: 96.2440\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 457us/sample - loss: 0.4744 - mse: 0.2252 - mae: 0.4744 - mape: 96.1993\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 271us/sample - loss: 0.4742 - mse: 0.2249 - mae: 0.4742 - mape: 96.1547\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 225us/sample - loss: 0.4739 - mse: 0.2247 - mae: 0.4739 - mape: 96.1101\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 306us/sample - loss: 0.4737 - mse: 0.2245 - mae: 0.4737 - mape: 96.0654\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 207us/sample - loss: 0.4735 - mse: 0.2243 - mae: 0.4735 - mape: 96.0208\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 259us/sample - loss: 0.4733 - mse: 0.2241 - mae: 0.4733 - mape: 95.9762\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 229us/sample - loss: 0.4731 - mse: 0.2239 - mae: 0.4731 - mape: 95.9315\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 183us/sample - loss: 0.4728 - mse: 0.2237 - mae: 0.4728 - mape: 95.8869\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 228us/sample - loss: 0.4726 - mse: 0.2235 - mae: 0.4726 - mape: 95.8422\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 271us/sample - loss: 0.4724 - mse: 0.2233 - mae: 0.4724 - mape: 95.7975\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 195us/sample - loss: 0.4722 - mse: 0.2231 - mae: 0.4722 - mape: 95.7529\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 205us/sample - loss: 0.4720 - mse: 0.2229 - mae: 0.4720 - mape: 95.7082\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 254us/sample - loss: 0.4717 - mse: 0.2227 - mae: 0.4717 - mape: 95.6635\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 260us/sample - loss: 0.4715 - mse: 0.2224 - mae: 0.4715 - mape: 95.6188\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 245us/sample - loss: 0.4713 - mse: 0.2222 - mae: 0.4713 - mape: 95.5741\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 402us/sample - loss: 0.4711 - mse: 0.2220 - mae: 0.4711 - mape: 95.5293\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 234us/sample - loss: 0.4709 - mse: 0.2218 - mae: 0.4709 - mape: 95.4846\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 226us/sample - loss: 0.4706 - mse: 0.2216 - mae: 0.4706 - mape: 95.4399\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 278us/sample - loss: 0.4704 - mse: 0.2214 - mae: 0.4704 - mape: 95.3951\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 226us/sample - loss: 0.4702 - mse: 0.2212 - mae: 0.4702 - mape: 95.3503\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 233us/sample - loss: 0.4700 - mse: 0.2210 - mae: 0.4700 - mape: 95.3055\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 226us/sample - loss: 0.4698 - mse: 0.2208 - mae: 0.4698 - mape: 95.2606\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 243us/sample - loss: 0.4695 - mse: 0.2206 - mae: 0.4695 - mape: 95.2158\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 245us/sample - loss: 0.4693 - mse: 0.2204 - mae: 0.4693 - mape: 95.1710\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 200us/sample - loss: 0.4691 - mse: 0.2202 - mae: 0.4691 - mape: 95.1261\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 218us/sample - loss: 0.4689 - mse: 0.2200 - mae: 0.4689 - mape: 95.0813\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 239us/sample - loss: 0.4687 - mse: 0.2198 - mae: 0.4687 - mape: 95.0364\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 189us/sample - loss: 0.4684 - mse: 0.2195 - mae: 0.4684 - mape: 94.9916\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 276us/sample - loss: 0.4682 - mse: 0.2193 - mae: 0.4682 - mape: 94.9467\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 302us/sample - loss: 0.4680 - mse: 0.2191 - mae: 0.4680 - mape: 94.9019\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 463us/sample - loss: 0.4678 - mse: 0.2189 - mae: 0.4678 - mape: 94.8570\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 255us/sample - loss: 0.4675 - mse: 0.2187 - mae: 0.4675 - mape: 94.8121\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 251us/sample - loss: 0.4673 - mse: 0.2185 - mae: 0.4673 - mape: 94.7673\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 248us/sample - loss: 0.4671 - mse: 0.2183 - mae: 0.4671 - mape: 94.7223\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 317us/sample - loss: 0.4669 - mse: 0.2181 - mae: 0.4669 - mape: 94.6774\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 270us/sample - loss: 0.4667 - mse: 0.2179 - mae: 0.4667 - mape: 94.6324\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 190us/sample - loss: 0.4664 - mse: 0.2177 - mae: 0.4664 - mape: 94.5874\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 230us/sample - loss: 0.4662 - mse: 0.2175 - mae: 0.4662 - mape: 94.5424\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 265us/sample - loss: 0.4660 - mse: 0.2173 - mae: 0.4660 - mape: 94.4973\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 192us/sample - loss: 0.4658 - mse: 0.2171 - mae: 0.4658 - mape: 94.4523\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 207us/sample - loss: 0.4656 - mse: 0.2169 - mae: 0.4656 - mape: 94.4072\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 259us/sample - loss: 0.4653 - mse: 0.2166 - mae: 0.4653 - mape: 94.3621\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 289us/sample - loss: 0.4651 - mse: 0.2164 - mae: 0.4651 - mape: 94.3169\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 358us/sample - loss: 0.4649 - mse: 0.2162 - mae: 0.4649 - mape: 94.2718\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 281us/sample - loss: 0.4647 - mse: 0.2160 - mae: 0.4647 - mape: 94.2266\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 238us/sample - loss: 0.4644 - mse: 0.2158 - mae: 0.4644 - mape: 94.1814\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 247us/sample - loss: 0.4642 - mse: 0.2156 - mae: 0.4642 - mape: 94.1362\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 298us/sample - loss: 0.4640 - mse: 0.2154 - mae: 0.4640 - mape: 94.0909\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 272us/sample - loss: 0.4638 - mse: 0.2152 - mae: 0.4638 - mape: 94.0456\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 209us/sample - loss: 0.4635 - mse: 0.2150 - mae: 0.4635 - mape: 94.0003\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 207us/sample - loss: 0.4633 - mse: 0.2148 - mae: 0.4633 - mape: 93.9550\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 319us/sample - loss: 0.4631 - mse: 0.2146 - mae: 0.4631 - mape: 93.9096\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 374us/sample - loss: 0.4629 - mse: 0.2144 - mae: 0.4629 - mape: 93.8642\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 326us/sample - loss: 0.4627 - mse: 0.2142 - mae: 0.4627 - mape: 93.8188\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 270us/sample - loss: 0.4624 - mse: 0.2140 - mae: 0.4624 - mape: 93.7734\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 199us/sample - loss: 0.4622 - mse: 0.2137 - mae: 0.4622 - mape: 93.7280\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 224us/sample - loss: 0.4620 - mse: 0.2135 - mae: 0.4620 - mape: 93.6826\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 266us/sample - loss: 0.4618 - mse: 0.2133 - mae: 0.4618 - mape: 93.6370\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 235us/sample - loss: 0.4615 - mse: 0.2131 - mae: 0.4615 - mape: 93.5916\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 160us/sample - loss: 0.4613 - mse: 0.2129 - mae: 0.4613 - mape: 93.5460\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 262us/sample - loss: 0.4611 - mse: 0.2127 - mae: 0.4611 - mape: 93.5005\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 262us/sample - loss: 0.4609 - mse: 0.2125 - mae: 0.4609 - mape: 93.4549\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 362us/sample - loss: 0.4606 - mse: 0.2123 - mae: 0.4606 - mape: 93.4093\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 255us/sample - loss: 0.4604 - mse: 0.2121 - mae: 0.4604 - mape: 93.3636\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 192us/sample - loss: 0.4602 - mse: 0.2119 - mae: 0.4602 - mape: 93.3180\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 216us/sample - loss: 0.4600 - mse: 0.2117 - mae: 0.4600 - mape: 93.2723\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 240us/sample - loss: 0.4597 - mse: 0.2115 - mae: 0.4597 - mape: 93.2265\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 200us/sample - loss: 0.4595 - mse: 0.2113 - mae: 0.4595 - mape: 93.1808\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 222us/sample - loss: 0.4593 - mse: 0.2111 - mae: 0.4593 - mape: 93.1349\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 222us/sample - loss: 0.4591 - mse: 0.2108 - mae: 0.4591 - mape: 93.0892\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 204us/sample - loss: 0.4588 - mse: 0.2106 - mae: 0.4588 - mape: 93.0433\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 229us/sample - loss: 0.4586 - mse: 0.2104 - mae: 0.4586 - mape: 92.9974\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 292us/sample - loss: 0.4584 - mse: 0.2102 - mae: 0.4584 - mape: 92.9515\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 375us/sample - loss: 0.4582 - mse: 0.2100 - mae: 0.4582 - mape: 92.9056\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 334us/sample - loss: 0.4579 - mse: 0.2098 - mae: 0.4579 - mape: 92.8597\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 286us/sample - loss: 0.4577 - mse: 0.2096 - mae: 0.4577 - mape: 92.8136\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 240us/sample - loss: 0.4575 - mse: 0.2094 - mae: 0.4575 - mape: 92.7677\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 213us/sample - loss: 0.4572 - mse: 0.2092 - mae: 0.4572 - mape: 92.7216\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 268us/sample - loss: 0.4570 - mse: 0.2090 - mae: 0.4570 - mape: 92.6755\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 237us/sample - loss: 0.4568 - mse: 0.2088 - mae: 0.4568 - mape: 92.6293\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 248us/sample - loss: 0.4566 - mse: 0.2086 - mae: 0.4566 - mape: 92.5832\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 237us/sample - loss: 0.4563 - mse: 0.2084 - mae: 0.4563 - mape: 92.5370\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 373us/sample - loss: 0.4561 - mse: 0.2082 - mae: 0.4561 - mape: 92.4907\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/9Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 60 samples\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 8ms/sample - loss: 0.6519 - mse: 0.4272 - mae: 0.6519 - mape: 103.9341\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 133us/sample - loss: 0.6517 - mse: 0.4269 - mae: 0.6517 - mape: 103.9000\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 153us/sample - loss: 0.6515 - mse: 0.4267 - mae: 0.6515 - mape: 103.8656\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6513 - mse: 0.4264 - mae: 0.6513 - mape: 103.8319\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 122us/sample - loss: 0.6511 - mse: 0.4261 - mae: 0.6511 - mape: 103.7976\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 141us/sample - loss: 0.6509 - mse: 0.4258 - mae: 0.6509 - mape: 103.7633\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 143us/sample - loss: 0.6507 - mse: 0.4256 - mae: 0.6507 - mape: 103.7293\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 210us/sample - loss: 0.6505 - mse: 0.4253 - mae: 0.6505 - mape: 103.6952\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 150us/sample - loss: 0.6502 - mse: 0.4250 - mae: 0.6502 - mape: 103.6611\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 139us/sample - loss: 0.6500 - mse: 0.4247 - mae: 0.6500 - mape: 103.6269\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 212us/sample - loss: 0.6498 - mse: 0.4245 - mae: 0.6498 - mape: 103.5928\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 151us/sample - loss: 0.6496 - mse: 0.4242 - mae: 0.6496 - mape: 103.5587\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 140us/sample - loss: 0.6494 - mse: 0.4239 - mae: 0.6494 - mape: 103.5245\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 126us/sample - loss: 0.6492 - mse: 0.4236 - mae: 0.6492 - mape: 103.4904\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 134us/sample - loss: 0.6490 - mse: 0.4234 - mae: 0.6490 - mape: 103.4562\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 129us/sample - loss: 0.6488 - mse: 0.4231 - mae: 0.6488 - mape: 103.4219\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 140us/sample - loss: 0.6485 - mse: 0.4228 - mae: 0.6485 - mape: 103.3881\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 165us/sample - loss: 0.6483 - mse: 0.4225 - mae: 0.6483 - mape: 103.3538\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 239us/sample - loss: 0.6481 - mse: 0.4223 - mae: 0.6481 - mape: 103.3199\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 137us/sample - loss: 0.6479 - mse: 0.4220 - mae: 0.6479 - mape: 103.2857\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 166us/sample - loss: 0.6477 - mse: 0.4217 - mae: 0.6477 - mape: 103.2513\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 157us/sample - loss: 0.6475 - mse: 0.4214 - mae: 0.6475 - mape: 103.2173\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 143us/sample - loss: 0.6473 - mse: 0.4212 - mae: 0.6473 - mape: 103.1832\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 124us/sample - loss: 0.6470 - mse: 0.4209 - mae: 0.6470 - mape: 103.1491\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 142us/sample - loss: 0.6468 - mse: 0.4206 - mae: 0.6468 - mape: 103.1148\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 154us/sample - loss: 0.6466 - mse: 0.4203 - mae: 0.6466 - mape: 103.0809\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6464 - mse: 0.4201 - mae: 0.6464 - mape: 103.0467\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 145us/sample - loss: 0.6462 - mse: 0.4198 - mae: 0.6462 - mape: 103.0127\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 174us/sample - loss: 0.6460 - mse: 0.4195 - mae: 0.6460 - mape: 102.9782\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 181us/sample - loss: 0.6458 - mse: 0.4192 - mae: 0.6458 - mape: 102.9444\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 159us/sample - loss: 0.6456 - mse: 0.4190 - mae: 0.6456 - mape: 102.9101\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 154us/sample - loss: 0.6453 - mse: 0.4187 - mae: 0.6453 - mape: 102.8761\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 160us/sample - loss: 0.6451 - mse: 0.4184 - mae: 0.6451 - mape: 102.8419\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6449 - mse: 0.4181 - mae: 0.6449 - mape: 102.8076\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 134us/sample - loss: 0.6447 - mse: 0.4179 - mae: 0.6447 - mape: 102.7737\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 131us/sample - loss: 0.6445 - mse: 0.4176 - mae: 0.6445 - mape: 102.7393\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 126us/sample - loss: 0.6443 - mse: 0.4173 - mae: 0.6443 - mape: 102.7051\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 115us/sample - loss: 0.6441 - mse: 0.4170 - mae: 0.6441 - mape: 102.6713\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 125us/sample - loss: 0.6439 - mse: 0.4168 - mae: 0.6439 - mape: 102.6368\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 110us/sample - loss: 0.6436 - mse: 0.4165 - mae: 0.6436 - mape: 102.6028\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 128us/sample - loss: 0.6434 - mse: 0.4162 - mae: 0.6434 - mape: 102.5685\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6432 - mse: 0.4159 - mae: 0.6432 - mape: 102.5343\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6430 - mse: 0.4157 - mae: 0.6430 - mape: 102.5001\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 260us/sample - loss: 0.6428 - mse: 0.4154 - mae: 0.6428 - mape: 102.4658\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 127us/sample - loss: 0.6426 - mse: 0.4151 - mae: 0.6426 - mape: 102.4316\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 168us/sample - loss: 0.6424 - mse: 0.4148 - mae: 0.6424 - mape: 102.3975\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 159us/sample - loss: 0.6422 - mse: 0.4146 - mae: 0.6422 - mape: 102.3633\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 149us/sample - loss: 0.6419 - mse: 0.4143 - mae: 0.6419 - mape: 102.3290\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 154us/sample - loss: 0.6417 - mse: 0.4140 - mae: 0.6417 - mape: 102.2948\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 126us/sample - loss: 0.6415 - mse: 0.4137 - mae: 0.6415 - mape: 102.2604\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 125us/sample - loss: 0.6413 - mse: 0.4135 - mae: 0.6413 - mape: 102.2260\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 146us/sample - loss: 0.6411 - mse: 0.4132 - mae: 0.6411 - mape: 102.1918\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 171us/sample - loss: 0.6409 - mse: 0.4129 - mae: 0.6409 - mape: 102.1574\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 122us/sample - loss: 0.6407 - mse: 0.4126 - mae: 0.6407 - mape: 102.1233\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 142us/sample - loss: 0.6404 - mse: 0.4124 - mae: 0.6404 - mape: 102.0889\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 238us/sample - loss: 0.6402 - mse: 0.4121 - mae: 0.6402 - mape: 102.0545\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 164us/sample - loss: 0.6400 - mse: 0.4118 - mae: 0.6400 - mape: 102.0201\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 148us/sample - loss: 0.6398 - mse: 0.4116 - mae: 0.6398 - mape: 101.9857\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 173us/sample - loss: 0.6396 - mse: 0.4113 - mae: 0.6396 - mape: 101.9514\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6394 - mse: 0.4110 - mae: 0.6394 - mape: 101.9171\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 149us/sample - loss: 0.6392 - mse: 0.4107 - mae: 0.6392 - mape: 101.8826\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 139us/sample - loss: 0.6389 - mse: 0.4105 - mae: 0.6389 - mape: 101.8481\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 127us/sample - loss: 0.6387 - mse: 0.4102 - mae: 0.6387 - mape: 101.8137\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 136us/sample - loss: 0.6385 - mse: 0.4099 - mae: 0.6385 - mape: 101.7793\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 143us/sample - loss: 0.6383 - mse: 0.4096 - mae: 0.6383 - mape: 101.7448\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 126us/sample - loss: 0.6381 - mse: 0.4094 - mae: 0.6381 - mape: 101.7103\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 126us/sample - loss: 0.6379 - mse: 0.4091 - mae: 0.6379 - mape: 101.6759\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 179us/sample - loss: 0.6377 - mse: 0.4088 - mae: 0.6377 - mape: 101.6412\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 227us/sample - loss: 0.6374 - mse: 0.4085 - mae: 0.6374 - mape: 101.6067\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 155us/sample - loss: 0.6372 - mse: 0.4083 - mae: 0.6372 - mape: 101.5723\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 140us/sample - loss: 0.6370 - mse: 0.4080 - mae: 0.6370 - mape: 101.5378\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 169us/sample - loss: 0.6368 - mse: 0.4077 - mae: 0.6368 - mape: 101.5031\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 168us/sample - loss: 0.6366 - mse: 0.4074 - mae: 0.6366 - mape: 101.4687\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 121us/sample - loss: 0.6364 - mse: 0.4072 - mae: 0.6364 - mape: 101.4340\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 137us/sample - loss: 0.6361 - mse: 0.4069 - mae: 0.6361 - mape: 101.3991\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 134us/sample - loss: 0.6359 - mse: 0.4066 - mae: 0.6359 - mape: 101.3647\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 135us/sample - loss: 0.6357 - mse: 0.4063 - mae: 0.6357 - mape: 101.3299\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 144us/sample - loss: 0.6355 - mse: 0.4061 - mae: 0.6355 - mape: 101.2952\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 147us/sample - loss: 0.6353 - mse: 0.4058 - mae: 0.6353 - mape: 101.2604\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 172us/sample - loss: 0.6351 - mse: 0.4055 - mae: 0.6351 - mape: 101.2257\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 246us/sample - loss: 0.6349 - mse: 0.4052 - mae: 0.6349 - mape: 101.1909\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 178us/sample - loss: 0.6346 - mse: 0.4050 - mae: 0.6346 - mape: 101.1561\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 128us/sample - loss: 0.6344 - mse: 0.4047 - mae: 0.6344 - mape: 101.1212\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 162us/sample - loss: 0.6342 - mse: 0.4044 - mae: 0.6342 - mape: 101.0867\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 173us/sample - loss: 0.6340 - mse: 0.4041 - mae: 0.6340 - mape: 101.0519\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 152us/sample - loss: 0.6338 - mse: 0.4039 - mae: 0.6338 - mape: 101.0167\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 178us/sample - loss: 0.6336 - mse: 0.4036 - mae: 0.6335 - mape: 100.9821\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 154us/sample - loss: 0.6333 - mse: 0.4033 - mae: 0.6333 - mape: 100.9473\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 233us/sample - loss: 0.6331 - mse: 0.4030 - mae: 0.6331 - mape: 100.9123\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 130us/sample - loss: 0.6329 - mse: 0.4028 - mae: 0.6329 - mape: 100.8774\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 160us/sample - loss: 0.6327 - mse: 0.4025 - mae: 0.6327 - mape: 100.8422\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 185us/sample - loss: 0.6325 - mse: 0.4022 - mae: 0.6325 - mape: 100.8073\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 152us/sample - loss: 0.6322 - mse: 0.4019 - mae: 0.6322 - mape: 100.7722\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 141us/sample - loss: 0.6320 - mse: 0.4017 - mae: 0.6320 - mape: 100.7373\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 115us/sample - loss: 0.6318 - mse: 0.4014 - mae: 0.6318 - mape: 100.7021\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 137us/sample - loss: 0.6316 - mse: 0.4011 - mae: 0.6316 - mape: 100.6671\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 166us/sample - loss: 0.6314 - mse: 0.4008 - mae: 0.6314 - mape: 100.6318\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 139us/sample - loss: 0.6312 - mse: 0.4006 - mae: 0.6312 - mape: 100.5969\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 203us/sample - loss: 0.6309 - mse: 0.4003 - mae: 0.6309 - mape: 100.5616\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 157us/sample - loss: 0.6307 - mse: 0.4000 - mae: 0.6307 - mape: 100.5265\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 3/9Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 28 samples\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 16ms/sample - loss: 0.7541 - mse: 0.5897 - mae: 0.7541 - mape: 110.5512\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 157us/sample - loss: 0.7540 - mse: 0.5895 - mae: 0.7540 - mape: 110.5341\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 171us/sample - loss: 0.7539 - mse: 0.5894 - mae: 0.7539 - mape: 110.5170\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 146us/sample - loss: 0.7538 - mse: 0.5892 - mae: 0.7538 - mape: 110.4999\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 115us/sample - loss: 0.7536 - mse: 0.5890 - mae: 0.7536 - mape: 110.4828\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 135us/sample - loss: 0.7535 - mse: 0.5889 - mae: 0.7535 - mape: 110.4657\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 131us/sample - loss: 0.7534 - mse: 0.5887 - mae: 0.7534 - mape: 110.4486\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 150us/sample - loss: 0.7533 - mse: 0.5885 - mae: 0.7533 - mape: 110.4315\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 135us/sample - loss: 0.7532 - mse: 0.5884 - mae: 0.7532 - mape: 110.4144\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 147us/sample - loss: 0.7531 - mse: 0.5882 - mae: 0.7531 - mape: 110.3973\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 145us/sample - loss: 0.7530 - mse: 0.5880 - mae: 0.7530 - mape: 110.3802\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 122us/sample - loss: 0.7529 - mse: 0.5879 - mae: 0.7529 - mape: 110.3631\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7528 - mse: 0.5877 - mae: 0.7528 - mape: 110.3459\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 118us/sample - loss: 0.7526 - mse: 0.5875 - mae: 0.7526 - mape: 110.3288\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 155us/sample - loss: 0.7525 - mse: 0.5874 - mae: 0.7525 - mape: 110.3117\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 222us/sample - loss: 0.7524 - mse: 0.5872 - mae: 0.7524 - mape: 110.2946\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 167us/sample - loss: 0.7523 - mse: 0.5870 - mae: 0.7523 - mape: 110.2775\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 141us/sample - loss: 0.7522 - mse: 0.5869 - mae: 0.7522 - mape: 110.2603\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 148us/sample - loss: 0.7521 - mse: 0.5867 - mae: 0.7521 - mape: 110.2432\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 130us/sample - loss: 0.7520 - mse: 0.5865 - mae: 0.7520 - mape: 110.2261\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 166us/sample - loss: 0.7519 - mse: 0.5864 - mae: 0.7519 - mape: 110.2090\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 123us/sample - loss: 0.7518 - mse: 0.5862 - mae: 0.7518 - mape: 110.1919\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 165us/sample - loss: 0.7516 - mse: 0.5860 - mae: 0.7516 - mape: 110.1747\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 116us/sample - loss: 0.7515 - mse: 0.5859 - mae: 0.7515 - mape: 110.1576\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 125us/sample - loss: 0.7514 - mse: 0.5857 - mae: 0.7514 - mape: 110.1405\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 137us/sample - loss: 0.7513 - mse: 0.5855 - mae: 0.7513 - mape: 110.1233\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 117us/sample - loss: 0.7512 - mse: 0.5854 - mae: 0.7512 - mape: 110.1062\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7511 - mse: 0.5852 - mae: 0.7511 - mape: 110.0891\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 105us/sample - loss: 0.7510 - mse: 0.5850 - mae: 0.7510 - mape: 110.0719\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7509 - mse: 0.5849 - mae: 0.7509 - mape: 110.0548\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 131us/sample - loss: 0.7508 - mse: 0.5847 - mae: 0.7508 - mape: 110.0377\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 134us/sample - loss: 0.7506 - mse: 0.5845 - mae: 0.7506 - mape: 110.0205\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 141us/sample - loss: 0.7505 - mse: 0.5844 - mae: 0.7505 - mape: 110.0034\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 133us/sample - loss: 0.7504 - mse: 0.5842 - mae: 0.7504 - mape: 109.9862\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 219us/sample - loss: 0.7503 - mse: 0.5840 - mae: 0.7503 - mape: 109.9691\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 133us/sample - loss: 0.7502 - mse: 0.5839 - mae: 0.7502 - mape: 109.9520\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 288us/sample - loss: 0.7501 - mse: 0.5837 - mae: 0.7501 - mape: 109.9348\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 241us/sample - loss: 0.7500 - mse: 0.5835 - mae: 0.7500 - mape: 109.9177\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 489us/sample - loss: 0.7499 - mse: 0.5834 - mae: 0.7499 - mape: 109.9005\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 150us/sample - loss: 0.7498 - mse: 0.5832 - mae: 0.7498 - mape: 109.8834\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 162us/sample - loss: 0.7496 - mse: 0.5830 - mae: 0.7496 - mape: 109.8662\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 150us/sample - loss: 0.7495 - mse: 0.5829 - mae: 0.7495 - mape: 109.8491\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 127us/sample - loss: 0.7494 - mse: 0.5827 - mae: 0.7494 - mape: 109.8319\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 120us/sample - loss: 0.7493 - mse: 0.5825 - mae: 0.7493 - mape: 109.8147\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 162us/sample - loss: 0.7492 - mse: 0.5824 - mae: 0.7492 - mape: 109.7976\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 131us/sample - loss: 0.7491 - mse: 0.5822 - mae: 0.7491 - mape: 109.7804\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 137us/sample - loss: 0.7490 - mse: 0.5820 - mae: 0.7490 - mape: 109.7633\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 145us/sample - loss: 0.7489 - mse: 0.5819 - mae: 0.7489 - mape: 109.7461\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 160us/sample - loss: 0.7488 - mse: 0.5817 - mae: 0.7488 - mape: 109.7289\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 157us/sample - loss: 0.7487 - mse: 0.5815 - mae: 0.7487 - mape: 109.7118\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 186us/sample - loss: 0.7485 - mse: 0.5814 - mae: 0.7485 - mape: 109.6946\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 132us/sample - loss: 0.7484 - mse: 0.5812 - mae: 0.7484 - mape: 109.6774\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 235us/sample - loss: 0.7483 - mse: 0.5810 - mae: 0.7483 - mape: 109.6602\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 160us/sample - loss: 0.7482 - mse: 0.5809 - mae: 0.7482 - mape: 109.6431\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 199us/sample - loss: 0.7481 - mse: 0.5807 - mae: 0.7481 - mape: 109.6259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 299us/sample - loss: 0.7480 - mse: 0.5805 - mae: 0.7480 - mape: 109.6087\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 155us/sample - loss: 0.7479 - mse: 0.5804 - mae: 0.7479 - mape: 109.5915\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 149us/sample - loss: 0.7478 - mse: 0.5802 - mae: 0.7478 - mape: 109.5743\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 146us/sample - loss: 0.7476 - mse: 0.5800 - mae: 0.7476 - mape: 109.5571\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 183us/sample - loss: 0.7475 - mse: 0.5799 - mae: 0.7475 - mape: 109.5399\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 145us/sample - loss: 0.7474 - mse: 0.5797 - mae: 0.7474 - mape: 109.5227\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 156us/sample - loss: 0.7473 - mse: 0.5795 - mae: 0.7473 - mape: 109.5055\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 140us/sample - loss: 0.7472 - mse: 0.5794 - mae: 0.7472 - mape: 109.4883\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 132us/sample - loss: 0.7471 - mse: 0.5792 - mae: 0.7471 - mape: 109.4711\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 125us/sample - loss: 0.7470 - mse: 0.5790 - mae: 0.7470 - mape: 109.4539\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 172us/sample - loss: 0.7469 - mse: 0.5789 - mae: 0.7469 - mape: 109.4367\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 177us/sample - loss: 0.7468 - mse: 0.5787 - mae: 0.7468 - mape: 109.4195\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 186us/sample - loss: 0.7466 - mse: 0.5785 - mae: 0.7466 - mape: 109.4023\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 289us/sample - loss: 0.7465 - mse: 0.5784 - mae: 0.7465 - mape: 109.3851\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 232us/sample - loss: 0.7464 - mse: 0.5782 - mae: 0.7464 - mape: 109.3679\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7463 - mse: 0.5780 - mae: 0.7463 - mape: 109.3507\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 187us/sample - loss: 0.7462 - mse: 0.5779 - mae: 0.7462 - mape: 109.3334\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 125us/sample - loss: 0.7461 - mse: 0.5777 - mae: 0.7461 - mape: 109.3162\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 158us/sample - loss: 0.7460 - mse: 0.5775 - mae: 0.7460 - mape: 109.2990\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 133us/sample - loss: 0.7459 - mse: 0.5774 - mae: 0.7459 - mape: 109.2817\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 198us/sample - loss: 0.7458 - mse: 0.5772 - mae: 0.7458 - mape: 109.2645\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 164us/sample - loss: 0.7456 - mse: 0.5770 - mae: 0.7456 - mape: 109.2473\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 145us/sample - loss: 0.7455 - mse: 0.5769 - mae: 0.7455 - mape: 109.2300\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 122us/sample - loss: 0.7454 - mse: 0.5767 - mae: 0.7454 - mape: 109.2128\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 158us/sample - loss: 0.7453 - mse: 0.5765 - mae: 0.7453 - mape: 109.1955\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 130us/sample - loss: 0.7452 - mse: 0.5764 - mae: 0.7452 - mape: 109.1783\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 362us/sample - loss: 0.7451 - mse: 0.5762 - mae: 0.7451 - mape: 109.1610\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 201us/sample - loss: 0.7450 - mse: 0.5760 - mae: 0.7450 - mape: 109.1438\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 127us/sample - loss: 0.7449 - mse: 0.5759 - mae: 0.7449 - mape: 109.1265\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7447 - mse: 0.5757 - mae: 0.7447 - mape: 109.1092\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 167us/sample - loss: 0.7446 - mse: 0.5755 - mae: 0.7446 - mape: 109.0920\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 170us/sample - loss: 0.7445 - mse: 0.5754 - mae: 0.7445 - mape: 109.0747\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 132us/sample - loss: 0.7444 - mse: 0.5752 - mae: 0.7444 - mape: 109.0574\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 153us/sample - loss: 0.7443 - mse: 0.5750 - mae: 0.7443 - mape: 109.0402\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 130us/sample - loss: 0.7442 - mse: 0.5749 - mae: 0.7442 - mape: 109.0229\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 124us/sample - loss: 0.7441 - mse: 0.5747 - mae: 0.7441 - mape: 109.0056\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 139us/sample - loss: 0.7440 - mse: 0.5745 - mae: 0.7440 - mape: 108.9883\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 124us/sample - loss: 0.7439 - mse: 0.5744 - mae: 0.7439 - mape: 108.9710\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 136us/sample - loss: 0.7437 - mse: 0.5742 - mae: 0.7437 - mape: 108.9537\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 127us/sample - loss: 0.7436 - mse: 0.5740 - mae: 0.7436 - mape: 108.9364\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 125us/sample - loss: 0.7435 - mse: 0.5739 - mae: 0.7435 - mape: 108.9191\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 143us/sample - loss: 0.7434 - mse: 0.5737 - mae: 0.7434 - mape: 108.9018\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 171us/sample - loss: 0.7433 - mse: 0.5735 - mae: 0.7433 - mape: 108.8845\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 205us/sample - loss: 0.7432 - mse: 0.5734 - mae: 0.7432 - mape: 108.8672\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 171us/sample - loss: 0.7431 - mse: 0.5732 - mae: 0.7431 - mape: 108.8499\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 4/9Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 38 samples\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 13ms/sample - loss: 0.7999 - mse: 0.6404 - mae: 0.7999 - mape: 94.8564\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 214us/sample - loss: 0.7997 - mse: 0.6401 - mae: 0.7997 - mape: 94.8331\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 184us/sample - loss: 0.7995 - mse: 0.6398 - mae: 0.7995 - mape: 94.8098\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 198us/sample - loss: 0.7993 - mse: 0.6395 - mae: 0.7993 - mape: 94.7865\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 199us/sample - loss: 0.7991 - mse: 0.6392 - mae: 0.7991 - mape: 94.7632\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 201us/sample - loss: 0.7989 - mse: 0.6389 - mae: 0.7989 - mape: 94.7399\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 153us/sample - loss: 0.7987 - mse: 0.6385 - mae: 0.7987 - mape: 94.7166\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 187us/sample - loss: 0.7985 - mse: 0.6382 - mae: 0.7985 - mape: 94.6933\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 238us/sample - loss: 0.7983 - mse: 0.6379 - mae: 0.7983 - mape: 94.6700\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 179us/sample - loss: 0.7981 - mse: 0.6376 - mae: 0.7981 - mape: 94.6467\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 149us/sample - loss: 0.7979 - mse: 0.6373 - mae: 0.7979 - mape: 94.6234\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 237us/sample - loss: 0.7977 - mse: 0.6370 - mae: 0.7977 - mape: 94.6001\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 301us/sample - loss: 0.7975 - mse: 0.6367 - mae: 0.7975 - mape: 94.5768\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 203us/sample - loss: 0.7973 - mse: 0.6364 - mae: 0.7973 - mape: 94.5535\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 168us/sample - loss: 0.7971 - mse: 0.6360 - mae: 0.7971 - mape: 94.5303\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 202us/sample - loss: 0.7969 - mse: 0.6357 - mae: 0.7969 - mape: 94.5070\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 210us/sample - loss: 0.7968 - mse: 0.6354 - mae: 0.7968 - mape: 94.4837\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 188us/sample - loss: 0.7966 - mse: 0.6351 - mae: 0.7966 - mape: 94.4604\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 184us/sample - loss: 0.7964 - mse: 0.6348 - mae: 0.7964 - mape: 94.4371\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 207us/sample - loss: 0.7962 - mse: 0.6345 - mae: 0.7962 - mape: 94.4139\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 155us/sample - loss: 0.7960 - mse: 0.6342 - mae: 0.7960 - mape: 94.3906\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 197us/sample - loss: 0.7958 - mse: 0.6339 - mae: 0.7958 - mape: 94.3673\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 211us/sample - loss: 0.7956 - mse: 0.6335 - mae: 0.7956 - mape: 94.3440\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 166us/sample - loss: 0.7954 - mse: 0.6332 - mae: 0.7954 - mape: 94.3208\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 172us/sample - loss: 0.7952 - mse: 0.6329 - mae: 0.7952 - mape: 94.2975\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 180us/sample - loss: 0.7950 - mse: 0.6326 - mae: 0.7950 - mape: 94.2742\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 168us/sample - loss: 0.7948 - mse: 0.6323 - mae: 0.7948 - mape: 94.2509\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 218us/sample - loss: 0.7946 - mse: 0.6320 - mae: 0.7946 - mape: 94.2276\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 279us/sample - loss: 0.7944 - mse: 0.6317 - mae: 0.7944 - mape: 94.2043\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 209us/sample - loss: 0.7942 - mse: 0.6314 - mae: 0.7942 - mape: 94.1810\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 187us/sample - loss: 0.7940 - mse: 0.6311 - mae: 0.7940 - mape: 94.1577\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 205us/sample - loss: 0.7938 - mse: 0.6307 - mae: 0.7938 - mape: 94.1344\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 217us/sample - loss: 0.7936 - mse: 0.6304 - mae: 0.7936 - mape: 94.1111\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 201us/sample - loss: 0.7934 - mse: 0.6301 - mae: 0.7934 - mape: 94.0878\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 236us/sample - loss: 0.7932 - mse: 0.6298 - mae: 0.7932 - mape: 94.0645\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 188us/sample - loss: 0.7930 - mse: 0.6295 - mae: 0.7930 - mape: 94.0412\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 186us/sample - loss: 0.7928 - mse: 0.6292 - mae: 0.7928 - mape: 94.0179\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 193us/sample - loss: 0.7926 - mse: 0.6289 - mae: 0.7926 - mape: 93.9946\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 201us/sample - loss: 0.7924 - mse: 0.6286 - mae: 0.7924 - mape: 93.9713\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 293us/sample - loss: 0.7922 - mse: 0.6282 - mae: 0.7922 - mape: 93.9480\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 200us/sample - loss: 0.7920 - mse: 0.6279 - mae: 0.7920 - mape: 93.9246\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 174us/sample - loss: 0.7918 - mse: 0.6276 - mae: 0.7918 - mape: 93.9013\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 242us/sample - loss: 0.7917 - mse: 0.6273 - mae: 0.7917 - mape: 93.8779\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 218us/sample - loss: 0.7915 - mse: 0.6270 - mae: 0.7915 - mape: 93.8546\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 225us/sample - loss: 0.7913 - mse: 0.6267 - mae: 0.7913 - mape: 93.8313\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 151us/sample - loss: 0.7911 - mse: 0.6264 - mae: 0.7911 - mape: 93.8079\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 209us/sample - loss: 0.7909 - mse: 0.6261 - mae: 0.7909 - mape: 93.7846\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 191us/sample - loss: 0.7907 - mse: 0.6258 - mae: 0.7907 - mape: 93.7612\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 204us/sample - loss: 0.7905 - mse: 0.6254 - mae: 0.7905 - mape: 93.7378\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 222us/sample - loss: 0.7903 - mse: 0.6251 - mae: 0.7903 - mape: 93.7144\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 321us/sample - loss: 0.7901 - mse: 0.6248 - mae: 0.7901 - mape: 93.6911\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 233us/sample - loss: 0.7899 - mse: 0.6245 - mae: 0.7899 - mape: 93.6677\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 199us/sample - loss: 0.7897 - mse: 0.6242 - mae: 0.7897 - mape: 93.6443\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 181us/sample - loss: 0.7895 - mse: 0.6239 - mae: 0.7895 - mape: 93.6209\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 251us/sample - loss: 0.7893 - mse: 0.6236 - mae: 0.7893 - mape: 93.5975\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 229us/sample - loss: 0.7891 - mse: 0.6233 - mae: 0.7891 - mape: 93.5741\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 213us/sample - loss: 0.7889 - mse: 0.6230 - mae: 0.7889 - mape: 93.5507\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 181us/sample - loss: 0.7887 - mse: 0.6226 - mae: 0.7887 - mape: 93.5273\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 196us/sample - loss: 0.7885 - mse: 0.6223 - mae: 0.7885 - mape: 93.5038\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 168us/sample - loss: 0.7883 - mse: 0.6220 - mae: 0.7883 - mape: 93.4804\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 173us/sample - loss: 0.7881 - mse: 0.6217 - mae: 0.7881 - mape: 93.4570\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 214us/sample - loss: 0.7879 - mse: 0.6214 - mae: 0.7879 - mape: 93.4335\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 168us/sample - loss: 0.7877 - mse: 0.6211 - mae: 0.7877 - mape: 93.4101\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 311us/sample - loss: 0.7875 - mse: 0.6208 - mae: 0.7875 - mape: 93.3866\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 201us/sample - loss: 0.7873 - mse: 0.6205 - mae: 0.7873 - mape: 93.3631\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 208us/sample - loss: 0.7871 - mse: 0.6202 - mae: 0.7871 - mape: 93.3396\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 206us/sample - loss: 0.7869 - mse: 0.6198 - mae: 0.7869 - mape: 93.3162\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 182us/sample - loss: 0.7867 - mse: 0.6195 - mae: 0.7867 - mape: 93.2926\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 217us/sample - loss: 0.7865 - mse: 0.6192 - mae: 0.7865 - mape: 93.2691\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 249us/sample - loss: 0.7863 - mse: 0.6189 - mae: 0.7863 - mape: 93.2457\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 155us/sample - loss: 0.7861 - mse: 0.6186 - mae: 0.7861 - mape: 93.2221\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 176us/sample - loss: 0.7859 - mse: 0.6183 - mae: 0.7859 - mape: 93.1985\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 193us/sample - loss: 0.7857 - mse: 0.6180 - mae: 0.7857 - mape: 93.1750\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 167us/sample - loss: 0.7855 - mse: 0.6177 - mae: 0.7855 - mape: 93.1514\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 183us/sample - loss: 0.7853 - mse: 0.6174 - mae: 0.7853 - mape: 93.1278\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 176us/sample - loss: 0.7851 - mse: 0.6170 - mae: 0.7851 - mape: 93.1043\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 161us/sample - loss: 0.7849 - mse: 0.6167 - mae: 0.7849 - mape: 93.0806\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 236us/sample - loss: 0.7847 - mse: 0.6164 - mae: 0.7847 - mape: 93.0571\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 220us/sample - loss: 0.7845 - mse: 0.6161 - mae: 0.7845 - mape: 93.0334\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 274us/sample - loss: 0.7843 - mse: 0.6158 - mae: 0.7843 - mape: 93.0099\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 155us/sample - loss: 0.7841 - mse: 0.6155 - mae: 0.7841 - mape: 92.9862\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 206us/sample - loss: 0.7839 - mse: 0.6152 - mae: 0.7839 - mape: 92.9625\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 203us/sample - loss: 0.7837 - mse: 0.6149 - mae: 0.7837 - mape: 92.9389\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 186us/sample - loss: 0.7835 - mse: 0.6145 - mae: 0.7835 - mape: 92.9152\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 183us/sample - loss: 0.7833 - mse: 0.6142 - mae: 0.7833 - mape: 92.8916\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 176us/sample - loss: 0.7831 - mse: 0.6139 - mae: 0.7831 - mape: 92.8678\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 153us/sample - loss: 0.7829 - mse: 0.6136 - mae: 0.7829 - mape: 92.8442\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 192us/sample - loss: 0.7827 - mse: 0.6133 - mae: 0.7827 - mape: 92.8204\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 204us/sample - loss: 0.7825 - mse: 0.6130 - mae: 0.7825 - mape: 92.7967\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 292us/sample - loss: 0.7823 - mse: 0.6127 - mae: 0.7823 - mape: 92.7730\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 180us/sample - loss: 0.7821 - mse: 0.6124 - mae: 0.7821 - mape: 92.7492\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 191us/sample - loss: 0.7819 - mse: 0.6120 - mae: 0.7819 - mape: 92.7255\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 196us/sample - loss: 0.7817 - mse: 0.6117 - mae: 0.7817 - mape: 92.7016\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 183us/sample - loss: 0.7815 - mse: 0.6114 - mae: 0.7815 - mape: 92.6779\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 200us/sample - loss: 0.7813 - mse: 0.6111 - mae: 0.7813 - mape: 92.6541\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 204us/sample - loss: 0.7811 - mse: 0.6108 - mae: 0.7811 - mape: 92.6302\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 151us/sample - loss: 0.7809 - mse: 0.6105 - mae: 0.7809 - mape: 92.6064\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 176us/sample - loss: 0.7807 - mse: 0.6102 - mae: 0.7807 - mape: 92.5826\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 141us/sample - loss: 0.7805 - mse: 0.6098 - mae: 0.7805 - mape: 92.5588\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 190us/sample - loss: 0.7803 - mse: 0.6095 - mae: 0.7803 - mape: 92.5349\n"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "# q_implicit_N_parts_possibilities = np.linspace(min_parts_threshold,max_parts_threshold,N_plot_finess)\n",
    "N_parts_possibilities = np.unique(np.round(np.linspace(N_min_parts,N_max_plots,num=N_plot_finess))).astype(int)\n",
    "# Custom: N_parts_possibilities = np.array([1,2,3,4,5,8]); N_plot_finess = len(N_parts_possibilities)\n",
    "\n",
    "# Get Performance Metric\n",
    "for inplicit_N_parts_loop in range(len(N_parts_possibilities)):\n",
    "    ### UPDATE USER ###\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    print('Ablation Completion Percentage:',(inplicit_N_parts_loop/N_plot_finess))\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    \n",
    "    # Implicitly Set: Current Number of Parts\n",
    "#     q_implicit_N_parts_loop = q_implicit_N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    N_parts_possibilities_loop = N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    # Run Algos. 1+2\n",
    "    performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop, N_neurons_subPatterns_loop, N_neurons_deep_Zero_Sets_loop, height_mean_loop, performance_PCNN_ffNN_logistic_loop, N_params_PCNN_logistic_loop = get_PCNNs(N_parts_possibilities_loop,X_train,y_train,X_test,y_test)\n",
    "#     performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop, height_mean_loop = Ablate_PCNNs(q_implicit_N_parts_loop,data_y,X_train,X_test,y_test)\n",
    "    # Reshape\n",
    "    performance_Architope_loop = performance_Architope_loop.to_numpy().reshape([3,2,1])\n",
    "    Architope_Model_Complexity_full_loop = Architope_Model_Complexity_full_loop.to_numpy().reshape([1,6,1])\n",
    "    performance_PCNN_ffNN_logistic_loop = performance_PCNN_ffNN_logistic_loop.to_numpy().reshape([3,2,1])\n",
    "    # Record\n",
    "    if inplicit_N_parts_loop == 0:\n",
    "        # Don't count partitioner if only one parts is active!\n",
    "        if N_parts_possibilities_loop <= 1:\n",
    "            Architope_Model_Complexity_full_loop[:,1] = Architope_Model_Complexity_full_loop[:,0]\n",
    "            N_neurons_deep_Zero_Sets_loop = 0\n",
    "        # Record Model Complexities Otherwise    \n",
    "        performance_Architope_history = performance_Architope_loop\n",
    "        Architope_Model_Complexity_history = Architope_Model_Complexity_full_loop\n",
    "        N_parts_Generated_by_Algo_2_history = N_parts_Generated_by_Algo_2_loop\n",
    "        N_params_subPatterns_hist = N_neurons_subPatterns_loop\n",
    "        N_neurons_deep_Zero_Sets_hist = N_neurons_deep_Zero_Sets_loop\n",
    "        N_params_architope_hist = N_neurons_deep_Zero_Sets_loop + N_neurons_subPatterns_loop\n",
    "        height_mean_hist = height_mean_loop\n",
    "        N_neurons_per_input = N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))\n",
    "        ### BENCHMARKs\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = performance_PCNN_ffNN_logistic_loop\n",
    "        N_params_PCNN_logistic_hist = N_params_PCNN_logistic_loop\n",
    "    else:\n",
    "        performance_Architope_history = np.concatenate((performance_Architope_history,performance_Architope_loop),axis=2)\n",
    "        Architope_Model_Complexity_history = np.concatenate((Architope_Model_Complexity_history,Architope_Model_Complexity_full_loop),axis=2)\n",
    "        N_parts_Generated_by_Algo_2_history = np.append(N_parts_Generated_by_Algo_2_history,N_parts_Generated_by_Algo_2_loop)\n",
    "        N_params_architope_hist = np.append(N_params_architope_hist,N_params_architope_loop)\n",
    "        N_params_subPatterns_hist = np.append(N_params_subPatterns_hist,N_neurons_subPatterns_loop)\n",
    "        N_neurons_deep_Zero_Sets_hist = np.append(N_neurons_deep_Zero_Sets_hist,N_neurons_deep_Zero_Sets_loop)\n",
    "        height_mean_hist = np.append(height_mean_hist,height_mean_loop)\n",
    "        N_neurons_per_input = np.append(N_neurons_per_input,(N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))))\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = np.concatenate((performance_PCNN_ffNN_logistic_hist,\n",
    "                                                              performance_PCNN_ffNN_logistic_loop),\n",
    "                                                             axis=2)\n",
    "        N_params_PCNN_logistic_hist = np.append(N_params_PCNN_logistic_hist,N_params_PCNN_logistic_loop)\n",
    "\n",
    "# Cleanup\n",
    "## Randomization may produce duplicates; we remove these with the following snippet:\n",
    "get_unique_entries = np.unique(N_parts_Generated_by_Algo_2_history, return_index=True)[1]\n",
    "N_parts_Generated_by_Algo_2_history_report = N_parts_Generated_by_Algo_2_history[get_unique_entries]\n",
    "\n",
    "# Write\n",
    "## Prediction Qualities\n",
    "performance_Architope_history_report_MAE_train = (performance_Architope_history[0,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MAE_test = (performance_Architope_history[0,1,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_train = (performance_Architope_history[1,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_test = (performance_Architope_history[1,1,:])[get_unique_entries]\n",
    "## Model Complexities\n",
    "L_Times = (Architope_Model_Complexity_history[:,1].reshape(-1,))[get_unique_entries]\n",
    "P_Times = (Architope_Model_Complexity_history[:,0].reshape(-1,))[get_unique_entries]\n",
    "N_Params = (N_params_architope_hist.reshape(-1,))[get_unique_entries]\n",
    "mean_subpattern_widths_hist = (height_mean_hist.reshape(-1,))[get_unique_entries]\n",
    "AIC_Like = (Architope_Model_Complexity_history[:,3].reshape(-1,))[get_unique_entries]\n",
    "Eff = (Architope_Model_Complexity_history[:,4].reshape(-1,))[get_unique_entries]\n",
    "N_neurons_per_input = (N_neurons_per_input.reshape(-1,))[get_unique_entries]\n",
    "\n",
    "# Record Benchmark Complexities\n",
    "performance_PCNN_ffNN_logistic_report_MAE_train = (performance_PCNN_ffNN_logistic_hist[0,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MAE_test = (performance_PCNN_ffNN_logistic_hist[0,1,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MSE_train = (performance_PCNN_ffNN_logistic_hist[1,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MSE_test = (performance_PCNN_ffNN_logistic_hist[1,1,:])[get_unique_entries]\n",
    "N_params_PCNN_logistic_hist = N_params_PCNN_logistic_hist[get_unique_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feedforward Neural Network (ffNN) Benchmark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Model complexities for ffNNs\n",
    "P_time_ffNN = P_Times[0]\n",
    "L_time_ffNN = P_Times[0]\n",
    "Width_ffNN = height_mean_hist[0]\n",
    "# For: Plots\n",
    "MAE_ffNN = np.repeat(performance_Architope_history_report_MAE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "MSE_ffNN = np.repeat(performance_Architope_history_report_MSE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "L_times_ffNN_plot = np.repeat(L_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "P_times_ffNN_plot = np.repeat(P_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_per_input_ffNN = np.repeat(N_neurons_per_input[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "Width_neurons_ffNN = np.repeat(mean_subpattern_widths_hist[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_ffNN = np.repeat(N_Params[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "# Record in Table\n",
    "ffNN_Model_Complexity = pd.DataFrame({'L-time': [L_time_ffNN],\n",
    "                                               'P-time':[P_time_ffNN],\n",
    "                                               'N_params_expt': [N_neurons_ffNN],\n",
    "                                               'AIC-like': [0],\n",
    "                                               'Eff': [0],\n",
    "                                               'N. Parts':[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MSE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MSE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MSE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MSE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "# Add Legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MSE_test___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MAE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MAE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MAE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MAE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MAE___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"L-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"L-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_L_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"P-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"P-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_P_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"N. Params\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"N. Params\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_Params,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_N_Params___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Active Neurons Per Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Active Neurons per. Input\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Active Neurons per. Input\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_per_input,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Active_Neurons_per_input___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Widths for Sub-Pattern Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Mean Subpattern Widths\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Mean Subpattern Widths\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         mean_subpattern_widths_hist,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         Width_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Mean_Widths___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCNN with Logistic-Classifier Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_architope_ffNN_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
