{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  5001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 10\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6660667866426715\n",
      "0.42451509698060386\n",
      "0.2501499700059988\n",
      "0.047590481903619274\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    \n",
    "# Trash removal (removes empty parts)\n",
    "X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "    \n",
    "    \n",
    "# ICML Rebuttle Deadline = Coersion!\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 5.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 5 parts.\n",
      "Heights to iterate over: [134]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   16.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   16.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0608 - mse: 0.0061 - mae: 0.0608 - mape: 180.7863\n",
      "Epoch 2/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0344 - mse: 0.0022 - mae: 0.0344 - mape: 170.5175\n",
      "Epoch 3/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0021 - mae: 0.0330 - mape: 157.3782\n",
      "Epoch 4/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0018 - mae: 0.0313 - mape: 147.1158\n",
      "Epoch 5/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0295 - mse: 0.0016 - mae: 0.0295 - mape: 138.8710\n",
      "Epoch 6/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0274 - mse: 0.0014 - mae: 0.0274 - mape: 118.0083\n",
      "Epoch 7/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0011 - mae: 0.0252 - mape: 103.7847\n",
      "Epoch 8/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 9.0604e-04 - mae: 0.0230 - mape: 88.0773\n",
      "Epoch 9/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 7.6450e-04 - mae: 0.0211 - mape: 64.4913\n",
      "Epoch 10/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0196 - mse: 6.6568e-04 - mae: 0.0196 - mape: 64.0453\n",
      "Epoch 11/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 5.7459e-04 - mae: 0.0182 - mape: 71.2617\n",
      "Epoch 12/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 5.6362e-04 - mae: 0.0173 - mape: 81.2395\n",
      "Epoch 13/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 5.0628e-04 - mae: 0.0167 - mape: 87.9211\n",
      "Epoch 14/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 5.3612e-04 - mae: 0.0164 - mape: 100.6874\n",
      "Epoch 15/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 5.4196e-04 - mae: 0.0164 - mape: 99.9154\n",
      "Epoch 16/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 5.6009e-04 - mae: 0.0164 - mape: 106.4606\n",
      "Epoch 17/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 5.5487e-04 - mae: 0.0164 - mape: 101.9201\n",
      "Epoch 18/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 5.5101e-04 - mae: 0.0164 - mape: 103.2756\n",
      "Epoch 19/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4476e-04 - mae: 0.0163 - mape: 101.7725\n",
      "Epoch 20/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 5.5691e-04 - mae: 0.0165 - mape: 102.1791\n",
      "Epoch 21/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 5.6064e-04 - mae: 0.0165 - mape: 101.9322\n",
      "Epoch 22/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4604e-04 - mae: 0.0163 - mape: 101.5947\n",
      "Epoch 23/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4942e-04 - mae: 0.0163 - mape: 102.0085\n",
      "Epoch 24/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.5804e-04 - mae: 0.0163 - mape: 104.0251\n",
      "Epoch 25/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.5212e-04 - mae: 0.0163 - mape: 102.9526\n",
      "Epoch 26/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.4483e-04 - mae: 0.0163 - mape: 101.6603\n",
      "Epoch 27/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.5754e-04 - mae: 0.0163 - mape: 102.8752\n",
      "Epoch 28/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4957e-04 - mae: 0.0163 - mape: 101.7040\n",
      "Epoch 29/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4739e-04 - mae: 0.0163 - mape: 101.6257\n",
      "Epoch 30/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.5156e-04 - mae: 0.0163 - mape: 102.8199\n",
      "Epoch 31/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4493e-04 - mae: 0.0163 - mape: 99.8576\n",
      "Epoch 32/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.4590e-04 - mae: 0.0163 - mape: 101.9240\n",
      "Epoch 33/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4979e-04 - mae: 0.0163 - mape: 103.9124\n",
      "Epoch 34/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 5.4427e-04 - mae: 0.0162 - mape: 101.4861\n",
      "Epoch 35/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.5316e-04 - mae: 0.0163 - mape: 103.3291\n",
      "Epoch 36/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 5.5024e-04 - mae: 0.0162 - mape: 103.2658\n",
      "Epoch 37/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.5207e-04 - mae: 0.0163 - mape: 102.9029\n",
      "Epoch 38/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 5.5591e-04 - mae: 0.0165 - mape: 103.6202\n",
      "Epoch 39/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4267e-04 - mae: 0.0162 - mape: 100.6249\n",
      "Epoch 40/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4855e-04 - mae: 0.0162 - mape: 101.6541\n",
      "Epoch 41/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.3877e-04 - mae: 0.0163 - mape: 101.4497\n",
      "Epoch 42/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5257e-04 - mae: 0.0162 - mape: 103.3523\n",
      "Epoch 43/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.4628e-04 - mae: 0.0163 - mape: 100.4131\n",
      "Epoch 44/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.3887e-04 - mae: 0.0162 - mape: 101.0866\n",
      "Epoch 45/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5255e-04 - mae: 0.0162 - mape: 103.6108\n",
      "Epoch 46/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 5.5212e-04 - mae: 0.0164 - mape: 102.9420\n",
      "Epoch 47/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 5.4821e-04 - mae: 0.0163 - mape: 102.0748\n",
      "Epoch 48/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4083e-04 - mae: 0.0162 - mape: 100.6232\n",
      "Epoch 49/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.4932e-04 - mae: 0.0163 - mape: 103.9096\n",
      "Epoch 50/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4060e-04 - mae: 0.0162 - mape: 101.3970\n",
      "Epoch 51/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4917e-04 - mae: 0.0162 - mape: 102.2329\n",
      "Epoch 52/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4496e-04 - mae: 0.0162 - mape: 102.0665\n",
      "Epoch 53/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5804e-04 - mae: 0.0162 - mape: 103.1930\n",
      "Epoch 54/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.3951e-04 - mae: 0.0162 - mape: 101.5980\n",
      "Epoch 55/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.5234e-04 - mae: 0.0161 - mape: 103.0700\n",
      "Epoch 56/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.4621e-04 - mae: 0.0163 - mape: 102.1193\n",
      "Epoch 57/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4615e-04 - mae: 0.0162 - mape: 102.0955\n",
      "Epoch 58/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.3216e-04 - mae: 0.0162 - mape: 98.7868\n",
      "Epoch 59/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.5067e-04 - mae: 0.0161 - mape: 103.2416\n",
      "Epoch 60/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4526e-04 - mae: 0.0161 - mape: 100.9716\n",
      "Epoch 61/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.3945e-04 - mae: 0.0162 - mape: 99.4671\n",
      "Epoch 62/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4079e-04 - mae: 0.0162 - mape: 100.7146\n",
      "Epoch 63/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5432e-04 - mae: 0.0162 - mape: 103.6670\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.3759e-04 - mae: 0.0162 - mape: 100.1211\n",
      "Epoch 65/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4900e-04 - mae: 0.0162 - mape: 102.2948\n",
      "Epoch 66/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3559e-04 - mae: 0.0161 - mape: 99.6036\n",
      "Epoch 67/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4541e-04 - mae: 0.0162 - mape: 101.1130\n",
      "Epoch 68/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3267e-04 - mae: 0.0161 - mape: 99.4308\n",
      "Epoch 69/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4929e-04 - mae: 0.0161 - mape: 103.8855\n",
      "Epoch 70/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4893e-04 - mae: 0.0162 - mape: 105.5425\n",
      "Epoch 71/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4434e-04 - mae: 0.0161 - mape: 101.9987\n",
      "Epoch 72/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4292e-04 - mae: 0.0161 - mape: 102.8104\n",
      "Epoch 73/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4223e-04 - mae: 0.0161 - mape: 102.4508\n",
      "Epoch 74/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4063e-04 - mae: 0.0162 - mape: 100.7361\n",
      "Epoch 75/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4195e-04 - mae: 0.0162 - mape: 99.9192\n",
      "Epoch 76/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.5138e-04 - mae: 0.0161 - mape: 103.4323\n",
      "Epoch 77/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4669e-04 - mae: 0.0161 - mape: 101.8152\n",
      "Epoch 78/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4260e-04 - mae: 0.0161 - mape: 101.6268\n",
      "Epoch 79/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4301e-04 - mae: 0.0162 - mape: 101.5106\n",
      "Epoch 80/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5776e-04 - mae: 0.0162 - mape: 104.5059\n",
      "Epoch 81/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4382e-04 - mae: 0.0162 - mape: 101.6596\n",
      "Epoch 82/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4451e-04 - mae: 0.0161 - mape: 100.8501\n",
      "Epoch 83/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4109e-04 - mae: 0.0161 - mape: 100.2391\n",
      "Epoch 84/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3940e-04 - mae: 0.0161 - mape: 102.4753\n",
      "Epoch 85/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.2305e-04 - mae: 0.0161 - mape: 97.9716\n",
      "Epoch 86/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 5.5731e-04 - mae: 0.0163 - mape: 104.1143\n",
      "Epoch 87/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3666e-04 - mae: 0.0161 - mape: 99.8900\n",
      "Epoch 88/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3932e-04 - mae: 0.0160 - mape: 100.7512\n",
      "Epoch 89/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4684e-04 - mae: 0.0161 - mape: 103.2620\n",
      "Epoch 90/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4510e-04 - mae: 0.0161 - mape: 102.8801\n",
      "Epoch 91/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4220e-04 - mae: 0.0161 - mape: 100.1938\n",
      "Epoch 92/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 5.4211e-04 - mae: 0.0164 - mape: 98.9193\n",
      "Epoch 93/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.5493e-04 - mae: 0.0162 - mape: 104.8188\n",
      "Epoch 94/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4305e-04 - mae: 0.0161 - mape: 99.7472\n",
      "Epoch 95/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4502e-04 - mae: 0.0161 - mape: 101.8481\n",
      "Epoch 96/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3534e-04 - mae: 0.0160 - mape: 99.8442\n",
      "Epoch 97/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3257e-04 - mae: 0.0160 - mape: 99.4317\n",
      "Epoch 98/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4404e-04 - mae: 0.0161 - mape: 100.6703\n",
      "Epoch 99/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4037e-04 - mae: 0.0160 - mape: 101.1138\n",
      "Epoch 100/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4523e-04 - mae: 0.0160 - mape: 103.3150\n",
      "Epoch 101/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3630e-04 - mae: 0.0160 - mape: 99.8663\n",
      "Epoch 102/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 5.4299e-04 - mae: 0.0162 - mape: 100.7662\n",
      "Epoch 103/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3853e-04 - mae: 0.0160 - mape: 100.2343\n",
      "Epoch 104/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3456e-04 - mae: 0.0160 - mape: 100.2361\n",
      "Epoch 105/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.4328e-04 - mae: 0.0161 - mape: 102.3052\n",
      "Epoch 106/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3931e-04 - mae: 0.0160 - mape: 100.2336\n",
      "Epoch 107/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3930e-04 - mae: 0.0160 - mape: 99.4767\n",
      "Epoch 108/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.5132e-04 - mae: 0.0161 - mape: 102.2166\n",
      "Epoch 109/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.2912e-04 - mae: 0.0160 - mape: 98.7177\n",
      "Epoch 110/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3480e-04 - mae: 0.0160 - mape: 99.6654\n",
      "Epoch 111/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4249e-04 - mae: 0.0160 - mape: 101.3139\n",
      "Epoch 112/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4120e-04 - mae: 0.0160 - mape: 103.1505\n",
      "Epoch 113/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3940e-04 - mae: 0.0161 - mape: 98.6238\n",
      "Epoch 114/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4064e-04 - mae: 0.0159 - mape: 101.3582\n",
      "Epoch 115/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4540e-04 - mae: 0.0159 - mape: 101.4144\n",
      "Epoch 116/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.5903e-04 - mae: 0.0161 - mape: 102.8609\n",
      "Epoch 117/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.3151e-04 - mae: 0.0160 - mape: 99.9185\n",
      "Epoch 118/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4546e-04 - mae: 0.0160 - mape: 103.7858\n",
      "Epoch 119/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.2877e-04 - mae: 0.0161 - mape: 98.4517\n",
      "Epoch 120/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.5068e-04 - mae: 0.0160 - mape: 102.0566\n",
      "Epoch 121/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4494e-04 - mae: 0.0159 - mape: 102.3592\n",
      "Epoch 122/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3192e-04 - mae: 0.0159 - mape: 99.5444\n",
      "Epoch 123/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3388e-04 - mae: 0.0159 - mape: 100.4605\n",
      "Epoch 124/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 5.3238e-04 - mae: 0.0161 - mape: 97.8067\n",
      "Epoch 125/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4671e-04 - mae: 0.0159 - mape: 102.4262\n",
      "Epoch 126/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2835e-04 - mae: 0.0159 - mape: 99.6681\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.4119e-04 - mae: 0.0160 - mape: 98.1946\n",
      "Epoch 128/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4679e-04 - mae: 0.0159 - mape: 101.6694\n",
      "Epoch 129/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2760e-04 - mae: 0.0159 - mape: 99.8707\n",
      "Epoch 130/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4700e-04 - mae: 0.0159 - mape: 103.0830\n",
      "Epoch 131/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4053e-04 - mae: 0.0159 - mape: 101.1259\n",
      "Epoch 132/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3583e-04 - mae: 0.0159 - mape: 100.5860\n",
      "Epoch 133/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2810e-04 - mae: 0.0159 - mape: 98.5229\n",
      "Epoch 134/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2337e-04 - mae: 0.0159 - mape: 97.1807\n",
      "Epoch 135/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4150e-04 - mae: 0.0159 - mape: 101.8176\n",
      "Epoch 136/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3113e-04 - mae: 0.0159 - mape: 99.8063\n",
      "Epoch 137/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 5.2626e-04 - mae: 0.0160 - mape: 97.4492\n",
      "Epoch 138/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4107e-04 - mae: 0.0159 - mape: 99.9114\n",
      "Epoch 139/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3910e-04 - mae: 0.0158 - mape: 100.7625\n",
      "Epoch 140/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3235e-04 - mae: 0.0159 - mape: 100.3221\n",
      "Epoch 141/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4193e-04 - mae: 0.0159 - mape: 101.8135\n",
      "Epoch 142/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3128e-04 - mae: 0.0158 - mape: 100.0245\n",
      "Epoch 143/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4768e-04 - mae: 0.0159 - mape: 103.2857\n",
      "Epoch 144/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3047e-04 - mae: 0.0159 - mape: 100.3734\n",
      "Epoch 145/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3589e-04 - mae: 0.0159 - mape: 101.1111\n",
      "Epoch 146/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.4264e-04 - mae: 0.0159 - mape: 102.5050\n",
      "Epoch 147/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3753e-04 - mae: 0.0159 - mape: 102.5144\n",
      "Epoch 148/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3988e-04 - mae: 0.0159 - mape: 102.9105\n",
      "Epoch 149/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2446e-04 - mae: 0.0159 - mape: 97.5421\n",
      "Epoch 150/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3415e-04 - mae: 0.0159 - mape: 100.2548\n",
      "Epoch 151/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.4111e-04 - mae: 0.0158 - mape: 99.9196\n",
      "Epoch 152/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3609e-04 - mae: 0.0159 - mape: 99.9335\n",
      "Epoch 153/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3818e-04 - mae: 0.0158 - mape: 100.9699\n",
      "Epoch 154/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.4524e-04 - mae: 0.0158 - mape: 102.6181\n",
      "Epoch 155/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3797e-04 - mae: 0.0158 - mape: 100.1378\n",
      "Epoch 156/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.2780e-04 - mae: 0.0158 - mape: 100.4803\n",
      "Epoch 157/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.3744e-04 - mae: 0.0159 - mape: 102.4317\n",
      "Epoch 158/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.2935e-04 - mae: 0.0157 - mape: 99.5625\n",
      "Epoch 159/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3166e-04 - mae: 0.0158 - mape: 98.2769\n",
      "Epoch 160/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2468e-04 - mae: 0.0159 - mape: 100.8681\n",
      "Epoch 161/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.2575e-04 - mae: 0.0158 - mape: 99.3644\n",
      "Epoch 162/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3743e-04 - mae: 0.0157 - mape: 101.7246\n",
      "Epoch 163/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.2733e-04 - mae: 0.0158 - mape: 97.8039\n",
      "Epoch 164/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.4470e-04 - mae: 0.0157 - mape: 103.2561\n",
      "Epoch 165/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3366e-04 - mae: 0.0157 - mape: 99.2798\n",
      "Epoch 166/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3263e-04 - mae: 0.0158 - mape: 99.9947\n",
      "Epoch 167/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.1688e-04 - mae: 0.0157 - mape: 96.2572\n",
      "Epoch 168/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 5.3024e-04 - mae: 0.0157 - mape: 99.1420\n",
      "Epoch 169/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3219e-04 - mae: 0.0157 - mape: 99.9569\n",
      "Epoch 170/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.4138e-04 - mae: 0.0158 - mape: 100.6610\n",
      "Epoch 171/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3000e-04 - mae: 0.0157 - mape: 99.3645\n",
      "Epoch 172/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3338e-04 - mae: 0.0157 - mape: 98.7502\n",
      "Epoch 173/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.2150e-04 - mae: 0.0157 - mape: 96.5475\n",
      "Epoch 174/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.2464e-04 - mae: 0.0157 - mape: 98.5403\n",
      "Epoch 175/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 5.2940e-04 - mae: 0.0156 - mape: 98.7167\n",
      "Epoch 176/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3193e-04 - mae: 0.0157 - mape: 100.4947\n",
      "Epoch 177/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.3003e-04 - mae: 0.0158 - mape: 100.5355\n",
      "Epoch 178/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 5.4029e-04 - mae: 0.0158 - mape: 101.3953\n",
      "Epoch 179/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3402e-04 - mae: 0.0157 - mape: 101.1350\n",
      "Epoch 180/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.2360e-04 - mae: 0.0157 - mape: 98.2168\n",
      "Epoch 181/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2084e-04 - mae: 0.0156 - mape: 96.7180\n",
      "Epoch 182/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3054e-04 - mae: 0.0157 - mape: 99.6802\n",
      "Epoch 183/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2871e-04 - mae: 0.0156 - mape: 99.9773\n",
      "Epoch 184/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2856e-04 - mae: 0.0156 - mape: 98.6572\n",
      "Epoch 185/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3635e-04 - mae: 0.0157 - mape: 100.3710\n",
      "Epoch 186/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2084e-04 - mae: 0.0156 - mape: 98.4374\n",
      "Epoch 187/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.3174e-04 - mae: 0.0157 - mape: 98.4062\n",
      "Epoch 188/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2229e-04 - mae: 0.0156 - mape: 98.9558\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.2942e-04 - mae: 0.0157 - mape: 100.1331\n",
      "Epoch 190/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 5.2907e-04 - mae: 0.0159 - mape: 99.6628\n",
      "Epoch 191/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.1232e-04 - mae: 0.0156 - mape: 96.3170\n",
      "Epoch 192/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.3254e-04 - mae: 0.0156 - mape: 100.6066\n",
      "Epoch 193/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2815e-04 - mae: 0.0156 - mape: 98.7097\n",
      "Epoch 194/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2054e-04 - mae: 0.0155 - mape: 97.4015\n",
      "Epoch 195/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.1689e-04 - mae: 0.0156 - mape: 97.5276\n",
      "Epoch 196/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2282e-04 - mae: 0.0155 - mape: 98.6920\n",
      "Epoch 197/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.3140e-04 - mae: 0.0156 - mape: 99.2794\n",
      "Epoch 198/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2442e-04 - mae: 0.0156 - mape: 97.9135\n",
      "Epoch 199/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.1626e-04 - mae: 0.0156 - mape: 98.1625\n",
      "Epoch 200/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.2117e-04 - mae: 0.0156 - mape: 95.2463\n",
      "Epoch 201/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 5.1317e-04 - mae: 0.0157 - mape: 96.4436\n",
      "Epoch 202/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.3142e-04 - mae: 0.0155 - mape: 100.5357\n",
      "Epoch 203/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2269e-04 - mae: 0.0155 - mape: 97.1986\n",
      "Epoch 204/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.1742e-04 - mae: 0.0155 - mape: 97.8692\n",
      "Epoch 205/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.0655e-04 - mae: 0.0155 - mape: 93.8771\n",
      "Epoch 206/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.3509e-04 - mae: 0.0154 - mape: 99.0367\n",
      "Epoch 207/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.0118e-04 - mae: 0.0156 - mape: 94.9676\n",
      "Epoch 208/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2909e-04 - mae: 0.0155 - mape: 99.5831\n",
      "Epoch 209/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.1935e-04 - mae: 0.0154 - mape: 97.9656\n",
      "Epoch 210/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.3141e-04 - mae: 0.0156 - mape: 98.5062\n",
      "Epoch 211/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 5.1316e-04 - mae: 0.0156 - mape: 97.0409\n",
      "Epoch 212/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.1133e-04 - mae: 0.0154 - mape: 96.4745\n",
      "Epoch 213/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2873e-04 - mae: 0.0155 - mape: 99.3746\n",
      "Epoch 214/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.1714e-04 - mae: 0.0154 - mape: 98.0630\n",
      "Epoch 215/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.1351e-04 - mae: 0.0154 - mape: 96.4491\n",
      "Epoch 216/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.1252e-04 - mae: 0.0154 - mape: 95.3410\n",
      "Epoch 217/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 5.2547e-04 - mae: 0.0155 - mape: 99.7423\n",
      "Epoch 218/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.0598e-04 - mae: 0.0154 - mape: 94.0420\n",
      "Epoch 219/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1104e-04 - mae: 0.0153 - mape: 95.5305\n",
      "Epoch 220/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1587e-04 - mae: 0.0153 - mape: 96.8027\n",
      "Epoch 221/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1655e-04 - mae: 0.0153 - mape: 96.7570\n",
      "Epoch 222/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1064e-04 - mae: 0.0153 - mape: 95.5752\n",
      "Epoch 223/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1636e-04 - mae: 0.0153 - mape: 97.1921\n",
      "Epoch 224/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 5.1341e-04 - mae: 0.0152 - mape: 96.2511\n",
      "Epoch 225/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 5.1882e-04 - mae: 0.0152 - mape: 96.7244\n",
      "Epoch 226/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 5.0450e-04 - mae: 0.0154 - mape: 94.2628\n",
      "Epoch 227/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.0197e-04 - mae: 0.0153 - mape: 92.6139\n",
      "Epoch 228/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.0414e-04 - mae: 0.0153 - mape: 95.3437\n",
      "Epoch 229/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1731e-04 - mae: 0.0153 - mape: 96.5076\n",
      "Epoch 230/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 5.1060e-04 - mae: 0.0153 - mape: 95.8752\n",
      "Epoch 231/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 5.1258e-04 - mae: 0.0153 - mape: 94.7677\n",
      "Epoch 232/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 4.9987e-04 - mae: 0.0152 - mape: 91.8023\n",
      "Epoch 233/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 5.0469e-04 - mae: 0.0152 - mape: 95.2062\n",
      "Epoch 234/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 4.9994e-04 - mae: 0.0151 - mape: 94.0305\n",
      "Epoch 235/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 5.0997e-04 - mae: 0.0151 - mape: 94.9115\n",
      "Epoch 236/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 5.1218e-04 - mae: 0.0151 - mape: 96.3812\n",
      "Epoch 237/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 5.0026e-04 - mae: 0.0151 - mape: 93.4051\n",
      "Epoch 238/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 5.1610e-04 - mae: 0.0151 - mape: 95.8425\n",
      "Epoch 239/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 4.9282e-04 - mae: 0.0151 - mape: 90.8347\n",
      "Epoch 240/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 5.1106e-04 - mae: 0.0150 - mape: 95.0297\n",
      "Epoch 241/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 4.9233e-04 - mae: 0.0151 - mape: 93.1136\n",
      "Epoch 242/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 4.8539e-04 - mae: 0.0150 - mape: 90.8463\n",
      "Epoch 243/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 4.9263e-04 - mae: 0.0149 - mape: 92.9111\n",
      "Epoch 244/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 4.9713e-04 - mae: 0.0150 - mape: 92.5531\n",
      "Epoch 245/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 5.0939e-04 - mae: 0.0149 - mape: 94.8678\n",
      "Epoch 246/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 4.8039e-04 - mae: 0.0149 - mape: 89.6842\n",
      "Epoch 247/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 4.8733e-04 - mae: 0.0149 - mape: 91.0632\n",
      "Epoch 248/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 4.9486e-04 - mae: 0.0149 - mape: 91.0220\n",
      "Epoch 249/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 4.8724e-04 - mae: 0.0148 - mape: 91.3127\n",
      "Epoch 250/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 4.9422e-04 - mae: 0.0147 - mape: 92.7035\n",
      "Epoch 251/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 4.8223e-04 - mae: 0.0148 - mape: 90.6534\n",
      "Epoch 252/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 4.8227e-04 - mae: 0.0148 - mape: 90.1153\n",
      "Epoch 253/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 4.7810e-04 - mae: 0.0146 - mape: 90.1816\n",
      "Epoch 254/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 4.7828e-04 - mae: 0.0146 - mape: 88.9762\n",
      "Epoch 255/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 4.8732e-04 - mae: 0.0146 - mape: 91.5198\n",
      "Epoch 256/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 4.7988e-04 - mae: 0.0145 - mape: 89.8558\n",
      "Epoch 257/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 4.8181e-04 - mae: 0.0144 - mape: 91.6456\n",
      "Epoch 258/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 4.6361e-04 - mae: 0.0144 - mape: 86.4350\n",
      "Epoch 259/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 4.7687e-04 - mae: 0.0144 - mape: 87.8860\n",
      "Epoch 260/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 4.7286e-04 - mae: 0.0143 - mape: 87.9627\n",
      "Epoch 261/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0142 - mse: 4.5702e-04 - mae: 0.0142 - mape: 85.2299\n",
      "Epoch 262/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 4.6898e-04 - mae: 0.0144 - mape: 86.0948\n",
      "Epoch 263/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0142 - mse: 4.7137e-04 - mae: 0.0142 - mape: 88.6682\n",
      "Epoch 264/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 4.6253e-04 - mae: 0.0141 - mape: 87.2025\n",
      "Epoch 265/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 4.5664e-04 - mae: 0.0140 - mape: 85.1832\n",
      "Epoch 266/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 4.4521e-04 - mae: 0.0140 - mape: 83.1033\n",
      "Epoch 267/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 4.6826e-04 - mae: 0.0139 - mape: 90.0130\n",
      "Epoch 268/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 4.6070e-04 - mae: 0.0139 - mape: 86.3604\n",
      "Epoch 269/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0137 - mse: 4.3373e-04 - mae: 0.0137 - mape: 80.0338\n",
      "Epoch 270/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 4.4795e-04 - mae: 0.0136 - mape: 83.2090\n",
      "Epoch 271/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 4.3436e-04 - mae: 0.0135 - mape: 81.0895\n",
      "Epoch 272/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 4.3954e-04 - mae: 0.0135 - mape: 81.2621\n",
      "Epoch 273/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 4.3426e-04 - mae: 0.0133 - mape: 80.8005\n",
      "Epoch 274/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 4.2648e-04 - mae: 0.0131 - mape: 79.7304\n",
      "Epoch 275/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 4.2146e-04 - mae: 0.0130 - mape: 78.6409\n",
      "Epoch 276/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 4.1953e-04 - mae: 0.0128 - mape: 77.5134\n",
      "Epoch 277/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 4.1058e-04 - mae: 0.0127 - mape: 75.7370\n",
      "Epoch 278/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 4.0650e-04 - mae: 0.0126 - mape: 73.2686\n",
      "Epoch 279/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 3.9025e-04 - mae: 0.0125 - mape: 71.0033\n",
      "Epoch 280/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 3.9663e-04 - mae: 0.0123 - mape: 73.6817\n",
      "Epoch 281/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 3.9011e-04 - mae: 0.0120 - mape: 71.5937\n",
      "Epoch 282/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 3.7714e-04 - mae: 0.0118 - mape: 68.6936\n",
      "Epoch 283/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 3.6528e-04 - mae: 0.0116 - mape: 65.4743\n",
      "Epoch 284/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 3.5863e-04 - mae: 0.0112 - mape: 63.4432\n",
      "Epoch 285/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 3.4638e-04 - mae: 0.0110 - mape: 58.9912\n",
      "Epoch 286/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 3.3286e-04 - mae: 0.0107 - mape: 57.9575\n",
      "Epoch 287/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 3.2968e-04 - mae: 0.0103 - mape: 55.5109\n",
      "Epoch 288/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 3.1794e-04 - mae: 0.0099 - mape: 52.5564\n",
      "Epoch 289/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 3.0839e-04 - mae: 0.0097 - mape: 46.6527\n",
      "Epoch 290/300\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 2.9660e-04 - mae: 0.0091 - mape: 46.8234\n",
      "Epoch 291/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 2.7992e-04 - mae: 0.0086 - mape: 41.4461\n",
      "Epoch 292/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 2.6791e-04 - mae: 0.0081 - mape: 36.3842\n",
      "Epoch 293/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 2.5636e-04 - mae: 0.0076 - mape: 32.2724\n",
      "Epoch 294/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 2.3644e-04 - mae: 0.0070 - mape: 26.2828\n",
      "Epoch 295/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 2.2754e-04 - mae: 0.0065 - mape: 22.2869\n",
      "Epoch 296/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 2.1265e-04 - mae: 0.0064 - mape: 22.7221\n",
      "Epoch 297/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 2.0882e-04 - mae: 0.0058 - mape: 19.4381\n",
      "Epoch 298/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 2.0260e-04 - mae: 0.0057 - mape: 21.2711\n",
      "Epoch 299/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.9598e-04 - mae: 0.0056 - mape: 22.7730\n",
      "Epoch 300/300\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.9188e-04 - mae: 0.0056 - mape: 23.4565\n",
      "157/157 [==============================] - 0s 606us/step\n",
      "157/157 [==============================] - 0s 831us/step\n",
      "Status: Current part: 1 out of : 5 parts.\n",
      "Heights to iterate over: [85]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   13.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2749 - mse: 0.0809 - mae: 0.2749 - mape: 101.0551\n",
      "Epoch 2/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2418 - mse: 0.0637 - mae: 0.2418 - mape: 88.0068\n",
      "Epoch 3/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2008 - mse: 0.0456 - mae: 0.2008 - mape: 71.8446\n",
      "Epoch 4/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1454 - mse: 0.0264 - mae: 0.1454 - mape: 50.0191\n",
      "Epoch 5/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0833 - mse: 0.0105 - mae: 0.0833 - mape: 27.3275\n",
      "Epoch 6/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0051 - mae: 0.0633 - mape: 23.6739\n",
      "Epoch 7/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0045 - mae: 0.0596 - mape: 24.5682\n",
      "Epoch 8/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0586 - mse: 0.0046 - mae: 0.0586 - mape: 25.3068\n",
      "Epoch 9/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0048 - mae: 0.0584 - mape: 25.7993\n",
      "Epoch 10/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0047 - mae: 0.0584 - mape: 25.4891\n",
      "Epoch 11/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0049 - mae: 0.0582 - mape: 26.0269\n",
      "Epoch 12/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0047 - mae: 0.0580 - mape: 25.6890\n",
      "Epoch 13/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0047 - mae: 0.0579 - mape: 25.5643\n",
      "Epoch 14/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0048 - mae: 0.0577 - mape: 25.8336\n",
      "Epoch 15/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0049 - mae: 0.0576 - mape: 26.0395\n",
      "Epoch 16/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0574 - mse: 0.0048 - mae: 0.0574 - mape: 25.7319\n",
      "Epoch 17/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0048 - mae: 0.0572 - mape: 25.8283\n",
      "Epoch 18/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0049 - mae: 0.0570 - mape: 26.0442\n",
      "Epoch 19/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0570 - mse: 0.0049 - mae: 0.0570 - mape: 25.9353\n",
      "Epoch 20/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0049 - mae: 0.0567 - mape: 25.9315\n",
      "Epoch 21/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0049 - mae: 0.0566 - mape: 25.9213\n",
      "Epoch 22/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0566 - mse: 0.0047 - mae: 0.0566 - mape: 25.5585\n",
      "Epoch 23/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0049 - mae: 0.0564 - mape: 25.9993\n",
      "Epoch 24/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0048 - mae: 0.0563 - mape: 25.7736\n",
      "Epoch 25/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0048 - mae: 0.0562 - mape: 25.8075\n",
      "Epoch 26/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0561 - mse: 0.0049 - mae: 0.0561 - mape: 25.9023\n",
      "Epoch 27/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0048 - mae: 0.0561 - mape: 25.7058\n",
      "Epoch 28/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0049 - mae: 0.0561 - mape: 25.8781\n",
      "Epoch 29/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0048 - mae: 0.0560 - mape: 25.7004\n",
      "Epoch 30/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0049 - mae: 0.0560 - mape: 25.9641\n",
      "Epoch 31/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8306\n",
      "Epoch 32/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0048 - mae: 0.0560 - mape: 25.8488\n",
      "Epoch 33/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.6923\n",
      "Epoch 34/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7752\n",
      "Epoch 35/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.8965\n",
      "Epoch 36/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.7750\n",
      "Epoch 37/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9404\n",
      "Epoch 38/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8123\n",
      "Epoch 39/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.7980\n",
      "Epoch 40/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8003\n",
      "Epoch 41/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.8981\n",
      "Epoch 42/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8450\n",
      "Epoch 43/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9009\n",
      "Epoch 44/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8473\n",
      "Epoch 45/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9240\n",
      "Epoch 46/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8108\n",
      "Epoch 47/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9109\n",
      "Epoch 48/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7949\n",
      "Epoch 49/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8849\n",
      "Epoch 50/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9278\n",
      "Epoch 51/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8591\n",
      "Epoch 52/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8857\n",
      "Epoch 53/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8738\n",
      "Epoch 54/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.7890\n",
      "Epoch 55/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9051\n",
      "Epoch 56/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9914\n",
      "Epoch 57/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0047 - mae: 0.0556 - mape: 25.6160\n",
      "Epoch 58/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0435\n",
      "Epoch 59/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9447\n",
      "Epoch 60/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7967\n",
      "Epoch 61/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7572\n",
      "Epoch 62/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 26.0336\n",
      "Epoch 63/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8913\n",
      "Epoch 64/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9347\n",
      "Epoch 65/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9048\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.7904\n",
      "Epoch 67/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8591\n",
      "Epoch 68/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9177\n",
      "Epoch 69/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9541\n",
      "Epoch 70/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8823\n",
      "Epoch 71/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8672\n",
      "Epoch 72/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8066\n",
      "Epoch 73/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9911\n",
      "Epoch 74/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8935\n",
      "Epoch 75/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.7752\n",
      "Epoch 76/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9343\n",
      "Epoch 77/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8600\n",
      "Epoch 78/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9388\n",
      "Epoch 79/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8470\n",
      "Epoch 80/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8711\n",
      "Epoch 81/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9324\n",
      "Epoch 82/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0047 - mae: 0.0560 - mape: 25.7583\n",
      "Epoch 83/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0048\n",
      "Epoch 84/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8015\n",
      "Epoch 85/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9486\n",
      "Epoch 86/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8264\n",
      "Epoch 87/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8371\n",
      "Epoch 88/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8881\n",
      "Epoch 89/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8658\n",
      "Epoch 90/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8666\n",
      "Epoch 91/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8998\n",
      "Epoch 92/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8830\n",
      "Epoch 93/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8845\n",
      "Epoch 94/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9754\n",
      "Epoch 95/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8919\n",
      "Epoch 96/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9712\n",
      "Epoch 97/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8485\n",
      "Epoch 98/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8569\n",
      "Epoch 99/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8624\n",
      "Epoch 100/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 26.0496\n",
      "Epoch 101/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0186\n",
      "Epoch 102/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8888\n",
      "Epoch 103/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8609\n",
      "Epoch 104/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8948\n",
      "Epoch 105/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0134\n",
      "Epoch 106/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9270\n",
      "Epoch 107/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0049 - mae: 0.0560 - mape: 25.9729\n",
      "Epoch 108/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0047 - mae: 0.0560 - mape: 25.7513\n",
      "Epoch 109/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.7646\n",
      "Epoch 110/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0141\n",
      "Epoch 111/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8550\n",
      "Epoch 112/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8285\n",
      "Epoch 113/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9145\n",
      "Epoch 114/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9258\n",
      "Epoch 115/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7954\n",
      "Epoch 116/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9802\n",
      "Epoch 117/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 26.0053\n",
      "Epoch 118/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0046 - mae: 0.0558 - mape: 25.6231\n",
      "Epoch 119/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9548\n",
      "Epoch 120/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9221\n",
      "Epoch 121/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9157\n",
      "Epoch 122/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9174\n",
      "Epoch 123/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8619\n",
      "Epoch 124/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8098\n",
      "Epoch 125/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9822\n",
      "Epoch 126/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.6846\n",
      "Epoch 127/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9981\n",
      "Epoch 128/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8064\n",
      "Epoch 129/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7739\n",
      "Epoch 130/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 26.0575\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9067\n",
      "Epoch 132/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9496\n",
      "Epoch 133/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8586\n",
      "Epoch 134/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7975\n",
      "Epoch 135/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9099\n",
      "Epoch 136/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7801\n",
      "Epoch 137/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7858\n",
      "Epoch 138/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9979\n",
      "Epoch 139/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7958\n",
      "Epoch 140/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9654\n",
      "Epoch 141/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7131\n",
      "Epoch 142/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8599\n",
      "Epoch 143/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8147\n",
      "Epoch 144/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9168\n",
      "Epoch 145/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9302\n",
      "Epoch 146/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8229\n",
      "Epoch 147/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7982\n",
      "Epoch 148/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.6647\n",
      "Epoch 149/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9611\n",
      "Epoch 150/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9949\n",
      "Epoch 151/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0046 - mae: 0.0557 - mape: 25.5983\n",
      "Epoch 152/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9825\n",
      "Epoch 153/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8858\n",
      "Epoch 154/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9132\n",
      "Epoch 155/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9767\n",
      "Epoch 156/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9146\n",
      "Epoch 157/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8020\n",
      "Epoch 158/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9100\n",
      "Epoch 159/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7676\n",
      "Epoch 160/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0401\n",
      "Epoch 161/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8344\n",
      "Epoch 162/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0048 - mae: 0.0560 - mape: 25.9189\n",
      "Epoch 163/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8479\n",
      "Epoch 164/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9637\n",
      "Epoch 165/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0046 - mae: 0.0558 - mape: 25.5906\n",
      "Epoch 166/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.9020\n",
      "Epoch 167/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9794\n",
      "Epoch 168/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.7044\n",
      "Epoch 169/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9195\n",
      "Epoch 170/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8996\n",
      "Epoch 171/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9829\n",
      "Epoch 172/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7823\n",
      "Epoch 173/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9777\n",
      "Epoch 174/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0048 - mae: 0.0560 - mape: 25.8639\n",
      "Epoch 175/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7938\n",
      "Epoch 176/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9092\n",
      "Epoch 177/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8538\n",
      "Epoch 178/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8290\n",
      "Epoch 179/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.6855\n",
      "Epoch 180/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 26.0297\n",
      "Epoch 181/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7123\n",
      "Epoch 182/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9828\n",
      "Epoch 183/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8693\n",
      "Epoch 184/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9283\n",
      "Epoch 185/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7739\n",
      "Epoch 186/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9558\n",
      "Epoch 187/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8041\n",
      "Epoch 188/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9798\n",
      "Epoch 189/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.6807\n",
      "Epoch 190/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8519\n",
      "Epoch 191/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9123\n",
      "Epoch 192/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9485\n",
      "Epoch 193/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7088\n",
      "Epoch 194/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8703\n",
      "Epoch 195/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9266\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8755\n",
      "Epoch 197/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7655\n",
      "Epoch 198/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0431\n",
      "Epoch 199/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7979\n",
      "Epoch 200/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9141\n",
      "Epoch 201/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7608\n",
      "Epoch 202/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0049 - mae: 0.0559 - mape: 25.9635\n",
      "Epoch 203/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8174\n",
      "Epoch 204/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7570\n",
      "Epoch 205/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 26.0009\n",
      "Epoch 206/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8726\n",
      "Epoch 207/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.6796\n",
      "Epoch 208/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9462\n",
      "Epoch 209/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8323\n",
      "Epoch 210/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9451\n",
      "Epoch 211/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7994\n",
      "Epoch 212/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8079\n",
      "Epoch 213/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9624\n",
      "Epoch 214/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8673\n",
      "Epoch 215/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8554\n",
      "Epoch 216/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.9035\n",
      "Epoch 217/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8179\n",
      "Epoch 218/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8801\n",
      "Epoch 219/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9108\n",
      "Epoch 220/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8817\n",
      "Epoch 221/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8783\n",
      "Epoch 222/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7397\n",
      "Epoch 223/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9817\n",
      "Epoch 224/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8218\n",
      "Epoch 225/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0049 - mae: 0.0556 - mape: 25.9313\n",
      "Epoch 226/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8164\n",
      "Epoch 227/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8227\n",
      "Epoch 228/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8434\n",
      "Epoch 229/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9211\n",
      "Epoch 230/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8664\n",
      "Epoch 231/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.7448\n",
      "Epoch 232/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9175\n",
      "Epoch 233/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9386\n",
      "Epoch 234/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8763\n",
      "Epoch 235/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7265\n",
      "Epoch 236/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9969\n",
      "Epoch 237/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8277\n",
      "Epoch 238/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7952\n",
      "Epoch 239/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8497\n",
      "Epoch 240/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 26.0061\n",
      "Epoch 241/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7598\n",
      "Epoch 242/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8422\n",
      "Epoch 243/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8199\n",
      "Epoch 244/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8744\n",
      "Epoch 245/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8695\n",
      "Epoch 246/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7191\n",
      "Epoch 247/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8365\n",
      "Epoch 248/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9403\n",
      "Epoch 249/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9879\n",
      "Epoch 250/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.6945\n",
      "Epoch 251/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8773\n",
      "Epoch 252/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7772\n",
      "Epoch 253/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8249\n",
      "Epoch 254/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9216\n",
      "Epoch 255/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7777\n",
      "Epoch 256/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 26.0128\n",
      "Epoch 257/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7596\n",
      "Epoch 258/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7990\n",
      "Epoch 259/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9412\n",
      "Epoch 260/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7559\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8000\n",
      "Epoch 262/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 26.0165\n",
      "Epoch 263/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8854\n",
      "Epoch 264/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7464\n",
      "Epoch 265/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8685\n",
      "Epoch 266/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8209\n",
      "Epoch 267/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9930\n",
      "Epoch 268/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7516\n",
      "Epoch 269/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9037\n",
      "Epoch 270/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8389\n",
      "Epoch 271/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9887\n",
      "Epoch 272/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8430\n",
      "Epoch 273/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.7816\n",
      "Epoch 274/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9285\n",
      "Epoch 275/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8126\n",
      "Epoch 276/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8122\n",
      "Epoch 277/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8092\n",
      "Epoch 278/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.8943\n",
      "Epoch 279/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9687\n",
      "Epoch 280/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7355\n",
      "Epoch 281/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8406\n",
      "Epoch 282/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8352\n",
      "Epoch 283/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0048 - mae: 0.0559 - mape: 25.9336\n",
      "Epoch 284/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0049 - mae: 0.0558 - mape: 25.9770\n",
      "Epoch 285/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0559 - mse: 0.0047 - mae: 0.0559 - mape: 25.7709\n",
      "Epoch 286/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8143\n",
      "Epoch 287/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9196\n",
      "Epoch 288/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8826\n",
      "Epoch 289/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8148\n",
      "Epoch 290/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8458\n",
      "Epoch 291/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8695\n",
      "Epoch 292/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0048 - mae: 0.0556 - mape: 25.8204\n",
      "Epoch 293/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7381\n",
      "Epoch 294/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.8853\n",
      "Epoch 295/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8838\n",
      "Epoch 296/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8465\n",
      "Epoch 297/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7387\n",
      "Epoch 298/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0048 - mae: 0.0558 - mape: 25.7958\n",
      "Epoch 299/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 25.9676\n",
      "Epoch 300/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0048 - mae: 0.0557 - mape: 25.8047\n",
      "157/157 [==============================] - 0s 556us/step\n",
      "  1/157 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_begin` is slow compared to the batch time (batch time: 0.0009s vs `on_predict_batch_begin` time: 0.0018s). Check your callbacks.\n",
      "157/157 [==============================] - 0s 704us/step\n",
      "Status: Current part: 2 out of : 5 parts.\n",
      "Heights to iterate over: [51]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.5606 - mse: 0.3162 - mae: 0.5606 - mape: 112.1646\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.5479 - mse: 0.3021 - mae: 0.5479 - mape: 109.6070\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5342 - mse: 0.2873 - mae: 0.5342 - mape: 106.8423\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5187 - mse: 0.2710 - mae: 0.5187 - mape: 103.7218\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5006 - mse: 0.2526 - mae: 0.5006 - mape: 100.0623\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4787 - mse: 0.2312 - mae: 0.4787 - mape: 95.6459\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.4517 - mse: 0.2062 - mae: 0.4517 - mape: 90.2141\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4184 - mse: 0.1772 - mae: 0.4184 - mape: 83.4927\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.3771 - mse: 0.1444 - mae: 0.3771 - mape: 75.1631\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3261 - mse: 0.1087 - mae: 0.3261 - mape: 64.8641\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2632 - mse: 0.0719 - mae: 0.2632 - mape: 52.1824\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1864 - mse: 0.0376 - mae: 0.1864 - mape: 36.7088\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0957 - mse: 0.0122 - mae: 0.0957 - mape: 18.4629\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0490 - mse: 0.0032 - mae: 0.0490 - mape: 9.8659\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0469 - mse: 0.0028 - mae: 0.0469 - mape: 9.7040\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0469 - mse: 0.0028 - mae: 0.0469 - mape: 9.6720\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0028 - mae: 0.0467 - mape: 9.6275\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0466 - mse: 0.0028 - mae: 0.0466 - mape: 9.6172\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0028 - mae: 0.0467 - mape: 9.5812\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0465 - mse: 0.0028 - mae: 0.0465 - mape: 9.5746\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0028 - mae: 0.0464 - mape: 9.5617\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0028 - mae: 0.0463 - mape: 9.5629\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0462 - mse: 0.0028 - mae: 0.0462 - mape: 9.5640\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0027 - mae: 0.0463 - mape: 9.4988\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0461 - mse: 0.0027 - mae: 0.0461 - mape: 9.5093\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0460 - mse: 0.0027 - mae: 0.0460 - mape: 9.4873\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0027 - mae: 0.0459 - mape: 9.4693\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0027 - mae: 0.0459 - mape: 9.5112\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0458 - mse: 0.0027 - mae: 0.0458 - mape: 9.4843\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0458 - mse: 0.0027 - mae: 0.0458 - mape: 9.4076\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0457 - mse: 0.0027 - mae: 0.0457 - mape: 9.4929\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0027 - mae: 0.0456 - mape: 9.3766\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0454 - mse: 0.0027 - mae: 0.0454 - mape: 9.4120\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0027 - mae: 0.0453 - mape: 9.3970\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0452 - mse: 0.0026 - mae: 0.0452 - mape: 9.3485\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0451 - mse: 0.0026 - mae: 0.0451 - mape: 9.3090\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0027 - mae: 0.0450 - mape: 9.3798\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0026 - mae: 0.0450 - mape: 9.3158\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0449 - mse: 0.0026 - mae: 0.0449 - mape: 9.2657\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0447 - mse: 0.0026 - mae: 0.0447 - mape: 9.3121\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0026 - mae: 0.0446 - mape: 9.2670\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0026 - mae: 0.0445 - mape: 9.2215\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0026 - mae: 0.0445 - mape: 9.1936\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0444 - mse: 0.0026 - mae: 0.0444 - mape: 9.2570\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0026 - mae: 0.0442 - mape: 9.1707\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0441 - mse: 0.0026 - mae: 0.0441 - mape: 9.1762\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0440 - mse: 0.0026 - mae: 0.0440 - mape: 9.1694\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0025 - mae: 0.0439 - mape: 9.1227\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0025 - mae: 0.0437 - mape: 9.1151\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0026 - mae: 0.0437 - mape: 9.1740\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0436 - mse: 0.0025 - mae: 0.0436 - mape: 9.0606\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0436 - mse: 0.0025 - mae: 0.0436 - mape: 9.0837\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0434 - mse: 0.0025 - mae: 0.0434 - mape: 9.0433\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0025 - mae: 0.0432 - mape: 9.0428\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0025 - mae: 0.0431 - mape: 9.0234\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0025 - mae: 0.0430 - mape: 9.0187\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0025 - mae: 0.0430 - mape: 8.9663\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0025 - mae: 0.0428 - mape: 8.9723\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0025 - mae: 0.0428 - mape: 8.9844\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0025 - mae: 0.0426 - mape: 8.9281\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0025 - mae: 0.0425 - mape: 8.8989\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0025 - mae: 0.0424 - mape: 8.9180\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0025 - mae: 0.0423 - mape: 8.8688\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0024 - mae: 0.0423 - mape: 8.8525\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0024 - mae: 0.0421 - mape: 8.7994\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0024 - mae: 0.0419 - mape: 8.7933\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0024 - mae: 0.0418 - mape: 8.7612\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0024 - mae: 0.0416 - mape: 8.7579\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0415 - mse: 0.0024 - mae: 0.0415 - mape: 8.7210\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0025 - mae: 0.0415 - mape: 8.7608\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0024 - mae: 0.0413 - mape: 8.7035\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0412 - mse: 0.0024 - mae: 0.0412 - mape: 8.6339\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0025 - mae: 0.0411 - mape: 8.6928\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0024 - mae: 0.0409 - mape: 8.6311\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0408 - mse: 0.0025 - mae: 0.0408 - mape: 8.6515\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0025 - mae: 0.0407 - mape: 8.6422\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0023 - mae: 0.0407 - mape: 8.5413\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0025 - mae: 0.0405 - mape: 8.5935\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0403 - mse: 0.0025 - mae: 0.0403 - mape: 8.5545\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0402 - mse: 0.0023 - mae: 0.0402 - mape: 8.4611\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0400 - mse: 0.0024 - mae: 0.0400 - mape: 8.4515\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0399 - mse: 0.0024 - mae: 0.0399 - mape: 8.4628\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0398 - mse: 0.0024 - mae: 0.0398 - mape: 8.4446\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0397 - mse: 0.0024 - mae: 0.0397 - mape: 8.4274\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0396 - mse: 0.0024 - mae: 0.0396 - mape: 8.4142\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0395 - mse: 0.0024 - mae: 0.0395 - mape: 8.3709\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0394 - mse: 0.0023 - mae: 0.0394 - mape: 8.3109\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0392 - mse: 0.0024 - mae: 0.0392 - mape: 8.3194\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0390 - mse: 0.0024 - mae: 0.0390 - mape: 8.2979\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0390 - mse: 0.0023 - mae: 0.0390 - mape: 8.2680\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0389 - mse: 0.0023 - mae: 0.0389 - mape: 8.2434\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0388 - mse: 0.0023 - mae: 0.0388 - mape: 8.2260\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0387 - mse: 0.0023 - mae: 0.0387 - mape: 8.2149\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0386 - mse: 0.0023 - mae: 0.0386 - mape: 8.1819\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0385 - mse: 0.0022 - mae: 0.0385 - mape: 8.1316\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0385 - mse: 0.0023 - mae: 0.0385 - mape: 8.1604\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0023 - mae: 0.0384 - mape: 8.1660\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0382 - mse: 0.0022 - mae: 0.0382 - mape: 8.0907\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0023 - mae: 0.0381 - mape: 8.0870\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - mse: 0.0022 - mae: 0.0380 - mape: 8.0449\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - mse: 0.0022 - mae: 0.0380 - mape: 8.0485\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - mse: 0.0022 - mae: 0.0380 - mape: 8.0675\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0022 - mae: 0.0378 - mape: 8.0222\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0022 - mae: 0.0378 - mape: 7.9965\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0022 - mae: 0.0378 - mape: 8.0151\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0376 - mse: 0.0022 - mae: 0.0376 - mape: 7.9826\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0375 - mse: 0.0022 - mae: 0.0375 - mape: 7.9622\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0375 - mse: 0.0022 - mae: 0.0375 - mape: 7.9363\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0374 - mse: 0.0022 - mae: 0.0374 - mape: 7.9359\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0021 - mae: 0.0373 - mape: 7.8950\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0374 - mse: 0.0022 - mae: 0.0374 - mape: 7.9179\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0022 - mae: 0.0373 - mape: 7.9010\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0372 - mse: 0.0021 - mae: 0.0372 - mape: 7.8605\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0022 - mae: 0.0373 - mape: 7.9031\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0371 - mse: 0.0021 - mae: 0.0371 - mape: 7.8514\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0370 - mse: 0.0021 - mae: 0.0370 - mape: 7.8115\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0371 - mse: 0.0021 - mae: 0.0371 - mape: 7.8541\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0370 - mse: 0.0021 - mae: 0.0370 - mape: 7.8297\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7876\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0369 - mse: 0.0021 - mae: 0.0369 - mape: 7.8055\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.7905\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7542\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7615\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - mse: 0.0021 - mae: 0.0366 - mape: 7.7642\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - mse: 0.0021 - mae: 0.0366 - mape: 7.7510\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.7096\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0021 - mae: 0.0365 - mape: 7.7343\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7247\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0020 - mae: 0.0367 - mape: 7.7138\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7105\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7186\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7157\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6757\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0021 - mae: 0.0363 - mape: 7.6837\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.6272\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7232\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.6513\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.6544\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.6313\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0362 - mse: 0.0021 - mae: 0.0362 - mape: 7.6776\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5981\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.6143\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.6208\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0021 - mae: 0.0361 - mape: 7.6379\n",
      "Epoch 145/300\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.6029\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5951\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5949\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5706\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.6089\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5677\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.7470\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.5246\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.6132\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5929\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5303\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.6087\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5239\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5912\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5493\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5644\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5181\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.5024\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5387\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5324\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.5272\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5306\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4906\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5384\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5156\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4938\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5640\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4897\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5467\n",
      "Epoch 174/300\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4736\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4860\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4700\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.5138\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4861\n",
      "Epoch 179/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4540\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5794\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4589\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4506\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5709\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4798\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4468\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.5030\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4566\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4595\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.4925\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4089\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.5330\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4400\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.4906\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.4906\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4416\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4487\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.4779\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4249\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4420\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4312\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4656\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4105\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0020 - mae: 0.0354 - mape: 7.4700\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4389\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4210\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4652\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4363\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4373\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4222\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4551\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4130\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4283\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4043\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4483\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4259\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4135\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4430\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0354 - mse: 0.0020 - mae: 0.0354 - mape: 7.4649\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4280\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4191\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3986\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4417\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4157\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4269\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4334\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4313\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4131\n",
      "Epoch 228/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4198\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4215\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4280\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4234\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4905\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3868\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4400\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4234\n",
      "Epoch 236/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4066\n",
      "Epoch 237/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4504\n",
      "Epoch 238/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3955\n",
      "Epoch 239/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4417\n",
      "Epoch 240/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4277\n",
      "Epoch 241/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3977\n",
      "Epoch 242/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4495\n",
      "Epoch 243/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4083\n",
      "Epoch 244/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3955\n",
      "Epoch 245/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4291\n",
      "Epoch 246/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3897\n",
      "Epoch 247/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0020 - mae: 0.0355 - mape: 7.4723\n",
      "Epoch 248/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4478\n",
      "Epoch 249/300\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4279\n",
      "Epoch 250/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3938\n",
      "Epoch 251/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4125\n",
      "Epoch 252/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3714\n",
      "Epoch 253/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4462\n",
      "Epoch 254/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4092\n",
      "Epoch 255/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4178\n",
      "Epoch 256/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4159\n",
      "Epoch 257/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4060\n",
      "Epoch 258/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4125\n",
      "Epoch 259/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4106\n",
      "Epoch 260/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4044\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4260\n",
      "Epoch 262/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4414\n",
      "Epoch 263/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4023\n",
      "Epoch 264/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4015\n",
      "Epoch 265/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4216\n",
      "Epoch 266/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4088\n",
      "Epoch 267/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4168\n",
      "Epoch 268/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4016\n",
      "Epoch 269/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4196\n",
      "Epoch 270/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4070\n",
      "Epoch 271/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3839\n",
      "Epoch 272/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4200\n",
      "Epoch 273/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4120\n",
      "Epoch 274/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3752\n",
      "Epoch 275/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4339\n",
      "Epoch 276/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4355\n",
      "Epoch 277/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3962\n",
      "Epoch 278/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4165\n",
      "Epoch 279/300\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4482\n",
      "Epoch 280/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0020 - mae: 0.0354 - mape: 7.4634\n",
      "Epoch 281/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4105\n",
      "Epoch 282/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4105\n",
      "Epoch 283/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4222\n",
      "Epoch 284/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3653\n",
      "Epoch 285/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0020 - mae: 0.0354 - mape: 7.4729\n",
      "Epoch 286/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3820\n",
      "Epoch 287/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0020 - mae: 0.0354 - mape: 7.4624\n",
      "Epoch 288/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.3827\n",
      "Epoch 289/300\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4047\n",
      "Epoch 290/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4302\n",
      "Epoch 291/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4296\n",
      "Epoch 292/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3933\n",
      "Epoch 293/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4241\n",
      "Epoch 294/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4074\n",
      "Epoch 295/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4110\n",
      "Epoch 296/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4140\n",
      "Epoch 297/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.3818\n",
      "Epoch 298/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.3618\n",
      "Epoch 299/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0019 - mae: 0.0354 - mape: 7.4427\n",
      "Epoch 300/300\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - mse: 0.0019 - mae: 0.0353 - mape: 7.4002\n",
      "157/157 [==============================] - 0s 538us/step\n",
      "157/157 [==============================] - 0s 519us/step\n",
      "Status: Current part: 3 out of : 5 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8465 - mse: 0.7202 - mae: 0.8465 - mape: 108.4629\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8317 - mse: 0.6954 - mae: 0.8317 - mape: 106.5586\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8153 - mse: 0.6684 - mae: 0.8153 - mape: 104.4501\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7961 - mse: 0.6373 - mae: 0.7961 - mape: 101.9760\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7725 - mse: 0.6005 - mae: 0.7725 - mape: 98.9344\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.7430 - mse: 0.5556 - mae: 0.7430 - mape: 95.1350\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7056 - mse: 0.5015 - mae: 0.7056 - mape: 90.3214\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6585 - mse: 0.4372 - mae: 0.6585 - mape: 84.2574\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.5996 - mse: 0.3632 - mae: 0.5996 - mape: 76.6731\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5271 - mse: 0.2816 - mae: 0.5271 - mape: 67.3443\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4393 - mse: 0.1968 - mae: 0.4393 - mape: 56.0527\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3348 - mse: 0.1160 - mae: 0.3348 - mape: 42.5955\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2120 - mse: 0.0493 - mae: 0.2120 - mape: 26.7934\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0828 - mse: 0.0095 - mae: 0.0828 - mape: 10.3174\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0029 - mae: 0.0417 - mape: 5.5448\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4385\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4321\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4384\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4145\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4393\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4567\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4406\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4323\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4306\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4361\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4241\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4296\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4344\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4342\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4256\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4352\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4292\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4371\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4378\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4323\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4349\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4409\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4224\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4331\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4470\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4306\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4311\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4373\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0409 - mse: 0.0027 - mae: 0.0409 - mape: 5.4418\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4392\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4278\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4326\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4342\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0409 - mse: 0.0027 - mae: 0.0409 - mape: 5.4470\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4579\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4357\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4416\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4397\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4277\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4421\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4183\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4392\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4235\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4253\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4369\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4222\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4440\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4486\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4559\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4471\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4253\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4296\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4448\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4396\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0410 - mse: 0.0028 - mae: 0.0410 - mape: 5.4681\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4345\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4419\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4403\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4464\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4219\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4203\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4283\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4361\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4330\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4268\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4309\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4242\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4438\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4329\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4298\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4377\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4180\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4567\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4429\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4504\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4393\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4248\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4353\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4297\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4304\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4509\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4129\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4428\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4490\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4270\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4335\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4209\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4367\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4306\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4167\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4577\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4302\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4239\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4174\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4520\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4241\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4446\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4403\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4271\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4347\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4215\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4212\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4730\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4457\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4142\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5197\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4380\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4347\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4259\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4169\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4439\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4554\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4221\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4295\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4341\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4305\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4210\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4354\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4349\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4269\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4328\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4439\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4283\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4239\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4235\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4161\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4310\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4241\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4226\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4306\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4319\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4179\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4548\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4281\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4457\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4399\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4411\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4400\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4183\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4281\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4450\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4370\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4265\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4320\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4370\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4465\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0029 - mae: 0.0411 - mape: 5.5136\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4331\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4174\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4361\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4330\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4329\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4216\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4218\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4404\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4467\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4306\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4478\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4517\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4364\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4215\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4226\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4311\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4288\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4593\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4340\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4196\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4286\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4287\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4354\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4307\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4155\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4592\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4428\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4189\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4601\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4195\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4261\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4276\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4359\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4273\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0410 - mse: 0.0028 - mae: 0.0410 - mape: 5.4962\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4539\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4280\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4234\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4389\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4279\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0404 - mse: 0.0028 - mae: 0.0404 - mape: 5.4228\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4243\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4255\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4381\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4272\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4323\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4387\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4327\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4496\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4407\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4518\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4237\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4279\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4365\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4437\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4247\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4322\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4150\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4165\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4300\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4744\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0027 - mae: 0.0408 - mape: 5.4389\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4276\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4180\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4379\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4286\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4161\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4303\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4191\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4518\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4413\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4360\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4246\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4298\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4310\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4211\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4328\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4344\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4397\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4288\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4366\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4577\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4578\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4280\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4269\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4305\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4344\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4301\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4201\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4706\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4340\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4256\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4485\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4315\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4425\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4340\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4292\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4258\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4298\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4373\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4232\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4304\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4318\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4365\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4324\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4329\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4418\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4173\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4449\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4477\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4284\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4274\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4441\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4417\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4383\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4416\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4315\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4300\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4298\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4519\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4382\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4396\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4268\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4307\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4390\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0028 - mae: 0.0407 - mape: 5.4430\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4325\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0028 - mae: 0.0405 - mape: 5.4357\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0027 - mae: 0.0406 - mape: 5.4353\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4361\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4207\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4414\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4437\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0027 - mae: 0.0405 - mape: 5.4217\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4353\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0028 - mae: 0.0406 - mape: 5.4403\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0404 - mse: 0.0028 - mae: 0.0404 - mape: 5.4228\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0027 - mae: 0.0407 - mape: 5.4435\n",
      "157/157 [==============================] - 0s 544us/step\n",
      "157/157 [==============================] - 0s 513us/step\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Silly Coercsion for ICML rebuttle deadline timeline\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    Iteration_Length = len(X_parts_list) -1\n",
    "else:\n",
    "    Iteration_Length = len(X_parts_list)\n",
    "\n",
    "    \n",
    "# Train each part!\n",
    "for current_part in range(Iteration_Length):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.7564\n",
      "Epoch 2/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.7620\n",
      "Epoch 3/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.7620\n",
      "Epoch 4/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.7620\n",
      "Epoch 5/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.7620\n",
      "Epoch 6/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.7620\n",
      "Epoch 7/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7620\n",
      "Epoch 8/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.7620\n",
      "Epoch 9/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.7624\n",
      "Epoch 10/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7792\n",
      "Epoch 11/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.7952\n",
      "Epoch 12/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.8046\n",
      "Epoch 13/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.8112\n",
      "Epoch 14/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.8132\n",
      "Epoch 15/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.8136\n",
      "Epoch 16/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.8192\n",
      "Epoch 17/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8254\n",
      "Epoch 18/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8294\n",
      "Epoch 19/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8336\n",
      "Epoch 20/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8356\n",
      "Epoch 21/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8422\n",
      "Epoch 22/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.8518\n",
      "Epoch 23/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.8528\n",
      "Epoch 24/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.8612\n",
      "Epoch 25/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.8680\n",
      "Epoch 26/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.8678\n",
      "Epoch 27/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.8686\n",
      "Epoch 28/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.8892\n",
      "Epoch 29/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.8888\n",
      "Epoch 30/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.8880\n",
      "Epoch 31/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.8894\n",
      "Epoch 32/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.8924\n",
      "Epoch 33/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9000\n",
      "Epoch 34/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.8982\n",
      "Epoch 35/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9062\n",
      "Epoch 36/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9082\n",
      "Epoch 37/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9052\n",
      "Epoch 38/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9032\n",
      "Epoch 39/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9046\n",
      "Epoch 40/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9098\n",
      "Epoch 41/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9100\n",
      "Epoch 42/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9100\n",
      "Epoch 43/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9108\n",
      "Epoch 44/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9148\n",
      "Epoch 45/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9080\n",
      "Epoch 46/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9150\n",
      "Epoch 47/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9138\n",
      "Epoch 48/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9114\n",
      "Epoch 49/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9108\n",
      "Epoch 50/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9110\n",
      "Epoch 51/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9092\n",
      "Epoch 52/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9062\n",
      "Epoch 53/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9074\n",
      "Epoch 54/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9122\n",
      "Epoch 55/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9102\n",
      "Epoch 56/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9088\n",
      "Epoch 57/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9112\n",
      "Epoch 58/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9146\n",
      "Epoch 59/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9132\n",
      "Epoch 60/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9146\n",
      "Epoch 61/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9130\n",
      "Epoch 62/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9162\n",
      "Epoch 63/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9130\n",
      "Epoch 64/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9160\n",
      "Epoch 65/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9174\n",
      "Epoch 66/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9140\n",
      "Epoch 67/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9136\n",
      "Epoch 68/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9188\n",
      "Epoch 69/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9162\n",
      "Epoch 70/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9176\n",
      "Epoch 71/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9188\n",
      "Epoch 72/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9206\n",
      "Epoch 73/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9192\n",
      "Epoch 74/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9158\n",
      "Epoch 75/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9172\n",
      "Epoch 76/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9200\n",
      "Epoch 77/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9206\n",
      "Epoch 78/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9248\n",
      "Epoch 79/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9224\n",
      "Epoch 80/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9206\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9198\n",
      "Epoch 82/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9212\n",
      "Epoch 83/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9252\n",
      "Epoch 84/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9240\n",
      "Epoch 85/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9230\n",
      "Epoch 86/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9228\n",
      "Epoch 87/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9254\n",
      "Epoch 88/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9282\n",
      "Epoch 89/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9262\n",
      "Epoch 90/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9278\n",
      "Epoch 91/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9236\n",
      "Epoch 92/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9240\n",
      "Epoch 93/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9286\n",
      "Epoch 94/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9288\n",
      "Epoch 95/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9272\n",
      "Epoch 96/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9284\n",
      "Epoch 97/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9246\n",
      "Epoch 98/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9266\n",
      "Epoch 99/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9284\n",
      "Epoch 100/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9310\n",
      "Epoch 101/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9274\n",
      "Epoch 102/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9264\n",
      "Epoch 103/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9300\n",
      "Epoch 104/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9290\n",
      "Epoch 105/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9268\n",
      "Epoch 106/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9292\n",
      "Epoch 107/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9268\n",
      "Epoch 108/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9234\n",
      "Epoch 109/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9306\n",
      "Epoch 110/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9316\n",
      "Epoch 111/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9334\n",
      "Epoch 112/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9262\n",
      "Epoch 113/400\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9322\n",
      "Epoch 114/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.9292\n",
      "Epoch 115/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9286\n",
      "Epoch 116/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9290\n",
      "Epoch 117/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9298\n",
      "Epoch 118/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9300\n",
      "Epoch 119/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9314\n",
      "Epoch 120/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9330\n",
      "Epoch 121/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9300\n",
      "Epoch 122/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9336\n",
      "Epoch 123/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9316\n",
      "Epoch 124/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9322\n",
      "Epoch 125/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9328\n",
      "Epoch 126/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9332\n",
      "Epoch 127/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9270\n",
      "Epoch 128/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9270\n",
      "Epoch 129/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9312\n",
      "Epoch 130/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9330\n",
      "Epoch 131/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9306\n",
      "Epoch 132/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9296\n",
      "Epoch 133/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9334\n",
      "Epoch 134/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9342\n",
      "Epoch 135/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9322\n",
      "Epoch 136/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9304\n",
      "Epoch 137/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9330\n",
      "Epoch 138/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9316\n",
      "Epoch 139/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9364\n",
      "Epoch 140/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9336\n",
      "Epoch 141/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9346\n",
      "Epoch 142/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9330\n",
      "Epoch 143/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9302\n",
      "Epoch 144/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9374\n",
      "Epoch 145/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9366\n",
      "Epoch 146/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9240\n",
      "Epoch 147/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9352\n",
      "Epoch 148/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9386\n",
      "Epoch 149/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9312\n",
      "Epoch 150/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9370\n",
      "Epoch 151/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9338\n",
      "Epoch 152/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9332\n",
      "Epoch 153/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9330\n",
      "Epoch 154/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9350\n",
      "Epoch 155/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9364\n",
      "Epoch 156/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9398\n",
      "Epoch 157/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9372\n",
      "Epoch 158/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9390\n",
      "Epoch 159/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9326\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9366\n",
      "Epoch 161/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9414\n",
      "Epoch 162/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9400\n",
      "Epoch 163/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9406\n",
      "Epoch 164/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9366\n",
      "Epoch 165/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9368\n",
      "Epoch 166/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9402\n",
      "Epoch 167/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9432\n",
      "Epoch 168/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9402\n",
      "Epoch 169/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9444\n",
      "Epoch 170/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9424\n",
      "Epoch 171/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9424\n",
      "Epoch 172/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9434\n",
      "Epoch 173/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9424\n",
      "Epoch 174/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9392\n",
      "Epoch 175/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9482\n",
      "Epoch 176/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9486\n",
      "Epoch 177/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9402\n",
      "Epoch 178/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9418\n",
      "Epoch 179/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9420\n",
      "Epoch 180/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9446\n",
      "Epoch 181/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9476\n",
      "Epoch 182/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9438\n",
      "Epoch 183/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9458\n",
      "Epoch 184/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9506\n",
      "Epoch 185/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9458\n",
      "Epoch 186/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9498\n",
      "Epoch 187/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9472\n",
      "Epoch 188/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9528\n",
      "Epoch 189/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9478\n",
      "Epoch 190/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9520\n",
      "Epoch 191/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9568\n",
      "Epoch 192/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9544\n",
      "Epoch 193/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9504\n",
      "Epoch 194/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9520\n",
      "Epoch 195/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9538\n",
      "Epoch 196/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9582\n",
      "Epoch 197/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9556\n",
      "Epoch 198/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9522\n",
      "Epoch 199/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9552\n",
      "Epoch 200/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9546\n",
      "Epoch 201/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9542\n",
      "Epoch 202/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9560\n",
      "Epoch 203/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9564\n",
      "Epoch 204/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9598\n",
      "Epoch 205/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9540\n",
      "Epoch 206/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9582\n",
      "Epoch 207/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9594\n",
      "Epoch 208/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9526\n",
      "Epoch 209/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9554\n",
      "Epoch 210/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9568\n",
      "Epoch 211/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9612\n",
      "Epoch 212/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9540\n",
      "Epoch 213/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9584\n",
      "Epoch 214/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9590\n",
      "Epoch 215/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9620\n",
      "Epoch 216/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9594\n",
      "Epoch 217/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9600\n",
      "Epoch 218/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9576\n",
      "Epoch 219/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9616\n",
      "Epoch 220/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9606\n",
      "Epoch 221/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9642\n",
      "Epoch 222/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9598\n",
      "Epoch 223/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9600\n",
      "Epoch 224/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9620\n",
      "Epoch 225/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9630\n",
      "Epoch 226/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9634\n",
      "Epoch 227/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9630\n",
      "Epoch 228/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9594\n",
      "Epoch 229/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9664\n",
      "Epoch 230/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9610\n",
      "Epoch 231/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9596\n",
      "Epoch 232/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9610\n",
      "Epoch 233/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9666\n",
      "Epoch 234/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9620\n",
      "Epoch 235/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9650\n",
      "Epoch 236/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9638\n",
      "Epoch 237/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9630\n",
      "Epoch 238/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9606\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9664\n",
      "Epoch 240/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9672\n",
      "Epoch 241/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9674\n",
      "Epoch 242/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9638\n",
      "Epoch 243/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9690\n",
      "Epoch 244/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9670\n",
      "Epoch 245/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9678\n",
      "Epoch 246/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9636\n",
      "Epoch 247/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9662\n",
      "Epoch 248/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9672\n",
      "Epoch 249/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9680\n",
      "Epoch 250/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9660\n",
      "Epoch 251/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9722\n",
      "Epoch 252/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9676\n",
      "Epoch 253/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9694\n",
      "Epoch 254/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9678\n",
      "Epoch 255/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9666\n",
      "Epoch 256/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9662\n",
      "Epoch 257/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9666\n",
      "Epoch 258/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9604\n",
      "Epoch 259/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9682\n",
      "Epoch 260/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9656\n",
      "Epoch 261/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9708\n",
      "Epoch 262/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9712\n",
      "Epoch 263/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9624\n",
      "Epoch 264/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9698\n",
      "Epoch 265/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9632\n",
      "Epoch 266/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9688\n",
      "Epoch 267/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9688\n",
      "Epoch 268/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9610\n",
      "Epoch 269/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9656\n",
      "Epoch 270/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9734\n",
      "Epoch 271/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9692\n",
      "Epoch 272/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9702\n",
      "Epoch 273/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9708\n",
      "Epoch 274/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9692\n",
      "Epoch 275/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9678\n",
      "Epoch 276/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9672\n",
      "Epoch 277/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9702\n",
      "Epoch 278/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9698\n",
      "Epoch 279/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9690\n",
      "Epoch 280/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9722\n",
      "Epoch 281/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9704\n",
      "Epoch 282/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9712\n",
      "Epoch 283/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9694\n",
      "Epoch 284/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9742\n",
      "Epoch 285/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9668\n",
      "Epoch 286/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9736\n",
      "Epoch 287/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9700\n",
      "Epoch 288/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9698\n",
      "Epoch 289/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9698\n",
      "Epoch 290/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9724\n",
      "Epoch 291/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9676\n",
      "Epoch 292/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9700\n",
      "Epoch 293/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9730\n",
      "Epoch 294/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9682\n",
      "Epoch 295/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9722\n",
      "Epoch 296/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9662\n",
      "Epoch 297/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9726\n",
      "Epoch 298/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9710\n",
      "Epoch 299/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9704\n",
      "Epoch 300/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9742\n",
      "Epoch 301/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9724\n",
      "Epoch 302/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9676\n",
      "Epoch 303/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9740\n",
      "Epoch 304/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9720\n",
      "Epoch 305/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9694\n",
      "Epoch 306/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9690\n",
      "Epoch 307/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9730\n",
      "Epoch 308/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9716\n",
      "Epoch 309/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9742\n",
      "Epoch 310/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9692\n",
      "Epoch 311/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9688\n",
      "Epoch 312/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9710\n",
      "Epoch 313/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9704\n",
      "Epoch 314/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9702\n",
      "Epoch 315/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9734\n",
      "Epoch 316/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9736\n",
      "Epoch 317/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9690\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9700\n",
      "Epoch 319/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9730\n",
      "Epoch 320/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9734\n",
      "Epoch 321/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9644\n",
      "Epoch 322/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9660\n",
      "Epoch 323/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9678\n",
      "Epoch 324/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9728\n",
      "Epoch 325/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9706\n",
      "Epoch 326/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9716\n",
      "Epoch 327/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9760\n",
      "Epoch 328/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9724\n",
      "Epoch 329/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9754\n",
      "Epoch 330/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9714\n",
      "Epoch 331/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9668\n",
      "Epoch 332/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9746\n",
      "Epoch 333/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9732\n",
      "Epoch 334/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9666\n",
      "Epoch 335/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9766\n",
      "Epoch 336/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9726\n",
      "Epoch 337/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9692\n",
      "Epoch 338/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9724\n",
      "Epoch 339/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9776\n",
      "Epoch 340/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9666\n",
      "Epoch 341/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9740\n",
      "Epoch 342/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9750\n",
      "Epoch 343/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9770\n",
      "Epoch 344/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9746\n",
      "Epoch 345/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9718\n",
      "Epoch 346/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9724\n",
      "Epoch 347/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9734\n",
      "Epoch 348/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9692\n",
      "Epoch 349/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9706\n",
      "Epoch 350/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9734\n",
      "Epoch 351/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9744\n",
      "Epoch 352/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9668\n",
      "Epoch 353/400\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9758\n",
      "Epoch 354/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9704\n",
      "Epoch 355/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9714\n",
      "Epoch 356/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9714\n",
      "Epoch 357/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9732\n",
      "Epoch 358/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9706\n",
      "Epoch 359/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9762\n",
      "Epoch 360/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9772\n",
      "Epoch 361/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9770\n",
      "Epoch 362/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9694\n",
      "Epoch 363/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9746\n",
      "Epoch 364/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9720\n",
      "Epoch 365/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9742\n",
      "Epoch 366/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9790\n",
      "Epoch 367/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9708\n",
      "Epoch 368/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9712\n",
      "Epoch 369/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9702\n",
      "Epoch 370/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9698\n",
      "Epoch 371/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9720\n",
      "Epoch 372/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9724\n",
      "Epoch 373/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9756\n",
      "Epoch 374/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9754\n",
      "Epoch 375/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9714\n",
      "Epoch 376/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9726\n",
      "Epoch 377/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9740\n",
      "Epoch 378/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9758\n",
      "Epoch 379/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9726\n",
      "Epoch 380/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9688\n",
      "Epoch 381/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9744\n",
      "Epoch 382/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9742\n",
      "Epoch 383/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9754\n",
      "Epoch 384/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9768\n",
      "Epoch 385/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9710\n",
      "Epoch 386/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9710\n",
      "Epoch 387/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9768\n",
      "Epoch 388/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9752\n",
      "Epoch 389/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9758\n",
      "Epoch 390/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9738\n",
      "Epoch 391/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9718\n",
      "Epoch 392/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9764\n",
      "Epoch 393/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9726\n",
      "Epoch 394/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9724\n",
      "Epoch 395/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9684\n",
      "Epoch 396/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9740\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9754\n",
      "Epoch 398/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9714\n",
      "Epoch 399/400\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9746\n",
      "Epoch 400/400\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9744\n",
      "WARNING:tensorflow:From /scratch/users/kratsioa/.local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "157/157 [==============================] - 0s 709us/step\n",
      "157/157 [==============================] - 0s 729us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.012215   0.012215\n",
      "MSE    0.000604   0.000604\n",
      "MAPE  38.256912  38.256912\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       L-time     P-time  N_params_expt   AIC-like    Eff\n",
      "0  110.780768  41.172826          72970  145948.81  0.137\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=2020,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.5, 1.0, 10, 100, 1000],\n",
       "                                        'penalty': ['none', 'l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2020, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.048790   0.048790\n",
      "MSE    0.008937   0.008937\n",
      "MAPE  60.784626  60.784626\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Performance\n",
      "          train       test\n",
      "MAE    0.061573   0.061573\n",
      "MSE    0.006233   0.006233\n",
      "MAPE  43.008723  43.008723\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Partition: Generated!...Feature Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   45.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   45.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2501 - mse: 0.1035 - mae: 0.2501 - mape: 352.7253\n",
      "Epoch 2/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1417 - mse: 0.0287 - mae: 0.1417 - mape: 267.7476\n",
      "Epoch 3/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0869 - mse: 0.0095 - mae: 0.0869 - mape: 164.6144\n",
      "Epoch 4/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0853 - mse: 0.0092 - mae: 0.0853 - mape: 181.1342\n",
      "Epoch 5/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0848 - mse: 0.0091 - mae: 0.0848 - mape: 180.8669\n",
      "Epoch 6/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0847 - mse: 0.0091 - mae: 0.0847 - mape: 176.3282\n",
      "Epoch 7/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0843 - mse: 0.0090 - mae: 0.0843 - mape: 173.1852\n",
      "Epoch 8/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0839 - mse: 0.0089 - mae: 0.0839 - mape: 177.1647\n",
      "Epoch 9/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0835 - mse: 0.0089 - mae: 0.0835 - mape: 176.7463\n",
      "Epoch 10/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0830 - mse: 0.0088 - mae: 0.0830 - mape: 177.0637\n",
      "Epoch 11/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0829 - mse: 0.0088 - mae: 0.0829 - mape: 173.9406\n",
      "Epoch 12/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0824 - mse: 0.0087 - mae: 0.0824 - mape: 172.8379\n",
      "Epoch 13/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0819 - mse: 0.0086 - mae: 0.0819 - mape: 169.6386\n",
      "Epoch 14/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0816 - mse: 0.0086 - mae: 0.0816 - mape: 170.4264\n",
      "Epoch 15/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0816 - mse: 0.0087 - mae: 0.0816 - mape: 172.7469\n",
      "Epoch 16/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0811 - mse: 0.0085 - mae: 0.0811 - mape: 166.8001\n",
      "Epoch 17/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0806 - mse: 0.0085 - mae: 0.0806 - mape: 164.9646\n",
      "Epoch 18/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0804 - mse: 0.0085 - mae: 0.0804 - mape: 169.3652\n",
      "Epoch 19/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0084 - mae: 0.0801 - mape: 162.6958\n",
      "Epoch 20/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0084 - mae: 0.0796 - mape: 171.5165\n",
      "Epoch 21/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0794 - mse: 0.0083 - mae: 0.0794 - mape: 162.4413\n",
      "Epoch 22/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0788 - mse: 0.0082 - mae: 0.0788 - mape: 161.5204\n",
      "Epoch 23/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0783 - mse: 0.0082 - mae: 0.0783 - mape: 161.5970\n",
      "Epoch 24/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0780 - mse: 0.0081 - mae: 0.0780 - mape: 158.2253\n",
      "Epoch 25/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0775 - mse: 0.0081 - mae: 0.0775 - mape: 157.9601\n",
      "Epoch 26/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0771 - mse: 0.0080 - mae: 0.0771 - mape: 158.2588\n",
      "Epoch 27/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0081 - mae: 0.0769 - mape: 158.7970\n",
      "Epoch 28/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0760 - mse: 0.0079 - mae: 0.0760 - mape: 155.5059\n",
      "Epoch 29/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0079 - mae: 0.0757 - mape: 149.5213\n",
      "Epoch 30/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0749 - mse: 0.0078 - mae: 0.0749 - mape: 147.0788\n",
      "Epoch 31/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0740 - mse: 0.0078 - mae: 0.0740 - mape: 148.0000\n",
      "Epoch 32/300\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0729 - mse: 0.0076 - mae: 0.0729 - mape: 139.9409\n",
      "Epoch 33/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0714 - mse: 0.0075 - mae: 0.0714 - mape: 137.2867\n",
      "Epoch 34/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0698 - mse: 0.0074 - mae: 0.0698 - mape: 129.8800\n",
      "Epoch 35/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0678 - mse: 0.0073 - mae: 0.0678 - mape: 118.3804\n",
      "Epoch 36/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0647 - mse: 0.0071 - mae: 0.0647 - mape: 107.9355\n",
      "Epoch 37/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0611 - mse: 0.0072 - mae: 0.0611 - mape: 90.3678\n",
      "Epoch 38/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0562 - mse: 0.0072 - mae: 0.0562 - mape: 70.9365\n",
      "Epoch 39/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0499 - mse: 0.0076 - mae: 0.0499 - mape: 44.3655\n",
      "Epoch 40/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0434 - mse: 0.0081 - mae: 0.0434 - mape: 19.5509\n",
      "Epoch 41/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 20.0680\n",
      "Epoch 42/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 19.5768\n",
      "Epoch 43/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 19.1820\n",
      "Epoch 44/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 19.1118\n",
      "Epoch 45/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0082 - mae: 0.0422 - mape: 18.1971\n",
      "Epoch 46/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0082 - mae: 0.0422 - mape: 18.4592\n",
      "Epoch 47/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0082 - mae: 0.0421 - mape: 17.8824\n",
      "Epoch 48/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0082 - mae: 0.0421 - mape: 17.7572\n",
      "Epoch 49/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0082 - mae: 0.0420 - mape: 17.5749\n",
      "Epoch 50/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0082 - mae: 0.0419 - mape: 17.1711\n",
      "Epoch 51/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0082 - mae: 0.0419 - mape: 17.0708\n",
      "Epoch 52/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0082 - mae: 0.0419 - mape: 17.4937\n",
      "Epoch 53/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0082 - mae: 0.0420 - mape: 17.6342\n",
      "Epoch 54/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0082 - mae: 0.0418 - mape: 17.6056\n",
      "Epoch 55/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0082 - mae: 0.0420 - mape: 17.6224\n",
      "Epoch 56/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0082 - mae: 0.0420 - mape: 18.3020\n",
      "Epoch 57/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.4389\n",
      "Epoch 58/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 16.9618\n",
      "Epoch 59/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0083 - mae: 0.0418 - mape: 17.7599\n",
      "Epoch 60/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.2573\n",
      "Epoch 61/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0083 - mae: 0.0418 - mape: 18.2098\n",
      "Epoch 62/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.3166\n",
      "Epoch 63/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.4407\n",
      "Epoch 64/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.6283\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.3185\n",
      "Epoch 66/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.4926\n",
      "Epoch 67/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.7301\n",
      "Epoch 68/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0083 - mae: 0.0418 - mape: 18.0290\n",
      "Epoch 69/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.6264\n",
      "Epoch 70/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.7081\n",
      "Epoch 71/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0083 - mae: 0.0418 - mape: 18.3988\n",
      "Epoch 72/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.0367\n",
      "Epoch 73/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.6348\n",
      "Epoch 74/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.9383\n",
      "Epoch 75/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.7556\n",
      "Epoch 76/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9586\n",
      "Epoch 77/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8445\n",
      "Epoch 78/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9377\n",
      "Epoch 79/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.0571\n",
      "Epoch 80/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7931\n",
      "Epoch 81/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.2852\n",
      "Epoch 82/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8472\n",
      "Epoch 83/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9566\n",
      "Epoch 84/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.0579\n",
      "Epoch 85/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9195\n",
      "Epoch 86/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8699\n",
      "Epoch 87/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9854\n",
      "Epoch 88/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9647\n",
      "Epoch 89/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.8392\n",
      "Epoch 90/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9104\n",
      "Epoch 91/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.2951\n",
      "Epoch 92/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.2397\n",
      "Epoch 93/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.6427\n",
      "Epoch 94/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9662\n",
      "Epoch 95/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.7138\n",
      "Epoch 96/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9785\n",
      "Epoch 97/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.1665\n",
      "Epoch 98/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8671\n",
      "Epoch 99/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0083 - mae: 0.0420 - mape: 18.3376\n",
      "Epoch 100/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9081\n",
      "Epoch 101/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.1037\n",
      "Epoch 102/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.2286\n",
      "Epoch 103/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.3087\n",
      "Epoch 104/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0122\n",
      "Epoch 105/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8824\n",
      "Epoch 106/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.2298\n",
      "Epoch 107/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9985\n",
      "Epoch 108/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.6106\n",
      "Epoch 109/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.3958\n",
      "Epoch 110/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1084\n",
      "Epoch 111/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0211\n",
      "Epoch 112/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8896\n",
      "Epoch 113/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7454\n",
      "Epoch 114/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0234\n",
      "Epoch 115/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9930\n",
      "Epoch 116/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.0451\n",
      "Epoch 117/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.2161\n",
      "Epoch 118/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0083 - mae: 0.0418 - mape: 18.0900\n",
      "Epoch 119/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1081\n",
      "Epoch 120/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8574\n",
      "Epoch 121/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8139\n",
      "Epoch 122/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9688\n",
      "Epoch 123/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8901\n",
      "Epoch 124/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1613\n",
      "Epoch 125/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.8032\n",
      "Epoch 126/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4699\n",
      "Epoch 127/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8731\n",
      "Epoch 128/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1370\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1336\n",
      "Epoch 130/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0343\n",
      "Epoch 131/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.2269\n",
      "Epoch 132/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.2669\n",
      "Epoch 133/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9818\n",
      "Epoch 134/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7301\n",
      "Epoch 135/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9912\n",
      "Epoch 136/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0083\n",
      "Epoch 137/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.4594\n",
      "Epoch 138/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9040\n",
      "Epoch 139/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1756\n",
      "Epoch 140/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5954\n",
      "Epoch 141/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8695\n",
      "Epoch 142/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.8349\n",
      "Epoch 143/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.4697\n",
      "Epoch 144/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.6093\n",
      "Epoch 145/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0237\n",
      "Epoch 146/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7998\n",
      "Epoch 147/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9406\n",
      "Epoch 148/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5653\n",
      "Epoch 149/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1638\n",
      "Epoch 150/300\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.4725\n",
      "Epoch 151/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.8647\n",
      "Epoch 152/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9662\n",
      "Epoch 153/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7551\n",
      "Epoch 154/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7705\n",
      "Epoch 155/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8945\n",
      "Epoch 156/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.9130\n",
      "Epoch 157/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.0039\n",
      "Epoch 158/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9551\n",
      "Epoch 159/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7921\n",
      "Epoch 160/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7146\n",
      "Epoch 161/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6640\n",
      "Epoch 162/300\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7317\n",
      "Epoch 163/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7088\n",
      "Epoch 164/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9317\n",
      "Epoch 165/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.9640\n",
      "Epoch 166/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9096\n",
      "Epoch 167/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.7750\n",
      "Epoch 168/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 18.1624\n",
      "Epoch 169/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4847\n",
      "Epoch 170/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6535\n",
      "Epoch 171/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1726\n",
      "Epoch 172/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9738\n",
      "Epoch 173/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.5946\n",
      "Epoch 174/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.2487\n",
      "Epoch 175/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1040\n",
      "Epoch 176/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2824\n",
      "Epoch 177/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6198\n",
      "Epoch 178/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8975\n",
      "Epoch 179/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.4880\n",
      "Epoch 180/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8366\n",
      "Epoch 181/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7736\n",
      "Epoch 182/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.0291\n",
      "Epoch 183/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 18.1299\n",
      "Epoch 184/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9062\n",
      "Epoch 185/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.3108\n",
      "Epoch 186/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6557\n",
      "Epoch 187/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5287\n",
      "Epoch 188/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7845\n",
      "Epoch 189/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6965\n",
      "Epoch 190/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5185\n",
      "Epoch 191/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5884\n",
      "Epoch 192/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6629\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.3137\n",
      "Epoch 194/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7222\n",
      "Epoch 195/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4182\n",
      "Epoch 196/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.5160\n",
      "Epoch 197/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.8894\n",
      "Epoch 198/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6690\n",
      "Epoch 199/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5342\n",
      "Epoch 200/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5970\n",
      "Epoch 201/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6363\n",
      "Epoch 202/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.5413\n",
      "Epoch 203/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2862\n",
      "Epoch 204/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7184\n",
      "Epoch 205/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9536\n",
      "Epoch 206/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 18.3573\n",
      "Epoch 207/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6672\n",
      "Epoch 208/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7935\n",
      "Epoch 209/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5934\n",
      "Epoch 210/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5967\n",
      "Epoch 211/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6691\n",
      "Epoch 212/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7366\n",
      "Epoch 213/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9190\n",
      "Epoch 214/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7479\n",
      "Epoch 215/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6105\n",
      "Epoch 216/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7286\n",
      "Epoch 217/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 18.0037\n",
      "Epoch 218/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5735\n",
      "Epoch 219/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5715\n",
      "Epoch 220/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7473\n",
      "Epoch 221/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2451\n",
      "Epoch 222/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5775\n",
      "Epoch 223/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5084\n",
      "Epoch 224/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3817\n",
      "Epoch 225/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3787\n",
      "Epoch 226/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6760\n",
      "Epoch 227/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7659\n",
      "Epoch 228/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4871\n",
      "Epoch 229/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3513\n",
      "Epoch 230/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4631\n",
      "Epoch 231/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3803\n",
      "Epoch 232/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3844\n",
      "Epoch 233/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3948\n",
      "Epoch 234/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.9808\n",
      "Epoch 235/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.9550\n",
      "Epoch 236/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6066\n",
      "Epoch 237/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6785\n",
      "Epoch 238/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.4474\n",
      "Epoch 239/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5057\n",
      "Epoch 240/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.8125\n",
      "Epoch 241/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.7784\n",
      "Epoch 242/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4443\n",
      "Epoch 243/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5593\n",
      "Epoch 244/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4231\n",
      "Epoch 245/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7418\n",
      "Epoch 246/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.3206\n",
      "Epoch 247/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.0865\n",
      "Epoch 248/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3880\n",
      "Epoch 249/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8975\n",
      "Epoch 250/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6681\n",
      "Epoch 251/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2314\n",
      "Epoch 252/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.3601\n",
      "Epoch 253/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4835\n",
      "Epoch 254/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.3625\n",
      "Epoch 255/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5348\n",
      "Epoch 256/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5368\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6024\n",
      "Epoch 258/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6420\n",
      "Epoch 259/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5156\n",
      "Epoch 260/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4734\n",
      "Epoch 261/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4178\n",
      "Epoch 262/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.3583\n",
      "Epoch 263/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3347\n",
      "Epoch 264/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5401\n",
      "Epoch 265/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.4254\n",
      "Epoch 266/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4327\n",
      "Epoch 267/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.1675\n",
      "Epoch 268/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4820\n",
      "Epoch 269/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7221\n",
      "Epoch 270/300\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3684\n",
      "Epoch 271/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4115\n",
      "Epoch 272/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4149\n",
      "Epoch 273/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.8660\n",
      "Epoch 274/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0083 - mae: 0.0417 - mape: 17.6452\n",
      "Epoch 275/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.6881\n",
      "Epoch 276/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4744\n",
      "Epoch 277/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.0407\n",
      "Epoch 278/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.1280\n",
      "Epoch 279/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.5867\n",
      "Epoch 280/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.7532\n",
      "Epoch 281/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.6026\n",
      "Epoch 282/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4620\n",
      "Epoch 283/300\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0083 - mae: 0.0416 - mape: 17.8038\n",
      "Epoch 284/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.4500\n",
      "Epoch 285/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2805\n",
      "Epoch 286/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.3557\n",
      "Epoch 287/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3009\n",
      "Epoch 288/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4359\n",
      "Epoch 289/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3771\n",
      "Epoch 290/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.0657\n",
      "Epoch 291/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0083 - mae: 0.0413 - mape: 17.0799\n",
      "Epoch 292/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.0899\n",
      "Epoch 293/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2481\n",
      "Epoch 294/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.1900\n",
      "Epoch 295/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.4049\n",
      "Epoch 296/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.0369\n",
      "Epoch 297/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.3993\n",
      "Epoch 298/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.7352\n",
      "Epoch 299/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0083 - mae: 0.0415 - mape: 17.5846\n",
      "Epoch 300/300\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0083 - mae: 0.0414 - mape: 17.2289\n",
      "157/157 [==============================] - 0s 560us/step\n",
      "157/157 [==============================] - 0s 577us/step\n"
     ]
    }
   ],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vanilla ffNNs\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Vanilla ffNNs\n",
      "           train        test\n",
      "MAE     0.041248    0.041248\n",
      "MSE     0.008321    0.008321\n",
      "MAPE  562.242209  562.242209\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preliminary table: Required Training Times\n",
      "   Architope  Architope-logistic Vanilla ffNN  Bagged ffNN\n",
      "0    266.175             113.752      121.422      111.213\n",
      "0    196.567              44.144            -       41.605\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 70 parameters.\n",
      "          train       test\n",
      "MAE    0.105796   0.105796\n",
      "MSE    0.014667   0.014667\n",
      "MAPE  37.346306  37.346306\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0863s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n",
      "                   In-Line (L-Time) Parallel (P-Time)\n",
      "Vanilla ffNN                121.422                 -\n",
      "Grad.Bstd Rand.F              0.134                 -\n",
      "Bagged ffNN                 111.213            41.605\n",
      "Architope-logistic          113.752            44.144\n",
      "Architope                   266.175           196.567\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       MSE        MAPE\n",
      "ffNN      0.041248  0.008321  562.242209\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061573  0.006233   43.008723\n",
      "ffNN-lgt  0.048790  0.008937   60.784626\n",
      "tope      0.012215  0.000604   38.256912\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   In-Line (L-Time) Parallel (P-Time)  N_par    AIC_like  \\\n",
      "Vanilla ffNN                121.422                 -  40801   81608.376   \n",
      "Grad.Bstd Rand.F              0.134                 -     70     144.492   \n",
      "Bagged ffNN                 111.213            41.605  31571   63147.575   \n",
      "Architope-logistic          113.752            44.144  31574   63154.040   \n",
      "Architope                   266.175           196.567  72970  145948.810   \n",
      "\n",
      "                      Eff  \n",
      "Vanilla ffNN        0.438  \n",
      "Grad.Bstd Rand.F    0.449  \n",
      "Bagged ffNN         0.638  \n",
      "Architope-logistic  0.505  \n",
      "Architope           0.137  \n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "#-------------------#\n",
      " PERFORMANCE SUMMARY:\n",
      "#-------------------#\n",
      " \n",
      " \n",
      "#===================#\n",
      " Individual Metrics: \n",
      "#======-============#\n",
      " \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Architope (Full)\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.012215   0.012215\n",
      "MSE    0.000604   0.000604\n",
      "MAPE  38.256912  38.256912\n",
      "----------------------------------------\n",
      "Architope - Naive Logistic\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.048790   0.048790\n",
      "MSE    0.008937   0.008937\n",
      "MAPE  60.784626  60.784626\n",
      "----------------------------------------\n",
      "Vanilla ffNN\n",
      "----------------------------------------\n",
      "           train        test\n",
      "MAE     0.041248    0.041248\n",
      "MSE     0.008321    0.008321\n",
      "MAPE  562.242209  562.242209\n",
      "----------------------------------------\n",
      "Bagged ffNN\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.061573   0.061573\n",
      "MSE    0.006233   0.006233\n",
      "MAPE  43.008723  43.008723\n",
      "----------------------------------------\n",
      "Gradient Boosted Random Forest Regressor\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.105796   0.105796\n",
      "MSE    0.014667   0.014667\n",
      "MAPE  37.346306  37.346306\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#==================#\n",
      " Overview  Metrics : \n",
      "#==================#\n",
      " \n",
      "----------------------------------------\n",
      "Training Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE        MAPE\n",
      "ffNN      0.041248  0.008321  562.242209\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061573  0.006233   43.008723\n",
      "ffNN-lgt  0.048790  0.008937   60.784626\n",
      "tope      0.012215  0.000604   38.256912\n",
      "----------------------------------------\n",
      "Testing Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE        MAPE\n",
      "ffNN      0.041248  0.008321  562.242209\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061573  0.006233   43.008723\n",
      "ffNN-lgt  0.048790  0.008937   60.784626\n",
      "tope      0.012215  0.000604   38.256912\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#====================#\n",
      " Efficiency Metrics: \n",
      "#====================#\n",
      " \n",
      "Model Training Times:\n",
      "----------------------------------------\n",
      "                   In-Line (L-Time) Parallel (P-Time)  N_par    AIC_like  \\\n",
      "Vanilla ffNN                121.422                 -  40801   81608.376   \n",
      "Grad.Bstd Rand.F              0.134                 -     70     144.492   \n",
      "Bagged ffNN                 111.213            41.605  31571   63147.575   \n",
      "Architope-logistic          113.752            44.144  31574   63154.040   \n",
      "Architope                   266.175           196.567  72970  145948.810   \n",
      "\n",
      "                      Eff  \n",
      "Vanilla ffNN        0.438  \n",
      "Grad.Bstd Rand.F    0.449  \n",
      "Bagged ffNN         0.638  \n",
      "Architope-logistic  0.505  \n",
      "Architope           0.137  \n",
      " \n",
      " \n",
      " Have a great day!!  \n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' Have a great day!!  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAAMOCAYAAACUGQCYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xdck9f+B/BPBhuR6cI9cFRRUByt1q3VOqmj1r1btVXbautotd56td4OtdZRR52tWqWWarW17q0IripuVBwIiDIDZPz+4McjDwmQhAxCPu/Xi3tzTp7znG9owHw5S6LRaDQgIiIiIiIyA6m1AyAiIiIiotKLCQcREREREZkNEw4iIiIiIjIbJhxERERERGQ2TDiIiIiIiMhsmHAQEREREZHZMOEgIiIiIiKzYcJBRFRK/frrr+jQoYPe14eFheH11183Y0T6GzRoEL7//nuhXLduXZw8edLo+3366af4+OOPTREaEREZiAkHEZGVDB06FHXr1sWOHTtE9QqFAk2bNkXdunVx7949K0WnLSwsDHXr1kXdunXRoEEDdOjQAd999x2ys7PN3vfx48fRrFkzva59/fXXERYWJqqbNWsW5syZY47QiIioCEw4iIisqEKFCvj9999Fdfv374e7u7uVIiqcn58fjh8/jkOHDmHatGnYsGEDVq9erfParKwsk/br6OhodPsyZcqgTJkyJouHiIj0x4SDiMiKOnfujCtXruDRo0dC3a5du9CrVy+ta48cOYKePXuiYcOG6Ny5M3bt2iV6/syZM+jWrRsCAwMxfvx4JCUlad1j48aN6NixIxo3boy33noLZ86cMSheqVQKPz8/lC9fHt26dUPPnj1x+PBhAC+nZP3xxx/o1KkTWrZsCQBQqVRYvHgxXn/9dQQFBWHo0KGIjo4W7qnRaPDdd98hJCQELVu2xJo1a7T6zT+l6sqVKxg2bBgaN26M5s2bY8KECQByRo3i4uIwY8YM1K1bF0OHDgWgPaUqISEBH3zwAYKCghASEoKZM2ciPT1deH7o0KFYtGgRPv/8cwQFBaFDhw7Ys2eP8HxSUhI++OADNG/eHE2aNEGvXr0QFRVl0PeSiMheMOEgIrIiNzc3dOjQAeHh4QCAuLg4nD9/Ht27dxddFxsbi4kTJ6Jjx44IDw/H8OHDMXPmTJw/fx4AkJKSgkmTJqFFixb47bff0K5dO62Rhx07dmDjxo2YM2cOdu/ejT59+mDcuHGIjY01On4nJycolUqhnJSUhLCwMCxduhRbt24FACxbtgxHjx7Ft99+i127diE4OBijRo1CamoqgJwEa+PGjZg3bx42bdqECxcuiBKS/J49e4YRI0agSpUq2L59OzZt2oQmTZoAAL7//nv4+flh5syZOH78uGgdSF7Tp0/H48ePsWnTJqxYsQIRERFYsGCB6Jpt27ahZs2a2LVrF/r27YsZM2YgMTERALBkyRKkpaVh8+bNCA8Px6RJk+Dg4GD095GIqDRjwkFEZGW9e/cWplWFh4fj9ddf15r+s3XrVtSrVw9TpkxBzZo1MWTIEHTt2hUbNmwAAPzxxx9wcXHB7NmzUatWLQwaNAitW7cW3WPFihWYNWsWXn/9dVSpUgVDhw5F06ZNhWTHUFevXsXu3bsREhIi1GVlZeE///kPGjRogICAAGRmZmLdunVYuHAhmjVrhmrVqmHq1KkoU6YMDhw4AAD4+eefMXjwYHTr1g116tTB/PnzoVarC+x38+bNqFixIr788kthTcm4ceMAAJ6enpBKpShTpgz8/Pzg6emp1f727ds4ceIEFixYgIYNG6JZs2aYPXs2wsLCkJKSIlwXHByMESNGoFq1anjvvfcglUpx6dIlAMCTJ08QHByMgIAAVK1aFV26dEHDhg2N+j4SEZV2cmsHQERk71577TWkpKTg0qVLCA8Px9SpU7WuuXv3rvBX/FxNmjQRFpzfvXsXDRo0gFz+8td6YGAgLl68CABIS0tDbGwspk6dColEIlyTlZWF8uXL6x3r06dPERQUBJVKBaVSiS5duuD9998Xni9btiwqV64slO/fvw+FQoGBAweK7qNQKPDgwQMh9rFjx4ruUbVq1QJjuHnzJkJCQkSvwxB3796Fm5sbateuLdQFBQVBqVTi/v37eOWVVwAAAQEBwvNyuRxeXl7CCEf//v0xdepUnDhxAq+++iq6d++OmjVrGhUPEVFpx4SDiMjKZDIZevToga+++goJCQlo06YN4uLiRNdoNJpC76HRaAr9AJ6RkQEA+Prrr1GnTh3Rc25ubnrH6uvriy1btkAmk6FcuXJaC7mdnZ1F5dx1ERs3boSHh4foubJlywqPDUkeivpeGENX/3mTt9xrcvvu2LEj/vnnHxw6dAhHjhzBypUrsWjRIq2pcERExClVREQlQp8+fRAREYE333xT51qAmjVr4sKFC6K6CxcuCH9Vr1GjBq5evQqVSiU8f/nyZeGxj48P/Pz88PjxY1SrVk305evrq3ecUqkU1apVQ+XKlfXaNapWrVpwcHBAfHy8Vr+5052qV68uTFUCgOTkZNy/f7/AewYEBODcuXMFJh5yuVz0fcivRo0aSEtLw61bt4S6yMhIyOXyQkdW8itXrhwGDhyI5cuXo1+/fvjtt9/0bktEZE+YcBARlQD16tXD6dOnMX36dJ3PDxo0CNHR0ViyZAnu3r2LzZs346+//sLw4cMBAD179kRqairmz5+PO3fuYNu2bTh+/LjQXiKRYPz48ViyZAl27tyJ+/fv4/Lly/jxxx9x6tQps70ud3d3DBkyBHPnzsVff/2FBw8eICoqCt9++y1u3rwpvLYtW7Zg3759uHXrFmbPng2ptOB/noYMGYLHjx9j9uzZuH79Om7duoW1a9cKz/v7+yMiIgLx8fGiNRm5atWqhdatW2PmzJm4cuUKzp8/j/nz5yM0NFTvrXOXLl2KQ4cO4cGDB7h8+TIiIyNRo0YNA787RET2gVOqiIhKCC8vrwKf8/f3xw8//ICvv/4aq1evRsWKFTF//nwEBwcDADw8PLBs2TLMnTsXv/76K1q0aIExY8YIO0UBOVu9Ojo6Ys2aNZgzZw48PT3RpEkTdOrUyayva/r06fD09MRXX32Fp0+fwsfHB82bNxdGOEJDQxETE4PZs2dDJpNh9OjRiI+PL/B+3t7e+Omnn7Bw4UL069cPrq6uooXrkyZNwpw5c9CuXTsEBwdj06ZNWvf46quv8MUXX2Do0KGQyWTo0qULZsyYofdrkslk+Oqrr/Dw4UOUKVMGHTp0wJQpUwz4rhAR2Q+JxhyTYYmIiIiIiMApVUREREREZEZMOIiIiIiIyGyYcBARERERkdkw4SAiIiIiIrNhwkFERERERGbDhIOIiIiIiMyGCQcREREREZlNiT74Lzk5AyqV2tphAAC8vNyQlJRm7TCohOH7ggrC9wbpwvcFFYTvDdKlJL0vZDIpPDxcjGpbohMOlUoNpdL6CYdEkvP/KpUaPCaRcvF9QQXhe4N04fuCCsL3BulSmt4XnFJFRERERERmw4SDiIiIiIjMhgkHERERERGZDRMOIiIiIiIyGyYcRERERERkNkw4iIiIiIjIbJhwEBERERGR2TDhICIiIiIis2HCQUREREREZsOEg4iIiIiIzIYJBxERERERmQ0TDiIiIiIiMhsmHEREREREZDZMOIiIiIiIyGyYcBARERERkdnIrR2AtWk0Gmg0mkKvkUgAlUoFtVqNIi4lO8L3RcEkEgkkEom1wyAiIqISwC4TDpVKBYUiDRkZqVAqlQCK/rQYHy+FWq02f3BkU/i+KJhUKoOTkyucnV3h6OjEBISIiMhO2V3CkZ6eguTkJDg6OsHNrSwcHBwhlUoBFP5hSC6XQqnkB0sS4/tCFw3Uag1UqmwoFBl48SIBgATe3uUglztYOzgiIiKyMLtKODIzM5CSkgRv73JwdHQ2qK1UKoWUK14oH74vdJNKAblcDicnF2g0XkhNfY5nz+Lg7V2eSQcREZGdsZuPSmq1Cs+fJ8DDw8fgZIOIjCeRSODu7gkXFzc8e/a0yDVTREREVLrYTcKRmamATCaHi4ubtUMhsju5SQegQXZ2prXDISIiIguyo4QjA05OLtYOg8huSSQSODm5IiMj3dqhEBERkQXZTcKRlaWAkxOnUhFZk7OzCzIzmXAQERHZE7tIODQaDdRqFWQyu1ojT1TiyGQOUKtVXMdBRERkR+wm4QAAicQuXi5RiSWV5mw/zYSDiIjIfvATOBFZEA//IyIisjdMOIiIiIiIyGz0Sjg2b96M0NBQNGzYEFOnTi302rNnz6JHjx5o3LgxBgwYgJs3b5okUCIiIiIisj16JRzlypXDhAkTMGDAgEKvS0pKwoQJEzBu3DicO3cOHTt2xIQJE6BUKk0SLBERERER2Ra9Eo4uXbqgU6dO8PLyKvS6/fv3o3r16ujVqxccHR0xZswYpKWl4dy5cyYJloiIiIjIHkRev4hf9u6EJCvB2qEUm0n3ib1x4wbq1asnlGUyGerUqYMbN26gVatWRt1TYoI1pqa4BxGZjkRSun8uc19baX6NZDi+L6ggfG9QflFPJXjvZHM4pSvwLPM0Brb2tXZIxWLShCM9PR1ly5YV1Xl4eCAtLc2o+3l5uZkiLKhUKsTHSyGXSyGVGr9OXi7nGnvSxveF/tRqQCqVwsfHHTKZzNrhmJ2PTxlrh0AlEN8XVBC+NyjXjyNO4d09JwAA6eWd4BnTAXJn2z1PzqSRu7q6IjU1VVSXkpICNzfjEoekpDSoVOpix6VWq6FWq6FUqmFsviGXS6FUFj8WKl34vjBM7s9iYmJqsZL/kk4iyfngkJiYAh45Qrn4vqCC8L1BeZ28nY3m/59sAIAkLhMHZx9B8KfNrRgVIJNJjR4MMGnCERAQgF9//VUoq9Vq3LhxA+PHjzf6nqb4weMPLxUmLS0V+/b9iTNnTuH27ZtITk5GRka68PzIkWMxerTx7+GCnDt3BlOnTgQABATUw9q1myCx8Hj6/PlzsXfvbgDApElT8PbbQyzSr0ZjHz+X9vI6yTB8X1BB+N4gAIhqvwWu+epSYmw7GdXrT4xKpRKZmZlQKpVQq9XIzMxEdna21nWdO3fG3bt3sXv3bmRlZWHNmjVwc3NDSEiIyQMnMoXz589h0KC38N13i3Dy5DHExT0RJRsAULt2gMn7VSqVWLz4f0L5vffet3iyAQCjR78LR0dHAMBPP63Gs2eJFo+BiIiIcuyNVMA1I1Mo534yCJ5l3dGN4tIr4VixYgUCAwOxcuVK7Nu3D4GBgfjss88AAEFBQYiIiAAAeHl54YcffsCKFSvQrFkz7N+/H8uXL4dcbrtzzqj0unPnFj799EOtD9kSiQQymUz4ql27jsn7Dgv7FffuxQAAgoKaIiSkhcn70EeFChXQq1dfAEBaWhpWr15plTiIiIgIeNBjk3alDHCvbNvreyQaTckdoElKSjPJ/Hi1Wo2nTx+gXLkqRs8b51z90mfy5Ak4f/4sAMDBwQFjxryLLl26wdfXT+/RBmPeFxkZGRgwoDeSkp4BAL755nu0aGHcLm6m8OTJYwwc2AcqlQoymQw//7wT/v6VzdKXKX4WbYFEAvj6lkFCgm0PgZNp8X1BBeF7gwBg1+54PB8VJpRzP4n0OdUfZWt5WyeoPORy49dwlN5/8YkKcefObSHZAIDRo8dj8ODh8PMrZ/apTWFh24Vko1at2lZNNgCgQoWKaN++E4CcHd3Wr19j1XiIiIjsUcLoMK06qZMUnrWtn2wUFxMOsksHDvwtPHZ0dETfvv0s0q9SqcSOHduEcq9eoRbptyi9e7+M459//kJCgu0fMkRERGQr1m98BHme0a3cP31OfDrRKvGYGhMOsksXL0YJj195pRHc3Nwt0u/Bg/8gPv4pAMDR0QldunSzSL9FCQpqisqVqwAAsrOzsWvXDitHREREZD/UH/+hVSfzcICTh5MVojE9Jhxkd9RqNaKjrwrlunXrW6zvPXvChcfNm7dAmTIlZxFY7rQqANi7dzdK8PIuIiKiUmP55/+KPpDnjm4MuDTYGuGYBRMOsjuxsQ+gUCiEcq1atS3Sb3z8U0RFRQjltm07WKRffbVt2154HBf3BFFR560YDRERkX1wWXlcq861ihuc3ErH6AZg4oP/iEqqzz77FIcO/aPzufnz52L+/LmiOnd3d+zbd9ikMRw7dgRq9csdrfTdCletVmPkyMG4ffsmAEAqlWLdui16bde7d+9u/Pe/XwijFQEBdbF06Sq4u2tPIatbtz48PMoiOfkFAODo0cMIDm6mV4xERERkuKVjTsEjTzl3dCP0zCBrhGM2HOEguxATc8eg62vUqGnyGM6cOSk8rly5Knx9/fRqJ5VKMWnSZKGsVquxatWyItsdPXoYCxf+R0g2qlevgW++WaYz2QByzh9p0iRYKJ8+fUKv+IiIiMg4HuGXtOr8WpWHTC6zQjTmw4SDSj2lUolHjx4KB/nl3/Y27yF/uV+1apn+sL9Lly4Kj+vXb2BQ25CQlmjZ8lWhfOrUiUKnPEVEnMXcuTOhUqkAAJUq+WPx4uXw8vIqtJ+8ccXGPkBCQrxBcRIREZF+vut9QFTO/XTSbVdvywdjZpxSRaWeXC7HgQMv/1o/eHA/4ZTvDh06Y968BWaP4eHDWKSkJAvlmjUNXzcyceIUnDt3RkgiVqz4Hj/+uF7ruitXLmPGjI+QlZUFAPDzK4fFi5frNaKSP9G6du1ftGnTzuBYiYiIqGAaDeB16pZWfZVe1cx+Hpg1cISD7Ep6ejoePLgvlOvVs8wOVbdvi3+pVKlSxeB71KhREz179hHKV69ewZEjB7X6mTZtMjIyMgAAnp5eWLx4OSpV8terjypVqhYaNxERERXfspbiQ/5yU4wOa96wfDAWwITDVmnUkGQlQJKVmJMmk15u3IgWLdy21Ja4T548EpX9/MobdZ/Ro8fD1dVNKK9a9YMw4hEb+wAffjhRGElxdy+Db7/9HtWqVdf7/n5+5UTlx48fFXAlERERGSMrS4Uyd7WnLNef0tgK0VgGEw4bI1Emw+XeMnieaQevU6/C61QreJ7rAufYnwCVgslHEa5fvyYqBwTUs0i/+ddCFLWWoiBeXt4YOnSEUL5//x727AnH06dxmDJlAhITEwEALi4u+PrrJQa/PmdnZ1FCEx/PNRxERESmtCZwq6icO7rRfGZLywdjIVzDYUMkmU9R9tJQSNPviuqlGffgensBnGPXIcu7PdID5lkpwpIvOvplwuHvX7nQg/cePoxFdPQ1REdfRXT0VVy/Ho309DQAwMyZc9C9e0+9+01PzxCVnZyM31t7wIB3sGvXTsTFPQEArFv3I7Zu3YwnTx4DABwdHbFgwTdo2DDQqPs7OTkJrzMjI93oOImIiEjsxfMsuD5L1ap/bWV7HVeXHkw4bEiZ6I+0ko28pIpHkGU+tGBEtifvCEdR6zcGDuxT6POGyM7OEpUdHByMvpeTkxPGj5+EefNmAxCPnshkMsybtxDNmjU3+v55Y8vMzDT6PkRERCS2LXAzHPOUc0c3aocGWCMci+GUKhvhHLsO8qTThV8kkcHh+WlIMp9aJigbk56eJlowru/6DQ+PsggJaYEOHTob3beDg6OonJ2dbfS9AKBz565aW+tKpVJ89tk8tG79erHunTe24ozEEBER0Uv3ol/AUaH973+XP3pYIRrL4giHDZBkv4DLvWUANHiZCxdAnQ3HxP3IrDTYEqHZlOvXo4VD8ICiE44vvliAevXqw9+/MgAgMjICBw/uN6pvV1cXUbm4Iwf37sVoLegODGyCTp26Fuu+AKBQKITHLi4uhVxJRERE+vqn/XbkPc5PAgBSoGIL/XaStGUc4bABGoeyyCrXE5Do959Lqnxh5ohsU971GxKJpMgF1R07dhaSjeLKfwbGs2fPjL7Xo0cPMXXqRDx//lxUf+FCZKGHAepDoVCI1m3oexo6ERERFezSgUeQqdRa9W9FvmOFaCyPCYeNUDv4GHAtPyTqknf9RlELxk2tYsVKonJCgnHT3hIS4jFlygTEx+e0d3JyEo1CLFu2WDSKY6jc++bKHzcREREZLmLQH6KyBIDERQL3Spb7LGJNTDhsRGb53oA+J0/KnJHlV/xpNaVR3hGOunUtsx1urvwni+ddS6Kv58+fY8qUiXj0KGdjALlcji+//AoDB76cPnf9+jXs27fH6Djv378nKuc/eZyIiIgMc3TVVdEH7txPc29fG2GFaKyDCYeNULtUQ5ZvlyKvU1QcCI3cwwIR2Za0tFQ8fPhAKFvqwL9cOSMqL/+7GHqCd1paKj766H3ExNwB8HKBeKtWrfHOO0Ph6fnyXI/Vq1cgM1NR0K0KdeeOOK78C9OJiIjIMLc/O6ZV51TRBY6ujjquLp2YcNiQ1IAFUJZtVuDzWb5dkF5jugUjsh35F4zXq2f5D9JNmgQJj6Ojr+rdTqFQYNq0KaIpYR9/PAMdO+YkoK6ubhgxYrTw3NOncfjll81GxXjt2su4/P0ra508TkRERPrbM/OsaLuf3MdvnRlkjXCshgmHLZG7IzlwA1Lr/Q9KjyBA6giJOgPZnq2Q8soPSG2wFJAaf75DaWbognFzaNGilfA4NvaB1noJXbKzszFz5jRcunRBqJswYTJ69eoruq5Pn36oVOnlLhdbtmxEYmKCQfFpNBpcuBAplFu2fNWg9kRERCQWvyZKq65sA084ONvX5zUmHLZG6oCs8r2RHLQNz16LQnqNj5Ba/1tk+3bWexcre3T9uvgv9+7u7haPoXXrtpBKX/43iog4W+j1KpUKc+fOxNmzp4S6YcNG4Z13hmpdK5fLMW7cBKGckZGONWtWGRTf9evXkJz8coezNm3aGdSeiIiIXtrc/y9ROXd0o/ehAZYPxsr4CdWWSR2QUX0KNI7672Blr65fjxYeW3r9Ri5fXz8EB7+cEnfkyMECr9VoNFiwYB6OHDkk1IWG9hclFfl17NhF9Nr+/DNca01GYfL25edXThQrERER6U+j0UB5JEarvkrP6pDoswlQKcOEg0q9lJQUPHwYK5StlXAAQI8evYXHZ8+eQWpqqs7rvvtukWi3qa5du2Pq1MLX50gkErz33vtCWaVSYdmyJXrHdujQAeHxG2+8KRqNISIiIv2ta7FDVM5NMTqstc+dRPmJgkq9GzfyLxi3XsLRrl1HlCtXHgCQlZWJv/76U+ualSuXISzsV6Hcpk1bzJjxuV5/EWnWrDmaN28plM+ePYXTp08W2e7ChUjExuZs1SuXyxEa2r/INkRERKRNmaWELEb7gN8mn+s/cyA1OwNTLi5H6D9fYM/j06YMzyrk1g6AyNyaNg3B8eMR1g4DQM6H+X793sby5TkjD+HhYXjrLfFcznffnYR3351kdB/ffrvM4Dbh4b8Jjzt27MzdqYiIiIy0ocEWyPKUc/9c2HhSU73vMTzyK2iQ88fSNff2ws/REyHelt/wxlQ4wkFkYaGh/eHtnbPu5vbtWzhz5lQRLcwrLu4JDh7cDwCQyWQYMWKsVeMhIiKyVRmJGZAla5+F1WZdB73vMe3SKiHZyHU08VKxY7MmJhxEFubs7IyhQ0cK5c2b11svGABbt26BUqkEAHTr1gNVqlS1ajxERES26ufG4nOwckc3avaoo1f79GwFbmc80qoP9tSvfUnFKVVEBXj4MBZJSUlCOSbmrui5K1cuQy6XQKnUwM3NDTVq1NT73n379sPvv+9ETMxdREWdR0TEWTRr1tyk8esjLu4Jfv89DEDOAYJjx75n8RiIiIhKg8Qr8ZBlqbXq3/wnVO97DI9cqLO+vV+QznpbwYSDqADr16/B3r27dT63YcNabNiwVig3aRKMZct+1Pvecrkckyd/jKlTJwIAVqz4HmvWbLT4Vnlr165CVlYmAGDkyLHw8fG1aP9ERESlRXiHMO1TxR0A30A/vdrvfxIBVb6pVAAwvFInk8RnTUw4iKwkJKSF1Rezz5w5BzNnzrFqDERERLYu+tcb0PUnw4H/Dtf7Hivu/aGzvk/VNtBo5yE2hQkHUQFmzZqLWbPmFnqNXC6FUqk9fEpERET249TEQ1qjG3JPBzh7OuvVfva/63TW/9H5CyhTih+ftXHROBERERGRkY7PPa1zdONtPUc3UrPScTX1nlZ9eQcveDqVKWZ0JQMTDiIiIiIiI91aflFUlgDwqO8FmYNMd4N8Rkd9rbP++6D3ixtaicGEg4iIiIjICLsG/qmzvs/h/nq1PxJ3CdlQadUP8+8MB6l+CYstYMJBRERERGQgtVqN54ceiOokAKr2raH3rpNLYnbqrO9TuXVxwytRmHAQERERERno55bbdNa3X9VFr/Zzrvyks35Zo9IzlSoXEw4iIiIiIgNkpmRCGZMsqpMAaPhJsH7tVdm4nBajVV9eXhaVXEvfmVhMOIiIiIiIDLA1cIuonDuBqulHIXq1HxqxQGf90qDJxQmrxGLCQURERESkp+d3n0OTlq1V//p6/U4EPxJ/EUodC8UHVmxbqhaK58WEg4iIiIhIT7+9tl1Ulvz//9ToXkuv9kvuhOmsH1i1QzEjK7mYcBARERER6SH2yH1IlBqt+l7H39Kr/YzLq3XWr2nycbHiKumYcBARERER6WF//72isgSA1E0KrzpFL/ROz1bgenqsVn0lB294l5ITxQvChIOIiIiIqAgXvzsPXadrDLgyTK/2IyIX6axf3GRSMaKyDUw4iIiIiIiKELkgQlSWAHCp7AInN6ci2x6Ov6BzofjQip0gL6ULxfNiwkFEREREVIj9w/fpHN3od3aIXu2X3vlNZ33fqm2KEZXtYMJBRERERFQAjUaDh3vvieokAMq3qwSpvOiP0tMv/qizfkVg6TxzQxcmHEREREREBdjRZpvO+i5b3yyybXq2ArcUD7XqK8o9Ud7Fu9ix2QomHEREREREOmSlZyHtxgtRnQRAo2nBkEqL/hg9PPIrnfVLgj4wRXg2gwkHEREREZEO24N+1lkfPC2kyLb74yKhglqrflgl+1gonhcTDiIiIiKifJLvvYAyKVNUJwHw6g/t9Gq/IuZ3nfV9qtjHQvG8mHAQEREREeX36dJwAAAgAElEQVTzW6utonLuLlV1+tctsu2HF5frrF8bVLpPFC8IEw4iIiIiojzuhN+ARqld3+NovyLbPs9MQ4wiTqve38kbXo6l+0TxgjDhICIiIiLK4+iYQ6KyBIDUVQqfej5Fth1zQfeJ4ksC3zdFaDaJCQcRERER0f87+/lxnfWDro8ssu3uR2d0LBMHRvu/odeuVqWV3NoBEFlbWloq9u37E2fOnMLt2zeRnJyMjIx04fmRI8di9OjxJu/33LkzmDp1IgAgIKAe1q7dBIlE1zmm5jN//lzs3bsbADBp0hS8/bZ+J6YSERGVVldX/isqSwC41/aA3Knoj83rHvyps/7Nyq1MEZrNYsJBdu38+XP44ovZePYsscBratcOMHm/SqUSixf/Tyi/9977Fk82AGD06Hdx4MDfyMrKwk8/rUaXLt3g7V30cDEREVFptDc0XGd9n6MDimw7MWqJzvoNQdOLFVNpYL9jO2T37ty5hU8//VAr2ZBIJJDJZMJX7dp1TN53WNivuHcvBgAQFNQUISEtTN6HPipUqIBevfoCANLS0rB69UqrxEFERGRtGo0Gcccfi+okAPx7VINMXvi5GfGK53ic9UyrvpqzH8o4upkyTJvEEQ6yW0uWfIuMjAwAgIODA8aMeRddunSDr6+fWUcbMjIysGnTT0J5yJARZutLH2+/PQS//bYDKpUKf/4ZjiFDhsPfv7JVYyIiIrK07cFbdNZ3XNu1yLbvXvxOZ/23gROLFVNpwREOskt37tzG+fNnhfLo0eMxePBw+PmVM/vUprCw7UhKyvkrSK1atdGihXXndVaoUBHt23cCAKhUKqxfv8aq8RAREVla+tM0ZDxME9VJAAR93rzIzwXb7h+ARkf9J7UGWmW6dEnEhIPs0oEDfwuPHR0d0bdv0ftqm4JSqcSOHduEcq9eoRbptyi9e7+M459//kJCQoIVoyEiIrKsHc1+0VkfOCmoyLbbHh/VqpMCaOHboLhhlRpMOMguXbwYJTx+5ZVGcHNzt0i/Bw/+g/j4pwAAR0cndOnSzSL9FiUoqCkqV64CAMjOzsauXTusHBEREZFlPL3wFGqFSlQnAfDGvt5Fth13/hud9euDPzVFaKUGEw6yO2q1GtHRV4Vy3br1Ldb3nj0vd79o3rwFypQpOSeO5k6rAoC9e3dDo9E1QExERFS67O3ym3alA1A+uEKh7e6nP0GCMlmrvpF7Dbg7uJgqvFKBCQfZndjYB1AoFEK5Vq3aFuk3Pv4poqIihHLbth0s0q++2rZtLzyOi3uCqKjzVoyGiIjI/K6suqi1/kICoM/Zt4tsO+XyCp31X7wyothxlTbcpYrswmeffYpDh/7R+dz8+XMxf/5cUZ27uzv27Tts0hiOHTsCtfrl+aP6boWrVqsxcuRg3L59EwAglUqxbt0Wvbbr3bt3N/773y+E0YqAgLpYunQV3N21p5DVrVsfHh5lkZz8AgBw9OhhBAc30ytGIiIiW3T+s9OisgSAQzknlPUvW2i75bd+11k/rWbR53XYI45wkF2Iiblj0PU1atQ0eQxnzpwUHleuXBW+vn56tZNKpZg0abJQVqvVWLVqWZHtjh49jIUL/yMkG9Wr18A33yzTmWwAOeePNGkSLJRPnz6hV3xERES26MCofTp3lxoYNbTQdhqNBv8kRmrVO0KGVn6vmCi60oUJB5V6SqUSjx49FA7yy79FXd5D/nK/atUy/WF/ly5dFB7Xr2/YzhUhIS3RsuWrQvnUqROFTnmKiDiLuXNnQqXKWQRXqZI/Fi9eDi8vr0L7yRtXbOwDJCTEGxQnERGRLdBoNHiw+56oTgLAr2U5yBwKP+RveMRXOus3hswwVXilDqdUUaknl8tx4MDLv9YPHtxPOOW7Q4fOmDdvgdljePgwFikpLxeW1axp+LqRiROn4Ny5M0ISsWLF9/jxx/Va1125chkzZnyErKwsAICfXzksXrxcrxGV/InWtWv/ok2bdgbHSkREVJLtem2rzvpuv/cptN3VF/eRqs7Qqm/lWR+OUgeTxFYacYSD7Ep6ejoePLgvlOvVs8wOVbdv3xKVq1SpYvA9atSoiZ49X/4ivHr1Co4cOajVz7Rpk4UT1D09vbB48XJUquSvVx9VqlQtNG4iIiJbl5GUgRe3xLtLSQAEjK1f5EF9s6PX6qz/OGCgqcIrlZhw2KgHKRIcjpXjSKwMcek8xVJfN25EixZuW2pL3CdPHonKfn7ljbrP6NHj4erqJpRXrfpBGPGIjX2ADz+cKIykuLuXwbfffo9q1arrfX8/v3Ki8uPHjwq4koiIyDbtaLJFZ32r+a8X2u6/0brbfVFnGE8ULwKnVNmYG0lSrLniiEsJL+cXSgGEVFBhxCuZ8HHWwMPRevGVdNevXxOVAwLqWaTf/GshilpLURAvL28MHToCq1b9AAC4f/8e9uwJR8uWr2LKlAlITEwEALi4uODrr5cY/PqcnZ3h6uqG9PQ0AEB8PNdwEBFR6ZF4JR6qDO1D/tpu6VJou0xlFiJe3NCqd5M4o5F3LVOGWCox4bAh/yZKMfOECzLFPydQAzjzRIYzT1zRsoISc1tlWiU+WxAd/TLh8PevXODBeyqVChcuROLs2dP499/LuHcvBikpyXB0dEK5cuXRpEkQevcORf36+o2QpKeL53s6OTkZ/RoGDHgHu3btRFzcEwDAunU/YuvWzXjy5DEAwNHREQsWfIOGDQONur+Tk5OQcGRkpBsdJxERUUmzu0OYzvrqnWsU2m7Yed3rPX9qNq3YMdkDJhw2Qq0BFkU4ayUbeWk0QKKCs+QKk3eEo7D1G2PHDsONG9e16pVKJWJi7iAm5g5+/z0MgwcPw/jxk4ocSs3OzhKVHRyMX1jm5OSE8eMnYd682QDEoycymQzz5i1Es2bNjb5/3tgyM5m8EhFR6fDv6su6D/k7XfjZGcfiLyIbaq36Hj7NIZfyo7Q++F2yAUo1MPeUMx6nSSAt5HOtRALcfC7FnRdS1Cyr/YNh79LT00QLxgtbv5GWlgaJRILg4BC0b98RjRo1hq+vLzIyFIiMPIc1a1bi6dM4bN68AQ4Ojhg9enyhfTs4iOe5ZWdnF+u1dO7cFb/++jOuXbsq1EmlUnz22Ty0bl34HNSi5I2tOCMxREREJUnErJNadfKyDihbs/Bpzt/d0T0qMqr2myaJyx4w4bABmSrgaYYE+i5HinwqY8Khw/Xr0cIheEDhCUfbth3w5pu9tBZcly0LdO/eEy1atMLo0UORkBCPzZvXo2/ffvD29inwfq6uLqJycUcO7t2L0VrQHRjYBJ06dS3WfQFAoVAIj11cXAq5koiIyDYcHL5X5+jGwMvDCm33yeVVOutXBE7WWU+6cf6NDXBzAAJ9VdB3AwQlcw2d8q7fkEgkhS6onjDhg0J3d/Lx8cXAgYMB5IwInD17utC+85+B8ezZMz0i1u3Ro4eYOnUinj9/Lqq/cCGy0MMA9aFQKETrNvQ9DZ2IiKik0mg0uL/3vqhOAsC7mR/kzgX/7f15Vhpupmvv1ugnL4vyLt6mDrNUY8JhIyq758/LC1alDDMOXfKu3yhswbi+atZ8uStFUbs5VaxYSVROSHhqVJ8JCfGYMmUC4uNz2js5OYlGIZYtWywaxTFU7n1z5Y+biIjI1uwI3qyzvsfuvoW2Gx21SGf9yuCpxY7J3jDhsBGdqmbDSY//Wt7OGrSoUMjKcjuWd4Sjbt3ib4f77Fmi8NjNza2QK7VPFs+7lkRfz58/x5QpE/Ho0UMAOSeof/nlV8JIC5CTVO3bt8fge+e6f/+eqJz/5HEiIiJbonihQNpD8Y6LEgCNPgyCpJCFsVvu7deaggUAw/w788wNIzDhsBHujkD/gKwirxtePwty/lfVkpaWiocPHwhlUxz4d+DA38LjRo0aF3ptzoiKh1A29ATvtLRUfPTR+4iJuQPg5QLxVq1a4513hsLT8+WCt9WrVyAzU1HQrQp15444rvr1Gxh1HyIiopJge8NNOuuDPy18N8edT45r1UkB9Knc2hRh2R1+NLUhQ+pnY2BANmQ6EmsHKfBuYBa6VldaPjAbkH/BeL16xfsgfebMKZw+nbPbRePGQahTJ6DINk2aBAmPo6OvFnKlmEKhwLRpU0RTwj7+eAY6dsw5pMjV1Q0jRowWnnv6NA6//KJ7+LgoeXe98vevrHXyOBERka14ej4O6kzxNHMJgPbbCt9gZVSE7qlUG4JmmCo0u8OEw8aMfCULP3VJx9t1sxHsp4JGA7xTNwub3khDn1rF22q1NDNkwXhRnj6Nw/z5cwHkHLI3ZYp+h/60aNFKeBwb+0BrvYQu2dnZmDlzGi5duiDUTZgwGb16ieed9unTD5Uq+QvlLVs2IjExQa+4cmk0Gly4ECmUW7Z81aD2REREJcnebru0KyVA1fbVC2xzL/UJnqvStOobuleHm6Oz6YKzM0w4bFA5Vw1GNMjCf15V4Ks2CvSrkw1PHpdQqOvXxX+5d3d3N+o+aWmp+PTTD4X1G1OnfqzX6AYAtG7dFlLpyx+5iIizhV6vUqkwd+5MnD17SqgbNmwU3nlnqNa1crkc48ZNEMoZGelYs0b3Vn4FuX79GpKTXwjlNm3aGdSeiIiopIiYf1rnNrj9rw0ptN3Uf1forJ9bf7hpArNTTDhsmEwKNPFTwdX4Q6vtxvXr0cJjY9dvKBQKTJ8+VTiBfOTIsejbt5/e7X19/RAc3EwoHzlysMBrNRoNFiyYhyNHDgl1oaH9RUlFfh07dhG9tj//DNdak1GYvH35+ZUTxUpERGRL/l1yUavOydcJrt4Fb/KyKHqrzvoZtQaJ/mBIhuN3j0q9lJQUPHwYK5SNSTiysrIwY8ZHuHgxCgDwzjvDijxdXJcePXoLj8+ePYPU1FSd13333SLRblNdu3bH1KnTC723RCLBe++9L5RVKhWWLVuid2yHDh0QHr/xxpv85UpERDZpX79w3Yf8/VvwKEWWKhunX1zTqneCA0J8i7+zpb3jJwoq9W7cyL9g3LCEQ6lUYvbsT3Du3BkAwIABgzBhwgdGxdKuXUeUK1ceAJCVlYm//vpT65qVK5chLOxXodymTVvMmPG5XtvwNWvWHM2btxTKZ8++XNxemAsXIhEbm7NVr1wuR2ho/yLbEBERlTQatQZxRx+L6iQAKnaqXOi/o8MjFuqs39DsE1OGZ7cKPl6RqJRo2jQEx49HGNVWqVRizpwZOHnyGACgb9/++OCDj4yORS6Xo1+/t7F8ec7IQ3h4GN56a4DomnffnYR3351kdB/ffrvM4Dbh4b8Jjzt27MzdqYiIyCZta7hR5/kZXX5+s8A2J+IvIxPau3x29gmGo4zz1k2BIxxEBVCr1fjyyznC2oaePfvgww8Ln9akj9DQ/vD29gGQcx7HmTOnimhhXnFxT3Dw4H4AgEwmw4gRY60aDxERkTFe3EqCIkF8DpUEQNCcws/c+ObODp3179XurbOeDMeEg0gHjUaDRYvm459//gIAdOvWA9OnzzLJ6aLOzs4YOnSkUN68eX2x71kcW7dugVKZ85edbt16oEqVqlaNh4iIyBi7Wm/XWR84MUhnPQB8dGG5zvqv6o8zSUyUgwkHkQ5LlnyD3bt/B5CzPeyUKR8jIyMD6enpOr+ysoo+BT6vvn37oXr1GgCAqKjzRW6Ray5xcU/w++9hAHIOEBw79j2rxEFERFQct369Do34jD9IALyxv+BRikRFMu5mxmnVl5eXRR0Pfx0tyFhcw0Gkw44dL7fGO3bsMLp2bVfo9d269cCsWXP1vr9cLsfkyR9j6tSJAIAVK77HmjUbTTKCYoi1a1chKysTQM42vz4+vhbtn4iIyBROTDysVSd1laJ84woFthl78Rud9d8HTTZVWPT/mHAQWUlISAujF7ObysyZczBz5hyrxkBERFQcB0f9pfuQvwvaB+Xm2nx/v876cZXfhFwqM11wBIAJB5FO+iYCcrkUSqW66AuJiIjI5DQaDR7sjtGqL1vfE86ezgW2CXt8XKteCuAN/8IXmJNxuIaDiIiIiGzSzuY/6xzd6HWw4POkhkcs0Fm/LphnbpgLEw4iIiIisjlp8alIu5cqqpMAqD28LqQy3R9xryffR6o6U6u+kWs1eDi4miNMAhMOIiIiIrJBYU1/0XnI32v/a1dgmxnX1uqsn9twpM56Mg0mHERERERkU+7/HQOVQryGUgKgw9auBbaZc3W9zvov6gyz+C6R9oYJBxERERHZlEND/tKulANVOlTXef2LrDRcTrmrVe8GJzTyrmXi6Cg/JhxEREREZDNOTj+ic6F4v8jBBbYZHfW1zvo1zaaZLjAqEBMOIiIiIrIZN9dHa9W5VHaFWwV3ndf/GnsYamhvYR9avg2cZA4mj4+0MeEgIiIiIpvwW2vtheISAKGnBxXY5peHh3TWD6neyXSBUaGYcBARERFRiad4oUDyjWSt+hr9a0PuqPss61ERi3TWr2w82aSxUeGYcBARERFRibc9cLPO0Y3Xf+io8/qYlEd4rkrTqq/tXBHlnL1NHyAViAkHEREREZVoj08+hDpDJaqTAGi3qXOBbT68ukpn/cJG40wZGumBCQcRERERlWh/99mtXSkBqnWtqfP6b27+qrP+89qDIZXy46+l6Z7wRkRERERUApz74qTuheIX3tF5/fIbu3Ai6YpWvRPkaOITYPoAqUhMOIiIiIioxLr6w2WtOkc/J5SpWEYop2UrMDJyIZRaqclLm0JmmCU+KhoTDiIiIiIqkXa1265zdGNA1BAAwOaY/QiLO17kfZq414Jcyo+91sLvPBERERGVOIpkBV5cTdKq93ujIoZGLYQC2Xrfa3q9gaYMjQzEhIOIiIiISpztDTeJRjeud0vC9fEZgOyRQffpUb4VnGVOpg2ODMKEg4iIiIhKlAeH7kOjUEMtUePPtU+g9jX8Hg6QYn790ajtUdn0AZJBmHAQERERUYmyZunPuLwrQ/sAB0nRbZuWqYNZDYaYJS4yDhMOIiIiIrI6tVqNcRFf45k6DfhExwWFJBtySDC37kg08KxmtvjIeEw4iIiIiMhqTsZfxtd3dhjVtoFbVXzZcLSJIyJTY8JBdkej0eD48SP4++99iI6+hufPnyEjI0N4/oMPPsSAAeLDhBQKBfbsCceJE8dw+/ZNpKQkIysrS3j+p5+2oE6duhZ7DURERLbuvXPfIU79XFxZ0DEaEvHD2bUHI4iH+NkMJhxkV9LT0/HZZ5/izJmTere5fz8G06ZNwcOHsXpdP3/+XOzdu1tU16hRIFasWGdQrP369cSTJ48BALVrB2D9+p8LvHbt2lX46afVorqKFSvh5593wsHBQe8+J00ahwsXIgEA7u7u2LfvsEExExGRiaU/hu/JQGgkciS9ehpqF9ueMnT52W3MubnRqLY1nMtjUcPxkMlkJo6KzI0JB9mVxYv/pzPZyPvLSyJ5uUItKysLM2Z8rJVsSCQSSKV5V7IVvort8uVLOHnyOF59tbVxgRvh8eNHCA//DW+9NcBifRIRkQml3oHvqSYAAIkmE84P1iI9YJ6VgzLOkus7cOS59onhIrpGNzKBafX6o1X5hmaJiyyDCQfZjcePH2Hfvj1CuW7d+pg8+SPUr/9KgaMABw78jXv3YoRyly7dMGLEaFSuXBVSqRRyuRRKpVqv/levXo5WrV6DRKLHFhsmsnHjOvTo0QtOTs4W65OIiEwg+Tp8z4SIqlSyslYKpnhW3PrdsGRDA7jeAtp/VA4d1nZFjfK1zRofmV/+zcaISq3jx49Crc5JDiQSCebNW4DAwCaFTjk6duyI8LhSJX/MmjUXVatWzze6oZ+bN2/g0KEDhgdeDImJCdi5c7tF+yQiomJKitRKNtRwQWb1KVYKqHgOJ17S78JsoNEiN/TqXQmdPqoEuVyOGj2ZbJQGTDjIbty8eV147O9fGf7+RR8EdPPmDeFx06YhRs0bzdtm7dqVUKlUBt+jOH1u2bIB6elpZu+TiIiKT5J4Cr4R7UR1arjgWcfHgI2uXSgrdy30eddncrzR1xe93qqEGsdzRnEkAPpH8iyN0oIJB9mN589f7oTh5eWtZ5skg9vk1717L+HxvXsx+PvvvUbdx9g+X7x4ga1bt5i9TyIiKh5p3H74RHYV1akl7njWOQ4wYmS9pPi8/nCd9cMqdcaOkDnoPLwcHFWOoufcapeBawU3S4RHFqD3uzc5ORmTJ09GUFAQ2rRpgy1bCv4A8+eff6J79+4ICgpC165dsWvXLpMES1QcGRnpwmN9RyqMaZPfkCHD4eb28pfmunWroVQqjbqXvnr27I2KFSsJ5W3btiA5+YVZ+yQiomK4Fwavi2+JqlRSTzzr9MhKAZlORRdvdPIJRqB7DdRwKo9NQZ8irMUX6FOlNbY33Ki1VlwCoO+RgdYIlcxE74Rj3rx5UKlUOHbsGFatWoWlS5fi9OnTWtc9fvwY06dPx8cff4zIyEjMnz8fc+bMwa1bt0waOJGhNJqCNvc2Lw+PsqJzPR4/fog//jBvEu7g4ICRI8cK5bS0NGzevMGsfRIRkXEc7v8MnMiXbMgqIKnjfStFZFoyiRQTavfG3FdG4JsmE+Dm6AIASL7/ApkJmVrX158cCJmDbU4fI9302qUqPT0d+/btw65du+Du7o4GDRqgb9++2LlzJ1q2bCm69tGjRyhTpgw6dOgAAGjWrBmqVq2KW7duoXZtLvwhy3n8+BH69++l87kLFyLRunUzrfoKFSoKZ1/k99NPq7XOugCApUtXIjhY+155vf32YOzcuV0YZdiwYS26d+8JJyenol6G0bp27Y4tWzYIu2yFhW3HwIHvwMfH12x9EhGRYRzur4PHdfFicJW8ApLa3yigRenxW7OtOkc3ms9qZY1wyIz0GuGIiYkBAFHCUK9ePdy8eVPr2saNG6N69erYv38/1Go1Tp8+jYSEBAQHBxsVoERimi8ia3Jzc8fgwcOEckJCPMLCfjVrnzKZDKNGjRfKCoUCGzcadviguZjq57okf9nL6+SXYV98X/Ar75fjne9RNl+yoXSsgucdblg9NnN/Xf1Re+cqCYAuf7xp9dhK0ldJ+p1RHHqPcOSdgw4AHh4eSEvT3vlGLpcjNDQU06dPR2ZmJqRSKb788kuUK1fO4OC8vEyzWEilUiE+PufMBGO2M80ll9vugi17JJdLResu8u8OpWtNRs+evbFu3ctRjLxttA/7y+1HJnpv5D9nQy7Pee8NHPg2tm//BYmJCQCALVvWIzT0La2fLV0kksLff1KpuE+ZLKfPLl26YMuW9bhxI2eHrvDw3zBkyDDR+g5xP9qxm5JaDUilUvj4uNvFSbE+PmWsHQKVQHxfEAAgcgZwe6GoSuJWBw69b8AexqHPzT6lPbrhIkFgj/pWiackKw2/M/RKOFxdXbWSi5SUFJ0flI4dO4ZFixZh3bp1aNy4MW7fvo3x48fD09MT7dq1Myi4pKQ0qFT6HapWGLVaDbVaDaVSbfQmD4Yc8EYlg59fBRw5ckYoT5o0DhcuRAIAmjQJxrJlP+psN3z4GOFx3mlXI0aMwejR40XX5r4v8r438q8VyX1eLnfCsGEj8d13/wOQs2vWL79swYgRY1AUjQaFvv/UanGfKtXLmEaPfheffDIVAJCdnY01a37EjBmfF9CPduymlPuzmJiYWqzkv6STSHL+gUhMTIGVlg5RCcT3BeVyip4N9/tLRXWSsk2Q2PIoNAkpVorKcvb2/l3nVKpBV0cgwQ5ev75K2u8MmUxq9GCAXv/iV69eHQBw+/ZtoS46Ohp16tTRuvbGjRsIDg5GUFAQpFIp6tSpg7Zt2+Lo0aNGBajRmOaLqCTo1SsUFSpUFMpbt25GcnKyWft87bU2eOWVRkJ53749uH//nln7LIqpfq5L8pe9vE5+GfbF9wW/nK98rJVsZLk3Bd6MsnpslvjKyshG3MknWv8ueDbyhoObo9XjK2lfJel3RnHolXC4urqia9euWLJkCVJTUxEdHY2wsDCEhoZqXRsYGIioqChcupQzN+/OnTs4cuQI6tWrV7xISZCdmo0bm6/h7KwTODv7BO6E3YJKYd5tVsk0HBwcRCMaqamp+PnnjWbvd9y4CcJjlUqFtWtXmb1PIiISc7swCm6PxKPrmR6vIuXVQ1aKyPK21luvc3Sj599v6bqcSgm95zTMmTMHANCmTRuMGTMGH3zwAVq1ytlFICgoCBEREQCAkJAQTJ06FdOmTUNQUBBGjRqFHj16oF+/fmYI3/7c2HgVv7XaiojPT+HWL9dx6+frOP3xUfz22jbc2HwNiZcTrB0iFaFbtx6oUqWqUN6xYyuePUs0a59Nm4agadMQoXzw4H7cuqW96QMREZmHW9QQuMTvENUpvNohpcU+K0VkeY9OPoQ6XXuqbtMvW0IqK73TbMmAhMPDwwNLly5FVFQUjh8/jsGDBwvPRUVFoVmzl3PdBw0ahL/++gtRUVE4fPgwPvzww1I9X9tSbmy8ioi5p6FMy9Z6LispE2dnnsDlxVFWiIwMIZPJRGtBcnaP+sns/Y4d+3KUQ6PRYM2aFWbvk4iIALeIXnBJCBfVKby6ILVZeAEtSqf9fXbrHN1oOK6xNcIhC2IWYCOU6dm48PX5Qq+RyqV4cTMJGnUxJ9qR2XXs2AW1ar1cAxUeHoa4OO05rabUsGEjvPpqG6F8/PhR/PvvFbP2SURk79zP9YBL0mFRXYZ3N6Q226G7QSl1fMohnclGnwieKG4PmHDYAGWGEuHtdiA7JavIa9NiU/H42EMLREXFIZFIMHbsu0I5KysL69evMXu/Y8e+J9r6dvXq5Wbvk4jIXnmc7gDn5+JNc9LLD0Ja021Wisg6NBoNbv+sfZChUwVnlK3qaYWIyNKYcNgAiQTwauij9/VJV5+ZMRoyldat26JBg4ZC+c8//0Bs7AOz9lmnTgDat+8klDX2MpYAACAASURBVCMiziIyMsKsfRIR2aOyJ1rBMUX8+zW94nCkB9rfph3bAzfpHN0YEDnUGuGQFTDhsAEyZzncq5TROpStIBJZMY+DJIsZO/Y94bGldo8aM2a86NA9jnIQEZlW2WNBcEj/V1SXWnki0ht+b6WIrOf53edQxGVo1dcaVhdSHqhsN/hf2kaUa1Ze72v9mhp+qjtZR0hICwQFNRXKBw78jTt3bpm1z6pVq6Nr1+5C+fLlSzh16rhZ+yQisheeRxvCQXFbVJdS/RMo6i+wUkTW9XvLbTpHN1p/3c4K0ZC1MOGwEVXeqAZnP5cir/Nq4AO/pvonJ2R9ec/IUKvVWL16pdn7HDlyLBwcHITy6tUrkP+UcSIiMozXwZqQZ94X1aXUmofMOrOMvufD9AR8cPF7zPp3HV5kpxU3RIu69MMFaGUbADpsf8PywZBVMeGwEVIHGZr/97VCp0vJnOUI+fJVC0ZFptCoUWO0avWaUD527DCuXfu3kBbFV7FiJfTo0Uco37hxHYcPHzBrn0REpZnnwRqQqcRnYSXXmIPMmlOMut/8KxsRemYO3r/8PWIVCbiWeg+jIv+HdKXCFOFaRNQXZ7TyDamzBFXaVbNKPGQ9TDhsSOWOVdF2dWeUqVkWQM6uD7lb4Hq94oOOP3eDbxM/a4ZIRtLePcr8Z2QMHz4aTk5OQnnt2lVQq7UPZCIiosJ5HagMuUp8gOvz+suRVfsjg+6TmJGM0DNzEHpmDs6n3dZ6XgMNTj+7VqxYLSW88686p1INvDzMGuGQlcmtHQAZplK7yqjUrjKenHyEhKinuLjoPNqu7Qz/9lWsHRoVQ0BAPbRt20EYZTh79rRoYbc5+Pr6IjR0AH75ZRMAICbmrtn7JCIqbbz3l4cU4kXRzxusgNJ/cAEttC2O3oEjzy/rdW0V15K/TjMrNQtJF7V3zPQO9oVTWWcrRETWxoTDRlV4tRLKt6qIV95rDImUu1KVBmPGvItjxw5DpVIBgPD/5jRkyHD8/nsY0tPTLNYnEVFp4aUr2Wi0CcoKvYts+0KRilEX/6driUOByjt6oY67v4FRWt4vddfrHN3osTfUGuFQCcApVTZMIpEw2ShFqlevgc6dLbuQrmxZTwwc+I5F+yQiKg289/tCli/ZSGq8s8hkY+3tPQg9MwcjDUw2JJBgbPU3jYjUsmL+ugtka7+yZgtf03t7fyp9OMJBVIKMGjUO//zzF5RKpcX6fPvtwdi5czuSk19YrE8iIlvmvd8bUoh/Tz8L2g217+s6r89UZmP4+f8iC4avk3OGHEsDJ8PXxcOoWC3tyNC/tUc3JMAroxrqvJ7sAxMOohKkUiV/9OjRG7t27bRYn25u7njnnaFYuXKZxfokIrJVPvu9IIF4+umzpoeh9g7WunbbvYPY9uSIUf20926C9+v0Naqttfw9aI/OUZt+l4dYPBYqWSSaErz5flJSGpTK4u+ao1ar8fTpA5QrVwVSqXGzyORyqUliodKF7wvDmOJn0RZIJICvbxkkJKSg5P6GJUvj+8L2+ewvC0m+j9QJLU4DHg2EslKlxIiIhUhHtsH3d4IMXzV4F1XLlPyF4fmpslXY7L9GK+FwreKKAeeHWiUmW1fSfmfI5VJ4ebkZ19bEsRARERGVOj77PZB/BUJCqwuAe00AwN+PzmLlgz1G3btZmTr4ru17JeaDpTF+CfhJ50Lx/hEc3SAmHEREREQF02jg809Z7WTj1X+hca2MEWcWIAWGH8YngwT/rT8WdTz8YetrqR8ei4UqTXuXw8afBnOhOAFgwkFERESkm0oFn4NeomRDAyC83m58c2WNUbds6FoN8xqNMkl4JcU/b2mv3ZAAaPJhiDXCoRKICQcRERFRfspM+BzyEyUb/Z2HIM7RD3h0wKBbSQHMCRiGRl61TBpiSXB47H6d9T2OvmXhSKgkY8JBRERElFdmMnyPVgYAnEMFfOQ+AJBIYejcp5rOFbGo0bhSu0mGWq3Gvd/vaI1uOPk6waeer6guNiMeTzOfI8C9MtzlLpYLkkoEJhxEREREuRSJ8D1WAyOd+uO2Y55TvQ1INj6p0R8typX+cye2NtigcyrVgAviXanmXduIC8m3AQBl5C5YEjgJng7ulgmSSgQmHEREREQAbj29iOm3tgNlpoif0CPZ8HfwwXeBEyCX28dHq/jLT5H9LEurvvaoupA5yoTy348jhGQDAFKUGfg77jwGVG5rkTipZLCPnwoiIiKiAnx6aTVuZMQCGg0glYmfLCLZmFS9NzqU1z70r7T7s+NvOkc3XlvYTlS38v4fWm3VGp5fZW+YcBAREZFdup78ADOu/f9uU7oOwCgg2Sgv88TSJpPgIHcwY3Ql18npR3XWdwp7U1QeEfGVzuveqtTG5DFRycaEg4iIiOzS59fW/R979x0eVZmwcfiZmfSQkEIJTXrvTUFFFEQUAQVEQEUsrLoW1FXUtXyIfdVdBStWkKoiTUWUooiIKIIgJTSlS0shvUz5/gADw5xAIJkz7Xdfl5c573vOzBM5JvNw2tEvylg2bq7VW/1qn+/lVP5v68RNHkc3wirZVOvC2iXLa9K3KcuR57FtvchqCrfx8TPU8CcOAABCkl3O05aNJGucxrW9U7ERMSYm81+ftPnI+ELxdTe6jT29dbLh9i+2ucM7weDXKBwAACAk9SzcoEURLdwHj5WNQdUu0PX1L/NBKv+VkZqm/P35HuO1r6yjiEoRJct3rn7VcPuH6w9R2MnXyCAkUDgAAEBIuqnoZy2KaH5syaI4S5Rea3+f4jmaYWjeRTMNj270/LBPyfLevEPaX5zhsW2MInVetRYe4wgNFA4AABCS4s6dr+9W9pQzPFGZF6f6Oo5f+/GhpYbjveb2dVu+5/fXDdd7v+PoCs+EwEHhAAAAIckR30rpvQ74OkZA2Dox1ePohjXGpppdjz8c8dHf3zXc9tbavRUZonf0wlFWXwcAAACA//q4rfGF4kPW3lCynF5wRKl5ezy2tcmiK2txZ69QR+EAAACAoYyt6Sr4y/NC8ZSetRRZOapkeeTa/xluP6Xjo17LhsBB4QAAAICheRd8anh047Jpxx/y99Lm6YbbDqh2gSLDIgznEFooHAAAAPCwcsxyw/HL5vaV5djtg3OK8rUi0/iC++HcVhjHUDgAAADgIfWt9Z5HN6IsqnHCheIj1rxguO177R70YjIEGgoHAAAA3MxoNcmjbEjSdZtvLvn67e2fG67TI7GtkiLjvJYNgYfCAQAAgBLpW9JVeLDAY7xO33oKjz56e9tih13fHF5luP3dTQZ6NR8CD4UDAAAAJT6/0PhC8R7vH78m47pVzxpuO6Ht/d4LhoBF4QAAAIAk6Yf7lhiOXzK5V8mF4tN3LpFDTo912sc1UtWoBK/mQ2CicAAAAEBOp1Pbp231fKJ4tFXn9G4gSXK5XPp0/1LD7Z9oMdzLCRGoKBwAAADQJy09nyguSUM3jSj5etjPzxhuO67VXV5KhWBA4QAAAAhxB1buV2Faocd43QENFBFz9OF98/YuV5HsnutEVVOd2Gpez4jAReEAAAAIcQv6zTW8UPySCb1Klifu+cZw2/+1udN7wRAUKBwAAAAh7NvbFxqO9/6qX8nX1600PpXqpea3lVxMDpQmzNcBAG/bunWzvv/+u5Lla6+9TnFxPJAIAACnw6lds//wOLoRFh+mlI41JUlLD6xVgYo9tq0VnqSG8bU8xoGTUTgQ9LZu3aIPP3y3ZLlPn34UDgAAJE1r+IHhheLXrj1+x6lxO2YZbvtKu7u9lArBhlOqAAAAQtDuJTvlyHN4jDcc2lARsUcvFL951X8Mt32i0Q0Ks9q8mg/Bg8IBAAAQgpYMXWB4oXi38ZdKkn45tFlHHHke2yVaY9U+ubH3AyJoUDgAAABCzNeDPjcc7/fj4JKvn/9jmuE6Ezo+4JVMCF4UDgAAgBBSmFuo/cv2eRzdiKweraRGSZKkW1e9ZLjtIw2HcioVzhgXjQNnyOl0atOmjdq1a4eysjLlcDiVmJikunXrqVmzFrJaK6bHu1wubdjwu3bv3qW0tMOKiYlVjRo11aFDJ0VGRpb7e0hN3ahdu3YqMzNDDodDCQmJOuecumrRopVsNn6ZAECw+rjpJOMLxX+9TpK04cgfynDkeMzHW6J1bpXmXk6HYEThQNC68MJOhuODB/cvdZvx499Whw7G22VnZ2vy5A/15ZdzdeTIEcN1EhIS1K/fAN1wwwjFxlY6bcZnn31SX331hSQpJaWGZs48eoh79uyZmjZtsv76a6/HNjExserff4BuvfV2RUdHn/Y9TpSRka5Jkz7QwoVflfo9VKpUSf37D9QNN4xQfHzlM3p9AIB/2/ZJqlxFnnWj5ag2skUc/Vj4ROokw205lQpni1OqgDJYv36dhg0boGnTPir1g7okZWZmavLkD3XddYOUmrrpjN/HbrfriSce0X//+4Jh2ZCkvLxczZgxRTfffJ0OHNhf5tdevHihrr32as2cOeOU30NOTo6mTftIw4cPUWrqxjP+HgAA/mv53Us9LxS3SJ0f7ypJum31/wy3u6NuX0Xawr2cDsGKIxwIWn+fFuRyueR0Oj3GjRg9LXXdut/0r3/drYKCgpKxiIhInXvueapbt55cLmnXrh36+eefVFRUJElKS0vTPffcrvHj31Lz5i3LnHnChDf07beLJEmVKsWpS5fzVaNGTRUWFmjLls1at+63ku9lz57dGjXqDr377qTTHon47LOP9eqrL8vlOv5rpkaNmmrTpq2qVq0um82mQ4cOatWqn3Xw4IFj38Nh3XPP7Zow4UM1aNCozN8DAMA/fXbedMPxAauGSJI2ZP6pw8WefyEVowhdltLZq9kQ3CgcCFpLl66UJM2f/7mee25syfiMGbNVo0bNMr1Gbm6OnnrqCbey0a1bdz300GNKTExSWJhVdvvRApCWdlgvvPC0VqxYLknKz8/T2LGP64MPpiomJua075WWdlgzZkyRJF111UDdfff9HqdMbd26RWPHPqYdO/6UJO3du0fjx/9Pjz8+1uP1/vbbb6s1fvz/SspGjRo1df/9D6lr1ws8CpbD4dCXX87TuHEvq7CwUPn5+XriiUc0ceJ0hYfzN1sAEKiydh5Rzp9ZHkc34hpXVnydBEnSE5snGm77QceHvBsOQY9TqgJUkbNY+/IPa19BmuxOz4f2oGLMmDFV+/f/VbJ84YUX6ZlnXlRiYpLHusnJVfT88//Vued2KRnbs2e3PvnE+LaCJysuLpbL5dLVVw/S6NGPGl6f0bhxE40b95aqVateMrZgwZfavDnV8DUdDoeee26sHI6j+0jduvX0zjuTdP75FxoezbHZbOrff4CeffalkvmdO3fo66/nl+l7AAD4p9nnzTB85saAZddKku741fhUqlH1BigijL9wQvlQOAJMZnGOJu9aqLvXvqbR69/R6N8n6N51r+vTvUuVW5wvh4vyUVGKi4s1d+6skuXY2Fg99NBjpzwlKywsTI888oRbWZg9e6bsdnuZ3rNq1Wq66677TrlOcnIVjRr1L7exOXNmGq777beLtG/f8WtBHn30SSUmJp42R5cu56tHj0tPeP3PTrsNAMA//fzEcsnpOd75xfNltVq1NWu3Dto9T6WKVoQurt7OhIQIdhSOAHKoMFP/t3GiFhz4Rbn246f4ZBbnas6+5XpwwwS9u+NLHyYMLhs2/K709LSS5V69rlBSUvJpt6tWrbp69rysZDkt7bA2blxfpvfs2/eqMt15qnv3HqpePaVk+fvvvzVcb8GC4/tDixat1LJlqzLlkKQePY5/D1u2pCo31/MWiQAA/7dpwnrPoxthUoubWkuSHt70nuF2H3Qc7eVkCBUUjgDy2vbZSivKKnX+SFGuMov4UFhR1q9f57bcrVv3Mm/bvfslp3yt0lxwQbcyrWexWNS164Uly0eOHNGePbvd1nE4HPr997Uly23bti/Ta/+tTp06JV87nU5t27btjLYHAPjejGYTDcev/X24JOnO1a8azt9+Th9FhkV4KxZCDBeNBwCXy6VP9y7Vtpx9hufd/81isWhD9k4dLjyiKpE8P6G8du3a6bbcpEnTMm/bpEkzt+WdO3ecdhur1ar69RuW+T0aN27itrxjxx+qXft4Sdi7d49yc3NLlj/+eGqZrycxkpWVedbbAgDM99dP+1SYXuhxdKPmZXUUnRyjbTl7tb84w2O7CFnVu8Z55oRESOAIRwDIcxTo+7Sy/Q250+XSr5lbvJwoNGRnZ5d8bbValZBw+msf/paUlOz2xPETX6s0sbGVzugJ4klJ7heun/weR464FwSn0ymHw3FG/5woJ4ejZwAQSL7p/7nhheK9Jl8hSXpowzuG233U6VHvBkPIoXAEgNiwaHVIaHzKoxsnyncUejlRaMjLyyv5OjIyqsz//aWjR5tOLA95ebmnWPuoM31qeFSU+/on5pWknJzTl5wzceIzPAAA/m3BoM8Nxy+d1UcWi0X3/Paa4fyNtS5VBA/4QwXjlKoAkRBeqczrJkXEezFJ6Djx2RmFhQVyuVxlLh0ul0uFhceLX0xM7Gm3yc/PP6N8BQXu65/8rI/IyCi35Ycfflz9+l19Ru8BAAg8hbmFOrBsn8fRjbDKEap1YR1tz96nvYWHPbaLkE1X1y7btYTAmeAIR4C4KLlNmT7sRtkidG5is9Ouh9OLi4sr+drpdCoz0/M819Kkp6e5Pd38xNcqTV5ebsmTysv2Huluyye/R0JCgtvy3r17yvzaAIDANaPpRI+yIUlD1x+9UHz0xgmG233QgQf8wTsoHAGiSmRlXZDc8rTr9a7eSVE27ipREc45p67b8pYtm8u87ZYt7g/iq1u33mm3cTgc+uOPst8Jatu2rW7L9eo1cFuuVau2IiKO7wu//ba6zK8NAAhMa19dLRn83VWrf7VTWGSYRv32uuF2w2perJjwKMM5oLwoHAHk1rpXqG3l0u9idFGVNrqm5kUmJgoMYWHuZw6eeOThVFq3buu2vGzZ0jK/5/fff+e23KpVmzJtt3z5sjKt53K59OOPx9etXLmy2x2qpKOnVLVs2bpkeePG9RzlAIAg99tzv3heKG6ROj1ynlKP7NSewkMe20TKpsF1LvEYByoKhSOARFjD9WDjwXqw8bVql9BQCeGVZLFI5yY20+PNrtft9fvKauGP9GQnX9uQnV36s0xO1KJFK7cH/S1c+JXbgwBLc/jwIS1a9E3JcpUqVdWiRdkeuPfll/NUUFBw2vW+//5bHTiwv2T5oouMf1H06nV5yddOp1PvvPNGmXIAAALPpx2mGI4P+GWoJOnR1A8M5yd2+rfXMgEShSPgWC1WtU9opNGNh2hcm7t0Xe2euqXu5WoeV/f0G4eolJSabsubNm0s03bh4eG66qqBJcu5ubl66aXnPG4XeyK73a4XXnha+fnH7xg1YMA1HkdZSnPw4AG9+ea4U66TkZGu8eP/5zZ21VWDDNft06efUlJqlCwvXrxQU6dOKlOWv+Xk5Cg1tWz/zQAAvpG+KU15e3I9jm4ktE5S/DmVdeca498tw1IuUSR3pYKXUTgCWJjVpj4p5ykuPOb0K4ewevXqq1Kl43f5mjTpfa1YsVyFhac/kjB06PVuH9iXLVuqxx9/WBkZ6R7rpqen6dFHR+unn34sGatdu44GDx5Wppzh4eGyWCyaNetT/fe//zE80rFt21aNGnWH29GNyy+/Us2aNTd8zbCwMD366BjZbLaSsbfeek1jxz5+2tOrNmxYr/Hj/6trrumrr7/+qkzfAwDANz7vPtPwmRv9Fw7Sxsyd2l/k+XsrUmEaXPdiM+IhxHFbXAS9sLAw9enTT598Ml3S0VOeRo++V5IUGRnp9oC+l18er7Zt25csx8ZW0v/939O6//67Sm5zu2zZd/r55xU699wuqlevvpxOl3bt2qGVK39SUdHxW+FGR8dozJhnPE7pKk1ychVdcsmlmj59smbP/lQLFy5Q164XqEaNmiosLNSWLalau3aN2zUotWrV1qhR/zrl63bo0EkPPPCIXn75+ZJtFy5coMWLv1Hjxk3VvHkLVa6cIKfTqZycHO3du1ubN2/SkSNHypQbAOBbS2752nC8+0e9ZLVa9fhm41OpPuzIXalgDgoHQsI//nGnUlM3ad2639zGT3xWhiTD06XatGmncePe0iOP/EuZmZkl2y1btrTUC8mTkpL14ouvqFmzFmeU8/bb79Jff+3Vd98tUU5OthYuXFDqurVr19G4cW8pPr7yaV+3f/8BqlGjhsaOfaLk9r5Op1ObN2/S5s2bTrt9eDiH2wHAH9mL7Nr9xQ7PoxtRVtW7vIHuWP2K4XYja1+hqLBIwzmgolE4EBKio6P12msT9N13i7V06bfaunWz0tLSVFCQX6a7VrVq1UbTps3SlCkf6osv5ikry/hv/xMSEtS379UaPvwmxcaW/WGNfwsLC9Mzz7yomTNnaPr0KW6nTh3/XmLUv/8AjRx5xxk9nbxz5y765JM5mj17pubNm33aU6qqV09R587n6dJLe6tjx85n/L0AALxveqMPjZ+58ftwrcv4QweLMz3mohWhPrW6eD8ccAyFAyHDZrOpZ8/L1LPnZWe1fXx8vO68817dccc92rhxg3bt2qEjRzLkckkJCYmqW7e+mjdv4XaK1tm65pqhGjjwWq1fv0579uxWWlqaYmJiVLNmTXXo0MnjKeJlFRMTq+uvH6Hrrx+h/fv3a9Om9crMzFR2dpZsNptiY2NVo0Yt1a1bXykpKeX+PgAA3rN56iY5Czz/0qzekEaKrBylJ1ca3yTk3Y4Pejsa4IbCAZwhq9WqVq1aq1Wr1goLs8puL9tzPc7mfdq0aac2bdp55fVTUlIoFQAQwH66/3vDC8W7j++hkb++ZLjNLbUvVwynUsFk3KUKAAAgwMzqOt1w/KqfrtVvmVuVbs/xmItSuPrW6urtaIAHCgcAAEAASfv9kLK3Z3kc3YipH6eEBol6estUw+24KxV8hcIBAAAQQL7oOcujbLgkDV4xTCN+ecFwm1H1BigyLMLr2QAjFA4AAIAAsfgm4wexXvjWxVp26HdlO/M95ipZInVxde9cDwiUBYUDAAAgABTlFWnP/F0Gz9ywqPGgpnp1x2eG273HqVTwMQoHAABAACjtmRvDNt2kG35+znCb0fUHK8LGTUnhW+yBgA899tiTeuyxJ30dAwDg59a9vlqye443uaWFFh9ZozxXocdcgjVGXau1MiEdcGoc4QAAAPBza576xfCZG+e/0E3v7p5vuM2EDg94PRdQFhQOAAAAPza9xUTD8WvW3qBhK582nHu0wTCFcyoV/ASFAwAAwE/tXbZHRYcLPY5uxLVI1Nf21So0OM8qyVpJnao2MycgUAYUDgAAAD+1aNCXhqdSXb14kKbsW2S4zZsd7vd6LuBMUDgAAAD80BdXzjIc7zHjcg1b9azh3JgmN3JXKvgdCgcAAICfyd2fq7RfDnmM2xLC9fk5v8kuh8dczYgktU1saEY84IxQOACYyOgO8gCAk81sO6Xka8sJ/x74yxAtSlttuM34dvd4PxhwFkKicFgsR/9XdbmcPk4ChDan82jh+Pv/SQCAp2WjFnv8/YxFUtuHOujG1BcNt3mp5W2yWkLiYx0CUEjsmRaLRVarTQ6HwRNzAJjG4SiW1WqjcABAKRx2h/6Ysc1zwiYt7Lvd8Dhxk+haalipltezAWcrJAqHJEVERKmwsMDXMYCQVlCQr8jIGF/HAAC/NaXe+4bjl68dpBVHNhnOPddqpDcjAeUWMoUjMjJahYX5vo4BhCyXy6XCwjxFR1M4AMDI5kkbpSLPYxh1rq6nf/75muE2b7W9T1ZryHycQ4AKmT00MjJKDodd+fm5vo4ChByXy6WcnExJFoWHR/o6DgD4pRUPLjMcX3LPbsPxc+ObqHpUojcjARUiZAqH1WpTQkIVZWWlqaiIU6sAs/xdNvLzc5WUVI3rNwDAwBvV3zAc77SkhzbmGReOR5pf781IQIUJqSfDREZGKy4uUenpBxUREano6FiFh0ceOxR56g9BTqfkdHKXK7hjvzDiktPpksNRrIKCfBUW5kmyKCmpusLCwn0dDgD8zt7le5R/0PO079iG8Xo292PDbSa0uc/bsYAKE1KFQ5JiYuIUGRmjgoJc5eZmyW63qyzPBrBarXywhAf2i9JZrTZFRsYoIaGKwsMjObIBAKVYePWXhuODfhyqGT+P9RjvkdBOVaM5lQqBI+QKhyTZbDbFxsYrNjZeLpdLLtepC4fFIiUnV1JaWo5OsypCCPtF6SwWCwUDAMpgziWfGI5f+EEPWSwWtYqrr3XZf5SMh8mqu5sOMCseUCFCsnCcqCwfjCyWoyXFarXywRIl2C8AAOWRuT1DRzZkeIyHVQ5Tw76NJUm31++ru9aNL5l7t/0DpuUDKkrIFw4AAABfmNvV+OjG0A03lXxdIzpZH3QYLbvTobiwaEXaIkxKB1QcCgcAAIDJFg2fbzje8anzZIuwuY0lhFcyIxLgNSFzW1wAAAB/kJ+Zr71fG9zqNtKiVne0Mz8Q4GUUDgAAABN90uwjw/Gh6240OQlgDgoHAACASVY+8YNkcDf1lv9oqaikKPMDASagcAAAAJjA6XAqdcIGw7kr3rnC5DSAeSgcAAAAJphS/33D8YGrhpicBDAXhQMAAMDL1r+9Vq4Cz3Opql1cU/F1E3yQCDAPhQMAAMDLfv2/nwzHr/ikn8lJAPNROAAAALxoWqMPDMf7/jDI5CSAb1A4AAAAvGT7Z1tVnFXsMR7XKE7JTar4IBFgPgoHAACAl/zwzyWG4wOWDzM5CeA7FA4AAAAv+LjdZMPxnnP6yGKxmJwG8B0KBwAAQAXbu2yPCvbleYxHVItU7fPr+CAR4DsUDgAAgAq2aNCXhuPXrhluchLA9ygcAAAAFeizf3D5TgAAIABJREFUrtMNxy98p4ds4TaT0wC+R+EAAACoIIfWH1TO9iyPcVt8mBpe3dgHiQDfo3AAAABUkPk9ZhuOD/19hMlJAP9B4QAAAKgAcy/91HD8vJcvUFh0mMlpAP9B4QAAACinzK3pylyX7jFujbaq2Y2tfJAI8B8UDgAAgHKae4Hx0Y0hGzmVCqBwAAAAlMP8/nMMx1ve10YRsREmpwH8D4UDAADgLGXtOqJDPx3wnAiXOj3a1fxAgB8qc+HIysrSvffeq/bt26tbt26aOnVqqesWFhbqmWeeUdeuXdWhQwcNHDhQOTk5FRIYAADAX8zuNMNwfMjvN5qcBPBfZb5lwlNPPSWHw6Fly5Zp165duvnmm9WwYUN16dLFY90xY8YoLy9Pn3/+uZKSkrRlyxZFRHBIEQAABI+vBsw1HG8+qpWikqJNTgP4rzIVjry8PC1YsEBz5sxRpUqV1KJFCw0YMECfffaZR+H4888/9c033+i7775TfHy8JKlZs2YVnxwAAMBHcg/k6uDy/Z4TNuncxy8wPxDgx8pUOHbs2CFJatSoUclYs2bNNHHiRI91165dq1q1aun111/X3LlzlZSUpJtuuklDhgw5q4AWy1ltVqH+zuAPWeA/2C9QGvYNGGG/CC4zW08xHB/y+/Az/jNm34CRYNovynyEIzY21m0sPj5eubm5Huvu379fW7ZsUa9evbRs2TKlpqbqlltuUd26dQ1PvzqVxMTY069kouTkOF9HgB9iv0Bp2DdghP0i8H186ceG482GN1Od5tXP+nXZN2AkGPaLMhWOmJgYj3KRnZ3tUUIkKSoqSuHh4brzzjsVFhamNm3a6PLLL9fSpUvPuHBkZOTK4XCe0TbeYLEc/cNOS8uWy+XrNPAX7BcoDfsGjLBfBIe8w3navXi354RV6vK/7jp8OPuMX5N9A0b8bb+w2axnfTCgTIWjXr16kqTt27erYcOGkqTU1FQ1btzYY92mTZueVZDS+MN/4L+5XP6VB/6B/QKlYd+AEfaLwPZJ88mG44PXDy/3nyv7BowEw35RptvixsTEqHfv3ho3bpxycnKUmpqqWbNmaeDAgR7rdu7cWbVq1dLbb78tu92ujRs36uuvv1aPHj0qPDwAAIBZvhnyheF4g6ENFVMlxuQ0QOAo83M4xowZI0nq1q2bRo4cqVGjRqlr16MPtGnfvr1WrVolSQoLC9Obb76pH3/8UZ06ddJ9992nRx55RJ07d/ZCfAAAAO/LO5ynv77d6zlhkbqNv9T8QEAAsbhc/nuQJiMjV3a7f1zDUaVKnA4f9o9z6OAf2C9QGvYNGGG/CGyTqk0wHL92w3BFVy3f0Q32DRjxt/0iLOzsr+Eo8xEOAACAULTgms8Nx+sNbljusgGEAgoHAABAKXL35+jA9/sM57q/walUQFlQOAAAAEoxs81Uw/EhW0aYnAQIXBQOAAAAA1+XcipV/aGNFZUQZXIaIHBROAAAAE6SvTdL+41OpbJKF43nVv/AmaBwAAAAnGRW++mG44PXDTc5CRD4KBwAAAAn+OqqOYbjDa5rophq3JUKOFMUDgAAgGMyt6Xr4IoDnhNWqdurl5gfCAgCFA4AAIBj5p7/qeH44PWcSgWcLQoHAACApNkXfWw43mRkC8VU4VQq4GxROAAAQMg7tOGQslIzPSdsUtfnupkfCAgiFA4AABDy5l8yy3D82g03mpwECD4UDgAAENJmnmf8NPFW97dVdFK0yWmA4EPhAAAAIWvv97uV+2eO50SERR3/3cX8QEAQonAAAICQteia+YbjQ9ePMDkJELwoHAAAICR93Oojw/EOYzorMiHS5DRA8KJwAACAkLN9ZqoKDuZ7jFtjrGp9VwcfJAKCF4UDABDybFm/KSzzJ1/HgIl+uHOp4fjQDTeZGwQIAWG+DgAAgC9V/qGTwvO3SJIyO30jeyIXCge7KQ3ekyS5ji1bjv27+8RLFR4b7pNMQDCjcAAAQlbC960UVrirZNni9DzFBsFl7Su/yJHjKCkbfwtPDle9Pg19kgkIdhQOAEBISvi2ocLsh9zGnLZ4H6WBGVwul357frVb2ciuU6ziSk7dtehmn+UCgh2FAwAQchKW1FeYI81tLKvx/+RI6OijRDDDR7XfcVv+5r39KqjmlCT9seFtvdLmToVb+WgEVDQuGgcAhJTExXU9ykZm0zdUVG+kjxLBDD+O/k4qPn7dxuJX95WUDVmkfYVp2pC1w0fpgOBGjQcAhIykRSmyuvLcxo40e0v2Otf7KBHMUJRbpK2TNpeUjX1tc5Xb4NiC5fh64VYuGAe8gcIBAAgJSYuqy+pyvyg8o9V0OWpc6aNEMMv0+h+6Xbex6ukjR7+wuK/XMr6uaZmAUELhAAAEveSFybKo2G0so/1cOapc4qNEMMvXgz93W543c5/hejfU7mFGHCAkUTgAAEEtaWGiLHK4jaV3/ErOpAt8lAhmydyRqf1L95Uc3fjpoYNSxLGFE45uRMimgbW6mx0PCBkUDgBA0EpemCCLnG5jaR2XyJXUyUeJYKa5535cUjYyahbq4IX2owsnnUr1YceHTc0FhBoKBwAgKCUvjD/5c6UOd/5BSmjjkzww16yu092Wl72VZrjek01vVHRYpBmRgJBF4QAABB3DsnHeSim+uU/ywFx7l+5W9vaskqMbX0zZd/yoxgk7RuvY+mqTwNPFAW+jcAAAgofLpeRFlT3LxvkbpNg6PokE8y0aPL+kbKy9OV3Ovx8gf8KOYZX0ZMsRJicDQhOFAwAQHBwOJS9J9CwbF26Xoqv6JBLMN63JByVf58cUa+eAAsP1JrR9UBbLyXsLAG+gcAAAAl9xgZK/q+ZWNlyS0i7aKUUm+ioVTLbujbUqziwuObqxcNqh45Mn7Bx31Omr5Kg4U7MBoczq6wAAAJRLUbaqGJWNbrsoGyHE6XRqzdifSsrGgvf3Hf+Uc8LOkRKWoMtqdjY7HhDSOMIBAAhchZmq8v05bkMuWZTWfZ8UEeujUPCFybXeLfl6S98jKirlLLrX299rUiIAf+MIBwAgMOXvNygbVqVdcpCyEWKWjPxachw9slVkK1LqbbnHJ084uvFWm1GyWvnoA5iN/+sAAIEnZ7uq/NDEbaikbPBMhZCSezBXu+ftOH4q1czDxydPKBs31bpM1aOTTc0G4CgKBwAgsORsV5UV7d2GnIpUWo80KSzCR6HgKzNbTTl+kfj4fZLt2MIJZaOyNVr9a19gdjQAx1A4AACBI+NXw7KR3vOAZLOVshGC1ewLZpR8vfv8HOXXM17vvY6jzQkEwBCFAwAQECxpK1Rl1SVuY05FHS0bnJcfcvb9uFdZW4/IJckuu9Y8knV88oSjG883v1U2K2UU8CV+QgMA/J7t4BIlr+7tNuawxCm910HKRohaePUXJadSzZ998PjECWWjd5UOahrvfmMBAObjpzQAwK/Z/pqjxLVXu405rAnKuHSvjxLB16Y2eL/k66XPHzh+3cYJohWu2xteZWIqAKWhcAAA/Fb4nulKXH+j25jDlqyMnrt8lAi+tualn2XPscsl6a/2OTrS0nF88oSjGx92etj0bACM8eA/AIBXPbNxilZnbz3lOpUUqa6JLXTDOZcpLipGkhS2e4oqp97ptp49LEWZl2zxWlb4N3uhXeteWlNyKtUvY42v23ixxe2KsIWbmg1A6SgcAACvOVKce9qyIUk5KtTCjDVamLHm+KDLJcXdd/TfLpdsLrsaxzXU9Rl/qmVifS+mhr+aWuf9krIx77N9hutcnNhGjeJqmhcKwGlROAAAXpPvKDy7DV2u419bLJLFIoclUqn5e/TElomn3LSqLU69qnTSoLrdZbFYTrkuAsf8q+aWfL30uQPSiQcwjv0xR8imUU0GmRsMwGlROAAAXpMSlSSbLHLIdfqVJUkuGa56BsXhkCNb0w58q2kHvi11nWhFqF18fQ2v11spPH3a7x3ecFCHVuyXS9KBljk60sr4uo2JHR8xPRuA06NwAAC8qkdyey1MW12GNctfNsoqX0VakbVZK9Ztdhu/o25fXZbSucLfD+Xz5SWzS3aNlc8bX7cxtulNiuJJ84BfonAAALzqn42u0j8bHb09aXZenuYeWK7vD63VYVf2CWuZVzZO5e2dX6hLcgvFh8ea+r4o3fQWE0u+njfL+LqNLpWbqXUC1/UA/orCAQAwTVxMjG6o30s31O9VMha7ZriiDx8/P98paXF8b30Sdam2FeyTw+B1vOlgYSaFw0+sfXW1ig4XyiVp2bMH3D+1HOui4QrTQ82G+SIegDKicAAAfCZ21TWKzvjGbawoqbfad/xU7U+z7a6sA/p834/66chG5aqoQvJYJNWOrlohr4Xysdvt+u25X44+b6NNrjJal3LdRoeHTM8G4MxQOAAAPlFpZW9FZa1wG8tP6qvcjtPKtP058dV1V/wA3aUBpa6Tn5+vRQd/1YJDv+ovR/ppX/O2un0VZeM6AH8wtebxW+D+8swRw3XGNh2h6PBI80IBOCsUDgCA6eJ/ulQR2T+7jeWl3KC81m9W6PtER0erX90L1a/uhadc73BBlmwWixIj4yr0/XF25vefU/K1x3Ubx45udI5votYJDUxMBeBsUTgAAKaKX3G+InLWu43l1rhF+a1e9VEiqUpUvM/eG+4OrD6gQz8dkEvSt//db3jdhk1W/bv59b6IB+AsUDgAAKapvKyDwgu2uY3l1v6n8pv/x0eJ4G8WXD5HLkl7O+Qou7Hz+MQJ121M5nkbQEChcAAATJHwXQuFFe9xG8upO1oFTZ7wUSL4m8kN35ckOeXUr09mGa4zpulwRYVx3QYQSCgcAACvS/iumcKK3c/Fz24wVoUN7/dRIvibNS//Ime2XS5JX8ze7z557OhGl8rN1TahkenZAJQPhQMA4FWJ3zaSzX7QbSyr0Qsqqn+njxLB3xTmFGrdi6vlkrTotb8k2wmTx8pGmKx6qNlQX8QDUE4UDgCA1yR+W182e5rbWGaz12SvM8JHieCPZjSYKJeknRdlK6+u0SPnpUlctwEELKuvAwAAgpPFnkXZwGl9dsF0SVKxrVhrH8x2nzx2dOOF5rcqmus2gIDFEQ4AgFe4rDFyWivL6jz60LaMVpPlqHGVj1PBn+xa8KdytmbJJemrzw65Tx4rG5cktVOT+HNMzwag4nCEAwDgHdYwpffcrfzq1yr93B8oG/Dw7Y3fyCVpwXv73D+RHCsbUQrXPY1Lf5I8gMDAEQ4AgFfltnnP1xHghybVmCCXpI2DMlVUzXidiZ25bgMIBhzhAAAAplo4fL7kkPJiirVtRJ775LGjGy+1uE0RVv5eFAgGFA4AAGCaI9vSte/r3UdvgTvd+LqNISnd1TCulunZAHgHhQMAAJhmzvmfyiXpy6n7SgrGiSpbozWkbg/TcwHwHgoHAAAwxeQG78ol6de7DssRd9LksfLxbsfRZscC4GUUDgAA4HWrnlspZ45TmdULtbd3kfvksbLxVpv7FGa1eW4MIKBROAAAgFflZeRpw6u/ySXp+3fcHwb5d9m4pc7lqh6daHo2AN5H4QAAAF71adPJckma96nxdRs1whPVt2ZX03MBMAeFAwAAeM3H7SdLkn4Ye0CKPGnyWPl4rd0oc0MBMBWFAwAAeMX6d9eqYG+e9rbLUXp7h/vksbLxYfuHZLXycQQIZvwfDgAAKlxxYbF+fewnFcuuVU9luU8eKxv31R+oyhGx5ocDYCoKBwAAqHDT6nwgl6T5sw8azreIraOLqrU1NxQAn6BwAACACvXZ+dMkSV+/s086+S63FilMVj3TaqT5wQD4BIUDAABUmD/mblPOtmytH5ahwpSTJo+dSjWxw8Om5wLgOxQOAABQIRwOh5b9Y7FyEou0fVi+++SxsvFss5sVEx5lfjgAPkPhAAAAFWJKjffkkrR44mHD+SuqdFbzyvVMzQTA9ygcAACg3OZ0/1iSNG+GwcP9LFJla4z+0bCv+cEA+ByFAwAAlMv2eVt1ZFOmvn/ygBRz0uSx8vFep9Gm5wLgHygcAACgXH4YuUR7OuYoo4Pxw/1eb3OPbBY+cgChiv/7AQDAWZuUMkHFsuvXMVmG8yPr9FHN6CompwLgTygcAADgrMzt9anklObPMXi4n0VqGXOO+tQ8z/xgAPwKhQMAAJyxP+dtU+badM3/cJ/np4ljD/d7qtUtPskGwL9QOAAAwBlxOp36fuRirb41XcXJJ00eu27jww4Py2I5+XZVAEIRhQMAAJyRyTXeVXrNAu2+qsBw/uWWdyiWh/sBOIbCAQAAymzWRdMll7Ts7XTPSYvUp8q5alCphvnBAPgtCgcAACiTLZ9sVnZqlubO2uc5aZGSbHEa2fBK84MB8GsUDgAAcFp2u10r7v5O37y+Two7afLYpRrvdPiX6bkA+D8KBwAAOK2pNd/Xpv4Zyj/HeH5iu9GyWvlYAcATPxkAAMApfdpxinISCrVlZL7npEX6d6Nhio+sZH4wAAHh5IOiAAAAJX5/fY3ydudq8dw0z0mL1LVyC3VObmZ+MAABgyMcAADAUN6RPK1+6mfNnbmv5DqNEhYpxhKh0c2G+CQbgMBB4QAAAIY+bTxZS176S4ownp/Y6RFzAwEISBQOAADgYXqzD7WlT6aym7o8Jy3SW21HKcxqMz8YgIBD4QAAAG5+uHeJsgpytemOPM9JizSq/gBVj0o2PxiAgMRF4wAAoETmHxnaPn2rvp57yHPSIrWJraeLq7UzPxiAgMURDgAAUGJul0+MLxKXFKEwPdnqZvNDAQhoFA4AACBJmlRrgr59cb/xReIWaWKHh0zPBCDwUTgAAIC+GjhPW3oeUVYzp+ekRRrf+h5FhUeaHwxAwOMaDgAAQtzuxTu1c81ObZqe6zlpkf5Zp69qx1QxPxiAoEDhAAAghNntdi0ZtkDfzD1sON88prZ61exscioAwYRTqgAACGFTa75f6kXiUZYwPdv6H+aHAhBUKBwAAISoj9t/pG9e21fqReIf8iRxABWAwgEAQAj66fEftKrLPuXXNZi0SONb3qVIW7jpuQAEHwoHAAAhJmvnEf0891dtH5FvOP/Pev1Uu1I1k1MBCFZcNA4AQIiZ3XmGvpuXbjjXsXJj9areyeREAIIZRzgAAAghk2pN0NzZ+wznoi0Reqz5DSYnAhDsKBwAAISILy//TPPf2ifZDCYt0qTOXCQOoOJROAAACAGbP9mkBRemqtjo0gyL9F670QqzGjURACgfCgcAAEHOXmDXnDe+1t5LiwznH240TEmRlUxOBSBUcNE4AABBblLdCVo5N8NwrntSa52X3MzkRABCCUc4AAAIYpPrv6cv5xw0nKsSnqB7m1xjciIAoYbCAQBAkFp4/XzN/mC3ZDGYtEhvtRtleiYAoYfCAQBAENqzdLem9v5ZijaYtEgT24+WzcZF4gC8j8IBAECQcTgcemPSNGU1cRnOP9d8pOIjuEgcgDm4aBwAgCDzZus3tPmDPMO5a1K6qVl8HZMTAQhlFA4AAILItEYf6NspaYZzDaJTdF29S01OBCDUcUoVAABB4tvbvtHMj3YazkVYbHq57T9NTgQAFA4AAILC3mW79Oag5ca/2V3SR53+bXomAJAoHAAABLzi4mKNWTtRjsrG82+2v08RtnBzQwHAMWUuHFlZWbr33nvVvn17devWTVOnTj3tNrNmzVLTpk01ffr0coUEAACle3rEK0rv5DCce6jhEKVEJZqcCACOK/NF40899ZQcDoeWLVumXbt26eabb1bDhg3VpUsXw/UzMjL0zjvvqEmTJhUWFgAAuJvQ8U2tfyPXcK5n1fbqUrWFyYkAwF2ZjnDk5eVpwYIFuu+++1SpUiW1aNFCAwYM0GeffVbqNv/5z3906623KiEhocLCAgCA474Z9oW+fuOA4Vz1sMq6q+HVJicCAE9lOsKxY8cOSVKjRo1Kxpo1a6aJEycarr9y5Urt2LFDzz//vObNm1eugBZLuTavEH9n8Ics8B/sFygN+waMVPR+8ecXf+jtu38xnLNZpLc63c8+GCD4mQEjwbRflKlw5OXlKTY21m0sPj5eubmeh3CLior01FNP6aWXXpKlnP+FEhNjT7+SiZKT43wdAX6I/QKlYd+AkYrYL4ryivRQ2CTJZjDpkr7s/YxiI2LK/T4wFz8zYCQY9osyFY6YmBiPcpGdne1RQiTpnXfeUdeuXdWiRfnPGc3IyJXD4Sz365SXxXL0DzstLVsul6/TwF+wX6A07BswUpH7xa3jn5K9s/Hcm+3vVX6WQ/nKLt+bwDT8zIARf9svbDbrWR8MKFPhqFevniRp+/btatiwoSQpNTVVjRs39lh35cqV2rRpkz7//HNJUk5OjtavX681a9boxRdfPOOA/vAf+G8ul3/lgX9gv0Bp2DdgpLz7xaO3vqD0fxjfkerfjYYpJSqJ/S5A8TMDRoJhvyjzEY7evXtr3Lhxeu6557Rnzx7NmjVLr776qse648aNU1FRUcnyvffeq549e2rw4MEVlxoAgBD00YDJSn0433Du4rg26lylmcmJAOD0yvwcjjFjxkiSunXrppEjR2rUqFHq2rWrJKl9+/ZatWqVJCkpKUkpKSkl/0RERCguLk6JidwDHACAs7X29dWa8/A2w7mqlkoa1XKQyYkAoGwsLpf/HqTJyMiV3e4f13BUqRKnw4f94xw6+Af2C5SGfQNGyrNfZP6RoVv2v2r414RWu/TpBU+W+0Yt8B1+ZsCIv+0XYWFnfw1HmY9wAAAA37hlh3HZkEua2uUxygYAv0bhAADAj42YPFYq5Q63b7a7V5FhEeYGAoAzROEAAMBPjX78P8pubHxq8YP1r1FKdJLJiQDgzFE4AADwQx8+NEXb++YZzl0e1l7nV29tciIAODsUDgAA/Mz6eev0+cCthnM1Cyrrtk5Xm5wIAM4ehQMAAD+Sn5mv/6v6meFceIFVr1/8L5MTAUD5UDgAAPAj1294QTK66ZRDmtLtMdPzAEB5UTgAAPATg78eI9kMJlzSex0fULgtzPRMAFBeFA4AAPzAyEnPyFHZeO6pc0YoKSre3EAAUEEoHAAA+NiTr7+p9KbFhnPXWi9Uq1oNTE4EABWHwgEAgA8tnP+D1nU6YDjXOqOmhp7by+REAFCxKBwAAPjIwb8O6a2khYZzldMjNPaK201OBAAVj8IBAICP3LHjdcNxS570wRWPmpwGALyDwgEAgA8MXD7G+Pa3TmnKhf+WxWI0CQCBh8IBAIDJrllU+u1v32h8l6IjokzPBADeQuEAAMBEN855Ws5KxnP3WfupRtVq5gYCAC+jcAAAYJL7Phqn7Op2w7lrDp+ri87rZHIiAPA+CgcAACaYv3a5fk3caTjXfGNVXdf3SpMTAYA5KBwAAHjZ7uwDejfvG8O5pG3hevaWu01OBADmoXAAAOBFDodD925403DOmiO9cx23vwUQ3CgcAAB40eCfnzKeKJY+6vKwrFZ+FQMIbvyUAwDASwb+UMqzNlzSayn/VEylGNMzAYDZKBwAAHjBtd+NkcKM5x4rGqRajVPMDQQAPkLhAACggt3+7Uuyl/LsvmHrO6lj9zbmBgIAH6JwAABQgf6zaooORecYzp33bU1d+49+JicCAN+icAAAUEG+2vuLVtq3Gs7V/DFSL//vQZMTAYDvUTgAAKgAf2Tt0bu7vzCci/lTev3+f5ucCAD8A4UDAIByyi0q0IMb3zWcs2ZJ7/d/VBar0e2qACD4UTgAACin4b8+bzxhl95pOEqRsZHmBgIAP0LhAACgHAb+WMqzNpzSC4XXKalhsumZAMCfUDgAADhLA5ePKfU36Z1rLlKTnk3NDQQAfojCAQDAWbh++dOSzXju6rnNdeldPc0NBAB+qpRnoAIAgNLc/fOryrfZDefO+6CqbnxnqMmJAMB/cYQDAIAz8ELqVO1zZhjONf40RqPfvtPkRADg3ygcAACU0YzdS/Rz5hbDuaorbHru+QdltfKrFQBOxE9FAADKYHX6Zn2yd6nhXOwf0is3PChbRCkXdQBACKNwAABwGn/lHtYzW6YZztmOSK+0vFsxVWNMTgUAgYHCAQDAKRTbi3XX76+VMik95xiuKm2rmhsKAAIIhQMAgFMYsuoZ4wmn9FhqfzXu08jcQAAQYCgcAACUYuCKMcYTLunGSe3U8R8dzQ0EAAGI53AAAGBg4IoxksV4rvcrdXT1JwPMDQQAAYrCAQDASYaufKbUsnHuS0m6/bOR5gYCgADGKVUAAJzg5l/+oyJXseFc23Hxeujje0xOBACBjcIBAMAx9695XUcceYZz9WdE6d/v3yNrGL86AeBM8FMTAABJL2+ZoZ2Fhwznqv5o05MP3KWImAiTUwFA4KNwAABC3kd/fqMf0zcZzsWvt+ipbv9QXJ14k1MBQHCgcAAAQtrKwxs058Byw7nwg9LY2iNUvXMNk1MBQPCgcAAAQtp/tnxiPJEjPbqnv+peXt/cQAAQZCgcAICQtfC6+ca3vy2U7lvQTW3v5MF+AFBeFA4AQEhaOXa59i3arciTrxN3SDdPaKeLXr7UJ7kAINhQOAB4X94eJSzvpJjNj/o6CSBJSp28QalvrJcktZh07GJwlyS7dPWj9dVvGk8RB4CKwpPGAXhX1mZVWdlZkhS2a4vy6z8gV0Syj0MhlB1Y+ZdWPvBDyfI5yyopZXW07FEuxdojNXzLCB+mA4DgQ+EA4D0Za1RlVXf3MYfxE5wBM+QezNWCfvM8xiNybYookq7fcbMsFqOLOgAAZ4tTqgB4hSXtJ4+y4bRWkiuquo8SIdQVFxZrZqsppc5ft/UW2cJtJiYCgNBA4QBQ4awHFyt59WVuYw5LnNJ77pP422P4yLQ6H5Q6d836GxQeE25iGgAIHRQOABUqbP98Ja11v+DWYUlQxqV7fZQIkCZVm1Dq3FU/XqvYarEmpgGA0ELhAFBhwncutC9FAAAgAElEQVRNVcLvQ93GHLZkZVy6y0eJgFOXjT4LByihUaKJaQAg9FA4AFSI8F0fqfLmf7qN2cNqKKPHnz5KBEiTapReNi6a2EtV21YzMQ0AhCYKB4Byi/hjnCpvvtttzB55jjIv2eyjRID0UZ13JIfxXJdxF6l+nwbmBgKAEEXhAFAuEdv/p/jtT7iNFUfVU+ZF632UCJCmNf1QrkKX4Vzbxzqq6bDmJicCgNDFczgAnLXIzU8qbtf/3MaKo5rpSLeffZQIkD7pNEXFGUWGc42GN1W7ezuZnAgAQhuFA8BZidkwSjH7JrqNFcW0UtYFP/omECBpbo9Plb8r13Cu9pXn6IL/XmxuIAAAhQPAmYtee7tiDk53GyuK76Ss85b4KBEgLRz6hTLXpxvOJbRJUs8PrzA5EQBAonAAOEMxa25QzOF5bmMFiZcqp9MsHyUCpGX3Lta+JcbPeompFaurFg02OREA4G8UDgBlFrtqkKIzFrqNFVS+iLIBn/rlqRX6Y/o2w7nwyhG6ZvX1JicCAJyIu1QBKJO4n6/wKBv51a5Rzrlf+CgRIK17Y7U2vr7OcM4abdWwLTfJYrGYnAoAcCKOcAA4rfifeioi+xe3sbzqQ5XX5h0fJQKkP+Zs0ZqxvxhPWqXrtt9C2QAAP0DhAHBK8cvPV0Se+zM1cmrcooJWr/ooESDt+W6nlt32rfGkRbpu5y2yhdnMDQUAMEThAFCqyj90UHi++7nxuXVHqaDJMz5KBEgH1uzX4msXlDo/ZPMIhUeGm5gIAHAqFA4Ahiovba3wop1uYzl1R6ugyROlbAF4X8b2dC3oPbfU+SGbRygqIcrERACA06FwAPCQ+F0j2YoPuo1l1fs/FTV+0EeJACn3YK7mdf201PmBvw1TVCJlAwD8DYUDgJuEbxvKZj/kNpbd6BkV1R/lo0SAlJ+Vr5mtppQ6f9XyaxVXM97ERACAsqJwACiRuKimbK4ct7EjzV5XcZ0bfZQIkIoLi/VJo49Kne+7ZKASGieamAgAcCYoHAAkSYkLa8qmk8pG8zdVXPsGHyUCJLvdrml1Pih1/oqvBii5VVUTEwEAzhSFA4CSFlaXVfluY5ktJ8lec4CPEgGS0+nU1Jrvlzrfa2YfVetYzcREAICzQeEAQlzSwiqyqshtLKPNdDmqX+mjRMBRk1PeLXWu+6ReqnlRHRPTAADOFoUDCGFJCxNllcNtLKPdbDmq9vRRIuCoSdUmlDp3wduXqN4VDUxMAwAoDwoHEKKSFybIIqfbWFqnpXIltvdRIuCoU5WNLq90U6OBTUxMAwAoLwoHEIKSF1aWRS63scOdl0sJrSv8vQ7mZeqpLR8p31moa2terN4pnSv8PRA8TlU2zh/fXY2HNjMxDQCgIlA4gBCTvDBelpPGDp/3qxTfuEJe/4s9P+qDvV8bzk3Y+YX2FhzWLfWuqJD3QnA5Vdno/Mz5lA0ACFAUDiBUuFxKXlTZs2x0/U2qdHbnw9sdDj2x/l1tLvirzNssPPQrhQMeTlU2Oj51nlrcVvFH3wAA5qBwAKHA4VDykkS3suGSlHZhqhRds8wv83v6H3p+61QVyH7WUaJtkWe9LYLTqcpG20c6qdUd7UxMAwCoaBQOINg5ipS8pIpn2ej2pxSVfMpN39oyRwsz1lRonJda3lGhr4fAdqqy0fLuNmr3r44mpgEAeAOFAwhmxbmq8l0Nt6GjRzY8y0ZaQZYe/f1dHXJmeS1Oi0rnKCmiktdeH4HllEc2Hu6gdg9wgwEACAYUDiBYFWaoyvd13YZcktK675MiKmnBXyv17q75J92rqmIlWmL1aNNhaliZB7TB3anKRqsH21M2ACCIUDiAYJR3QFWWH7/rlF3SfRH9tS6qobTmJa+9bcdKjfRQk6EKDw/32nsg8J2qbLS4p406PnSuiWkAAN5G4QCCTd4+7Vp+kW6IHqk8W6xkOXb1huXk+1OVT4Ssuv2cq3RJDS7oRdmd8sjGA+3V8WHKBgAEGwoHEARe3zpbS9J/O7rgcklx17mvUAFlo3Z4FY1tfpMSo+PK/VoIPcVOu6bWeE8WjxszH9XqvnaUDQAIUhQOIIDd8utLyrTnHB9wGVyRcZZlo1/yebq5UZ+zTAYcVeyw6/pVz8ruckpzpA7/raw638e6rdPy3rbq+Oh5PkoIAPA2CgcQoD7/a0WFlY3Klmg90vg6NU08p4LSAVJuUb6Gr3lBJXcmsEhr7jviVjhaP9BOHR6mbABAMKNwAAFqV96B4wtnWDbaxNbXY02v5+JueE1GQbZuXfuyTr4NmuuE3zpt/91J7e7nORsAEOwoHECAurrmhVp8eM1py0aErLqtzlXqUZOLu2GOg7mZumP9Kx5lQ5Ji99gkSe0f76w2ozqYnAwA4AsUDiBA1YquokoWm3Jc9uODLodqR6ZobIublBjFxd0w387sA7p/45uGZUOSuv+rqjqN7aqW/2xjbjAAgM9QOIAA9lHnJ1Rp9WBFpX8je3gNZV682deREMI2Hdmlx1LfL7VstPtPnM4d3YWyAQAhhsIBBDKLRTkdZyq34C+5omr4Og1C2Or0VD2zdXqpZaP9c5U16OrL1OKWVuYGAwD4HIUDCAKUDfjSov2r9eaOuaXOd3w6QYOu661m17cwMRUAwF9QOAAAZ23unh80ac/CUuc7/1+CBo+8Qo2ubWZiKgCAP6FwAADOyvt/fKkvD/5c6vyF9ybpqkevVMOrGpmYCgDgbygcAIAz9srmT7QsY0Op893vTtbgcQNV84LaJqYCAPgjCgcA4Iw8/vt72pi723jSJV1yW7IGv3eNUs6raW4wAIBfonAAAMrsvt9e166CQ8aTTqnnP6pq2GdDldSsirnBAAB+i8IBACiTW395SRmOHONJp3TZ8Goa+tUwJTRJMjcYAMCvUTgAAKd1w8rnlOcqNJ60S1dcV03Dfh6hSimVzA0GAPB7FA4AwCkNXvmkHK5SnuhXJPUZVk03/H6LopKizQ0GAAgIFA4AQKkGrhxT6tPDlSddeUM13bB5pCLjIk3NBQAIHBQOAIChU5UNS7Z05U0pGv7HSIVHhZsbDAAQUCgcAAAPpyobEQekK++to+t23SybzWZuMABAwKFwAABKFBYXadjqZ0stG7HbpT7P1dfQP0fIYrGYGw4AEJAoHAAASdL+/Azdue7VUstG0hqbrpzaWAM2DDM3GAAgoFE4AABam7lNYzdPLrVspCyNUL8VrXTFD1eZGwwAEPAoHAAQ4ub/9ZPe2/lVqfP1ZkarX0YHXTLnMhNTAQCCBYUDAELY61tmaUn62lLnW74Rq34NLtC5L19gYioAQDChcABAiPr37+9qc+6eUufbvxCnQf17q8UtrU1MBQAINhQOAAhBt616WYft2aXOd304UYMf6q96VzYwMRUAIBhROAAgxAxZOVbFLqfxpEu66K4kDfv/9u49TuZC/+P4e3b2frWsO9li2SSsEipHlEubxCYnhdxSnHQ5v3Lqp1KiDp1O0Tm/U1KoOElupSg6xXaxpCRprdsmZFnWrt1l187M7w+RPXZmZ9Z8vzM7+3o+HvvIfucz4x2fZufdzHzntUGqf0VDc4MBAAIShQMAahBXH+gnu9T7znoatGaw4pvXNjUXACBwUTgAoIZwWTZKpdTB9TR022iFxYWZmgsAENgoHAAQ4E6UlurO75x/erilULppZH0Nyx6j4BB+LAAAvIufLAAQwHYXHNDDP73qtGyE/Sr1m3iJBu0ZIqvVam44AECNQOEAgAC16tcNmvXzh04vr70pSH3fu1T9tw0yMRUAoKahcABAAPr79kX6Im+r08vrrw3RoD2d1P2zniamAgDUREHuDhYUFOiBBx5QSkqKunbtqvnz51c4t3nzZo0aNUqdOnVSp06dNGbMGGVnZ3srLwCgEmO/fcll2Uh+I0rD8rup+yuUDQCA8dwuHJMnT5bNZlN6erpeffVVzZw5U+vXrz9vLj8/X7feeqvWrFmj9PR0JSUlaezYsV4NDQCo2O0Zk5VTmuf08g5TYzSqd391ebariakAADWZWy+pKi4u1qpVq7Rs2TJFR0erdevWGjBggBYvXqzOnTuXm+3WrVu570eOHKnZs2crLy9P8fHx3ksOACjH5WlvHdK1f66tIf+8XfU61Dc1FwCgZnOrcJx5SVSLFi3OHktOTtbcuXMrve6GDRtUt27dKpcNi6VKV/OqMxn8IQv8B3sBZ8zeDZvNpoEbJzsvGzbphpF1NfSTIYpNrGVOKJyH+ww4w26gIoG0F24/wxEVFVXuWGxsrIqKilxeb9++fZoyZYomTpxYpXDx8VGVD5moTp0YX0eAH2Iv4IwZu5Gd/6uGrn/eedk4Id0yspHuz71foeGhhudB5bjPgDPsBioSCHvhVuGIjIw8r1wcP378vBJyroMHD2r48OG6++67lZqaWqVweXlFstnsVbquN1ksp/+yjxw5LoezH+qocdgLOGPWbnx0YL1e+3ml08uDD0m3PtFcg3YPUUFhiVRYYlwYVIr7DDjDbqAi/rYXVmtQlZ8McKtwJCYmSpJ27dql5s2bS5IyMzOVlJRU4XxOTo6GDRumQYMGafjw4VUKdoY//AGf4XD4Vx74B/YCzhi5G9N+WqCM/O1OL6+1OUgDP2qv1O9vOZsF/oH7DDjDbqAigbAXbp2lKjIyUr1799aMGTNUWFiozMxMLVmyRGlpaefN5uTkaOjQoerXr5/GjBnj9cAAUNON3jjNZdlo+lGYxmRfr9T3bzExFQAAFXP7tLiTJk2SJHXt2lWjR4/W/fffry5dukiSUlJS9M0330iSFi1apJ9//lmvv/66UlJSzn4dOHDAgPgAULOkZUzSUVux08vbzIzWuFb91fmv15qYCgAA5ywOh/8+SZOXV6SyMv94D0dCQoxyc/3jNXTwD+wFnDFqNyo77e01j8Zr2Mt3qG7bet77TeE13GfAGXYDFfG3vQgONvg9HAAA39lfeFjjt/7D+UCZdP2YBI1YN0qRCZHmBQMAwA0UDgDwY+/v/1Jzf/nE+UChNODBprrjhxGyWq3mBQMAwE0UDgDwU49tmaXtxfudXh6ZLd3+Vnv13TrAvFAAAHiIwgEAfuiOjCk66Tjl9PL660I0oqi7rvrwGhNTAQDgOQoHAPgZl28Ol9T6lWiN6D9Azfu3MC8UAABVROEAAD9RUFqk4d9Odz7gkK55OF4jXx+i+OQE84IBAHABKBwA4AdW7V+vWb+sdD5QJvW5t4FGbrpbwWHcdQMAqg9+agGAjz2+dba2Ff7i9PLgY9Kg51pp4NY7TEwFAIB3UDgAwIf+mDFZpxw2p5fHf2/VqF3ddPXabiamAgDAeygcAOAjlb05vMXbURrbZ6AuvucS80IBAOBlFA4AMNmegv36n22zXM50fjRe984bodhmcSalAgDAGBQOADDRa7tWaOXhjc4HyqQbxzfUqI1jFBQcZF4wAAAMQuEAAJOM2DBN+fZip5eHHJGGvZ6im77rb2IqAACMReEAABNU9n6NOt9YdZ+9r9ot6WBeKAAATEDhAAAD7S/K1fgfXnY5c+kr0Xrwz3epbtt6JqUCAMA8FA4AMMjru1doRY6L92s4pD88Ulvj1oxVaHioecEAADARhQMADHDzysd1rMz5+zVULA39+2Ua8MUg80IBAOADFA4A8LIBX02SLM4vj94hPbC/r65Y0dG8UAAA+AiFAwC8ZPuxbD2WOcdl2bhkfoQevWeUEobWNS8YAAA+ROEAAC+YlrlAGce2Ox9wSNf+bx3dv2qcgsO46wUA1Bz81AOACzQo42mVOezOB0qkEa920M2f3WJeKAAA/ASFAwCqqLS0VLdvmuryJVRRuy16Mvh2JS1INi8YAAB+hMIBAFWw4pev9Mb+j12WjaQ3IzTpqfsVWS/SvGAAAPgZCgcAeOjujOd1xFHofMAu9Z7WWGOWjZbFEmReMAAA/BCFAwA8kPbVJMlFh7DkS3/+sof6f9VXubnH5XCYlw0AAH9E4QAAN3yTu13P7lzgsmzUXR+iqT3vUd1nOOUtAABnUDgAoBLjM2Zov+Ooy5mO/6ytCXPvk9VqNSkVAADVA4UDAFyo7CVUKpFGL7tKqW/dZFomAACqEwoHAFTguyNZembHfJdlI2q3Rc83H6MGLzYyLxgAANUMhQMA/st96S/qQMgxlzOXvhOrp6c/oOBQ7kYBAHCFn5QAcI60LydJIS4GyqQhH1yhtJf6mZYJAIDqjMIBAJK+OPiD/p79nuTiPd/h+6Tpje9Wk2lNzAsGAEA1R+EAUOMN+3SKCqNOuZxptTxGU6Y8xFmoAADwEIUDQI1VWlqq27+ZKkW5GLJJd31ylW55jrNQAQBQFRQOADXS/2Us0RrH9y7PQhX+izTzsj8p4el65gUDACDAUDgA1Dhpn02SIlzPXLYqXs889aA5gQAACGAUDgA1xk+H9mji7rmuy0aZ9Eh2qro81cmsWAAABDQKB4AaYcyyZ5XboMTlTMwui2b1e0xh14aZlAoAgMBH4QAQ0Ox2uwZ+/bTUwMWQQ+ryn6Z6ZOJo03IBAFBTUDgABKwX3ntLXzbZ6fKzNVQsvVxrtBpPbGpaLgAAahIKB4CAlPb5JKmSz+dr8k2EZvzpL7JYLOaEAgCgBqJwAAgo769Yo7kJ6VK4iyG7dN/hXupx3zWm5QIAoKaicAAIGLd9NEm2BNcz4QcteqPnowqPctVIAACAt1A4AFR7Gz7/Vn8NWy7VdjHkkHpkJum+EUNMywUAACgcAKq5OxdO0olmlQwVS69f/pDiu9QyJRMAAPgdhQNAtfTdp1v0TORiqZKy0SorQc8NG29OKAAAcB4KB4BqZ/jsp1TQxuF66JT0XMPhatX5YnNCAQCAClE4AFQbm5du1uT6S6U2rufq743Uvwb9xZxQAADAJQoHgGphxKxJym9byZBNmhCZps6D2pmSCQAAVI7CAcCvffXyF/rbFaulSspGXE6o5twy0ZxQAADAbRQOAH7Jbrdr+JtPq7BjZYPSvZG91euWq03JBQAAPEPhAOB3Ft73rhbe+aOU7Hou8phVb/V+QhaLxZxgAADAYxQOAH6j8HChRq17Xqcq+2w+h/Sn+L66vnNlT38AAABfo3AA8Asv3fJPrXv0kNTY9VxUfojm3vCYrFarOcEAAMAFoXAA8KndH+zSw+FvSo9VMuiQHmjcX906p5iSCwAAeAeFA4DPPH7XNG0bW1zpXHxhhGZ1f4RnNQAAqIYoHABM99Efl2v2+G+lsZUM2qWJLQbrinqVvHscAAD4LQoHANPk/pCjCZ//S8ceclQ626Q0XjP/8KAJqQAAgJEoHABM8VLHGVo386hU2YmlbNLf296rxJiGpuQCAADGonAAMNRnYz7RW1d8rWMv2yudbR98iZ7sfJcJqQAAgFkoHAAMcWhLjlbesEyHLzupYyNdl42gU9Lsjo+oVni0SekAAIBZKBwAvG5ew1cl2+lfH+pQ4nL29vrXadDF3U1IBQAAfIHCAcBr3u+9WHnf5ZY71viLCO28rei82Vr2SL3W6WFOdQsAQICjcAC4YNsXbNP6B9MrvKzWnlBZ8yVb3G8H7NLTlw7T5fHNzQsIAAB8hsIBoMpO5J/Qu0lvVjqXOqKhlBisG1cNUIPYOiYkAwAA/oLCAaBK5jV7VTrh3mzvZTer0VWNjQ0EAAD8EoUDgEdWDFiqI18ecmu2+dCWuvYF3hAOAEBNRuEA4JbvZnyjLVM3uTUb3jhSA7+5gzeEAwAACgcA13K3HtKHPZa6Nxws9Vt3m+Jb1DY2FAAAqDYoHAAqVHqiVP9uNsft+Sue6aw297QzMBEAAKiOKBwAzuPJG8Ibdm+sXgv7GhsIAABUWxQOAGct7PCWTu4rdms2onGk0jYOVnAwdyMAAMA5HikA0KqB7ytn3a/uDYdKaesHK6ZJrLGhAABAQKBwADVY+sOfafebWW7P3/DujWp83UUGJgIAAIGGwgHUQN//81ttfnqj2/OXP9pBHf7c0cBEAAAgUFE4gBpkx7s/6av71rk936hPE/V88yYDEwEAgEBH4QBqgOyVu7X2rtVuz8e0itOAdX+UxWIxMBUAAKgJKBxAANu75md9dscqt+fDG0UoLWOwQsJCDEwFAABqEgoHEID2rsnWZ3d87Pa8NdqqtE13KDI+0sBUAACgJqJwAAFk94c7lT7iU/evEG5R/7W3Ke7ieONCAQCAGo3CAQSAn+b/qA0PfeH+FYKlfp8NVHyrOsaFAgAAEIUDqNY2z9ik76d+4/4VrFLv929Wg46NjAsFAABwDgpHILGfkizBEmcWCnjrxq/RnoW7tPHBIyr8u01J70aryXoX77+wSDcsSlXjPzQ1LyQAAIAoHAEj7uurFVK4VbbwROV13eLrODDIh32XKHfDYa2YfUC2O38/vul/j6nkFZuafxRT/goWqdeyvmrYpbG5QQEAAH5D4QgAtT5vpeBTv0qSrCezJYddsgT5NhS86p1281R8sEgr5udI0RXP7BhU9HvhsEo9F9+kRlc3MS8kAABABSgc1Vz8fxJltR0954hFspdI1gifZYJ3lJ4s1b8vmaOTYaf08bzDUqjr+bBjQVKwdNPH/ZVweX1zQgIAAFSCwlGNxX/aRFZ7Qbljx1q9SNmo5nJ/PKQPuy9V7sUn9OV7eZI7T1Y5pL+mjFaDAw0NzwcAAOAJCkc1VXtNIwU5CssdO9b6dZU1vs1HiXChvntho7ZM+1bbbs7TjuUnJHff+2+ROsUnq0ErygYAAPA/FI5qKH51AwWpuNyxvMvmyNboVh8lwoVYdt1C5W87ps+f/lX57zvcv6JFSopopGlt7zEuHAAAwAWicFQztVcnKEil5Y7lXf6ubA36+CgRquJkwUktbDVPNrtNK97OkWIqv85ZFumq2GQ9eulgw/IBAAB4C4WjGqmzurYsKit3LC/lI9kSrvVRInjqpzd/1IaHv9Ch5if09Xt5ktWDK1ukAfWu0dCLexmWDwAAwNsoHNVE7dW1ZJG93LGjHT6RvU5nHyWCJxb/4R0VZuZr/YM5ylluc//9GZJkke5vNkDXNWhvWD4AAACjUDiqgTqr42RR+df25171tRR3mY8SwR1Hdx7RB1e/p7LgMn0475DHL5sKkvS3NvcoMaqRUREBAAAMR+Hwc3VWx573P8NzO38jxbT0SR5UbvWdH+rA6n3acUO+ti0rcu+0tmdYpLigSP2j3f2KCuX0xgAAoPqjcPgrh0N11sRVUDY2SzGX+CQSnCv45ZiWXrlQNodNq2bnqGy8hzdgkdpGX6KnLrvLkHwAAAC+QuHwR2VlqvNZ7XJlwyHpyLU/SRGNfZUKFXin5zvat2afdvQ8pm1Liz17NkOSLNKYi1LVp2EnQ/IBAAD4GoXD35SVqM5ndc8vG113S+EJvkqFcxzI2KfVN3+oUyFl+uiNQ9L9Ht6ARQpTsGZePl51I2sZkhEAAMBfUDj8yakiJXxe/tOiT5eNn6XweN9kgiTJVmbTwnbzdOrwKa1/6JBylpd5dqYpSbJI7WNa6MnWQw3JCAAA4I8oHP7ixBElfHFxuUMOSUf+sE8Ki/VNJujzsav18+LdOtjmuDJmHffsczMkyXK6l0xsMVgd6iQbEREAAMCvUTj8wYlDSviiRblDDll05LoDUkiUj0LVXDuXZOrLe9fqREypPpmVK1XlfdwWqWlYHb3QZpyCg/nPDAAA1Fw8EvK1on1K+Kp1uUMOWXWk+yEpOMRHoWqevJ1H9P6178nusGvlKwdV9n4VbuS3l1g9fMlAXV33cq/mAwAAqK4oHL50fIcS1l9R7pBdVh29jrJhhuIjxXrvyvlyFNm1ZtoBFS2V5+/L0OnrtIpoqimXjZDV6ulrrgAAAAIbhcNXjm1RwsZryx2yK1xHe/wq8aDVMGUlZVqU8rZKc0v06dQDKlygKpeMUAXplWseUrwtVg5H5VcBAACoiSgcvnBskxI2di93yK5wHb3+oBTk6Qc5oDKnTp7Soivmq+TwCX067aCKX1eVS4YkDWzQVXc0u0EWi5QQH6Pc3OPejAsAABBQKBwmsx7+j+I39y93zK5IHe150EeJAtOJIyf0bse3VVpWok/+eVi22apayZB4yRQAAMAFoHCYyJqzUvFb/ljumN0Sq6M37PNRosBy5KdcreixWLnNTujLv+ZJCy7gxixSraBovdzuT4oKjfRaRgAAgJqGwmGSkH2LFPfTqHLHbNYE5fXY7aNEgWHrq99q0xMblTH2kA72LpOWXsCNWaQIhepvre9Rwxg+1R0AAMAbKBwmCPn5dcVlPVTuGGWjaux2uz5IXaLsvfu09sU8qa2kqpzC9gyLFCarnr30bl0c27DyeQAAAHiEwmGw0OzXFLvjf8odOxWeqPyuW3yUqPrZ9/U+rRm4QumPHlTeFQ7pqQu8wd+eyXju0tG6KLa+NyICAADACQqHgUJ3TlPsnqnljpWFNqNsVMJms+nDm5bqP22ytLd/yektXXyBN2qR4i2Rer7tONUOj/FGTAAAALiBwmGQsMxJivnlxXLHToW3Un7XjT5K5N82/W2D5h9Yo+y03wrGU164UYuUFNpQUy8freBgVh0AAMAXeBRmgIitDyjq1znljpVGp6igy1ofJfI/25du0/T9i5SXYpeskq6t9CrusUiDG1yn25p1r3wWAAAAhqNweFnkD39S5MG3yh0riemk451X+yiRf1i2bI3eDE+X4nT68zAa/vZ1oRxS7eAoPdf6btWNivfCDQIAAMCbKBxeFLl5hCIPl3+zwcm4a1V41Uc+SuQbBwpzNXH9q8qPLJXOfHB6Ay/duENSkHRngx66tVk3L90oAAAAjELh8JLob9IUnrem3LGSWtepsOOFnLPV/20+mqUXdyzWcdvJ38uFJEV78TexS+1jL9HES4fwSd8AAADVDIXDC6I3pin8WPmycTK+pwqvvNBTK/mPYyWFmv4MujsAAA07SURBVJa5QNtP7pfsOv2yqHMFVXStKrJJraIa68nWdykiNMyLNwwAAACzUTguUMz67go7vqncseL6d6i47Ss+SnRhvjr0o17/+UPl2YtOH3BUMPTfZeNCOCSdktrHXKyJbYfyDAYAAECAoXBcgNgvOyu0eFu5Y8X1h6i47f/5KFHliktOas7elfry6I86qVPlL6yoXHibXVKhNLTedRrQnjNJAQAABDoKRxXFpXdUyMnt5Y4VNn1AJ5Of8VEi6eeCHL2z/1NtLchWkUqcD5pRLKTT5eKUVG9rqKb0u0cJTRNM+o0BAADgLygcVRCX3lYhJ7PLHSts+pBOJj99wbdtt9u1s2C/Mo7+pMzje7X/5BEVqlj2qtyYWcVCOl0uSqXamyxK295Bvf910+8vj+JkUgAAADUWhaMSj215TdtP7Pv9gMMhhfSXQs4ZslikfEkZk8yOZ26pOPP72SXlSZe+GaHWP9RT1/+7Xhd1b3b68utMzgMAAAC/5nbhKCgo0BNPPKF169YpOjpa9957r+68884KZzds2KDJkyfrl19+UatWrTR16lQlJSV5LbRZNuVtP79s/DeLN99B7YTZpUI6XSrsUtARKWlRmJI/qSOFS23Gp+iKR646PdPXB7kAAABQrbhdOCZPniybzab09HTt3btXI0aMUPPmzdW5c+dyc3l5eRo3bpyefPJJ9enTR3PmzNG4ceO0cuVKBQdXrydU9p3I/f0bI8qGL4rEueySbJLypcbpVl32ZqwibBGnL4uQ2j9ypdrdd4V0iy9DAgAAoDpzqwEUFxdr1apVWrZsmaKjo9W6dWsNGDBAixcvPq9wrF69WomJierXr58kafTo0Zo3b542btyoLl26eP/fwEDd67bXvF8+cb9s+LpAnOE456tMsuRKTdcFq+WyaEWeiDzvrLbRrWJ0zcvd1WBaQ/OzAgAAIKC5VTiys7MlSS1atDh7LDk5WXPnzj1vNisrS8nJyWe/t1qtSkpKUlZWVpUKhxmvWHImLjRKdYulwxE+LBeOc/555ssm6ZhUa6fUJD1KjdaHKsIeUW68oj+2sKYRumpKFzVPrX4vb/NHZ3bTlzsK/8RuoCLsBZxhN1CRQNoLt5/hiIqKKncsNjZWRUVFFc7GxcW5NVuZ+PioyocMdDTrqK7+YyOdeRjvkEMndFKlcad0Is6uonoOldSyqaS2XaXRNilMsoVKNqvksJ9eEGupZD0phZwMUvixIIUfsir0eJCic0IUVhCkMFuYrPLeh91ZQqXEGxN1/b+uV3zDeK/dLpyrUyfG1xHgp9gNVIS9gDPsBioSCHvhVuGIjIw8rzAcP378vBJyZrawsNCt2crk5RXJZqvSCWG9Yuv8H3/7lUWSQxYFKVKRisyXauVL2uubXJZaVrUYmKQOj12liNiICmdsknJzj5sbrIaxWE7fCRw5crzCV92h5mI3UBH2As6wG6iIv+2F1RpU5ScD3CociYmJkqRdu3apefPmkqTMzMwKzzzVsmVLLVq06Oz3drtdWVlZuueee6oU0Jd/wPWvbXTOdyY9nxUkxV4ap5YjLlXLwa0VEhLictwfFrCmczj4e0DF2A1UhL2AM+wGKhIIe+H2Mxy9e/fWjBkz9Oyzz2rfvn1asmSJXnrppfNme/bsqenTp2vFihXq1auX5s6dq6ioKHXs2NHr4Y2W0L6egqKDZC+88GdZrLWDVe+qekoacpmadG9aaZEAAAAAAoHF4XCvMxUUFOjxxx9Xenq6oqKiNHbs2LOfw5GSkqLXXntNV155pSQpIyOj3OdwPPvss1X6HI68vCKVlfnuJVWSVHyoWJv/tkGHvj4om8Om2OR41b+6kRpe00jxzWtXu1P9wnssFikhIUa5uf7xVCf8B7uBirAXcIbdQEX8bS+Cg6v+kiq3C4cv+EPhkPzvLxz+gb2AM+wGKsJewBl2AxXxt724kMIR5OUsAAAAAHAWhQMAAACAYSgcAAAAAAxD4QAAAABgGAoHAAAAAMNQOAAAAAAYhsIBAAAAwDAUDgAAAACGoXAAAAAAMAyFAwAAAIBhKBwAAAAADEPhAAAAAGAYCgcAAAAAw1A4AAAAABiGwgEAAADAMBQOAAAAAIahcAAAAAAwDIUDAAAAgGEoHAAAAAAMQ+EAAAAAYBgKBwAAAADDUDgAAAAAGIbCAQAAAMAwFA4AAAAAhqFwAAAAADAMhQMAAACAYSgcAAAAAAxD4QAAAABgGAoHAAAAAMME+zqAK1arf/Uhf8sD/8BewBl2AxVhL+AMu4GK+MteXEgOi8PhcHgxCwAAAACc5R+VCQAAAEBAonAAAAAAMAyFAwAAAIBhKBwAAAAADEPhAAAAAGAYCgcAAAAAw1A4AAAAABiGwgEAAADAMBQOAAAAAIahcAAAAAAwDIUDAAAAgGEoHL8pKCjQAw88oJSUFHXt2lXz5893Orthwwb17dtX7dq106BBg7Rjxw4Tk8JM7u7F5s2bNWrUKHXq1EmdOnXSmDFjlJ2dbW5YmMqT+4wzlixZolatWunf//63CQnhC57sRUlJiaZMmaIuXbqoQ4cOSktLU2FhoYlpYSZPduOjjz5SamqqUlJS1Lt3by1btszEpDDT22+/rbS0NLVp00YPPfSQy9nq/Pgz2NcB/MXkyZNls9mUnp6uvXv3asSIEWrevLk6d+5cbi4vL0/jxo3Tk08+qT59+mjOnDkaN26cVq5cqeBg/jgDjbt7kZ+fr1tvvVUvvfSSwsLCNGPGDI0dO1YrV670UXIYzd3dOCMvL0+zZs1Sy5YtTU4KM3myF5MmTVJxcbE++OAD1a5dW1lZWQoNDfVBapjB3d349ddfNWHCBM2cOVPdu3fXpk2bNGrUKLVp00YtWrTwUXoYpV69eho3bpy++uor5eXlOZ2r7o8/eYZDUnFxsVatWqUHH3xQ0dHRat26tQYMGKDFixefN7t69WolJiaqX79+Cg0N1ejRo1VUVKSNGzf6IDmM5MledOvWTampqYqJiVFoaKhGjhyp3bt3u7zzQPXlyW6cMW3aNI0aNUq1atUyMSnM5Mle7NmzR5988ommTJmihIQEBQUFKTk5mcIRoDzZjQMHDigmJkY9evSQxWLRlVdeqYsuukg7d+70QXIYrVevXrrhhhsUHx/vcq66P/6kcEhnX/py7v85SE5OrvCpqqysLCUnJ5/93mq1KikpSVlZWYbnhLk82Yv/tmHDBtWtW7fSOxBUT57uRkZGhrKzszVw4EAz4sFHPNmL77//Xo0bN9Y//vEPderUSTfeeKMWLlxoVlSYzJPdaNeunRITE7V69WrZ7XatX79eubm56tChg1lx4Yeq++NP/38OxgTFxcWKiooqdyw2NlZFRUUVzsbFxbk1i+rNk7041759+zRlyhRNnDjRyHjwIU92o7S0VJMnT9bzzz8vi8ViVkT4gCd7cfDgQWVlZalnz55KT09XZmamRo4cqWbNmjl9WR6qL092Izg4WGlpaZowYYJKSkoUFBSkKVOmqF69embFhR+q7o8/eYZDUmRk5Hl/YcePHz/vzuHM7H+/qc/ZLKo3T/bijIMHD2r48OG6++67lZqaanRE+IgnuzFr1ix16dJFrVu3NisefMSTvQgPD1dISIjGjRun0NBQtW3bVn369NHatWvNigsTebIb6enpmj59ut544w1t3bpVS5cu1cyZM/X555+blBb+qLo//qRwSEpMTJQk7dq16+yxzMxMJSUlnTfbsmVLZWZmnv3ebrcrKyuLN4IGIE/2QpJycnI0bNgwDRo0SMOHDzchIXzFk93IyMjQsmXLzp7B7Ntvv9X06dM1YcIEs+LCJJ7sRatWrcyKBT/gyW5kZWWpQ4cOSklJUVBQkJKSktStWzetW7fOrLjwQ9X98SeFQ6dbY+/evTVjxgwVFhYqMzNTS5YsUVpa2nmzPXv21J49e7RixQqVlpZq9uzZioqKUseOHX2QHEbyZC9ycnI0dOhQ9evXT2PGjPFBWpjJk92YMWOGVqxYoeXLl2v58uVq06aNxo4dq8cee8wHyWEkT/aiY8eOaty4sV555RWVlZVp27Zt+vjjj9WjRw8fJIfRPNmNtm3b6rvvvtOWLVskSbt379batWvLvX4fgaOsrEwlJSUqKyuT3W5XSUmJTp06dd5ctX/86YDD4XA48vPzHePHj3e0b9/ecc011zjefvvts5e1b9/esXHjxrPfr1+/3pGamuq4/PLLHQMHDnRkZWX5IjJM4O5evPzyy46WLVs62rdvX+5r//79vooOg3lyn3GuIUOGOBYsWGBWTJjMk73YuXOnY/DgwY527do5evbs6Xjvvfd8ERkm8WQ3FixY4OjVq5ejffv2jm7dujleeOEFh81m80VsGGzmzJmOli1blvv6y1/+4nA4Auvxp8XhcDh8XXoAAAAABCZeUgUAAADAMBQOAAAAAIahcAAAAAAwDIUDAAAAgGEoHAAAAAAMQ+EAAAAAYBgKBwAAAADDUDgAAAAAGIbCAQAAAMAwFA4AAAAAhvl/SNCbPnMPdQIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 960x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "plt.scatter(x_1,y_1,color='orange',label=r'$f_1(x)$',linestyle=(0,(1,10)),s=5,alpha=.9)\n",
    "plt.scatter(x_2,y_2,color='dodgerblue',label=r'$f_2(x)$',linestyle=(0,(1,10)),s=5,alpha=.9)\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'darkmagenta',linestyle=(0,(1,10)),  label='ffNN',s=15,alpha=.95)\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'mediumseagreen',linestyle=(0,(1,10)), label='tope',s=15,alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "# Plot legend.\n",
    "lgnd = plt.legend(loc=\"upper left\", scatterpoints=1, fontsize=35)\n",
    "plt.title(\"Model Predictions\")\n",
    "# Format\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([100])\n",
    "# plt.show()\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/DEMO_Seaborn.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
