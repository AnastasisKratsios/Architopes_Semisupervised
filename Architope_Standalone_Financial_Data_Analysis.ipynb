{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 0.95\n",
    "min_height = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "#================================================#\n",
      " Training Datasize: 201 and test datasize: 11.  \n",
      "#================================================#\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "exec(open('Financial_Data_Preprocessor.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "else:\n",
    "    q_in_auto = .99\n",
    "    Min_data_size_percentage_auto = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47761194029850745\n",
      "0.3781094527363184\n",
      "0.35323383084577115\n",
      "0.29850746268656714\n",
      "0.27860696517412936\n",
      "0.2736318407960199\n",
      "0.26865671641791045\n",
      "0.25870646766169153\n",
      "0.24875621890547264\n",
      "0.24378109452736318\n",
      "0.23880597014925373\n",
      "0.23383084577114427\n",
      "0.22885572139303484\n",
      "0.22388059701492538\n",
      "0.21393034825870647\n",
      "0.20398009950248755\n",
      "0.19900497512437812\n",
      "0.19402985074626866\n",
      "0.1890547263681592\n",
      "0.18407960199004975\n",
      "0.1791044776119403\n",
      "0.16417910447761194\n",
      "0.15920398009950248\n",
      "0.14925373134328357\n",
      "0.14427860696517414\n",
      "0.13930348258706468\n",
      "0.12935323383084577\n",
      "0.12437810945273632\n",
      "0.11940298507462686\n",
      "0.11442786069651742\n",
      "0.10945273631840796\n",
      "0.1044776119402985\n",
      "0.09950248756218906\n",
      "0.0945273631840796\n",
      "0.08955223880597014\n",
      "0.0845771144278607\n",
      "0.07960199004975124\n",
      "0.07462686567164178\n",
      "0.06965174129353234\n",
      "0.05970149253731343\n",
      "0.05472636815920398\n",
      "0.04975124378109453\n",
      "0.04477611940298507\n",
      "0.03980099502487562\n",
      "0.029850746268656716\n",
      "0.01990049751243781\n",
      "0.014925373134328358\n",
      "0.009950248756218905\n",
      "0.004975124378109453\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 2.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = 100)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 2.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 2 parts.\n",
      "Heights to iterate over: [100]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.7408 - mse: 128330.1172 - mae: 212.7408 - mape: 99.1088\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.6385 - mse: 128243.8281 - mae: 212.6385 - mape: 98.0444\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.5484 - mse: 128170.4922 - mae: 212.5484 - mape: 98.0750\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.4647 - mse: 128083.7344 - mae: 212.4647 - mape: 98.1113\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.3577 - mse: 127985.7891 - mae: 212.3577 - mape: 98.2188\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 212.2703 - mse: 127901.7031 - mae: 212.2703 - mape: 98.2559\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.1656 - mse: 127815.0312 - mae: 212.1656 - mape: 98.1873\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 212.0537 - mse: 127702.8672 - mae: 212.0537 - mape: 98.1407\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 211.9265 - mse: 127586.4922 - mae: 211.9265 - mape: 98.0450\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 211.7820 - mse: 127453.3516 - mae: 211.7820 - mape: 97.8255\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 211.6623 - mse: 127352.6641 - mae: 211.6623 - mape: 97.7120\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 211.4905 - mse: 127199.3125 - mae: 211.4905 - mape: 97.5399\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 211.3191 - mse: 127036.3438 - mae: 211.3191 - mape: 97.6428\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 211.1095 - mse: 126833.7812 - mae: 211.1095 - mape: 97.4848\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 210.8971 - mse: 126635.4922 - mae: 210.8971 - mape: 97.5407\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 210.6867 - mse: 126433.8125 - mae: 210.6867 - mape: 97.5533\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 210.4495 - mse: 126211.8281 - mae: 210.4495 - mape: 97.4839\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 210.1598 - mse: 125940.0938 - mae: 210.1598 - mape: 97.4228\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 209.9008 - mse: 125703.0781 - mae: 209.9008 - mape: 97.6154\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 209.5924 - mse: 125409.3750 - mae: 209.5924 - mape: 97.4493\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 209.2679 - mse: 125141.2734 - mae: 209.2679 - mape: 97.8866\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 208.8990 - mse: 124775.1250 - mae: 208.8990 - mape: 97.5130\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 208.4569 - mse: 124366.4609 - mae: 208.4569 - mape: 97.6901\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 208.0491 - mse: 123996.8672 - mae: 208.0491 - mape: 97.4751\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 207.5158 - mse: 123527.4609 - mae: 207.5158 - mape: 97.6785\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 206.9999 - mse: 123038.9297 - mae: 206.9999 - mape: 98.2869\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 206.4205 - mse: 122526.3750 - mae: 206.4205 - mape: 99.3007\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 205.6898 - mse: 121853.7734 - mae: 205.6898 - mape: 99.5033\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 204.9908 - mse: 121182.2656 - mae: 204.9908 - mape: 99.9911\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 204.2793 - mse: 120646.6875 - mae: 204.2793 - mape: 100.4708\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 203.3791 - mse: 119780.6797 - mae: 203.3791 - mape: 100.8080\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 202.6000 - mse: 119079.0312 - mae: 202.6000 - mape: 102.0819\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 201.6094 - mse: 118191.1641 - mae: 201.6094 - mape: 103.5547\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 200.5491 - mse: 117216.5312 - mae: 200.5491 - mape: 105.7484\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 199.5667 - mse: 116303.4688 - mae: 199.5667 - mape: 107.5235\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 198.2669 - mse: 115230.5156 - mae: 198.2669 - mape: 109.4139\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 197.1133 - mse: 114304.0156 - mae: 197.1133 - mape: 110.7407\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 195.7749 - mse: 113113.0859 - mae: 195.7749 - mape: 114.2936\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 194.2416 - mse: 111721.8672 - mae: 194.2416 - mape: 118.5912\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 192.7263 - mse: 110419.9141 - mae: 192.7263 - mape: 120.1174\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 191.4533 - mse: 109481.3047 - mae: 191.4533 - mape: 124.0294\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 189.2820 - mse: 107811.4453 - mae: 189.2820 - mape: 127.3115\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 187.7560 - mse: 106574.7891 - mae: 187.7560 - mape: 129.5947\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 185.6641 - mse: 105281.2578 - mae: 185.6641 - mape: 134.8988\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 183.8311 - mse: 103754.4219 - mae: 183.8311 - mape: 138.5587\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 181.9181 - mse: 102483.2734 - mae: 181.9181 - mape: 142.7565\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 179.8520 - mse: 101008.0703 - mae: 179.8520 - mape: 148.7677\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 177.5519 - mse: 99352.5547 - mae: 177.5519 - mape: 152.5776\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 175.3110 - mse: 97827.4688 - mae: 175.3110 - mape: 158.4594\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 173.0996 - mse: 96780.2969 - mae: 173.0996 - mape: 164.7549\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 170.9572 - mse: 95019.5312 - mae: 170.9572 - mape: 172.9239\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 168.4986 - mse: 93664.6016 - mae: 168.4986 - mape: 180.2579\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 166.1735 - mse: 92325.1797 - mae: 166.1735 - mape: 186.0359\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 163.5681 - mse: 90972.1641 - mae: 163.5681 - mape: 193.8644\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 161.5011 - mse: 89892.3516 - mae: 161.5011 - mape: 200.1718\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 159.2380 - mse: 88571.2656 - mae: 159.2380 - mape: 207.9535\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 157.4874 - mse: 87572.1172 - mae: 157.4874 - mape: 218.9859\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 156.1497 - mse: 86459.7812 - mae: 156.1497 - mape: 229.0406\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 154.8384 - mse: 85285.0078 - mae: 154.8384 - mape: 240.0489\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 153.4454 - mse: 84191.9141 - mae: 153.4454 - mape: 254.0264\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 152.2702 - mse: 83244.3438 - mae: 152.2702 - mape: 258.4176\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 151.1189 - mse: 82392.0312 - mae: 151.1189 - mape: 263.5548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 150.1687 - mse: 81500.1328 - mae: 150.1687 - mape: 272.4018\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 149.2015 - mse: 80491.5391 - mae: 149.2015 - mape: 276.1699\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 148.3439 - mse: 79962.0547 - mae: 148.3439 - mape: 280.6312\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 147.2640 - mse: 79035.5078 - mae: 147.2640 - mape: 286.4335\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 146.4284 - mse: 78545.8125 - mae: 146.4284 - mape: 288.7383\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 145.3745 - mse: 77736.8438 - mae: 145.3745 - mape: 290.5052\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 144.4396 - mse: 77092.5781 - mae: 144.4396 - mape: 290.0949\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 143.5179 - mse: 76491.0859 - mae: 143.5179 - mape: 291.3123\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 142.5691 - mse: 75772.1641 - mae: 142.5691 - mape: 293.2014\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 141.5602 - mse: 75371.9688 - mae: 141.5602 - mape: 296.8345\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 140.5035 - mse: 74512.6406 - mae: 140.5035 - mape: 298.4675\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 139.4068 - mse: 73554.9453 - mae: 139.4068 - mape: 301.8672\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 138.5521 - mse: 72936.5234 - mae: 138.5521 - mape: 302.4713\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 137.4889 - mse: 72139.2891 - mae: 137.4889 - mape: 307.7994\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 136.3977 - mse: 71578.1641 - mae: 136.3977 - mape: 308.8010\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 135.6224 - mse: 71196.2656 - mae: 135.6224 - mape: 308.8946\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 134.4432 - mse: 70344.5078 - mae: 134.4432 - mape: 307.8293\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 133.4561 - mse: 69453.0078 - mae: 133.4561 - mape: 313.9149\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 132.2928 - mse: 68665.2500 - mae: 132.2928 - mape: 316.0599\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 131.3980 - mse: 68027.5000 - mae: 131.3980 - mape: 322.2101\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 130.6088 - mse: 67567.1094 - mae: 130.6088 - mape: 328.4979\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 129.3923 - mse: 66393.7656 - mae: 129.3923 - mape: 332.8978\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 128.7238 - mse: 65831.6016 - mae: 128.7238 - mape: 332.1841\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 127.8767 - mse: 65231.3008 - mae: 127.8767 - mape: 332.1480\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 127.0240 - mse: 64659.2461 - mae: 127.0240 - mape: 335.5702\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 126.1797 - mse: 63833.9570 - mae: 126.1797 - mape: 338.2888\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 125.4285 - mse: 63202.9141 - mae: 125.4285 - mape: 340.1962\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 124.4906 - mse: 62125.8242 - mae: 124.4906 - mape: 343.1606\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 123.9474 - mse: 61471.5586 - mae: 123.9474 - mape: 345.1454\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 123.4196 - mse: 61139.1914 - mae: 123.4196 - mape: 345.8991\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 122.5640 - mse: 60711.0391 - mae: 122.5640 - mape: 349.6333\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 121.7006 - mse: 60026.9219 - mae: 121.7006 - mape: 349.3275\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 121.1494 - mse: 59591.5195 - mae: 121.1494 - mape: 345.4471\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 120.4760 - mse: 59326.3438 - mae: 120.4760 - mape: 337.1230\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 119.7893 - mse: 58568.9219 - mae: 119.7893 - mape: 341.7543\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 119.1365 - mse: 57967.3203 - mae: 119.1365 - mape: 346.7991\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 118.3158 - mse: 57233.2891 - mae: 118.3158 - mape: 350.9137\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 117.7064 - mse: 56785.9766 - mae: 117.7064 - mape: 348.1385\n",
      "13/13 [==============================] - 0s 754us/step\n",
      "1/1 [==============================] - 0s 952us/step\n",
      "Status: Current part: 1 out of : 2 parts.\n",
      "Heights to iterate over: [100]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 661.6085 - mse: 832810.6250 - mae: 661.6085 - mape: 99.4614\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 660.8709 - mse: 830996.3750 - mae: 660.8709 - mape: 99.3644\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 660.2867 - mse: 829751.0625 - mae: 660.2867 - mape: 99.2574\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 659.6108 - mse: 828143.3125 - mae: 659.6108 - mape: 99.1434\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 659.0428 - mse: 826874.0000 - mae: 659.0428 - mape: 99.0627\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 658.3611 - mse: 825245.3125 - mae: 658.3611 - mape: 98.9673\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 657.6575 - mse: 823601.3125 - mae: 657.6575 - mape: 98.8312\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 657.0195 - mse: 822320.6250 - mae: 657.0195 - mape: 98.6941\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 656.2473 - mse: 820573.5625 - mae: 656.2473 - mape: 98.5462\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 655.5255 - mse: 819067.5000 - mae: 655.5255 - mape: 98.3838\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 654.7362 - mse: 817403.5000 - mae: 654.7362 - mape: 98.2214\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 653.7220 - mse: 815180.0000 - mae: 653.7220 - mape: 98.0419\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 652.8626 - mse: 813345.8125 - mae: 652.8626 - mape: 97.8862\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 541.1276 - mse: 544207.0000 - mae: 541.1276 - mape: 97.92 - 0s 3ms/step - loss: 651.8373 - mse: 811114.3750 - mae: 651.8373 - mape: 97.6242\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 650.8011 - mse: 808949.5000 - mae: 650.8011 - mape: 97.3930\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 649.5944 - mse: 806307.8125 - mae: 649.5944 - mape: 97.1512\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 648.3252 - mse: 803795.8125 - mae: 648.3252 - mape: 96.8591\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 646.9251 - mse: 800808.0000 - mae: 646.9251 - mape: 96.6245\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 645.5245 - mse: 797879.0625 - mae: 645.5245 - mape: 96.3580\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 643.7170 - mse: 794304.6250 - mae: 643.7170 - mape: 95.9330\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 642.0187 - mse: 790658.6875 - mae: 642.0187 - mape: 95.7527\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 639.8865 - mse: 786278.0000 - mae: 639.8865 - mape: 95.5405\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 637.8758 - mse: 782196.8750 - mae: 637.8758 - mape: 95.3404\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 635.3102 - mse: 776783.9375 - mae: 635.3102 - mape: 95.0015\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 632.7625 - mse: 771835.7500 - mae: 632.7625 - mape: 94.8772\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 630.0278 - mse: 766562.0000 - mae: 630.0278 - mape: 94.5653\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 626.9141 - mse: 760619.8125 - mae: 626.9142 - mape: 94.2379\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 623.9175 - mse: 754512.0625 - mae: 623.9175 - mape: 94.0371\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 620.2789 - mse: 747293.7500 - mae: 620.2789 - mape: 93.7649\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 616.6081 - mse: 739658.9375 - mae: 616.6081 - mape: 93.7720\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 613.5328 - mse: 734659.6250 - mae: 613.5328 - mape: 93.5909\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 609.3846 - mse: 725719.6250 - mae: 609.3846 - mape: 93.4007\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 605.2395 - mse: 717534.5000 - mae: 605.2395 - mape: 93.3987\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 600.5677 - mse: 708736.8125 - mae: 600.5677 - mape: 93.0473\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 596.0038 - mse: 699920.8750 - mae: 596.0038 - mape: 93.0399\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 591.3629 - mse: 692961.1875 - mae: 591.3629 - mape: 92.8165\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 585.6510 - mse: 682552.9375 - mae: 585.6510 - mape: 92.5863\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 579.8620 - mse: 672076.0625 - mae: 579.8620 - mape: 92.2582\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 574.7313 - mse: 663622.5000 - mae: 574.7313 - mape: 92.2848\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 568.0365 - mse: 652142.8750 - mae: 568.0365 - mape: 92.0389\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 561.5067 - mse: 641412.3750 - mae: 561.5067 - mape: 91.9610\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 553.9214 - mse: 630041.9375 - mae: 553.9214 - mape: 92.0154\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 548.4346 - mse: 621062.0625 - mae: 548.4346 - mape: 92.2287\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 542.4229 - mse: 611493.0000 - mae: 542.4229 - mape: 92.9901\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 534.9592 - mse: 600654.3125 - mae: 534.9592 - mape: 93.1784\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 527.8481 - mse: 590594.5000 - mae: 527.8481 - mape: 94.0110\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 520.8846 - mse: 581545.1250 - mae: 520.8846 - mape: 95.2702\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 513.0896 - mse: 571332.3125 - mae: 513.0896 - mape: 95.1919\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 507.8268 - mse: 562757.3750 - mae: 507.8268 - mape: 96.3678\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 501.7947 - mse: 554835.1250 - mae: 501.7947 - mape: 96.7608\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 495.3378 - mse: 547141.8125 - mae: 495.3378 - mape: 97.5101\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 489.1748 - mse: 539148.1875 - mae: 489.1748 - mape: 98.0081\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 481.6103 - mse: 532002.0625 - mae: 481.6103 - mape: 98.4589\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 476.9240 - mse: 525496.5625 - mae: 476.9240 - mape: 98.9550\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 473.3635 - mse: 520795.3438 - mae: 473.3635 - mape: 99.6224\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 470.5128 - mse: 516920.5312 - mae: 470.5128 - mape: 99.9046\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 468.2108 - mse: 513557.1250 - mae: 468.2108 - mape: 99.9539\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 465.1512 - mse: 509656.7812 - mae: 465.1512 - mape: 100.2941\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 462.2800 - mse: 506153.0312 - mae: 462.2800 - mape: 100.5777\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 459.5904 - mse: 502829.4688 - mae: 459.5904 - mape: 100.6384\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 457.7729 - mse: 499370.3438 - mae: 457.7729 - mape: 101.4238\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 455.1649 - mse: 496522.2500 - mae: 455.1649 - mape: 101.5144\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 454.1200 - mse: 494562.5312 - mae: 454.1200 - mape: 101.5238\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 452.2258 - mse: 491830.4688 - mae: 452.2258 - mape: 101.3901\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 450.9582 - mse: 490000.9062 - mae: 450.9582 - mape: 101.1109\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 449.7094 - mse: 488005.8750 - mae: 449.7094 - mape: 100.7949\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 448.7999 - mse: 485994.4375 - mae: 448.7999 - mape: 100.4095\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 447.8392 - mse: 483706.5938 - mae: 447.8392 - mape: 100.5731\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 446.5148 - mse: 481486.6562 - mae: 446.5148 - mape: 100.5863\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 445.3388 - mse: 480031.5938 - mae: 445.3388 - mape: 100.2885\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 444.5365 - mse: 478685.0312 - mae: 444.5365 - mape: 99.8376\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 443.4895 - mse: 477071.2188 - mae: 443.4895 - mape: 99.3460\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 442.3786 - mse: 475369.7500 - mae: 442.3786 - mape: 99.1730\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 441.4070 - mse: 473688.1250 - mae: 441.4070 - mape: 99.0062\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 440.4966 - mse: 472058.0312 - mae: 440.4966 - mape: 98.6041\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 439.3901 - mse: 470522.0000 - mae: 439.3901 - mape: 98.2187\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 438.3621 - mse: 469051.9062 - mae: 438.3621 - mape: 97.7418\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 437.7477 - mse: 467768.5312 - mae: 437.7477 - mape: 97.3396\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 436.6739 - mse: 466048.6875 - mae: 436.6739 - mape: 97.1035\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 436.1183 - mse: 464767.6875 - mae: 436.1183 - mape: 97.3863\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 434.8339 - mse: 462960.1875 - mae: 434.8339 - mape: 97.0083\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 433.8025 - mse: 461514.9688 - mae: 433.8025 - mape: 96.1516\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 432.8031 - mse: 460170.4062 - mae: 432.8031 - mape: 95.6027\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 431.7691 - mse: 458974.7500 - mae: 431.7691 - mape: 95.4075\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 431.0474 - mse: 457646.0938 - mae: 431.0474 - mape: 94.9976\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 429.6846 - mse: 455814.9688 - mae: 429.6846 - mape: 94.7931\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 428.8481 - mse: 454567.3125 - mae: 428.8481 - mape: 94.6409\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 427.7451 - mse: 452939.7500 - mae: 427.7451 - mape: 94.0358\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 427.0542 - mse: 451667.0938 - mae: 427.0542 - mape: 93.4914\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 425.8362 - mse: 449861.9062 - mae: 425.8362 - mape: 93.4485\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 424.8265 - mse: 448223.4062 - mae: 424.8265 - mape: 93.2688\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 423.8872 - mse: 446793.1250 - mae: 423.8872 - mape: 92.8506\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 422.7394 - mse: 445074.3438 - mae: 422.7394 - mape: 92.4449\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 421.9753 - mse: 444049.7500 - mae: 421.9753 - mape: 92.0050\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 420.8910 - mse: 442149.1875 - mae: 420.8910 - mape: 91.5722\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 419.6116 - mse: 440630.7812 - mae: 419.6116 - mape: 91.4956\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 418.5018 - mse: 438821.5938 - mae: 418.5018 - mape: 91.3045\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 417.8435 - mse: 437559.9062 - mae: 417.8435 - mape: 91.0027\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 416.8282 - mse: 436143.8125 - mae: 416.8282 - mape: 90.4543\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 415.7730 - mse: 434386.2188 - mae: 415.7730 - mape: 90.1743\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 951us/step\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for current_part in range(len(X_parts_list)):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2422 - accuracy: 0.6119\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.1663 - accuracy: 0.6020\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3006 - accuracy: 0.6070\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.6035 - accuracy: 0.6020\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.0769 - accuracy: 0.6020\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6288 - accuracy: 0.5920\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2217 - accuracy: 0.5920\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.8975 - accuracy: 0.5970\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.6352 - accuracy: 0.5970\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4001 - accuracy: 0.6020\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1909 - accuracy: 0.6020\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.0291 - accuracy: 0.6070\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8700 - accuracy: 0.6119\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7205 - accuracy: 0.6119\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5893 - accuracy: 0.6070\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4688 - accuracy: 0.6020\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3638 - accuracy: 0.6119\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2642 - accuracy: 0.5970\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1776 - accuracy: 0.5920\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0905 - accuracy: 0.5871\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0300 - accuracy: 0.5821\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.5970\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9114 - accuracy: 0.5970\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.5821\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8272 - accuracy: 0.5821\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7936 - accuracy: 0.6020\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.6169\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.6269\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.6169\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.6070\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6318\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.6219\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.6269\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6418\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6418\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6368\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6468\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6418\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6517\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6517\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6567\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6517\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6468\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6517\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6418\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6617\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.6567\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6617\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6468\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6517\n",
      "WARNING:tensorflow:From /scratch/users/kratsioa/.local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 853us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              train          test\n",
      "MAE      247.120596     92.476686\n",
      "MSE   202487.231961  12145.617989\n",
      "MAPE     550.226760    203.181318\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      L-time    P-time  N_params_expt   AIC-like      Eff\n",
      "0  17.565609  9.357821          32876  65742.946  961.804\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0\n",
      " 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=2020,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.5, 1.0, 10, 100, 1000],\n",
       "                                        'penalty': ['none', 'l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2020, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              train         test\n",
      "MAE      242.566069    75.106565\n",
      "MSE   202759.917756  9041.334700\n",
      "MAPE     355.181459   189.123378\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Performance\n",
      "              train          test\n",
      "MAE      269.362865    103.906163\n",
      "MSE   215043.769181  19257.155122\n",
      "MAPE     304.413677     83.044747\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Partition: Generated!...Feature Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 420.1524 - mse: 449134.0938 - mae: 420.1524 - mape: 100.9719\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 419.6539 - mse: 448163.2188 - mae: 419.6539 - mape: 100.6722\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 419.2234 - mse: 447359.2500 - mae: 419.2234 - mape: 100.3509\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 418.7156 - mse: 446263.2812 - mae: 418.7156 - mape: 100.1337\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 418.2386 - mse: 445278.2188 - mae: 418.2386 - mape: 100.2350\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 417.6879 - mse: 444052.5000 - mae: 417.6879 - mape: 100.3873\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 417.1061 - mse: 443008.4688 - mae: 417.1061 - mape: 100.4325\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 416.3966 - mse: 441488.0938 - mae: 416.3966 - mape: 100.5105\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 415.6859 - mse: 439851.1562 - mae: 415.6859 - mape: 100.9399\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 414.8021 - mse: 437988.7500 - mae: 414.8021 - mape: 101.3042\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 413.8972 - mse: 436319.8750 - mae: 413.8972 - mape: 101.6166\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 412.6727 - mse: 433623.1562 - mae: 412.6727 - mape: 101.8719\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 411.3473 - mse: 430896.9062 - mae: 411.3473 - mape: 102.2218\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 409.8525 - mse: 427901.0625 - mae: 409.8525 - mape: 103.1855\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 408.1392 - mse: 424455.2188 - mae: 408.1392 - mape: 103.5057\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 405.8134 - mse: 419690.0312 - mae: 405.8134 - mape: 104.2710\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 403.4087 - mse: 415087.4688 - mae: 403.4087 - mape: 104.7112\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 400.7468 - mse: 410460.6875 - mae: 400.7468 - mape: 106.4707\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 396.8921 - mse: 402690.1250 - mae: 396.8921 - mape: 106.6397\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 393.2170 - mse: 396168.6875 - mae: 393.2170 - mape: 109.1208\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 388.7937 - mse: 388449.1875 - mae: 388.7937 - mape: 110.1159\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 383.8254 - mse: 380152.0312 - mae: 383.8254 - mape: 112.8941\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 378.8882 - mse: 372425.1250 - mae: 378.8882 - mape: 115.2129\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 372.5054 - mse: 362852.2188 - mae: 372.5054 - mape: 118.0934\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 365.6773 - mse: 351739.2500 - mae: 365.6773 - mape: 121.0216\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 359.2865 - mse: 342730.5938 - mae: 359.2865 - mape: 124.7092\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 352.5243 - mse: 333045.6562 - mae: 352.5243 - mape: 130.3072\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 344.9258 - mse: 323213.3125 - mae: 344.9258 - mape: 136.3336\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 337.7250 - mse: 315391.1875 - mae: 337.7250 - mape: 140.8857\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 329.8926 - mse: 308055.6875 - mae: 329.8926 - mape: 140.3499\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 321.7731 - mse: 300503.9062 - mae: 321.7731 - mape: 150.8831\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 316.0119 - mse: 293952.7500 - mae: 316.0119 - mape: 156.7144\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 312.7177 - mse: 289764.9062 - mae: 312.7177 - mape: 170.1465\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 309.5338 - mse: 284836.9375 - mae: 309.5338 - mape: 177.3980\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 306.9370 - mse: 281222.4688 - mae: 306.9370 - mape: 181.2730\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 304.6310 - mse: 278184.8438 - mae: 304.6310 - mape: 190.4721\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 302.2438 - mse: 275258.8125 - mae: 302.2438 - mape: 194.2661\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 300.1142 - mse: 272230.0938 - mae: 300.1142 - mape: 198.9860\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 298.3947 - mse: 269062.1250 - mae: 298.3947 - mape: 203.9140\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 296.2902 - mse: 266645.6250 - mae: 296.2902 - mape: 209.7187\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 294.4886 - mse: 263991.1250 - mae: 294.4886 - mape: 214.0042\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 292.9407 - mse: 261471.7344 - mae: 292.9407 - mape: 218.3447\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 291.6663 - mse: 259486.7656 - mae: 291.6663 - mape: 222.2177\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 290.1462 - mse: 257265.1875 - mae: 290.1462 - mape: 225.8831\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 288.7498 - mse: 255449.0938 - mae: 288.7498 - mape: 227.3108\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 287.2187 - mse: 253278.0938 - mae: 287.2187 - mape: 231.5261\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 285.7860 - mse: 251104.7344 - mae: 285.7860 - mape: 234.4223\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 284.8093 - mse: 249796.7344 - mae: 284.8093 - mape: 234.2186\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 283.4275 - mse: 248266.1719 - mae: 283.4275 - mape: 234.6646\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 282.6337 - mse: 246862.3750 - mae: 282.6337 - mape: 235.7311\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 281.7754 - mse: 245871.5156 - mae: 281.7754 - mape: 236.0475\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 280.8745 - mse: 244573.2344 - mae: 280.8745 - mape: 237.6876\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 279.2258 - mse: 242613.0312 - mae: 279.2258 - mape: 238.6884\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 278.2040 - mse: 241516.2812 - mae: 278.2040 - mape: 239.0384\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 277.2709 - mse: 239869.3281 - mae: 277.2709 - mape: 241.6527\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 276.2954 - mse: 238426.0156 - mae: 276.2954 - mape: 242.3026\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 275.1266 - mse: 237111.2812 - mae: 275.1266 - mape: 241.2555\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 274.4575 - mse: 236296.7031 - mae: 274.4575 - mape: 241.1623\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 272.9740 - mse: 234849.8125 - mae: 272.9740 - mape: 241.1104\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 271.9672 - mse: 233384.6406 - mae: 271.9672 - mape: 243.4759\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 270.8872 - mse: 232039.6250 - mae: 270.8872 - mape: 244.5408\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 269.4307 - mse: 230346.1719 - mae: 269.4307 - mape: 246.8555\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 268.7849 - mse: 229116.5781 - mae: 268.7849 - mape: 243.9155\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 267.6293 - mse: 227948.7500 - mae: 267.6293 - mape: 245.4432\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 266.4242 - mse: 226622.9688 - mae: 266.4242 - mape: 245.6349\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 265.5055 - mse: 225071.3438 - mae: 265.5055 - mape: 247.8389\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 264.1460 - mse: 223893.6875 - mae: 264.1460 - mape: 247.9662\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 262.7380 - mse: 222537.3594 - mae: 262.7380 - mape: 248.1535\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 261.7197 - mse: 221108.6094 - mae: 261.7197 - mape: 250.3262\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 260.4611 - mse: 219656.0000 - mae: 260.4611 - mape: 250.8631\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 259.3962 - mse: 218533.1875 - mae: 259.3962 - mape: 250.0377\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 257.9637 - mse: 216742.8125 - mae: 257.9637 - mape: 251.1008\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 257.0265 - mse: 215837.0312 - mae: 257.0265 - mape: 251.1079\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 256.2591 - mse: 215006.7500 - mae: 256.2591 - mape: 246.9572\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 254.7654 - mse: 213542.9688 - mae: 254.7654 - mape: 247.3278\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 253.7043 - mse: 212432.0781 - mae: 253.7043 - mape: 249.6710\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 252.7464 - mse: 211219.5000 - mae: 252.7464 - mape: 249.2726\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 251.7693 - mse: 209762.4531 - mae: 251.7693 - mape: 249.7518\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 250.6537 - mse: 208236.4375 - mae: 250.6537 - mape: 253.0845\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 249.5489 - mse: 207309.0000 - mae: 249.5489 - mape: 252.1346\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 248.7269 - mse: 206358.2031 - mae: 248.7269 - mape: 252.8913\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 247.4830 - mse: 204487.6250 - mae: 247.4830 - mape: 254.3152\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 246.9036 - mse: 203214.9219 - mae: 246.9036 - mape: 255.8273\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 245.5470 - mse: 202079.0312 - mae: 245.5470 - mape: 258.8164\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 244.9521 - mse: 200667.5469 - mae: 244.9521 - mape: 260.4498\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 243.9559 - mse: 199441.9844 - mae: 243.9559 - mape: 264.3660\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 242.7607 - mse: 198260.4219 - mae: 242.7607 - mape: 264.9198\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 241.5824 - mse: 196841.6562 - mae: 241.5824 - mape: 266.4232\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 241.2277 - mse: 195712.7500 - mae: 241.2277 - mape: 266.0146\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 240.0822 - mse: 194506.5625 - mae: 240.0822 - mape: 270.2886\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 239.2717 - mse: 193351.9531 - mae: 239.2717 - mape: 270.5139\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 238.2454 - mse: 192458.6094 - mae: 238.2454 - mape: 269.3428\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 237.6376 - mse: 191383.7188 - mae: 237.6376 - mape: 272.7032\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 236.6882 - mse: 190225.7969 - mae: 236.6882 - mape: 274.3716\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 235.6630 - mse: 189052.4844 - mae: 235.6630 - mape: 274.3315\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 234.8298 - mse: 188124.0000 - mae: 234.8298 - mape: 272.8129\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 234.1810 - mse: 187366.5625 - mae: 234.1810 - mape: 273.3802\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 232.8889 - mse: 185755.2656 - mae: 232.8889 - mape: 276.6383\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 232.5426 - mse: 184463.5781 - mae: 232.5426 - mape: 280.0034\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 231.3522 - mse: 183527.9531 - mae: 231.3522 - mape: 279.2653\n",
      "13/13 [==============================] - 0s 632us/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vanilla ffNNs\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Vanilla ffNNs\n",
      "              train          test\n",
      "MAE      230.321364     95.660299\n",
      "MSE   182921.005386  13069.609178\n",
      "MAPE     241.350166    164.463984\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preliminary table: Required Training Times\n",
      "   Architope  Architope-logistic Vanilla ffNN  Bagged ffNN\n",
      "0     22.810              21.428        6.935       17.941\n",
      "0     14.602              13.220            -        9.733\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 4200 parameters.\n",
      "              train          test\n",
      "MAE      285.192374     94.711655\n",
      "MSE   186991.762124  15266.071119\n",
      "MAPE     220.969890    129.544104\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0967s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n",
      "                   In-Line (L-Time) Parallel (P-Time)\n",
      "Vanilla ffNN                  6.935                 -\n",
      "Grad.Bstd Rand.F              0.161                 -\n",
      "Bagged ffNN                  17.941             9.733\n",
      "Architope-logistic           21.428             13.22\n",
      "Architope                     22.81            14.602\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 MAE            MSE        MAPE\n",
      "ffNN      230.321364  182921.005386  241.350166\n",
      "GBRF      285.192374  186991.762124  220.969890\n",
      "ffNN-bag  269.362865  215043.769181  304.413677\n",
      "ffNN-lgt  242.566069  202759.917756  355.181459\n",
      "tope      247.120596  202487.231961  550.226760\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like  \\\n",
      "Vanilla ffNN                  6.935                 -  16301  32592.878   \n",
      "Grad.Bstd Rand.F              0.161                 -   4200   8390.898   \n",
      "Bagged ffNN                  17.941             9.733  32605  65200.713   \n",
      "Architope-logistic           21.428             13.22  32663  65317.362   \n",
      "Architope                     22.81            14.602  32876  65742.946   \n",
      "\n",
      "                         Eff  \n",
      "Vanilla ffNN         927.807  \n",
      "Grad.Bstd Rand.F     790.164  \n",
      "Bagged ffNN         1079.816  \n",
      "Architope-logistic   780.658  \n",
      "Architope            961.804  \n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "#-------------------#\n",
      " PERFORMANCE SUMMARY:\n",
      "#-------------------#\n",
      " \n",
      " \n",
      "#===================#\n",
      " Individual Metrics: \n",
      "#======-============#\n",
      " \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Architope (Full)\n",
      "----------------------------------------\n",
      "              train          test\n",
      "MAE      247.120596     92.476686\n",
      "MSE   202487.231961  12145.617989\n",
      "MAPE     550.226760    203.181318\n",
      "----------------------------------------\n",
      "Architope - Naive Logistic\n",
      "----------------------------------------\n",
      "              train         test\n",
      "MAE      242.566069    75.106565\n",
      "MSE   202759.917756  9041.334700\n",
      "MAPE     355.181459   189.123378\n",
      "----------------------------------------\n",
      "Vanilla ffNN\n",
      "----------------------------------------\n",
      "              train          test\n",
      "MAE      230.321364     95.660299\n",
      "MSE   182921.005386  13069.609178\n",
      "MAPE     241.350166    164.463984\n",
      "----------------------------------------\n",
      "Bagged ffNN\n",
      "----------------------------------------\n",
      "              train          test\n",
      "MAE      269.362865    103.906163\n",
      "MSE   215043.769181  19257.155122\n",
      "MAPE     304.413677     83.044747\n",
      "----------------------------------------\n",
      "Gradient Boosted Random Forest Regressor\n",
      "----------------------------------------\n",
      "              train          test\n",
      "MAE      285.192374     94.711655\n",
      "MSE   186991.762124  15266.071119\n",
      "MAPE     220.969890    129.544104\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#==================#\n",
      " Overview  Metrics : \n",
      "#==================#\n",
      " \n",
      "----------------------------------------\n",
      "Training Performance: \n",
      "----------------------------------------\n",
      "                 MAE            MSE        MAPE\n",
      "ffNN      230.321364  182921.005386  241.350166\n",
      "GBRF      285.192374  186991.762124  220.969890\n",
      "ffNN-bag  269.362865  215043.769181  304.413677\n",
      "ffNN-lgt  242.566069  202759.917756  355.181459\n",
      "tope      247.120596  202487.231961  550.226760\n",
      "----------------------------------------\n",
      "Testing Performance: \n",
      "----------------------------------------\n",
      "                 MAE           MSE        MAPE\n",
      "ffNN       95.660299  13069.609178  164.463984\n",
      "GBRF       94.711655  15266.071119  129.544104\n",
      "ffNN-bag  103.906163  19257.155122   83.044747\n",
      "ffNN-lgt   75.106565   9041.334700  189.123378\n",
      "tope       92.476686  12145.617989  203.181318\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#====================#\n",
      " Efficiency Metrics: \n",
      "#====================#\n",
      " \n",
      "Model Training Times:\n",
      "----------------------------------------\n",
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like  \\\n",
      "Vanilla ffNN                  6.935                 -  16301  32592.878   \n",
      "Grad.Bstd Rand.F              0.161                 -   4200   8390.898   \n",
      "Bagged ffNN                  17.941             9.733  32605  65200.713   \n",
      "Architope-logistic           21.428             13.22  32663  65317.362   \n",
      "Architope                     22.81            14.602  32876  65742.946   \n",
      "\n",
      "                         Eff  \n",
      "Vanilla ffNN         927.807  \n",
      "Grad.Bstd Rand.F     790.164  \n",
      "Bagged ffNN         1079.816  \n",
      "Architope-logistic   780.658  \n",
      "Architope            961.804  \n",
      " \n",
      " \n",
      "😃😃 Have a great day!! 😃😃 \n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('😃😃 Have a great day!! 😃😃 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
