{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  5001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 10\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6660667866426715\n",
      "0.42451509698060386\n",
      "0.2501499700059988\n",
      "0.047590481903619274\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    \n",
    "# Trash removal (removes empty parts)\n",
    "X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "    \n",
    "    \n",
    "# ICML Rebuttle Deadline = Coersion!\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 5.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 5 parts.\n",
      "Heights to iterate over: [334]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0369 - mse: 0.0024 - mae: 0.0369 - mape: 190.2451\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0286 - mse: 0.0016 - mae: 0.0286 - mape: 123.0746\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 6.5404e-04 - mae: 0.0191 - mape: 91.6425\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 5.4544e-04 - mae: 0.0170 - mape: 96.0993\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 5.7630e-04 - mae: 0.0169 - mape: 109.9137\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 5.6530e-04 - mae: 0.0168 - mape: 107.1641\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 5.6760e-04 - mae: 0.0166 - mape: 107.4657\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0166 - mse: 5.5663e-04 - mae: 0.0166 - mape: 100.6631\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mse: 5.7600e-04 - mae: 0.0169 - mape: 104.7773\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 5.4183e-04 - mae: 0.0167 - mape: 95.6157\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 5.4423e-04 - mae: 0.0163 - mape: 102.4137\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 5.5679e-04 - mae: 0.0167 - mape: 103.5505\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 5.4683e-04 - mae: 0.0166 - mape: 100.9065\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 5.5188e-04 - mae: 0.0164 - mape: 99.5010\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 5.6798e-04 - mae: 0.0166 - mape: 97.1990\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0164 - mse: 5.4535e-04 - mae: 0.0164 - mape: 105.0946\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 5.4316e-04 - mae: 0.0163 - mape: 99.4421\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 5.3883e-04 - mae: 0.0168 - mape: 94.2583\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 5.2627e-04 - mae: 0.0167 - mape: 100.2036\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 5.5167e-04 - mae: 0.0162 - mape: 99.8351\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 5.5016e-04 - mae: 0.0162 - mape: 104.4936\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 5.3124e-04 - mae: 0.0161 - mape: 100.2036\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 5.3828e-04 - mae: 0.0160 - mape: 99.4814\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 5.3694e-04 - mae: 0.0160 - mape: 97.7634\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 5.3062e-04 - mae: 0.0157 - mape: 96.8616\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 5.1113e-04 - mae: 0.0156 - mape: 95.7263\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 5.2657e-04 - mae: 0.0156 - mape: 97.2477\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 4.9551e-04 - mae: 0.0153 - mape: 90.5633\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 4.7690e-04 - mae: 0.0148 - mape: 85.0021\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 4.5076e-04 - mae: 0.0139 - mape: 82.2486\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0122 - mse: 3.9220e-04 - mae: 0.0122 - mape: 67.0809\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mse: 2.7227e-04 - mae: 0.0089 - mape: 41.5381\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 1.7680e-04 - mae: 0.0075 - mape: 35.2507\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 1.5977e-04 - mae: 0.0062 - mape: 36.7946\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0067 - mse: 1.6151e-04 - mae: 0.0067 - mape: 37.8590\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0067 - mse: 1.5745e-04 - mae: 0.0067 - mape: 43.2893\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0065 - mse: 1.5830e-04 - mae: 0.0065 - mape: 39.5498\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.6055e-04 - mae: 0.0061 - mape: 35.7071\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 1.6675e-04 - mae: 0.0066 - mape: 34.5940\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.6208e-04 - mae: 0.0061 - mape: 36.5098\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 1.6160e-04 - mae: 0.0067 - mape: 44.7227\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6136e-04 - mae: 0.0059 - mape: 36.1504\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 1.6065e-04 - mae: 0.0063 - mape: 41.8693\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.6518e-04 - mae: 0.0061 - mape: 33.2245\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 1.6534e-04 - mae: 0.0063 - mape: 38.6512\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6208e-04 - mae: 0.0059 - mape: 33.4772\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 1.6822e-04 - mae: 0.0066 - mape: 35.4711\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.5640e-04 - mae: 0.0061 - mape: 43.2483\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6386e-04 - mae: 0.0059 - mape: 35.8547\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.6203e-04 - mae: 0.0061 - mape: 37.4286\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.6452e-04 - mae: 0.0062 - mape: 36.7889\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0064 - mse: 1.5949e-04 - mae: 0.0064 - mape: 36.9771\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.4921e-04 - mae: 0.0061 - mape: 44.3832\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.5899e-04 - mae: 0.0061 - mape: 37.1762\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5879e-04 - mae: 0.0059 - mape: 38.2668\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.6145e-04 - mae: 0.0062 - mape: 36.2627\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.5993e-04 - mae: 0.0062 - mape: 37.9625\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.6012e-04 - mae: 0.0060 - mape: 35.8725\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.7008e-04 - mae: 0.0060 - mape: 30.7111\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5658e-04 - mae: 0.0058 - mape: 36.7554\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5872e-04 - mae: 0.0060 - mape: 36.9089\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6786e-04 - mae: 0.0059 - mape: 33.2352\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5983e-04 - mae: 0.0059 - mape: 37.3573\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6319e-04 - mae: 0.0059 - mape: 35.9207\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6579e-04 - mae: 0.0059 - mape: 31.0559\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6490e-04 - mae: 0.0059 - mape: 31.7242\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6698e-04 - mae: 0.0058 - mape: 33.9529\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.6346e-04 - mae: 0.0057 - mape: 32.9855\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6926e-04 - mae: 0.0059 - mape: 34.4932\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6148e-04 - mae: 0.0058 - mape: 37.4202\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.6597e-04 - mae: 0.0061 - mape: 34.6721\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.7040e-04 - mae: 0.0059 - mape: 31.6186\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6147e-04 - mae: 0.0059 - mape: 35.0432\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.6477e-04 - mae: 0.0060 - mape: 35.3057\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5640e-04 - mae: 0.0059 - mape: 38.2386\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6604e-04 - mae: 0.0059 - mape: 34.0473\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.6818e-04 - mae: 0.0060 - mape: 34.3378\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6420e-04 - mae: 0.0059 - mape: 35.6973\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6761e-04 - mae: 0.0058 - mape: 33.0517\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.6934e-04 - mae: 0.0061 - mape: 33.1906\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5673e-04 - mae: 0.0060 - mape: 36.9039\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0062 - mse: 1.6832e-04 - mae: 0.0062 - mape: 37.7018\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 1.5725e-04 - mae: 0.0063 - mape: 44.8884\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6367e-04 - mae: 0.0059 - mape: 33.1516\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.7126e-04 - mae: 0.0059 - mape: 30.9634\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.6684e-04 - mae: 0.0062 - mape: 33.3704\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6179e-04 - mae: 0.0059 - mape: 35.6343\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6190e-04 - mae: 0.0057 - mape: 34.9217\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6441e-04 - mae: 0.0057 - mape: 33.3286\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.6698e-04 - mae: 0.0061 - mape: 32.7571\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6025e-04 - mae: 0.0058 - mape: 37.1367\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.6498e-04 - mae: 0.0060 - mape: 36.4066\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6427e-04 - mae: 0.0059 - mape: 33.8006\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5581e-04 - mae: 0.0059 - mape: 38.7467\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6641e-04 - mae: 0.0057 - mape: 35.9070\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.6648e-04 - mae: 0.0062 - mape: 33.9666\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5468e-04 - mae: 0.0058 - mape: 38.5662\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6348e-04 - mae: 0.0059 - mape: 35.6419\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 1.6165e-04 - mae: 0.0065 - mape: 39.3869\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6067e-04 - mae: 0.0059 - mape: 34.2785\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6627e-04 - mae: 0.0057 - mape: 33.4820\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6469e-04 - mae: 0.0058 - mape: 33.2547\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6678e-04 - mae: 0.0058 - mape: 35.6074\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 1.6256e-04 - mae: 0.0066 - mape: 38.5985\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5222e-04 - mae: 0.0060 - mape: 41.5272\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6093e-04 - mae: 0.0058 - mape: 38.0702\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6589e-04 - mae: 0.0057 - mape: 33.3085\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.5925e-04 - mae: 0.0057 - mape: 35.7231\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6404e-04 - mae: 0.0059 - mape: 36.0068\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6312e-04 - mae: 0.0058 - mape: 36.3924\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6074e-04 - mae: 0.0057 - mape: 34.8071\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.6207e-04 - mae: 0.0056 - mape: 34.6588\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 1.6981e-04 - mae: 0.0058 - mape: 31.5399\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6745e-04 - mae: 0.0058 - mape: 32.9913\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6282e-04 - mae: 0.0058 - mape: 35.1523\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6095e-04 - mae: 0.0057 - mape: 35.6006\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.5796e-04 - mae: 0.0061 - mape: 37.4056\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.5502e-04 - mae: 0.0057 - mape: 39.6563\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6505e-04 - mae: 0.0059 - mape: 33.9013\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.6692e-04 - mae: 0.0061 - mape: 33.7607\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6247e-04 - mae: 0.0058 - mape: 34.4926\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6382e-04 - mae: 0.0057 - mape: 34.0764\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6074e-04 - mae: 0.0057 - mape: 35.4550\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6788e-04 - mae: 0.0057 - mape: 34.0314\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6425e-04 - mae: 0.0057 - mape: 33.6536\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6170e-04 - mae: 0.0059 - mape: 35.4507\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.5883e-04 - mae: 0.0059 - mape: 37.6576\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6047e-04 - mae: 0.0057 - mape: 37.8396\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 1.6231e-04 - mae: 0.0062 - mape: 34.0046\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.5718e-04 - mae: 0.0057 - mape: 40.0806\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6101e-04 - mae: 0.0057 - mape: 35.0342\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6306e-04 - mae: 0.0056 - mape: 34.5314\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.6059e-04 - mae: 0.0060 - mape: 37.4924\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5855e-04 - mae: 0.0058 - mape: 37.7437\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6287e-04 - mae: 0.0059 - mape: 34.6297\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5701e-04 - mae: 0.0059 - mape: 40.1402\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6143e-04 - mae: 0.0056 - mape: 34.7372\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6296e-04 - mae: 0.0056 - mape: 33.7452\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6408e-04 - mae: 0.0057 - mape: 34.6654\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6026e-04 - mae: 0.0058 - mape: 35.3266\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6087e-04 - mae: 0.0057 - mape: 34.0014\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 1.6213e-04 - mae: 0.0058 - mape: 34.6952\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.5899e-04 - mae: 0.0059 - mape: 37.1401\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5845e-04 - mae: 0.0059 - mape: 35.9366\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5748e-04 - mae: 0.0056 - mape: 37.9000\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6201e-04 - mae: 0.0059 - mape: 37.5590\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6281e-04 - mae: 0.0057 - mape: 34.0708\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5358e-04 - mae: 0.0058 - mape: 39.7500\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5867e-04 - mae: 0.0058 - mape: 36.0649\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5260e-04 - mae: 0.0059 - mape: 42.2715\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6199e-04 - mae: 0.0057 - mape: 35.3375\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6483e-04 - mae: 0.0056 - mape: 36.4253\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5657e-04 - mae: 0.0058 - mape: 37.8514\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6050e-04 - mae: 0.0058 - mape: 38.2555\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.5991e-04 - mae: 0.0056 - mape: 37.2780\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.7089e-04 - mae: 0.0056 - mape: 31.0500\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5381e-04 - mae: 0.0056 - mape: 39.1409\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6471e-04 - mae: 0.0056 - mape: 34.0652\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5822e-04 - mae: 0.0060 - mape: 38.7782\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5348e-04 - mae: 0.0056 - mape: 40.3666\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6162e-04 - mae: 0.0056 - mape: 35.0827\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.6396e-04 - mae: 0.0055 - mape: 33.5367\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.6011e-04 - mae: 0.0058 - mape: 36.2391\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5759e-04 - mae: 0.0056 - mape: 37.5279\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6484e-04 - mae: 0.0056 - mape: 34.0757\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.6036e-04 - mae: 0.0059 - mape: 37.2096\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.5657e-04 - mae: 0.0057 - mape: 37.6632\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 1.5661e-04 - mae: 0.0058 - mape: 40.1970\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 1.5151e-04 - mae: 0.0058 - mape: 39.9882\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6092e-04 - mae: 0.0056 - mape: 36.7169\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0059 - mse: 1.6043e-04 - mae: 0.0059 - mape: 40.5188\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 1.5883e-04 - mae: 0.0057 - mape: 36.7781\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.5896e-04 - mae: 0.0057 - mape: 35.9757\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0057 - mse: 1.5737e-04 - mae: 0.0057 - mape: 37.7238\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0056 - mse: 1.5820e-04 - mae: 0.0056 - mape: 36.0257\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 1.6177e-04 - mae: 0.0058 - mape: 34.4957\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5821e-04 - mae: 0.0056 - mape: 36.5470\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.6247e-04 - mae: 0.0056 - mape: 35.0799\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.6402e-04 - mae: 0.0054 - mape: 34.4990\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.5495e-04 - mae: 0.0057 - mape: 37.4289\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5143e-04 - mae: 0.0056 - mape: 42.3035\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5308e-04 - mae: 0.0059 - mape: 39.4044\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.5583e-04 - mae: 0.0061 - mape: 39.4267\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 1.5519e-04 - mae: 0.0059 - mape: 39.0966\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 1.5197e-04 - mae: 0.0061 - mape: 42.7343\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.5159e-04 - mae: 0.0056 - mape: 39.1419\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.6311e-04 - mae: 0.0057 - mape: 37.4783\n",
      "Epoch 188/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5280e-04 - mae: 0.0058 - mape: 43.2427\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5706e-04 - mae: 0.0055 - mape: 37.3280\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6063e-04 - mae: 0.0056 - mape: 35.6156\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0056 - mse: 1.6081e-04 - mae: 0.0056 - mape: 36.4784\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0059 - mse: 1.5390e-04 - mae: 0.0059 - mape: 41.2851\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0055 - mse: 1.5483e-04 - mae: 0.0055 - mape: 37.6723\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0057 - mse: 1.5754e-04 - mae: 0.0057 - mape: 38.7974\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0056 - mse: 1.4967e-04 - mae: 0.0056 - mape: 41.0275\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 1.5350e-04 - mae: 0.0055 - mape: 37.8394\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.6156e-04 - mae: 0.0056 - mape: 33.5642\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 1.5778e-04 - mae: 0.0055 - mape: 36.8171\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 1.5500e-04 - mae: 0.0057 - mape: 38.9381\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5238e-04 - mae: 0.0060 - mape: 44.5076\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.4907e-04 - mae: 0.0057 - mape: 41.9595\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5834e-04 - mae: 0.0055 - mape: 37.0911\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5729e-04 - mae: 0.0056 - mape: 37.1383\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 1.5227e-04 - mae: 0.0058 - mape: 41.8854\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.5353e-04 - mae: 0.0056 - mape: 39.8711\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 1.5513e-04 - mae: 0.0055 - mape: 38.0644\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5777e-04 - mae: 0.0056 - mape: 36.9038\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 1.5785e-04 - mae: 0.0057 - mape: 37.6648\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.5402e-04 - mae: 0.0056 - mape: 39.1512\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.6137e-04 - mae: 0.0055 - mape: 36.0802\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5726e-04 - mae: 0.0056 - mape: 40.8844\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.5219e-04 - mae: 0.0054 - mape: 38.9217\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.5795e-04 - mae: 0.0056 - mape: 36.5993\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.5673e-04 - mae: 0.0054 - mape: 36.7581\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 1.5439e-04 - mae: 0.0057 - mape: 38.9104\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 1.5094e-04 - mae: 0.0055 - mape: 40.0773\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.5708e-04 - mae: 0.0054 - mape: 37.4447\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5041e-04 - mae: 0.0056 - mape: 42.8681\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5632e-04 - mae: 0.0054 - mape: 36.5568\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.5544e-04 - mae: 0.0054 - mape: 39.7274\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5579e-04 - mae: 0.0055 - mape: 40.1678\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5888e-04 - mae: 0.0055 - mape: 36.6559\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5670e-04 - mae: 0.0055 - mape: 37.5039\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5502e-04 - mae: 0.0055 - mape: 39.1420\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5442e-04 - mae: 0.0055 - mape: 41.7381\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.5657e-04 - mae: 0.0059 - mape: 39.5489\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 1.5383e-04 - mae: 0.0060 - mape: 41.6313\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.5047e-04 - mae: 0.0057 - mape: 41.7771\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5355e-04 - mae: 0.0054 - mape: 39.9328\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5464e-04 - mae: 0.0056 - mape: 39.7635\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4538e-04 - mae: 0.0054 - mape: 43.2936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.6042e-04 - mae: 0.0056 - mape: 36.7225\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5098e-04 - mae: 0.0055 - mape: 41.3248\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5935e-04 - mae: 0.0054 - mape: 37.6678\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5290e-04 - mae: 0.0055 - mape: 41.0896\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5627e-04 - mae: 0.0055 - mape: 38.2770\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4967e-04 - mae: 0.0054 - mape: 41.1016\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5962e-04 - mae: 0.0053 - mape: 35.5491\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5326e-04 - mae: 0.0053 - mape: 41.3229\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5226e-04 - mae: 0.0054 - mape: 40.6359\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5519e-04 - mae: 0.0055 - mape: 39.7011\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4811e-04 - mae: 0.0054 - mape: 43.8793\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5473e-04 - mae: 0.0054 - mape: 38.0249\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4764e-04 - mae: 0.0054 - mape: 43.4454\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5084e-04 - mae: 0.0053 - mape: 40.1146\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4831e-04 - mae: 0.0055 - mape: 43.1220\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.5442e-04 - mae: 0.0054 - mape: 38.6062\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4861e-04 - mae: 0.0053 - mape: 43.5358\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5324e-04 - mae: 0.0053 - mape: 39.7916\n",
      "Epoch 250/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.5041e-04 - mae: 0.0056 - mape: 41.7592\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5595e-04 - mae: 0.0055 - mape: 38.4885\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4596e-04 - mae: 0.0055 - mape: 43.4788\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 1.4923e-04 - mae: 0.0057 - mape: 45.3295\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4689e-04 - mae: 0.0054 - mape: 41.6635\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5152e-04 - mae: 0.0054 - mape: 40.6655\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0054 - mse: 1.4680e-04 - mae: 0.0054 - mape: 42.8216\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4475e-04 - mae: 0.0053 - mape: 43.8730\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.5491e-04 - mae: 0.0053 - mape: 38.6461\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4751e-04 - mae: 0.0053 - mape: 44.9548\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0058 - mse: 1.5521e-04 - mae: 0.0058 - mape: 40.9762\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 1.4661e-04 - mae: 0.0056 - mape: 45.2632\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5013e-04 - mae: 0.0056 - mape: 46.9509\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5049e-04 - mae: 0.0054 - mape: 42.0492\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4831e-04 - mae: 0.0055 - mape: 43.2967\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4873e-04 - mae: 0.0054 - mape: 43.0525\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5410e-04 - mae: 0.0053 - mape: 40.6993\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4853e-04 - mae: 0.0053 - mape: 44.6350\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.5172e-04 - mae: 0.0053 - mape: 41.9123\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4549e-04 - mae: 0.0053 - mape: 45.5179\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5053e-04 - mae: 0.0053 - mape: 41.5836\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4934e-04 - mae: 0.0053 - mape: 41.4051\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4882e-04 - mae: 0.0053 - mape: 43.4701\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 1.5217e-04 - mae: 0.0061 - mape: 46.0393\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4679e-04 - mae: 0.0053 - mape: 44.7866\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4816e-04 - mae: 0.0052 - mape: 42.7305\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4754e-04 - mae: 0.0052 - mape: 43.9057\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.5169e-04 - mae: 0.0052 - mape: 40.2951\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4618e-04 - mae: 0.0053 - mape: 45.9477\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4534e-04 - mae: 0.0053 - mape: 45.7589\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4667e-04 - mae: 0.0054 - mape: 44.1379\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5027e-04 - mae: 0.0053 - mape: 42.0531\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4844e-04 - mae: 0.0054 - mape: 43.0339\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5243e-04 - mae: 0.0054 - mape: 42.0182\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4610e-04 - mae: 0.0052 - mape: 43.5451\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4459e-04 - mae: 0.0053 - mape: 44.5639\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5377e-04 - mae: 0.0053 - mape: 41.4721\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4769e-04 - mae: 0.0054 - mape: 43.0595\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4633e-04 - mae: 0.0053 - mape: 45.5549\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.5007e-04 - mae: 0.0052 - mape: 41.8771\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4600e-04 - mae: 0.0053 - mape: 45.7010\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 1.4846e-04 - mae: 0.0057 - mape: 46.3602\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4877e-04 - mae: 0.0054 - mape: 44.8477\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4602e-04 - mae: 0.0053 - mape: 44.4490\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4740e-04 - mae: 0.0053 - mape: 43.5656\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4627e-04 - mae: 0.0052 - mape: 44.9624\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4915e-04 - mae: 0.0055 - mape: 42.8062\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5071e-04 - mae: 0.0055 - mape: 42.1747\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4416e-04 - mae: 0.0054 - mape: 47.5289\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.5152e-04 - mae: 0.0052 - mape: 40.9035\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4461e-04 - mae: 0.0053 - mape: 45.5504\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4610e-04 - mae: 0.0053 - mape: 45.4409\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5152e-04 - mae: 0.0055 - mape: 42.4476\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4494e-04 - mae: 0.0055 - mape: 46.4188\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4753e-04 - mae: 0.0053 - mape: 44.6869\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4685e-04 - mae: 0.0053 - mape: 44.8435\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4624e-04 - mae: 0.0054 - mape: 46.9810\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4755e-04 - mae: 0.0053 - mape: 42.7216\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5059e-04 - mae: 0.0053 - mape: 43.2713\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4503e-04 - mae: 0.0053 - mape: 46.8202\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4920e-04 - mae: 0.0054 - mape: 44.8284\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4632e-04 - mae: 0.0053 - mape: 44.4237\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5098e-04 - mae: 0.0053 - mape: 43.3006\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4538e-04 - mae: 0.0052 - mape: 44.7680\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4273e-04 - mae: 0.0055 - mape: 50.6052\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4951e-04 - mae: 0.0054 - mape: 43.7117\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4688e-04 - mae: 0.0053 - mape: 44.9759\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4448e-04 - mae: 0.0054 - mape: 46.4858\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4309e-04 - mae: 0.0053 - mape: 48.0413\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4573e-04 - mae: 0.0052 - mape: 45.2338\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4731e-04 - mae: 0.0053 - mape: 44.5296\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4782e-04 - mae: 0.0053 - mape: 44.1894\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.5106e-04 - mae: 0.0054 - mape: 41.1724\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4675e-04 - mae: 0.0053 - mape: 45.3815\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4187e-04 - mae: 0.0053 - mape: 47.0896\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5010e-04 - mae: 0.0053 - mape: 43.9082\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4267e-04 - mae: 0.0053 - mape: 47.5373\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4776e-04 - mae: 0.0053 - mape: 46.0141\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4726e-04 - mae: 0.0052 - mape: 44.0006\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4583e-04 - mae: 0.0053 - mape: 46.3157\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4223e-04 - mae: 0.0053 - mape: 49.3758\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4890e-04 - mae: 0.0055 - mape: 45.0466\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4347e-04 - mae: 0.0054 - mape: 46.9214\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4398e-04 - mae: 0.0054 - mape: 48.3147\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4639e-04 - mae: 0.0054 - mape: 46.6654\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4524e-04 - mae: 0.0052 - mape: 46.3934 \n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4695e-04 - mae: 0.0052 - mape: 44.8105\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4950e-04 - mae: 0.0053 - mape: 43.3933\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4663e-04 - mae: 0.0054 - mape: 44.6582\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4855e-04 - mae: 0.0053 - mape: 44.2520\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.3948e-04 - mae: 0.0053 - mape: 48.4685\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4298e-04 - mae: 0.0053 - mape: 48.0811\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4846e-04 - mae: 0.0054 - mape: 44.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4373e-04 - mae: 0.0053 - mape: 46.3011\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4490e-04 - mae: 0.0052 - mape: 46.1363\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4592e-04 - mae: 0.0053 - mape: 45.4109\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4360e-04 - mae: 0.0054 - mape: 45.4920\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4347e-04 - mae: 0.0053 - mape: 47.3850\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4880e-04 - mae: 0.0053 - mape: 44.1895\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4350e-04 - mae: 0.0052 - mape: 46.7871\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4636e-04 - mae: 0.0054 - mape: 47.1944\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4403e-04 - mae: 0.0054 - mape: 46.5943\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4604e-04 - mae: 0.0053 - mape: 45.4262\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4605e-04 - mae: 0.0054 - mape: 45.7105\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4403e-04 - mae: 0.0053 - mape: 46.7984\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4355e-04 - mae: 0.0052 - mape: 46.7716\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4673e-04 - mae: 0.0054 - mape: 44.3195\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4665e-04 - mae: 0.0054 - mape: 46.4351\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4566e-04 - mae: 0.0055 - mape: 45.6591\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4434e-04 - mae: 0.0053 - mape: 47.9587\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4928e-04 - mae: 0.0054 - mape: 44.0916\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.4748e-04 - mae: 0.0056 - mape: 50.8016\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4650e-04 - mae: 0.0054 - mape: 42.9060\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4712e-04 - mae: 0.0053 - mape: 45.2845\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4326e-04 - mae: 0.0053 - mape: 48.2849\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4865e-04 - mae: 0.0052 - mape: 43.2666\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4424e-04 - mae: 0.0052 - mape: 46.4672\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4681e-04 - mae: 0.0052 - mape: 44.9211\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4530e-04 - mae: 0.0054 - mape: 46.0856\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4790e-04 - mae: 0.0052 - mape: 46.0582\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4611e-04 - mae: 0.0053 - mape: 45.6257\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4345e-04 - mae: 0.0053 - mape: 47.9316\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4515e-04 - mae: 0.0053 - mape: 47.6237\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4567e-04 - mae: 0.0053 - mape: 44.9667\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4765e-04 - mae: 0.0054 - mape: 44.5196\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4577e-04 - mae: 0.0054 - mape: 45.0320\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.5024e-04 - mae: 0.0055 - mape: 42.7301\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4319e-04 - mae: 0.0053 - mape: 48.1417\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4255e-04 - mae: 0.0055 - mape: 48.2336\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4558e-04 - mae: 0.0053 - mape: 46.6976\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4441e-04 - mae: 0.0055 - mape: 49.0789\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4661e-04 - mae: 0.0052 - mape: 44.4213\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 1.5413e-04 - mae: 0.0056 - mape: 41.3698\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4086e-04 - mae: 0.0053 - mape: 48.3456\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.5134e-04 - mae: 0.0054 - mape: 44.1144\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4289e-04 - mae: 0.0054 - mape: 48.8497\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.5095e-04 - mae: 0.0053 - mape: 40.9710\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.3794e-04 - mae: 0.0055 - mape: 50.8083\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 1.4657e-04 - mae: 0.0057 - mape: 48.8239\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4150e-04 - mae: 0.0052 - mape: 49.1927\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4706e-04 - mae: 0.0052 - mape: 47.2904\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4542e-04 - mae: 0.0052 - mape: 45.5067\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4591e-04 - mae: 0.0052 - mape: 47.2896\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4599e-04 - mae: 0.0053 - mape: 46.1380\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4519e-04 - mae: 0.0053 - mape: 47.9307\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4383e-04 - mae: 0.0052 - mape: 45.4423\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4872e-04 - mae: 0.0054 - mape: 47.2144\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4607e-04 - mae: 0.0055 - mape: 47.0487\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4783e-04 - mae: 0.0053 - mape: 44.3433\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4247e-04 - mae: 0.0054 - mape: 47.8433\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4715e-04 - mae: 0.0053 - mape: 44.3014\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4176e-04 - mae: 0.0053 - mape: 48.9284\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4671e-04 - mae: 0.0052 - mape: 44.2131\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4164e-04 - mae: 0.0055 - mape: 48.4365\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4162e-04 - mae: 0.0052 - mape: 49.6850\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4412e-04 - mae: 0.0052 - mape: 45.7606\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.4532e-04 - mae: 0.0056 - mape: 47.4768\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 1.4533e-04 - mae: 0.0055 - mape: 49.6354\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4250e-04 - mae: 0.0052 - mape: 47.2886\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 1.5612e-04 - mae: 0.0055 - mape: 40.2250\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4803e-04 - mae: 0.0053 - mape: 44.2314\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4336e-04 - mae: 0.0053 - mape: 47.0497\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4410e-04 - mae: 0.0053 - mape: 46.3994\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4484e-04 - mae: 0.0053 - mape: 46.4578\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4194e-04 - mae: 0.0053 - mape: 46.8140\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4900e-04 - mae: 0.0053 - mape: 44.0182\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4335e-04 - mae: 0.0052 - mape: 45.8335\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4483e-04 - mae: 0.0053 - mape: 46.1148\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0052 - mse: 1.4174e-04 - mae: 0.0052 - mape: 48.2036\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0055 - mse: 1.4885e-04 - mae: 0.0055 - mape: 43.4796\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0055 - mse: 1.4271e-04 - mae: 0.0055 - mape: 47.8307\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4146e-04 - mae: 0.0052 - mape: 48.0626\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4798e-04 - mae: 0.0055 - mape: 44.8294\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4631e-04 - mae: 0.0054 - mape: 46.3115\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4603e-04 - mae: 0.0053 - mape: 45.6899\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4542e-04 - mae: 0.0052 - mape: 46.6707\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4765e-04 - mae: 0.0053 - mape: 44.9964\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4805e-04 - mae: 0.0054 - mape: 45.8404\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4745e-04 - mae: 0.0053 - mape: 44.7115\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4512e-04 - mae: 0.0053 - mape: 46.4496\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4806e-04 - mae: 0.0053 - mape: 45.5526\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4668e-04 - mae: 0.0054 - mape: 46.2318\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4439e-04 - mae: 0.0052 - mape: 47.6830\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4754e-04 - mae: 0.0054 - mape: 44.7809\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4209e-04 - mae: 0.0054 - mape: 50.7295\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4627e-04 - mae: 0.0053 - mape: 45.3807\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0053 - mse: 1.4383e-04 - mae: 0.0053 - mape: 47.1706\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0054 - mse: 1.4193e-04 - mae: 0.0054 - mape: 47.1496\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4198e-04 - mae: 0.0053 - mape: 47.9674\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0053 - mse: 1.4908e-04 - mae: 0.0053 - mape: 41.4553\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4164e-04 - mae: 0.0052 - mape: 47.6813\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4343e-04 - mae: 0.0054 - mape: 49.3342\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 1.4643e-04 - mae: 0.0055 - mape: 45.6178\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0056 - mse: 1.4772e-04 - mae: 0.0056 - mape: 46.1827\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4584e-04 - mae: 0.0053 - mape: 45.2758\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4188e-04 - mae: 0.0052 - mape: 47.3417\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4921e-04 - mae: 0.0054 - mape: 44.5164\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4458e-04 - mae: 0.0054 - mape: 45.9369\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4820e-04 - mae: 0.0052 - mape: 42.5564\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4202e-04 - mae: 0.0053 - mape: 51.0595\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4505e-04 - mae: 0.0052 - mape: 45.3840\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4270e-04 - mae: 0.0054 - mape: 49.1043\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4768e-04 - mae: 0.0053 - mape: 45.7414\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4351e-04 - mae: 0.0053 - mape: 45.8889\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4829e-04 - mae: 0.0053 - mape: 44.7615\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4093e-04 - mae: 0.0053 - mape: 49.5516\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4652e-04 - mae: 0.0053 - mape: 46.9498\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4372e-04 - mae: 0.0052 - mape: 46.8129\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4264e-04 - mae: 0.0053 - mape: 48.1333\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4768e-04 - mae: 0.0053 - mape: 45.8162\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4118e-04 - mae: 0.0053 - mape: 47.5751\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4463e-04 - mae: 0.0052 - mape: 47.1787\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4556e-04 - mae: 0.0053 - mape: 48.0343\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4546e-04 - mae: 0.0052 - mape: 46.1299\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4317e-04 - mae: 0.0052 - mape: 47.2980\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4676e-04 - mae: 0.0053 - mape: 47.2787\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4973e-04 - mae: 0.0053 - mape: 42.8420\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4958e-04 - mae: 0.0054 - mape: 42.8959\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4244e-04 - mae: 0.0052 - mape: 48.1238\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4472e-04 - mae: 0.0053 - mape: 47.7592\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 1.4673e-04 - mae: 0.0054 - mape: 46.4178\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4076e-04 - mae: 0.0053 - mape: 49.5361\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4652e-04 - mae: 0.0053 - mape: 46.8926\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4612e-04 - mae: 0.0053 - mape: 45.3262\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4682e-04 - mae: 0.0053 - mape: 44.9457\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4438e-04 - mae: 0.0052 - mape: 46.0015\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4131e-04 - mae: 0.0052 - mape: 46.8544\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4776e-04 - mae: 0.0053 - mape: 47.3342\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4568e-04 - mae: 0.0052 - mape: 46.2426\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4234e-04 - mae: 0.0054 - mape: 49.9003\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.5022e-04 - mae: 0.0053 - mape: 42.9438\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4268e-04 - mae: 0.0053 - mape: 47.9284\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4210e-04 - mae: 0.0052 - mape: 47.3852\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4202e-04 - mae: 0.0053 - mape: 48.1631\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4647e-04 - mae: 0.0053 - mape: 46.2911\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 1.4682e-04 - mae: 0.0056 - mape: 48.2950\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4338e-04 - mae: 0.0053 - mape: 48.5609\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4884e-04 - mae: 0.0053 - mape: 42.1843\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4689e-04 - mae: 0.0055 - mape: 46.1700\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4790e-04 - mae: 0.0053 - mape: 45.4433\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4681e-04 - mae: 0.0052 - mape: 46.6255\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4539e-04 - mae: 0.0053 - mape: 48.1239\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4279e-04 - mae: 0.0053 - mape: 48.1108\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4715e-04 - mae: 0.0054 - mape: 48.1654\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4658e-04 - mae: 0.0053 - mape: 45.2237\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4757e-04 - mae: 0.0052 - mape: 43.1598\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4350e-04 - mae: 0.0053 - mape: 45.4351\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4622e-04 - mae: 0.0053 - mape: 46.2186\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4649e-04 - mae: 0.0052 - mape: 46.0090\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4656e-04 - mae: 0.0053 - mape: 46.3375\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 1.4929e-04 - mae: 0.0054 - mape: 44.5979\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4746e-04 - mae: 0.0053 - mape: 45.9445\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4567e-04 - mae: 0.0053 - mape: 46.4821\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4719e-04 - mae: 0.0053 - mape: 45.2158\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4418e-04 - mae: 0.0052 - mape: 46.9437\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4519e-04 - mae: 0.0053 - mape: 46.3265\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4622e-04 - mae: 0.0053 - mape: 45.6005\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4448e-04 - mae: 0.0053 - mape: 46.6728\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4032e-04 - mae: 0.0054 - mape: 50.5509\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4755e-04 - mae: 0.0054 - mape: 43.1415\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4564e-04 - mae: 0.0052 - mape: 48.8324\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0055 - mse: 1.4676e-04 - mae: 0.0055 - mape: 47.3798\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4625e-04 - mae: 0.0053 - mape: 46.6451\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4817e-04 - mae: 0.0052 - mape: 42.7128\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4550e-04 - mae: 0.0052 - mape: 45.9609\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4286e-04 - mae: 0.0052 - mape: 48.4431\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4408e-04 - mae: 0.0053 - mape: 46.0514\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4661e-04 - mae: 0.0052 - mape: 45.2803\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4167e-04 - mae: 0.0053 - mape: 49.0483\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4792e-04 - mae: 0.0053 - mape: 45.2627\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4462e-04 - mae: 0.0052 - mape: 47.3168\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4293e-04 - mae: 0.0053 - mape: 48.4633\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.5292e-04 - mae: 0.0052 - mape: 40.9342\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4586e-04 - mae: 0.0052 - mape: 45.4462\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4346e-04 - mae: 0.0053 - mape: 47.4605\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4836e-04 - mae: 0.0053 - mape: 43.6860\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4660e-04 - mae: 0.0052 - mape: 45.2010\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4712e-04 - mae: 0.0053 - mape: 45.0045\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4582e-04 - mae: 0.0052 - mape: 45.3696\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4793e-04 - mae: 0.0053 - mape: 43.7557\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 1.4245e-04 - mae: 0.0055 - mape: 49.4201\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4369e-04 - mae: 0.0053 - mape: 48.8500\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4636e-04 - mae: 0.0052 - mape: 44.1630A: 0s - loss: 0.0056 - mse: 1.4793e-04 - mae: 0.0056 - mape:\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4470e-04 - mae: 0.0053 - mape: 46.9903\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0053 - mse: 1.4573e-04 - mae: 0.0053 - mape: 45.6125\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0055 - mse: 1.4805e-04 - mae: 0.0055 - mape: 44.6691\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0054 - mse: 1.4602e-04 - mae: 0.0054 - mape: 45.7636\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4622e-04 - mae: 0.0052 - mape: 44.3863\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4432e-04 - mae: 0.0052 - mape: 46.7812\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4088e-04 - mae: 0.0052 - mape: 50.4357\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4732e-04 - mae: 0.0053 - mape: 44.1557\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4529e-04 - mae: 0.0052 - mape: 46.2878\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4505e-04 - mae: 0.0052 - mape: 46.7471\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4588e-04 - mae: 0.0054 - mape: 46.3291\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4507e-04 - mae: 0.0052 - mape: 46.5357\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4155e-04 - mae: 0.0052 - mape: 47.7696\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.5043e-04 - mae: 0.0053 - mape: 42.6805\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.4570e-04 - mae: 0.0053 - mape: 45.0116\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0053 - mse: 1.4337e-04 - mae: 0.0053 - mape: 46.7335\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0053 - mse: 1.3740e-04 - mae: 0.0053 - mape: 50.8650\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4697e-04 - mae: 0.0052 - mape: 45.2653\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 1.4541e-04 - mae: 0.0054 - mape: 47.1089\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4664e-04 - mae: 0.0053 - mape: 45.1753\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4672e-04 - mae: 0.0053 - mape: 44.5873\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4457e-04 - mae: 0.0052 - mape: 46.8229\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0054 - mse: 1.4604e-04 - mae: 0.0054 - mape: 45.4783\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4394e-04 - mae: 0.0052 - mape: 48.3180\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4225e-04 - mae: 0.0052 - mape: 47.9104\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4331e-04 - mae: 0.0052 - mape: 46.9628\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4747e-04 - mae: 0.0052 - mape: 44.4065\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4697e-04 - mae: 0.0053 - mape: 44.7413\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4837e-04 - mae: 0.0052 - mape: 44.6361\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 1.4503e-04 - mae: 0.0055 - mape: 45.1152\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0055 - mse: 1.4523e-04 - mae: 0.0055 - mape: 46.4526\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4473e-04 - mae: 0.0052 - mape: 45.7520\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4804e-04 - mae: 0.0053 - mape: 44.7120\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0052 - mse: 1.4392e-04 - mae: 0.0052 - mape: 46.4282\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0052 - mse: 1.4461e-04 - mae: 0.0052 - mape: 46.9540\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0052 - mse: 1.4510e-04 - mae: 0.0052 - mape: 45.6911\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4335e-04 - mae: 0.0052 - mape: 46.9563\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4618e-04 - mae: 0.0053 - mape: 45.6943\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4124e-04 - mae: 0.0053 - mape: 47.9014\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4382e-04 - mae: 0.0052 - mape: 46.0542\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4683e-04 - mae: 0.0053 - mape: 45.4891\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4497e-04 - mae: 0.0052 - mape: 45.3208\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4406e-04 - mae: 0.0052 - mape: 46.9059\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4582e-04 - mae: 0.0053 - mape: 47.7453\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4550e-04 - mae: 0.0052 - mape: 45.2453\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4612e-04 - mae: 0.0052 - mape: 45.4387\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 1.4684e-04 - mae: 0.0052 - mape: 45.2274\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 1.4447e-04 - mae: 0.0053 - mape: 46.1052\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4808e-04 - mae: 0.0053 - mape: 44.3410\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4605e-04 - mae: 0.0053 - mape: 47.3951\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 1.4440e-04 - mae: 0.0053 - mape: 46.9347\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4711e-04 - mae: 0.0052 - mape: 43.0702\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4419e-04 - mae: 0.0052 - mape: 47.7173\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 1.4469e-04 - mae: 0.0052 - mape: 46.4383\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4782e-04 - mae: 0.0053 - mape: 43.6502\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4164e-04 - mae: 0.0052 - mape: 49.6010\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4672e-04 - mae: 0.0053 - mape: 44.7458\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 1.4294e-04 - mae: 0.0053 - mape: 48.8968\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 1.4232e-04 - mae: 0.0052 - mape: 50.4219\n",
      "Epoch 592/1000\n",
      "27/53 [==============>...............] - ETA: 0s - loss: 0.0057 - mse: 1.6460e-04 - mae: 0.0057 - mape: 51.2930"
     ]
    }
   ],
   "source": [
    "# Silly Coercsion for ICML rebuttle deadline timeline\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    Iteration_Length = len(X_parts_list) -1\n",
    "else:\n",
    "    Iteration_Length = len(X_parts_list)\n",
    "\n",
    "    \n",
    "# Train each part!\n",
    "for current_part in range(Iteration_Length):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' Have a great day!!  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "plt.scatter(x_1,y_1,color='slategrey',label=r'$f_1(x)$',linestyle=(0,(1,1)),s=3,alpha=.9,marker=1)\n",
    "plt.scatter(x_2,y_2,color='dodgerblue',label=r'$f_2(x)$',linestyle=(0,(1,1)),s=3,alpha=.9,marker=1)\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'darkmagenta',linestyle=(0,(1,10)),  label='ffNN',s=3,alpha=.95)\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'mediumseagreen',linestyle=(0,(1,10)), label='tope',s=3,alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.legend(loc=\"upper left\",prop={'size': 10})\n",
    "plt.title(\"Model Predictions\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/DEMO.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
