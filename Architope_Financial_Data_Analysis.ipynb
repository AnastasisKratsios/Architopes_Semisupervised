{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .2\n",
    "N = 100\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 10\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66\n",
      "0.47\n",
      "0.3\n",
      "0.18\n",
      "0.03\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    \n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 6 parts.\n",
      "Heights to iterate over: [66]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4724 - mse: 0.6142 - mae: 0.4724 - mape: 3458.7659\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7206 - mse: 0.8390 - mae: 0.7206 - mape: 3452.6594\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6415 - mse: 0.4318 - mae: 0.6415 - mape: 3174.9902\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2456 - mse: 0.0639 - mae: 0.2456 - mape: 1259.5792\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3280 - mse: 0.1146 - mae: 0.3280 - mape: 2047.6375\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.0606 - mae: 0.2401 - mape: 1250.7145\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1866 - mse: 0.0437 - mae: 0.1866 - mape: 1112.2954\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2552 - mse: 0.0690 - mae: 0.2552 - mape: 1617.4921\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1700 - mse: 0.0359 - mae: 0.1700 - mape: 867.7296\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0071 - mae: 0.0639 - mape: 287.4614\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1390 - mse: 0.0233 - mae: 0.1390 - mape: 783.9976\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1007 - mse: 0.0154 - mae: 0.1007 - mape: 863.8745\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4389 - mse: 0.1952 - mae: 0.4389 - mape: 2426.7974\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0958 - mse: 0.0144 - mae: 0.0958 - mape: 733.7739\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1863 - mse: 0.0384 - mae: 0.1863 - mape: 766.1979\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1802 - mse: 0.0354 - mae: 0.1802 - mape: 1186.1665\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0101 - mae: 0.0860 - mape: 284.8311\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1703 - mse: 0.0429 - mae: 0.1703 - mape: 1257.0858\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0948 - mse: 0.0115 - mae: 0.0948 - mape: 556.4417\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1031 - mse: 0.0122 - mae: 0.1031 - mape: 547.9602\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0975 - mse: 0.0135 - mae: 0.0975 - mape: 775.7685\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0895 - mse: 0.0101 - mae: 0.0895 - mape: 471.3016\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0025 - mae: 0.0426 - mape: 300.1657\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1475 - mse: 0.0243 - mae: 0.1475 - mape: 579.1323\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.0187 - mae: 0.1290 - mape: 911.7875\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0775 - mse: 0.0085 - mae: 0.0775 - mape: 305.0096\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0068 - mae: 0.0750 - mape: 560.5046\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0011 - mae: 0.0240 - mape: 60.5589\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1715 - mse: 0.0312 - mae: 0.1715 - mape: 1088.9121\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1378 - mse: 0.0208 - mae: 0.1378 - mape: 619.8555\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0070 - mae: 0.0678 - mape: 379.1430\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1435 - mse: 0.0262 - mae: 0.1435 - mape: 952.2734\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1018 - mse: 0.0131 - mae: 0.1018 - mape: 523.3960\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0772 - mse: 0.0092 - mae: 0.0772 - mape: 460.7373\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0346 - mse: 0.0016 - mae: 0.0346 - mape: 225.1881\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0019 - mae: 0.0366 - mape: 164.0962\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0016 - mae: 0.0331 - mape: 112.2239\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0017 - mae: 0.0315 - mape: 109.9649\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0015 - mae: 0.0316 - mape: 138.1524\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0503 - mse: 0.0033 - mae: 0.0503 - mape: 274.3461\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.0185 - mae: 0.1315 - mape: 854.3433\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0885 - mse: 0.0088 - mae: 0.0885 - mape: 487.6824\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0027 - mae: 0.0433 - mape: 312.0258\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0027 - mae: 0.0421 - mape: 150.3236\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0334 - mse: 0.0015 - mae: 0.0334 - mape: 168.8420\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0021 - mae: 0.0356 - mape: 130.2367\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0017 - mae: 0.0356 - mape: 245.6233\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0019 - mae: 0.0342 - mape: 118.2647\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 9.7372e-04 - mae: 0.0247 - mape: 81.2103\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 7.9272e-04 - mae: 0.0223 - mape: 78.9475\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 1: given 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-396c6d7cfc74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_part\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Register quality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtraining_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_train_full_loop\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtraining_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# TODO: why are we passing flex=True instead of flex=not special?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;31m#  15 tests fail if we pass flex=not special instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                 )\n\u001b[1;32m    468\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 1: given 100"
     ]
    }
   ],
   "source": [
    "for current_part in range(len(X_parts_list)):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'partition_labels_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-490edcf1ce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Redefine (Dimension-related) Elements of Grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mparam_grid_Deep_Classifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_dim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mparam_grid_Deep_Classifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_dim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpartition_labels_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'partition_labels_training' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partition_labels_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ae93d496ead6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                                         \u001b[0mparam_grid_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_Deep_Classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                                                         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                                                                         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition_labels_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                                                                         X_test = X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partition_labels_training' is not defined"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Architope_deep_classifier_training_begin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-98d2b96958c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Time-Elapsed Training Deep Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mArchitope_deep_classifier_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mArchitope_deep_classifier_training_begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Architope_deep_classifier_training_begin' is not defined"
     ]
    }
   ],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partition_labels_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a126bb9241dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Update User on shape of learned partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_labels_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'partition_labels_training' is not defined"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ee186027794f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_labels_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('😃😃 Have a great day!! 😃😃 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
