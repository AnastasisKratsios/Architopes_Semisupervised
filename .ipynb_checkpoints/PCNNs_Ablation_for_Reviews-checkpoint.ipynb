{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50\n",
    "# Ablation Finess\n",
    "N_plot_finess = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  5001\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ablate_PCNNs(q_inplicit_N_parts,data_y,X_train,X_test,y_test):\n",
    "    #---------------------#\n",
    "    # Building Partitions #\n",
    "    #---------------------#\n",
    "\n",
    "    ############# Partitioner Begin #######\n",
    "    import time\n",
    "    partitioning_time_begin = time.time()\n",
    "    if Option_Function == 'SnP':\n",
    "        q_in_auto = q_inplicit_N_parts\n",
    "        Min_data_size_percentage_auto = .1\n",
    "        min_size_part = 100\n",
    "    else:\n",
    "        if Option_Function == 'crypto':\n",
    "            q_in_auto = .99\n",
    "            Min_data_size_percentage_auto = .3\n",
    "            min_size_part = 100\n",
    "        if Option_Function == 'Motivational_Example':\n",
    "            q_in_auto = q_inplicit_N_parts\n",
    "            Min_data_size_percentage_auto = .5\n",
    "            min_size_part = 10\n",
    "            # Partition Based on Y\n",
    "            holder_temp = data_y\n",
    "            data_y = X_train\n",
    "            X_train = holder_temp\n",
    "        else:\n",
    "            q_in_auto = .5\n",
    "            Min_data_size_percentage_auto = .3\n",
    "            min_size_part = 100\n",
    "\n",
    "    # Initialize Number of Parts currently generated\n",
    "    N_parts_generated = 0\n",
    "\n",
    "    # Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "    while N_parts_generated < 2:\n",
    "        # Generate Parts\n",
    "        X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                          q_in=q_in_auto, \n",
    "                                                                          X_train_in=X_train, \n",
    "                                                                          y_train_in=data_y, \n",
    "                                                                          CV_folds_failsafe=CV_folds,\n",
    "                                                                          min_size = min_size_part)\n",
    "\n",
    "        # Update Number of Parts\n",
    "        N_parts_generated = len(X_parts_list)\n",
    "        # Shuffle hyperparameters\n",
    "        Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "        q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "\n",
    "        # Update User\n",
    "        print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "\n",
    "    # Trash removal (removes empty parts)\n",
    "    X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "    y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "\n",
    "\n",
    "    # ICML Rebuttle Deadline = Coersion!\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "        holder_temp = y_parts_list\n",
    "        y_parts_list = X_parts_list\n",
    "        X_parts_list = holder_temp\n",
    "\n",
    "\n",
    "    partitioning_time = time.time() - partitioning_time_begin\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    # Record the number of parts:\n",
    "    N_parts_Generated_by_Algo_2 = len(X_parts_list)\n",
    "    ############# Partitioner End ########\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------#\n",
    "    # #### Building Training Predictions on each part\n",
    "    #-----------------------------------------------#\n",
    "    # - Train locally (on each \"naive part\")\n",
    "    # - Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "    # - Generate predictions on all of testing-set (will be selected between later using classifier)\n",
    "\n",
    "    # Time-Elapse (Start) for Training on Each Part #\n",
    "    Architope_partition_training_begin = time.time()\n",
    "    # Initialize running max for Parallel time\n",
    "    Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "    # Initialize N_parameter counter for Architope\n",
    "    N_params_Architope = 0\n",
    "\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Silly Coercsion for ICML rebuttle deadline timeline\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        Iteration_Length = len(X_parts_list) -1\n",
    "    else:\n",
    "        Iteration_Length = len(X_parts_list)\n",
    "\n",
    "\n",
    "    # Initialize Parameter Counter\n",
    "    N_params_tally = 0\n",
    "    # Train each part!\n",
    "    for current_part in range(Iteration_Length):\n",
    "        #==============#\n",
    "        # Timer(begin) #\n",
    "        #==============#\n",
    "        current_part_training_time_for_parallel_begin = time.time()\n",
    "\n",
    "\n",
    "        # Initializations #\n",
    "        #-----------------#\n",
    "        # Reload Grid\n",
    "        exec(open('Grid_Enhanced_Network.py').read())\n",
    "        # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "        current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "        current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "        current_height = np.maximum(current_height,current_height_threshold)/N_parts_Generated_by_Algo_2\n",
    "        current_height = current_height.astype(int).tolist()\n",
    "        param_grid_Vanilla_Nets['height'] = current_height\n",
    "        # Automatically Fix Input Dimension\n",
    "        param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "        param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "        \n",
    "        # Update Parameter Counter for PC-NNs (tally parameter count for sub-patterns)\n",
    "        N_params_tally += (current_height[0])*(param_grid_Vanilla_Nets['depth'][0])\n",
    "\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "        print('Heights to iterate over: '+str(current_height))\n",
    "\n",
    "        # Generate Prediction(s) on current Part #\n",
    "        #----------------------------------------#\n",
    "        # Failsafe (number of data-points)\n",
    "        CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "        # Train Network\n",
    "        y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                          n_jobs = n_jobs,\n",
    "                                                                                          n_iter = n_iter, \n",
    "                                                                                          param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                          X_train= X_parts_list[current_part], \n",
    "                                                                                          y_train=y_parts_list[current_part],\n",
    "                                                                                          X_test_partial=X_train,\n",
    "                                                                                          X_test=X_test,\n",
    "                                                                                          NOCV=True)\n",
    "        #put shape formats in order\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_train_full_loop.shape = (y_hat_train_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_test_full_loop.shape = (y_hat_test_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "            training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_train_full_loop\n",
    "            predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "            predictions_test = y_hat_test_full_loop\n",
    "            predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "\n",
    "\n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "        # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "            predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "            y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "            predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "\n",
    "        #============#\n",
    "        # Timer(end) #\n",
    "        #============#\n",
    "        current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "        Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "        #============---===============#\n",
    "\n",
    "        # N_parameter Counter (Update) #\n",
    "        #------------===---------------#\n",
    "        N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "    # Update User\n",
    "    #-------------#\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('----------------------------------------------------')\n",
    "    print('Feature Generation (Learning Phase): Score Generated')\n",
    "    print('----------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "\n",
    "    # Time-Elapsed Training on Each Part\n",
    "    Architope_partition_training = time.time() - Architope_partition_training_begin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------#\n",
    "    # Train Deep Zero-Sets #\n",
    "    #----------------------#\n",
    "    #### Deep Classifier\n",
    "    # Prepare Labels/Classes\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training_begin = time.time()\n",
    "    # Initialize Classes Labels\n",
    "    partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    # Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    # Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    #### Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary.\n",
    "    # Re-Load Hyper-parameter Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Re-Load Helper Function(s)\n",
    "    exec(open('Helper_Functions.py').read())\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]\n",
    "    ## Re-adjust heights\n",
    "    param_grid_Deep_Classifier['height'] = [int(max(round(param_grid_Deep_Classifier['height'][0]/N_parts_Generated_by_Algo_2,0),1))]\n",
    "\n",
    "    \n",
    "    # Update Parameter Counter for PC-NNs (tally parameter count for sub-patterns)\n",
    "    N_params_tally += (param_grid_Deep_Classifier['height'][0])*(param_grid_Deep_Classifier['depth'][0])\n",
    "    \n",
    "    #### Train Deep Classifier\n",
    "    # Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train.values, \n",
    "                                                                                                        y_train = partition_labels_training.values,\n",
    "                                                                                                        X_test = X_test.values)\n",
    "    # COMMENT: .values() is used to convert the Pandas Dataframes here, and not in the vanilla ffNNs, since the former is coded in Keras and the latter in tensorflow.  \n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin\n",
    "\n",
    "    ##### Get Binary Classes (Discontinuous Unit)\n",
    "    #Maps deep classifier's outputs $\\tilde{C}(x)\\triangleq \\hat{s}(x)$ to deep zero-sets $I_{(.5,1]}\\circ \\sigma_{\\mbox{sigmoid}}(\\tilde{C}(x))$.\n",
    "\n",
    "    # Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>.5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "    # Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > .5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)\n",
    "    #### Get PC-NN Prediction(s)\n",
    "    # Comuptes $\\sum_{n=1}^N \\, \\hat{f}(x)\\cdot I_{K_n}$\n",
    "    # Train\n",
    "    Architope_prediction_y_train = (predictions_train*predicted_classes_train).sum(axis=1)\n",
    "    # Test\n",
    "    Architope_prediction_y_test = (predictions_test*predicted_classes_test).sum(axis=1)\n",
    "\n",
    "\n",
    "    # Compute Peformance\n",
    "    performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "    # Update User\n",
    "    print(performance_Architope)\n",
    "\n",
    "    ### Model Complexity/Efficiency Metrics\n",
    "    # Compute Parameters for composite models #\n",
    "    #-----------------------------------------#\n",
    "    N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "    # Build AIC-like Metric #\n",
    "    #-----------------------#\n",
    "    AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "    AIC_like = np.round(AIC_like,3)\n",
    "    Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "    Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "    # Build Table #\n",
    "    #-------------#\n",
    "    Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "    # Write Required Training Time(s)\n",
    "    Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "    #--------------======---------------#\n",
    "    # Display Required Training Time(s) #\n",
    "    #--------------======---------------#\n",
    "    print(Architope_Model_Complexity_full)\n",
    "    \n",
    "    # Return Performance Metrics\n",
    "    return performance_Architope, Architope_Model_Complexity_full, N_parts_Generated_by_Algo_2, N_params_tally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform Ablation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.365126974605079\n",
      "0.006798640271945611\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 4.\n",
      "The_parts_listhe number of parts are: 3.\n",
      "Status: Current part: 0 out of : 3 parts.\n",
      "Heights to iterate over: [24]\n",
      "WARNING:tensorflow:From /Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 3175 samples\n",
      "Epoch 1/200\n",
      "3175/3175 [==============================] - 1s 181us/sample - loss: 0.1726 - mse: 0.0512 - mae: 0.1726 - mape: 104.8115\n",
      "Epoch 2/200\n",
      "3175/3175 [==============================] - 0s 49us/sample - loss: 0.1531 - mse: 0.0434 - mae: 0.1531 - mape: 100.8312\n",
      "Epoch 3/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.1406 - mse: 0.0368 - mae: 0.1406 - mape: 145.1670\n",
      "Epoch 4/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.1325 - mse: 0.0311 - mae: 0.1325 - mape: 199.4869\n",
      "Epoch 5/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.1243 - mse: 0.0253 - mae: 0.1243 - mape: 266.7639\n",
      "Epoch 6/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.1169 - mse: 0.0207 - mae: 0.1169 - mape: 330.5723\n",
      "Epoch 7/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.1131 - mse: 0.0184 - mae: 0.1131 - mape: 366.5504\n",
      "Epoch 8/200\n",
      "3175/3175 [==============================] - 0s 54us/sample - loss: 0.1104 - mse: 0.0171 - mae: 0.1104 - mape: 374.2261\n",
      "Epoch 9/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.1074 - mse: 0.0161 - mae: 0.1074 - mape: 364.0136\n",
      "Epoch 10/200\n",
      "3175/3175 [==============================] - 0s 65us/sample - loss: 0.1035 - mse: 0.0150 - mae: 0.1035 - mape: 342.3015\n",
      "Epoch 11/200\n",
      "3175/3175 [==============================] - 0s 62us/sample - loss: 0.0987 - mse: 0.0137 - mae: 0.0987 - mape: 316.7775\n",
      "Epoch 12/200\n",
      "3175/3175 [==============================] - 0s 73us/sample - loss: 0.0922 - mse: 0.0122 - mae: 0.0922 - mape: 280.4133\n",
      "Epoch 13/200\n",
      "3175/3175 [==============================] - 0s 63us/sample - loss: 0.0835 - mse: 0.0105 - mae: 0.0835 - mape: 224.9725\n",
      "Epoch 14/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0727 - mse: 0.0087 - mae: 0.0727 - mape: 151.2494\n",
      "Epoch 15/200\n",
      "3175/3175 [==============================] - 0s 49us/sample - loss: 0.0635 - mse: 0.0067 - mae: 0.0635 - mape: 106.3043\n",
      "Epoch 16/200\n",
      "3175/3175 [==============================] - 0s 52us/sample - loss: 0.0579 - mse: 0.0056 - mae: 0.0579 - mape: 89.6975\n",
      "Epoch 17/200\n",
      "3175/3175 [==============================] - 0s 63us/sample - loss: 0.0534 - mse: 0.0052 - mae: 0.0534 - mape: 91.3077\n",
      "Epoch 18/200\n",
      "3175/3175 [==============================] - 0s 70us/sample - loss: 0.0517 - mse: 0.0049 - mae: 0.0517 - mape: 109.3727\n",
      "Epoch 19/200\n",
      "3175/3175 [==============================] - 0s 67us/sample - loss: 0.0512 - mse: 0.0046 - mae: 0.0512 - mape: 122.2532\n",
      "Epoch 20/200\n",
      "3175/3175 [==============================] - 0s 73us/sample - loss: 0.0507 - mse: 0.0043 - mae: 0.0507 - mape: 125.4645\n",
      "Epoch 21/200\n",
      "3175/3175 [==============================] - 0s 61us/sample - loss: 0.0504 - mse: 0.0042 - mae: 0.0504 - mape: 131.8632\n",
      "Epoch 22/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0501 - mse: 0.0042 - mae: 0.0501 - mape: 139.9680\n",
      "Epoch 23/200\n",
      "3175/3175 [==============================] - 0s 85us/sample - loss: 0.0499 - mse: 0.0042 - mae: 0.0499 - mape: 143.6204\n",
      "Epoch 24/200\n",
      "3175/3175 [==============================] - 0s 90us/sample - loss: 0.0498 - mse: 0.0042 - mae: 0.0498 - mape: 144.2085\n",
      "Epoch 25/200\n",
      "3175/3175 [==============================] - 0s 73us/sample - loss: 0.0497 - mse: 0.0042 - mae: 0.0497 - mape: 145.3533\n",
      "Epoch 26/200\n",
      "3175/3175 [==============================] - 0s 81us/sample - loss: 0.0496 - mse: 0.0042 - mae: 0.0496 - mape: 145.8776\n",
      "Epoch 27/200\n",
      "3175/3175 [==============================] - 0s 71us/sample - loss: 0.0494 - mse: 0.0042 - mae: 0.0494 - mape: 144.3213\n",
      "Epoch 28/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0493 - mse: 0.0042 - mae: 0.0493 - mape: 142.6333\n",
      "Epoch 29/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0492 - mse: 0.0042 - mae: 0.0492 - mape: 144.6870\n",
      "Epoch 30/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0491 - mse: 0.0042 - mae: 0.0491 - mape: 140.5372\n",
      "Epoch 31/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0491 - mse: 0.0042 - mae: 0.0491 - mape: 143.8096\n",
      "Epoch 32/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0489 - mse: 0.0042 - mae: 0.0489 - mape: 142.2917\n",
      "Epoch 33/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0487 - mse: 0.0042 - mae: 0.0487 - mape: 143.7224\n",
      "Epoch 34/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0486 - mse: 0.0042 - mae: 0.0486 - mape: 142.7049\n",
      "Epoch 35/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0485 - mse: 0.0041 - mae: 0.0485 - mape: 141.7184\n",
      "Epoch 36/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0484 - mse: 0.0042 - mae: 0.0484 - mape: 140.3043\n",
      "Epoch 37/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0483 - mse: 0.0041 - mae: 0.0483 - mape: 138.8887\n",
      "Epoch 38/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0482 - mse: 0.0042 - mae: 0.0482 - mape: 140.5920\n",
      "Epoch 39/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0481 - mse: 0.0041 - mae: 0.0481 - mape: 139.8471\n",
      "Epoch 40/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0480 - mse: 0.0041 - mae: 0.0480 - mape: 140.5549\n",
      "Epoch 41/200\n",
      "3175/3175 [==============================] - 0s 56us/sample - loss: 0.0478 - mse: 0.0041 - mae: 0.0478 - mape: 138.6380\n",
      "Epoch 42/200\n",
      "3175/3175 [==============================] - 0s 62us/sample - loss: 0.0478 - mse: 0.0041 - mae: 0.0478 - mape: 139.1219\n",
      "Epoch 43/200\n",
      "3175/3175 [==============================] - 0s 59us/sample - loss: 0.0477 - mse: 0.0041 - mae: 0.0477 - mape: 136.4364\n",
      "Epoch 44/200\n",
      "3175/3175 [==============================] - 0s 62us/sample - loss: 0.0475 - mse: 0.0041 - mae: 0.0475 - mape: 137.1076\n",
      "Epoch 45/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0474 - mse: 0.0041 - mae: 0.0474 - mape: 138.5048\n",
      "Epoch 46/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0473 - mse: 0.0041 - mae: 0.0473 - mape: 135.4650\n",
      "Epoch 47/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0472 - mse: 0.0041 - mae: 0.0472 - mape: 135.6954\n",
      "Epoch 48/200\n",
      "3175/3175 [==============================] - 0s 53us/sample - loss: 0.0470 - mse: 0.0041 - mae: 0.0470 - mape: 135.8390\n",
      "Epoch 49/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0470 - mse: 0.0041 - mae: 0.0470 - mape: 134.4413\n",
      "Epoch 50/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0468 - mse: 0.0041 - mae: 0.0468 - mape: 133.9490\n",
      "Epoch 51/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0467 - mse: 0.0041 - mae: 0.0467 - mape: 134.4515\n",
      "Epoch 52/200\n",
      "3175/3175 [==============================] - 0s 53us/sample - loss: 0.0466 - mse: 0.0041 - mae: 0.0466 - mape: 134.2218\n",
      "Epoch 53/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0465 - mse: 0.0041 - mae: 0.0465 - mape: 136.0823\n",
      "Epoch 54/200\n",
      "3175/3175 [==============================] - 0s 56us/sample - loss: 0.0464 - mse: 0.0041 - mae: 0.0464 - mape: 133.2982\n",
      "Epoch 55/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0463 - mse: 0.0040 - mae: 0.0463 - mape: 131.9589\n",
      "Epoch 56/200\n",
      "3175/3175 [==============================] - 0s 52us/sample - loss: 0.0462 - mse: 0.0041 - mae: 0.0462 - mape: 133.6548\n",
      "Epoch 57/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0461 - mse: 0.0041 - mae: 0.0461 - mape: 132.9857\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0460 - mse: 0.0040 - mae: 0.0460 - mape: 131.2300\n",
      "Epoch 59/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0459 - mse: 0.0041 - mae: 0.0459 - mape: 132.4194\n",
      "Epoch 60/200\n",
      "3175/3175 [==============================] - 0s 62us/sample - loss: 0.0458 - mse: 0.0040 - mae: 0.0458 - mape: 130.7291\n",
      "Epoch 61/200\n",
      "3175/3175 [==============================] - 0s 61us/sample - loss: 0.0456 - mse: 0.0040 - mae: 0.0456 - mape: 129.2468\n",
      "Epoch 62/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0455 - mse: 0.0041 - mae: 0.0455 - mape: 130.1954\n",
      "Epoch 63/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0455 - mse: 0.0040 - mae: 0.0455 - mape: 128.1259\n",
      "Epoch 64/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0454 - mse: 0.0040 - mae: 0.0454 - mape: 129.5849\n",
      "Epoch 65/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0452 - mse: 0.0040 - mae: 0.0452 - mape: 129.7225\n",
      "Epoch 66/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0451 - mse: 0.0040 - mae: 0.0451 - mape: 129.2147\n",
      "Epoch 67/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0450 - mse: 0.0040 - mae: 0.0450 - mape: 127.2077\n",
      "Epoch 68/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0449 - mse: 0.0040 - mae: 0.0449 - mape: 127.3369\n",
      "Epoch 69/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0448 - mse: 0.0040 - mae: 0.0448 - mape: 128.1092\n",
      "Epoch 70/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0447 - mse: 0.0040 - mae: 0.0447 - mape: 127.1107\n",
      "Epoch 71/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0447 - mse: 0.0040 - mae: 0.0447 - mape: 127.0391\n",
      "Epoch 72/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0446 - mse: 0.0040 - mae: 0.0446 - mape: 127.6500\n",
      "Epoch 73/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0444 - mse: 0.0040 - mae: 0.0444 - mape: 127.7196\n",
      "Epoch 74/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0444 - mse: 0.0040 - mae: 0.0444 - mape: 125.5907\n",
      "Epoch 75/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0443 - mse: 0.0040 - mae: 0.0443 - mape: 125.3817\n",
      "Epoch 76/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0441 - mse: 0.0040 - mae: 0.0441 - mape: 124.3832\n",
      "Epoch 77/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0440 - mse: 0.0040 - mae: 0.0440 - mape: 125.6446\n",
      "Epoch 78/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0440 - mse: 0.0040 - mae: 0.0440 - mape: 124.3904\n",
      "Epoch 79/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0438 - mse: 0.0040 - mae: 0.0438 - mape: 125.0246\n",
      "Epoch 80/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0438 - mse: 0.0040 - mae: 0.0438 - mape: 122.6532\n",
      "Epoch 81/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0437 - mse: 0.0040 - mae: 0.0437 - mape: 125.1610\n",
      "Epoch 82/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0436 - mse: 0.0040 - mae: 0.0436 - mape: 123.7379\n",
      "Epoch 83/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0435 - mse: 0.0040 - mae: 0.0435 - mape: 121.7814\n",
      "Epoch 84/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0434 - mse: 0.0040 - mae: 0.0434 - mape: 123.6270\n",
      "Epoch 85/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0433 - mse: 0.0039 - mae: 0.0433 - mape: 120.8509\n",
      "Epoch 86/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0432 - mse: 0.0040 - mae: 0.0432 - mape: 121.6252\n",
      "Epoch 87/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0432 - mse: 0.0040 - mae: 0.0432 - mape: 121.4952\n",
      "Epoch 88/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0431 - mse: 0.0040 - mae: 0.0431 - mape: 121.1220\n",
      "Epoch 89/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0429 - mse: 0.0040 - mae: 0.0429 - mape: 121.1536\n",
      "Epoch 90/200\n",
      "3175/3175 [==============================] - 0s 62us/sample - loss: 0.0428 - mse: 0.0040 - mae: 0.0428 - mape: 120.3824\n",
      "Epoch 91/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0427 - mse: 0.0040 - mae: 0.0427 - mape: 120.8979\n",
      "Epoch 92/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0427 - mse: 0.0040 - mae: 0.0427 - mape: 120.2069\n",
      "Epoch 93/200\n",
      "3175/3175 [==============================] - 0s 56us/sample - loss: 0.0426 - mse: 0.0040 - mae: 0.0426 - mape: 121.0955\n",
      "Epoch 94/200\n",
      "3175/3175 [==============================] - 0s 53us/sample - loss: 0.0425 - mse: 0.0039 - mae: 0.0425 - mape: 117.9287\n",
      "Epoch 95/200\n",
      "3175/3175 [==============================] - 0s 52us/sample - loss: 0.0424 - mse: 0.0040 - mae: 0.0424 - mape: 119.7810\n",
      "Epoch 96/200\n",
      "3175/3175 [==============================] - 0s 54us/sample - loss: 0.0423 - mse: 0.0039 - mae: 0.0423 - mape: 119.1279\n",
      "Epoch 97/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0422 - mse: 0.0039 - mae: 0.0422 - mape: 115.6502\n",
      "Epoch 98/200\n",
      "3175/3175 [==============================] - 0s 75us/sample - loss: 0.0421 - mse: 0.0040 - mae: 0.0421 - mape: 118.5619\n",
      "Epoch 99/200\n",
      "3175/3175 [==============================] - 0s 57us/sample - loss: 0.0420 - mse: 0.0039 - mae: 0.0420 - mape: 117.0524\n",
      "Epoch 100/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0419 - mse: 0.0039 - mae: 0.0419 - mape: 117.2528\n",
      "Epoch 101/200\n",
      "3175/3175 [==============================] - 0s 55us/sample - loss: 0.0418 - mse: 0.0039 - mae: 0.0418 - mape: 116.9597\n",
      "Epoch 102/200\n",
      "3175/3175 [==============================] - 0s 61us/sample - loss: 0.0417 - mse: 0.0039 - mae: 0.0417 - mape: 116.4752\n",
      "Epoch 103/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0417 - mse: 0.0039 - mae: 0.0417 - mape: 116.0314\n",
      "Epoch 104/200\n",
      "3175/3175 [==============================] - 0s 58us/sample - loss: 0.0415 - mse: 0.0039 - mae: 0.0415 - mape: 114.3266\n",
      "Epoch 105/200\n",
      "3175/3175 [==============================] - 0s 52us/sample - loss: 0.0414 - mse: 0.0039 - mae: 0.0414 - mape: 116.2833\n",
      "Epoch 106/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0413 - mse: 0.0039 - mae: 0.0413 - mape: 113.6421\n",
      "Epoch 107/200\n",
      "3175/3175 [==============================] - 0s 52us/sample - loss: 0.0412 - mse: 0.0039 - mae: 0.0412 - mape: 112.5275\n",
      "Epoch 108/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0411 - mse: 0.0039 - mae: 0.0411 - mape: 114.4592\n",
      "Epoch 109/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0410 - mse: 0.0039 - mae: 0.0410 - mape: 113.3065\n",
      "Epoch 110/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0408 - mse: 0.0039 - mae: 0.0408 - mape: 113.1409\n",
      "Epoch 111/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0407 - mse: 0.0039 - mae: 0.0407 - mape: 111.3106\n",
      "Epoch 112/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0406 - mse: 0.0039 - mae: 0.0406 - mape: 111.5616\n",
      "Epoch 113/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0404 - mse: 0.0039 - mae: 0.0404 - mape: 109.8029\n",
      "Epoch 114/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0403 - mse: 0.0039 - mae: 0.0403 - mape: 107.5442\n",
      "Epoch 115/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0402 - mse: 0.0039 - mae: 0.0402 - mape: 109.8293\n",
      "Epoch 116/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0400 - mse: 0.0039 - mae: 0.0400 - mape: 106.6543\n",
      "Epoch 117/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0398 - mse: 0.0039 - mae: 0.0398 - mape: 107.1009\n",
      "Epoch 118/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0397 - mse: 0.0039 - mae: 0.0397 - mape: 105.3787\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0395 - mse: 0.0039 - mae: 0.0395 - mape: 104.8874\n",
      "Epoch 120/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0393 - mse: 0.0039 - mae: 0.0393 - mape: 104.4030\n",
      "Epoch 121/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0391 - mse: 0.0039 - mae: 0.0391 - mape: 103.6632\n",
      "Epoch 122/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0389 - mse: 0.0039 - mae: 0.0389 - mape: 101.0492\n",
      "Epoch 123/200\n",
      "3175/3175 [==============================] - 0s 65us/sample - loss: 0.0387 - mse: 0.0039 - mae: 0.0387 - mape: 101.0154\n",
      "Epoch 124/200\n",
      "3175/3175 [==============================] - 0s 58us/sample - loss: 0.0385 - mse: 0.0039 - mae: 0.0385 - mape: 100.4664\n",
      "Epoch 125/200\n",
      "3175/3175 [==============================] - 0s 59us/sample - loss: 0.0383 - mse: 0.0039 - mae: 0.0383 - mape: 98.3344\n",
      "Epoch 126/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0381 - mse: 0.0038 - mae: 0.0381 - mape: 96.8712\n",
      "Epoch 127/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0378 - mse: 0.0039 - mae: 0.0378 - mape: 95.9378\n",
      "Epoch 128/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0376 - mse: 0.0038 - mae: 0.0376 - mape: 92.4157\n",
      "Epoch 129/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0373 - mse: 0.0038 - mae: 0.0373 - mape: 92.6364\n",
      "Epoch 130/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0370 - mse: 0.0038 - mae: 0.0370 - mape: 92.3183\n",
      "Epoch 131/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0367 - mse: 0.0038 - mae: 0.0367 - mape: 90.3474\n",
      "Epoch 132/200\n",
      "3175/3175 [==============================] - 0s 56us/sample - loss: 0.0364 - mse: 0.0038 - mae: 0.0364 - mape: 86.9921\n",
      "Epoch 133/200\n",
      "3175/3175 [==============================] - 0s 51us/sample - loss: 0.0360 - mse: 0.0038 - mae: 0.0360 - mape: 85.2540\n",
      "Epoch 134/200\n",
      "3175/3175 [==============================] - 0s 53us/sample - loss: 0.0357 - mse: 0.0038 - mae: 0.0357 - mape: 83.0741\n",
      "Epoch 135/200\n",
      "3175/3175 [==============================] - 0s 58us/sample - loss: 0.0354 - mse: 0.0039 - mae: 0.0354 - mape: 84.7352\n",
      "Epoch 136/200\n",
      "3175/3175 [==============================] - 0s 50us/sample - loss: 0.0350 - mse: 0.0038 - mae: 0.0350 - mape: 79.8527\n",
      "Epoch 137/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0345 - mse: 0.0038 - mae: 0.0345 - mape: 77.0414\n",
      "Epoch 138/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0341 - mse: 0.0038 - mae: 0.0341 - mape: 76.8510\n",
      "Epoch 139/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0336 - mse: 0.0038 - mae: 0.0336 - mape: 72.0885\n",
      "Epoch 140/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0332 - mse: 0.0038 - mae: 0.0332 - mape: 70.5257\n",
      "Epoch 141/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0326 - mse: 0.0038 - mae: 0.0326 - mape: 67.6470\n",
      "Epoch 142/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0321 - mse: 0.0038 - mae: 0.0321 - mape: 65.9625\n",
      "Epoch 143/200\n",
      "3175/3175 [==============================] - 0s 46us/sample - loss: 0.0315 - mse: 0.0039 - mae: 0.0315 - mape: 62.3976\n",
      "Epoch 144/200\n",
      "3175/3175 [==============================] - 0s 48us/sample - loss: 0.0309 - mse: 0.0039 - mae: 0.0309 - mape: 56.8592\n",
      "Epoch 145/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0302 - mse: 0.0039 - mae: 0.0302 - mape: 55.6402\n",
      "Epoch 146/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0294 - mse: 0.0039 - mae: 0.0294 - mape: 51.2395\n",
      "Epoch 147/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0287 - mse: 0.0039 - mae: 0.0287 - mape: 47.6126\n",
      "Epoch 148/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0278 - mse: 0.0039 - mae: 0.0278 - mape: 42.7887\n",
      "Epoch 149/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0269 - mse: 0.0040 - mae: 0.0269 - mape: 37.9842\n",
      "Epoch 150/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0260 - mse: 0.0040 - mae: 0.0260 - mape: 32.6495\n",
      "Epoch 151/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0250 - mse: 0.0041 - mae: 0.0250 - mape: 27.3991\n",
      "Epoch 152/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0239 - mse: 0.0041 - mae: 0.0239 - mape: 21.6605\n",
      "Epoch 153/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0232 - mse: 0.0041 - mae: 0.0232 - mape: 18.5334\n",
      "Epoch 154/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6222\n",
      "Epoch 155/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6281\n",
      "Epoch 156/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0232 - mse: 0.0041 - mae: 0.0232 - mape: 17.7109\n",
      "Epoch 157/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5564\n",
      "Epoch 158/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5986\n",
      "Epoch 159/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6933\n",
      "Epoch 160/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6573\n",
      "Epoch 161/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6632\n",
      "Epoch 162/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6307\n",
      "Epoch 163/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7147\n",
      "Epoch 164/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6242\n",
      "Epoch 165/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5610\n",
      "Epoch 166/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7852\n",
      "Epoch 167/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6600\n",
      "Epoch 168/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7509\n",
      "Epoch 169/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6598\n",
      "Epoch 170/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0232 - mse: 0.0041 - mae: 0.0232 - mape: 17.7874\n",
      "Epoch 171/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5145\n",
      "Epoch 172/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.4899\n",
      "Epoch 173/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5479\n",
      "Epoch 174/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6537\n",
      "Epoch 175/200\n",
      "3175/3175 [==============================] - 0s 47us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7350\n",
      "Epoch 176/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6651\n",
      "Epoch 177/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7644\n",
      "Epoch 178/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5821\n",
      "Epoch 179/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7674\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6892\n",
      "Epoch 181/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6119\n",
      "Epoch 182/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5350\n",
      "Epoch 183/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6411\n",
      "Epoch 184/200\n",
      "3175/3175 [==============================] - 0s 45us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7153\n",
      "Epoch 185/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7085\n",
      "Epoch 186/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6402\n",
      "Epoch 187/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5595\n",
      "Epoch 188/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6664\n",
      "Epoch 189/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6413\n",
      "Epoch 190/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.9031\n",
      "Epoch 191/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6801\n",
      "Epoch 192/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0232 - mse: 0.0041 - mae: 0.0232 - mape: 17.6899\n",
      "Epoch 193/200\n",
      "3175/3175 [==============================] - 0s 44us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6328\n",
      "Epoch 194/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6365\n",
      "Epoch 195/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5623\n",
      "Epoch 196/200\n",
      "3175/3175 [==============================] - 0s 43us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.5472\n",
      "Epoch 197/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.7884\n",
      "Epoch 198/200\n",
      "3175/3175 [==============================] - 0s 42us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6610\n",
      "Epoch 199/200\n",
      "3175/3175 [==============================] - 0s 40us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6703\n",
      "Epoch 200/200\n",
      "3175/3175 [==============================] - 0s 41us/sample - loss: 0.0231 - mse: 0.0041 - mae: 0.0231 - mape: 17.6981\n",
      "Status: Current part: 1 out of : 3 parts.\n",
      "Heights to iterate over: [16]\n",
      "Train on 1792 samples\n",
      "Epoch 1/200\n",
      "1792/1792 [==============================] - 0s 185us/sample - loss: 0.7937 - mse: 0.6520 - mae: 0.7937 - mape: 110.9502\n",
      "Epoch 2/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.7818 - mse: 0.6331 - mae: 0.7818 - mape: 109.2109\n",
      "Epoch 3/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.7681 - mse: 0.6119 - mae: 0.7681 - mape: 107.2353\n",
      "Epoch 4/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.7520 - mse: 0.5873 - mae: 0.7520 - mape: 104.9016\n",
      "Epoch 5/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.7324 - mse: 0.5580 - mae: 0.7324 - mape: 102.0657\n",
      "Epoch 6/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.7081 - mse: 0.5226 - mae: 0.7081 - mape: 98.5569\n",
      "Epoch 7/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.6778 - mse: 0.4804 - mae: 0.6778 - mape: 94.1832\n",
      "Epoch 8/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.6401 - mse: 0.4303 - mae: 0.6401 - mape: 88.7288\n",
      "Epoch 9/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.5932 - mse: 0.3719 - mae: 0.5932 - mape: 81.9792\n",
      "Epoch 10/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.5356 - mse: 0.3061 - mae: 0.5356 - mape: 73.6948\n",
      "Epoch 11/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.4658 - mse: 0.2353 - mae: 0.4658 - mape: 63.6599\n",
      "Epoch 12/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.3825 - mse: 0.1635 - mae: 0.3825 - mape: 51.6804\n",
      "Epoch 13/200\n",
      "1792/1792 [==============================] - 0s 37us/sample - loss: 0.2843 - mse: 0.0968 - mae: 0.2843 - mape: 37.5677\n",
      "Epoch 14/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.1784 - mse: 0.0447 - mae: 0.1784 - mape: 22.5898\n",
      "Epoch 15/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.1166 - mse: 0.0192 - mae: 0.1166 - mape: 15.2087\n",
      "Epoch 16/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0957 - mse: 0.0120 - mae: 0.0957 - mape: 13.8062\n",
      "Epoch 17/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0902 - mse: 0.0110 - mae: 0.0902 - mape: 13.8184\n",
      "Epoch 18/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0890 - mse: 0.0111 - mae: 0.0890 - mape: 13.9770\n",
      "Epoch 19/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0886 - mse: 0.0112 - mae: 0.0886 - mape: 14.0208\n",
      "Epoch 20/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0883 - mse: 0.0112 - mae: 0.0883 - mape: 14.0243\n",
      "Epoch 21/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0880 - mse: 0.0111 - mae: 0.0880 - mape: 13.9668\n",
      "Epoch 22/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0877 - mse: 0.0110 - mae: 0.0877 - mape: 13.9041\n",
      "Epoch 23/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0874 - mse: 0.0111 - mae: 0.0874 - mape: 13.9355\n",
      "Epoch 24/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0870 - mse: 0.0110 - mae: 0.0870 - mape: 13.8534\n",
      "Epoch 25/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0868 - mse: 0.0109 - mae: 0.0868 - mape: 13.7940\n",
      "Epoch 26/200\n",
      "1792/1792 [==============================] - 0s 45us/sample - loss: 0.0863 - mse: 0.0106 - mae: 0.0863 - mape: 13.6631\n",
      "Epoch 27/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0860 - mse: 0.0105 - mae: 0.0860 - mape: 13.5820\n",
      "Epoch 28/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0856 - mse: 0.0105 - mae: 0.0856 - mape: 13.5874\n",
      "Epoch 29/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0852 - mse: 0.0104 - mae: 0.0852 - mape: 13.4846\n",
      "Epoch 30/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0849 - mse: 0.0103 - mae: 0.0849 - mape: 13.4108\n",
      "Epoch 31/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0844 - mse: 0.0102 - mae: 0.0844 - mape: 13.3722\n",
      "Epoch 32/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0841 - mse: 0.0100 - mae: 0.0841 - mape: 13.2517\n",
      "Epoch 33/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0836 - mse: 0.0100 - mae: 0.0836 - mape: 13.1973\n",
      "Epoch 34/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0832 - mse: 0.0098 - mae: 0.0832 - mape: 13.1119\n",
      "Epoch 35/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0827 - mse: 0.0097 - mae: 0.0827 - mape: 13.0346\n",
      "Epoch 36/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0823 - mse: 0.0097 - mae: 0.0823 - mape: 12.9746\n",
      "Epoch 37/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0818 - mse: 0.0095 - mae: 0.0818 - mape: 12.8355\n",
      "Epoch 38/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0813 - mse: 0.0095 - mae: 0.0813 - mape: 12.8640\n",
      "Epoch 39/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0808 - mse: 0.0093 - mae: 0.0808 - mape: 12.6986\n",
      "Epoch 40/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0803 - mse: 0.0092 - mae: 0.0803 - mape: 12.6057\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0798 - mse: 0.0091 - mae: 0.0798 - mape: 12.5728\n",
      "Epoch 42/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0793 - mse: 0.0089 - mae: 0.0793 - mape: 12.3935\n",
      "Epoch 43/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0787 - mse: 0.0087 - mae: 0.0787 - mape: 12.2429\n",
      "Epoch 44/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0782 - mse: 0.0088 - mae: 0.0782 - mape: 12.3119\n",
      "Epoch 45/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0776 - mse: 0.0086 - mae: 0.0776 - mape: 12.1659\n",
      "Epoch 46/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0771 - mse: 0.0084 - mae: 0.0771 - mape: 12.0180\n",
      "Epoch 47/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0765 - mse: 0.0083 - mae: 0.0765 - mape: 11.8824\n",
      "Epoch 48/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0759 - mse: 0.0082 - mae: 0.0759 - mape: 11.8332\n",
      "Epoch 49/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0753 - mse: 0.0081 - mae: 0.0753 - mape: 11.7778\n",
      "Epoch 50/200\n",
      "1792/1792 [==============================] - 0s 45us/sample - loss: 0.0747 - mse: 0.0080 - mae: 0.0747 - mape: 11.6236\n",
      "Epoch 51/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0741 - mse: 0.0079 - mae: 0.0741 - mape: 11.5054\n",
      "Epoch 52/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0736 - mse: 0.0077 - mae: 0.0736 - mape: 11.2745\n",
      "Epoch 53/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0728 - mse: 0.0076 - mae: 0.0728 - mape: 11.3200\n",
      "Epoch 54/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0721 - mse: 0.0075 - mae: 0.0721 - mape: 11.1748\n",
      "Epoch 55/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0715 - mse: 0.0073 - mae: 0.0715 - mape: 11.0121\n",
      "Epoch 56/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0708 - mse: 0.0073 - mae: 0.0708 - mape: 10.9219\n",
      "Epoch 57/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0702 - mse: 0.0071 - mae: 0.0702 - mape: 10.7972\n",
      "Epoch 58/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0694 - mse: 0.0070 - mae: 0.0694 - mape: 10.7066\n",
      "Epoch 59/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0687 - mse: 0.0069 - mae: 0.0687 - mape: 10.4781\n",
      "Epoch 60/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0680 - mse: 0.0068 - mae: 0.0680 - mape: 10.4330\n",
      "Epoch 61/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0673 - mse: 0.0067 - mae: 0.0673 - mape: 10.2484\n",
      "Epoch 62/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0666 - mse: 0.0066 - mae: 0.0666 - mape: 10.1654\n",
      "Epoch 63/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0658 - mse: 0.0064 - mae: 0.0658 - mape: 9.9398\n",
      "Epoch 64/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0649 - mse: 0.0064 - mae: 0.0649 - mape: 9.8766\n",
      "Epoch 65/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0642 - mse: 0.0062 - mae: 0.0642 - mape: 9.7208\n",
      "Epoch 66/200\n",
      "1792/1792 [==============================] - 0s 37us/sample - loss: 0.0634 - mse: 0.0061 - mae: 0.0634 - mape: 9.5290\n",
      "Epoch 67/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0626 - mse: 0.0060 - mae: 0.0626 - mape: 9.4086\n",
      "Epoch 68/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0617 - mse: 0.0059 - mae: 0.0617 - mape: 9.2812\n",
      "Epoch 69/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0609 - mse: 0.0059 - mae: 0.0609 - mape: 9.0869\n",
      "Epoch 70/200\n",
      "1792/1792 [==============================] - 0s 47us/sample - loss: 0.0601 - mse: 0.0058 - mae: 0.0601 - mape: 9.0078\n",
      "Epoch 71/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0593 - mse: 0.0057 - mae: 0.0593 - mape: 8.8956\n",
      "Epoch 72/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0586 - mse: 0.0056 - mae: 0.0586 - mape: 8.8436\n",
      "Epoch 73/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0580 - mse: 0.0055 - mae: 0.0580 - mape: 8.7629\n",
      "Epoch 74/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0575 - mse: 0.0055 - mae: 0.0575 - mape: 8.7009\n",
      "Epoch 75/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0571 - mse: 0.0055 - mae: 0.0571 - mape: 8.6848\n",
      "Epoch 76/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0567 - mse: 0.0054 - mae: 0.0567 - mape: 8.5933\n",
      "Epoch 77/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0564 - mse: 0.0054 - mae: 0.0564 - mape: 8.6223\n",
      "Epoch 78/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0561 - mse: 0.0054 - mae: 0.0561 - mape: 8.5643\n",
      "Epoch 79/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0559 - mse: 0.0054 - mae: 0.0559 - mape: 8.5793\n",
      "Epoch 80/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0556 - mse: 0.0053 - mae: 0.0556 - mape: 8.5119\n",
      "Epoch 81/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0556 - mse: 0.0054 - mae: 0.0556 - mape: 8.5727\n",
      "Epoch 82/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0555 - mse: 0.0054 - mae: 0.0555 - mape: 8.5532\n",
      "Epoch 83/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0554 - mse: 0.0054 - mae: 0.0554 - mape: 8.5414\n",
      "Epoch 84/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0553 - mse: 0.0054 - mae: 0.0553 - mape: 8.5314\n",
      "Epoch 85/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0552 - mse: 0.0054 - mae: 0.0552 - mape: 8.5414\n",
      "Epoch 86/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0552 - mse: 0.0054 - mae: 0.0552 - mape: 8.5373\n",
      "Epoch 87/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0552 - mse: 0.0054 - mae: 0.0552 - mape: 8.5513\n",
      "Epoch 88/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5415\n",
      "Epoch 89/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5405\n",
      "Epoch 90/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5519\n",
      "Epoch 91/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5401\n",
      "Epoch 92/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5490\n",
      "Epoch 93/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5542\n",
      "Epoch 94/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5620\n",
      "Epoch 95/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5485\n",
      "Epoch 96/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0552 - mse: 0.0054 - mae: 0.0552 - mape: 8.5768\n",
      "Epoch 97/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0055 - mae: 0.0550 - mape: 8.5689\n",
      "Epoch 98/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5578\n",
      "Epoch 99/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5534\n",
      "Epoch 100/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0552 - mse: 0.0054 - mae: 0.0552 - mape: 8.5674\n",
      "Epoch 101/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5617\n",
      "Epoch 102/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0055 - mae: 0.0551 - mape: 8.5791\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5787\n",
      "Epoch 104/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5645\n",
      "Epoch 105/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5698\n",
      "Epoch 106/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5444\n",
      "Epoch 107/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5802\n",
      "Epoch 108/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5599\n",
      "Epoch 109/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5646\n",
      "Epoch 110/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5699\n",
      "Epoch 111/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5664\n",
      "Epoch 112/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5731\n",
      "Epoch 113/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5528\n",
      "Epoch 114/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5618\n",
      "Epoch 115/200\n",
      "1792/1792 [==============================] - 0s 48us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5535\n",
      "Epoch 116/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5680\n",
      "Epoch 117/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5570\n",
      "Epoch 118/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5555\n",
      "Epoch 119/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5654\n",
      "Epoch 120/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5688\n",
      "Epoch 121/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5683\n",
      "Epoch 122/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5614\n",
      "Epoch 123/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5627\n",
      "Epoch 124/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5752\n",
      "Epoch 125/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5670\n",
      "Epoch 126/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5726\n",
      "Epoch 127/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5638\n",
      "Epoch 128/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5613\n",
      "Epoch 129/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5592\n",
      "Epoch 130/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5745\n",
      "Epoch 131/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5639\n",
      "Epoch 132/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5590\n",
      "Epoch 133/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5678\n",
      "Epoch 134/200\n",
      "1792/1792 [==============================] - 0s 45us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5595\n",
      "Epoch 135/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5603\n",
      "Epoch 136/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5512\n",
      "Epoch 137/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5761\n",
      "Epoch 138/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5736\n",
      "Epoch 139/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5678\n",
      "Epoch 140/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5619\n",
      "Epoch 141/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5539\n",
      "Epoch 142/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5627\n",
      "Epoch 143/200\n",
      "1792/1792 [==============================] - 0s 37us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5573\n",
      "Epoch 144/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5787\n",
      "Epoch 145/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5496\n",
      "Epoch 146/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5633\n",
      "Epoch 147/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5550\n",
      "Epoch 148/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5623\n",
      "Epoch 149/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5435\n",
      "Epoch 150/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5739\n",
      "Epoch 151/200\n",
      "1792/1792 [==============================] - 0s 44us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5634 0s - loss: 0.0548 - mse: 0.0055 - mae: 0.0548 - mape: 8.565\n",
      "Epoch 152/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5685\n",
      "Epoch 153/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5718\n",
      "Epoch 154/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5409\n",
      "Epoch 155/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0552 - mse: 0.0055 - mae: 0.0552 - mape: 8.6023\n",
      "Epoch 156/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5704\n",
      "Epoch 157/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5657\n",
      "Epoch 158/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5454\n",
      "Epoch 159/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5625\n",
      "Epoch 160/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5547\n",
      "Epoch 161/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5605\n",
      "Epoch 162/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5561\n",
      "Epoch 163/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5608\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5627\n",
      "Epoch 165/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5556\n",
      "Epoch 166/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5616\n",
      "Epoch 167/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5479\n",
      "Epoch 168/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5502\n",
      "Epoch 169/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5603\n",
      "Epoch 170/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5624\n",
      "Epoch 171/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5580\n",
      "Epoch 172/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5653\n",
      "Epoch 173/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5511\n",
      "Epoch 174/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5694\n",
      "Epoch 175/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5458\n",
      "Epoch 176/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5535\n",
      "Epoch 177/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5715\n",
      "Epoch 178/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5611\n",
      "Epoch 179/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5632\n",
      "Epoch 180/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5576\n",
      "Epoch 181/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5545\n",
      "Epoch 182/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5625\n",
      "Epoch 183/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5387\n",
      "Epoch 184/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5494\n",
      "Epoch 185/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5544\n",
      "Epoch 186/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5553\n",
      "Epoch 187/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5536\n",
      "Epoch 188/200\n",
      "1792/1792 [==============================] - 0s 38us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5508\n",
      "Epoch 189/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5632\n",
      "Epoch 190/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5518\n",
      "Epoch 191/200\n",
      "1792/1792 [==============================] - 0s 41us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5543\n",
      "Epoch 192/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5586\n",
      "Epoch 193/200\n",
      "1792/1792 [==============================] - 0s 42us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5566\n",
      "Epoch 194/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5656\n",
      "Epoch 195/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5577\n",
      "Epoch 196/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5595\n",
      "Epoch 197/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0551 - mse: 0.0054 - mae: 0.0551 - mape: 8.5770\n",
      "Epoch 198/200\n",
      "1792/1792 [==============================] - 0s 39us/sample - loss: 0.0553 - mse: 0.0054 - mae: 0.0553 - mape: 8.5744\n",
      "Epoch 199/200\n",
      "1792/1792 [==============================] - 0s 40us/sample - loss: 0.0549 - mse: 0.0054 - mae: 0.0549 - mape: 8.5506\n",
      "Epoch 200/200\n",
      "1792/1792 [==============================] - 0s 43us/sample - loss: 0.0550 - mse: 0.0054 - mae: 0.0550 - mape: 8.5612\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Train on 5001 samples\n",
      "5001/5001 [==============================] - 1s 100us/sample - loss: 0.5877 - accuracy: 0.7629\n",
      "            train         test\n",
      "MAE      0.044447     0.044447\n",
      "MSE      0.008460     0.008460\n",
      "MAPE  1891.963512  1891.963512\n",
      "      L-time     P-time  N_params_expt  AIC-like  Eff\n",
      "0  48.227268  32.168873              0     6.227 -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/ipykernel_launcher.py:298: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674865026994601\n",
      "0.4299140171965607\n",
      "0.2501499700059988\n",
      "0.05118976204759048\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 6.\n",
      "The_parts_listhe number of parts are: 5.\n",
      "Status: Current part: 0 out of : 5 parts.\n",
      "Heights to iterate over: [10]\n",
      "Train on 1626 samples\n",
      "Epoch 1/200\n",
      "1626/1626 [==============================] - 0s 208us/sample - loss: 0.0332 - mse: 0.0023 - mae: 0.0332 - mape: 143.6360\n",
      "Epoch 2/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0329 - mse: 0.0022 - mae: 0.0329 - mape: 157.9949\n",
      "Epoch 3/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0329 - mse: 0.0021 - mae: 0.0329 - mape: 165.1316\n",
      "Epoch 4/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0329 - mse: 0.0021 - mae: 0.0329 - mape: 165.4155\n",
      "Epoch 5/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0328 - mse: 0.0021 - mae: 0.0328 - mape: 165.6263\n",
      "Epoch 6/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0328 - mse: 0.0021 - mae: 0.0328 - mape: 166.4635\n",
      "Epoch 7/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0328 - mse: 0.0021 - mae: 0.0328 - mape: 162.6387\n",
      "Epoch 8/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0327 - mse: 0.0021 - mae: 0.0327 - mape: 166.3175\n",
      "Epoch 9/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0327 - mse: 0.0021 - mae: 0.0327 - mape: 165.2264\n",
      "Epoch 10/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0326 - mse: 0.0020 - mae: 0.0326 - mape: 165.8584\n",
      "Epoch 11/200\n",
      "1626/1626 [==============================] - 0s 37us/sample - loss: 0.0326 - mse: 0.0020 - mae: 0.0326 - mape: 164.0861\n",
      "Epoch 12/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0325 - mse: 0.0020 - mae: 0.0325 - mape: 162.7347\n",
      "Epoch 13/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0324 - mse: 0.0020 - mae: 0.0324 - mape: 166.6539\n",
      "Epoch 14/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0323 - mse: 0.0020 - mae: 0.0323 - mape: 166.2679\n",
      "Epoch 15/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0322 - mse: 0.0020 - mae: 0.0322 - mape: 161.7509\n",
      "Epoch 16/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0321 - mse: 0.0020 - mae: 0.0321 - mape: 162.6351\n",
      "Epoch 17/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0320 - mse: 0.0020 - mae: 0.0320 - mape: 159.4578\n",
      "Epoch 18/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0318 - mse: 0.0019 - mae: 0.0318 - mape: 162.3542\n",
      "Epoch 19/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0316 - mse: 0.0019 - mae: 0.0316 - mape: 161.5059\n",
      "Epoch 20/200\n",
      "1626/1626 [==============================] - 0s 55us/sample - loss: 0.0314 - mse: 0.0019 - mae: 0.0314 - mape: 159.8289\n",
      "Epoch 21/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0312 - mse: 0.0019 - mae: 0.0312 - mape: 154.6604\n",
      "Epoch 22/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0309 - mse: 0.0018 - mae: 0.0309 - mape: 157.8616\n",
      "Epoch 23/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0306 - mse: 0.0018 - mae: 0.0306 - mape: 155.1694\n",
      "Epoch 24/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0302 - mse: 0.0017 - mae: 0.0302 - mape: 151.8765\n",
      "Epoch 25/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0298 - mse: 0.0017 - mae: 0.0298 - mape: 146.3059\n",
      "Epoch 26/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0293 - mse: 0.0016 - mae: 0.0293 - mape: 147.7597\n",
      "Epoch 27/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0288 - mse: 0.0016 - mae: 0.0288 - mape: 142.5040\n",
      "Epoch 28/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0282 - mse: 0.0015 - mae: 0.0282 - mape: 135.9588\n",
      "Epoch 29/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0276 - mse: 0.0014 - mae: 0.0276 - mape: 135.5173\n",
      "Epoch 30/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0270 - mse: 0.0014 - mae: 0.0270 - mape: 128.7435\n",
      "Epoch 31/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0263 - mse: 0.0013 - mae: 0.0263 - mape: 117.1962\n",
      "Epoch 32/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0256 - mse: 0.0012 - mae: 0.0256 - mape: 123.1218\n",
      "Epoch 33/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0248 - mse: 0.0011 - mae: 0.0248 - mape: 108.4177\n",
      "Epoch 34/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0240 - mse: 0.0011 - mae: 0.0240 - mape: 102.6658\n",
      "Epoch 35/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0233 - mse: 9.8359e-04 - mae: 0.0233 - mape: 94.8792\n",
      "Epoch 36/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0225 - mse: 8.9895e-04 - mae: 0.0225 - mape: 91.5647\n",
      "Epoch 37/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0218 - mse: 8.4367e-04 - mae: 0.0218 - mape: 81.4472\n",
      "Epoch 38/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0212 - mse: 7.8340e-04 - mae: 0.0212 - mape: 75.9113\n",
      "Epoch 39/200\n",
      "1626/1626 [==============================] - 0s 66us/sample - loss: 0.0206 - mse: 7.2290e-04 - mae: 0.0206 - mape: 69.8961\n",
      "Epoch 40/200\n",
      "1626/1626 [==============================] - 0s 51us/sample - loss: 0.0201 - mse: 6.9338e-04 - mae: 0.0201 - mape: 63.2289\n",
      "Epoch 41/200\n",
      "1626/1626 [==============================] - 0s 68us/sample - loss: 0.0197 - mse: 6.5433e-04 - mae: 0.0197 - mape: 64.1023\n",
      "Epoch 42/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0192 - mse: 6.2173e-04 - mae: 0.0192 - mape: 65.9137\n",
      "Epoch 43/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0188 - mse: 6.2300e-04 - mae: 0.0188 - mape: 66.0266\n",
      "Epoch 44/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0183 - mse: 6.2888e-04 - mae: 0.0183 - mape: 65.9633\n",
      "Epoch 45/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0178 - mse: 5.9764e-04 - mae: 0.0178 - mape: 67.7189\n",
      "Epoch 46/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0173 - mse: 5.8787e-04 - mae: 0.0173 - mape: 70.2521\n",
      "Epoch 47/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0171 - mse: 5.8672e-04 - mae: 0.0171 - mape: 74.2632\n",
      "Epoch 48/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0170 - mse: 5.7206e-04 - mae: 0.0170 - mape: 77.1764\n",
      "Epoch 49/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0169 - mse: 5.6834e-04 - mae: 0.0169 - mape: 78.9807\n",
      "Epoch 50/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0168 - mse: 5.6208e-04 - mae: 0.0168 - mape: 81.9290\n",
      "Epoch 51/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0167 - mse: 5.3843e-04 - mae: 0.0167 - mape: 81.8100\n",
      "Epoch 52/200\n",
      "1626/1626 [==============================] - 0s 49us/sample - loss: 0.0167 - mse: 5.5341e-04 - mae: 0.0167 - mape: 85.6053\n",
      "Epoch 53/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0166 - mse: 5.3393e-04 - mae: 0.0166 - mape: 85.5337\n",
      "Epoch 54/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0166 - mse: 5.1760e-04 - mae: 0.0166 - mape: 86.6733\n",
      "Epoch 55/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0165 - mse: 5.2426e-04 - mae: 0.0165 - mape: 89.8735\n",
      "Epoch 56/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0164 - mse: 5.1418e-04 - mae: 0.0164 - mape: 90.8016\n",
      "Epoch 57/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0164 - mse: 5.1725e-04 - mae: 0.0164 - mape: 94.1561\n",
      "Epoch 58/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0163 - mse: 5.2609e-04 - mae: 0.0163 - mape: 95.1940\n",
      "Epoch 59/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0163 - mse: 5.0351e-04 - mae: 0.0163 - mape: 93.9368\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0162 - mse: 5.2292e-04 - mae: 0.0162 - mape: 98.0478\n",
      "Epoch 61/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0162 - mse: 5.2718e-04 - mae: 0.0162 - mape: 98.8752\n",
      "Epoch 62/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0162 - mse: 5.3372e-04 - mae: 0.0162 - mape: 100.4796\n",
      "Epoch 63/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0162 - mse: 5.4747e-04 - mae: 0.0162 - mape: 102.9837\n",
      "Epoch 64/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0161 - mse: 5.3777e-04 - mae: 0.0161 - mape: 101.9546\n",
      "Epoch 65/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0161 - mse: 5.4247e-04 - mae: 0.0161 - mape: 102.7335\n",
      "Epoch 66/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0161 - mse: 5.3922e-04 - mae: 0.0161 - mape: 101.8739\n",
      "Epoch 67/200\n",
      "1626/1626 [==============================] - 0s 53us/sample - loss: 0.0161 - mse: 5.4182e-04 - mae: 0.0161 - mape: 102.2687\n",
      "Epoch 68/200\n",
      "1626/1626 [==============================] - 0s 54us/sample - loss: 0.0161 - mse: 5.4317e-04 - mae: 0.0161 - mape: 102.3738\n",
      "Epoch 69/200\n",
      "1626/1626 [==============================] - 0s 81us/sample - loss: 0.0161 - mse: 5.3856e-04 - mae: 0.0161 - mape: 101.7780\n",
      "Epoch 70/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0161 - mse: 5.4580e-04 - mae: 0.0161 - mape: 102.2710\n",
      "Epoch 71/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0161 - mse: 5.3996e-04 - mae: 0.0161 - mape: 102.2848\n",
      "Epoch 72/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0161 - mse: 5.3959e-04 - mae: 0.0161 - mape: 102.5238\n",
      "Epoch 73/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0160 - mse: 5.4315e-04 - mae: 0.0160 - mape: 102.5460\n",
      "Epoch 74/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0160 - mse: 5.3591e-04 - mae: 0.0160 - mape: 101.7185\n",
      "Epoch 75/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0161 - mse: 5.3990e-04 - mae: 0.0161 - mape: 101.8424\n",
      "Epoch 76/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0160 - mse: 5.4712e-04 - mae: 0.0160 - mape: 103.4414\n",
      "Epoch 77/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0160 - mse: 5.3737e-04 - mae: 0.0160 - mape: 101.4409\n",
      "Epoch 78/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0160 - mse: 5.3509e-04 - mae: 0.0160 - mape: 101.1711\n",
      "Epoch 79/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0160 - mse: 5.3945e-04 - mae: 0.0160 - mape: 101.1784\n",
      "Epoch 80/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0160 - mse: 5.3955e-04 - mae: 0.0160 - mape: 102.1431\n",
      "Epoch 81/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0160 - mse: 5.3896e-04 - mae: 0.0160 - mape: 101.7840\n",
      "Epoch 82/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0160 - mse: 5.3712e-04 - mae: 0.0160 - mape: 101.5490\n",
      "Epoch 83/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0160 - mse: 5.3253e-04 - mae: 0.0160 - mape: 100.9624\n",
      "Epoch 84/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0159 - mse: 5.3945e-04 - mae: 0.0159 - mape: 101.7082\n",
      "Epoch 85/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0160 - mse: 5.3820e-04 - mae: 0.0160 - mape: 102.4815\n",
      "Epoch 86/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0159 - mse: 5.3045e-04 - mae: 0.0159 - mape: 100.1868\n",
      "Epoch 87/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0159 - mse: 5.3309e-04 - mae: 0.0159 - mape: 100.8616\n",
      "Epoch 88/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0159 - mse: 5.3740e-04 - mae: 0.0159 - mape: 101.5059\n",
      "Epoch 89/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0159 - mse: 5.3370e-04 - mae: 0.0159 - mape: 100.7591\n",
      "Epoch 90/200\n",
      "1626/1626 [==============================] - 0s 53us/sample - loss: 0.0160 - mse: 5.3766e-04 - mae: 0.0160 - mape: 101.9856\n",
      "Epoch 91/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0159 - mse: 5.2846e-04 - mae: 0.0159 - mape: 99.9705\n",
      "Epoch 92/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0159 - mse: 5.3732e-04 - mae: 0.0159 - mape: 100.7558\n",
      "Epoch 93/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0159 - mse: 5.2513e-04 - mae: 0.0159 - mape: 100.2479\n",
      "Epoch 94/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0159 - mse: 5.4021e-04 - mae: 0.0159 - mape: 101.7789\n",
      "Epoch 95/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0159 - mse: 5.3016e-04 - mae: 0.0159 - mape: 100.3586\n",
      "Epoch 96/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0159 - mse: 5.2968e-04 - mae: 0.0159 - mape: 100.4579\n",
      "Epoch 97/200\n",
      "1626/1626 [==============================] - 0s 55us/sample - loss: 0.0158 - mse: 5.3201e-04 - mae: 0.0158 - mape: 100.4765\n",
      "Epoch 98/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0158 - mse: 5.3215e-04 - mae: 0.0158 - mape: 100.3434\n",
      "Epoch 99/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0158 - mse: 5.3546e-04 - mae: 0.0158 - mape: 100.5798\n",
      "Epoch 100/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0158 - mse: 5.2820e-04 - mae: 0.0158 - mape: 100.1176\n",
      "Epoch 101/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0158 - mse: 5.3498e-04 - mae: 0.0158 - mape: 101.0245\n",
      "Epoch 102/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0158 - mse: 5.3624e-04 - mae: 0.0158 - mape: 101.0677\n",
      "Epoch 103/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0158 - mse: 5.2715e-04 - mae: 0.0158 - mape: 99.8145\n",
      "Epoch 104/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0158 - mse: 5.4017e-04 - mae: 0.0158 - mape: 101.1116\n",
      "Epoch 105/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0158 - mse: 5.3128e-04 - mae: 0.0158 - mape: 100.6092\n",
      "Epoch 106/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0158 - mse: 5.3001e-04 - mae: 0.0158 - mape: 101.0877\n",
      "Epoch 107/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0158 - mse: 5.2970e-04 - mae: 0.0158 - mape: 100.2372\n",
      "Epoch 108/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0158 - mse: 5.3293e-04 - mae: 0.0158 - mape: 101.0312\n",
      "Epoch 109/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0157 - mse: 5.2890e-04 - mae: 0.0157 - mape: 99.85230s - loss: 0.0157 - mse: 5.2667e-04 - mae: 0.0157 - mape: 92.968\n",
      "Epoch 110/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0157 - mse: 5.3065e-04 - mae: 0.0157 - mape: 100.6253\n",
      "Epoch 111/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0157 - mse: 5.3007e-04 - mae: 0.0157 - mape: 100.6676\n",
      "Epoch 112/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0157 - mse: 5.3650e-04 - mae: 0.0157 - mape: 101.4120\n",
      "Epoch 113/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0157 - mse: 5.3070e-04 - mae: 0.0157 - mape: 100.0458\n",
      "Epoch 114/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0157 - mse: 5.2375e-04 - mae: 0.0157 - mape: 99.0393\n",
      "Epoch 115/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0157 - mse: 5.2691e-04 - mae: 0.0157 - mape: 99.9019\n",
      "Epoch 116/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0157 - mse: 5.2787e-04 - mae: 0.0157 - mape: 99.6698\n",
      "Epoch 117/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0157 - mse: 5.2598e-04 - mae: 0.0157 - mape: 99.7596\n",
      "Epoch 118/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0157 - mse: 5.3012e-04 - mae: 0.0157 - mape: 100.2305\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0157 - mse: 5.2685e-04 - mae: 0.0157 - mape: 99.6410\n",
      "Epoch 120/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0157 - mse: 5.2752e-04 - mae: 0.0157 - mape: 99.5723\n",
      "Epoch 121/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0156 - mse: 5.3424e-04 - mae: 0.0156 - mape: 100.9071\n",
      "Epoch 122/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0156 - mse: 5.2131e-04 - mae: 0.0156 - mape: 99.6843\n",
      "Epoch 123/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0156 - mse: 5.2635e-04 - mae: 0.0156 - mape: 99.8667\n",
      "Epoch 124/200\n",
      "1626/1626 [==============================] - 0s 37us/sample - loss: 0.0156 - mse: 5.2890e-04 - mae: 0.0156 - mape: 100.0499\n",
      "Epoch 125/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0156 - mse: 5.2097e-04 - mae: 0.0156 - mape: 98.6730\n",
      "Epoch 126/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0156 - mse: 5.2688e-04 - mae: 0.0156 - mape: 99.9127\n",
      "Epoch 127/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0156 - mse: 5.2981e-04 - mae: 0.0156 - mape: 99.9798\n",
      "Epoch 128/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0156 - mse: 5.2257e-04 - mae: 0.0156 - mape: 98.8620\n",
      "Epoch 129/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0156 - mse: 5.2214e-04 - mae: 0.0156 - mape: 98.6876\n",
      "Epoch 130/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0156 - mse: 5.2352e-04 - mae: 0.0156 - mape: 98.6840\n",
      "Epoch 131/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0156 - mse: 5.2530e-04 - mae: 0.0156 - mape: 99.6879\n",
      "Epoch 132/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0156 - mse: 5.1821e-04 - mae: 0.0156 - mape: 98.2188\n",
      "Epoch 133/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0156 - mse: 5.2499e-04 - mae: 0.0156 - mape: 99.1449\n",
      "Epoch 134/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0155 - mse: 5.2158e-04 - mae: 0.0155 - mape: 98.8508\n",
      "Epoch 135/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0155 - mse: 5.2121e-04 - mae: 0.0155 - mape: 98.7439\n",
      "Epoch 136/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0155 - mse: 5.2471e-04 - mae: 0.0155 - mape: 99.0312\n",
      "Epoch 137/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0155 - mse: 5.1532e-04 - mae: 0.0155 - mape: 97.7185\n",
      "Epoch 138/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0155 - mse: 5.2228e-04 - mae: 0.0155 - mape: 98.5614\n",
      "Epoch 139/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0155 - mse: 5.1822e-04 - mae: 0.0155 - mape: 98.5603\n",
      "Epoch 140/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0155 - mse: 5.2441e-04 - mae: 0.0155 - mape: 99.3031\n",
      "Epoch 141/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0155 - mse: 5.1929e-04 - mae: 0.0155 - mape: 98.4296\n",
      "Epoch 142/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0155 - mse: 5.2338e-04 - mae: 0.0155 - mape: 99.0713\n",
      "Epoch 143/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0155 - mse: 5.1955e-04 - mae: 0.0155 - mape: 98.5793\n",
      "Epoch 144/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0155 - mse: 5.2685e-04 - mae: 0.0155 - mape: 99.2593\n",
      "Epoch 145/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0155 - mse: 5.2151e-04 - mae: 0.0155 - mape: 98.9208\n",
      "Epoch 146/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0155 - mse: 5.1757e-04 - mae: 0.0155 - mape: 98.5100\n",
      "Epoch 147/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0154 - mse: 5.1902e-04 - mae: 0.0154 - mape: 98.3344\n",
      "Epoch 148/200\n",
      "1626/1626 [==============================] - 0s 55us/sample - loss: 0.0154 - mse: 5.2307e-04 - mae: 0.0154 - mape: 98.9510\n",
      "Epoch 149/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0154 - mse: 5.1702e-04 - mae: 0.0154 - mape: 97.7283\n",
      "Epoch 150/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0154 - mse: 5.1889e-04 - mae: 0.0154 - mape: 98.4487\n",
      "Epoch 151/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0154 - mse: 5.1749e-04 - mae: 0.0154 - mape: 97.9334\n",
      "Epoch 152/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0154 - mse: 5.1882e-04 - mae: 0.0154 - mape: 98.1475\n",
      "Epoch 153/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0154 - mse: 5.2278e-04 - mae: 0.0154 - mape: 98.7049\n",
      "Epoch 154/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0154 - mse: 5.1484e-04 - mae: 0.0154 - mape: 96.9488\n",
      "Epoch 155/200\n",
      "1626/1626 [==============================] - 0s 36us/sample - loss: 0.0154 - mse: 5.1737e-04 - mae: 0.0154 - mape: 97.9112\n",
      "Epoch 156/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0154 - mse: 5.1205e-04 - mae: 0.0154 - mape: 97.1188\n",
      "Epoch 157/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0154 - mse: 5.1020e-04 - mae: 0.0154 - mape: 96.7497\n",
      "Epoch 158/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0154 - mse: 5.2502e-04 - mae: 0.0154 - mape: 99.0875\n",
      "Epoch 159/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0154 - mse: 5.1427e-04 - mae: 0.0154 - mape: 97.7664\n",
      "Epoch 160/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0153 - mse: 5.1683e-04 - mae: 0.0153 - mape: 97.7359\n",
      "Epoch 161/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0153 - mse: 5.1332e-04 - mae: 0.0153 - mape: 97.6280\n",
      "Epoch 162/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0154 - mse: 5.2063e-04 - mae: 0.0154 - mape: 98.4062\n",
      "Epoch 163/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0153 - mse: 5.1628e-04 - mae: 0.0153 - mape: 97.6007\n",
      "Epoch 164/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0153 - mse: 5.1720e-04 - mae: 0.0153 - mape: 97.9308\n",
      "Epoch 165/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0153 - mse: 5.1225e-04 - mae: 0.0153 - mape: 97.1960\n",
      "Epoch 166/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0154 - mse: 5.2240e-04 - mae: 0.0154 - mape: 99.1126\n",
      "Epoch 167/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0153 - mse: 5.1676e-04 - mae: 0.0153 - mape: 97.9132\n",
      "Epoch 168/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0153 - mse: 5.1452e-04 - mae: 0.0153 - mape: 96.9866\n",
      "Epoch 169/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0153 - mse: 5.1747e-04 - mae: 0.0153 - mape: 97.4905\n",
      "Epoch 170/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0153 - mse: 5.1331e-04 - mae: 0.0153 - mape: 97.1155\n",
      "Epoch 171/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0153 - mse: 5.1316e-04 - mae: 0.0153 - mape: 97.1139\n",
      "Epoch 172/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0153 - mse: 5.1192e-04 - mae: 0.0153 - mape: 96.8370\n",
      "Epoch 173/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0153 - mse: 5.1386e-04 - mae: 0.0153 - mape: 97.9778\n",
      "Epoch 174/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0153 - mse: 5.1547e-04 - mae: 0.0153 - mape: 97.8865\n",
      "Epoch 175/200\n",
      "1626/1626 [==============================] - 0s 45us/sample - loss: 0.0153 - mse: 5.1114e-04 - mae: 0.0153 - mape: 96.8713\n",
      "Epoch 176/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0152 - mse: 5.1702e-04 - mae: 0.0152 - mape: 97.8179\n",
      "Epoch 177/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0153 - mse: 5.1137e-04 - mae: 0.0153 - mape: 96.5868\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0152 - mse: 5.1035e-04 - mae: 0.0152 - mape: 96.3129\n",
      "Epoch 179/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0152 - mse: 5.1088e-04 - mae: 0.0152 - mape: 96.7344\n",
      "Epoch 180/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0152 - mse: 5.1260e-04 - mae: 0.0152 - mape: 96.7452\n",
      "Epoch 181/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0152 - mse: 5.0710e-04 - mae: 0.0152 - mape: 96.4393\n",
      "Epoch 182/200\n",
      "1626/1626 [==============================] - 0s 52us/sample - loss: 0.0152 - mse: 5.1015e-04 - mae: 0.0152 - mape: 96.4734\n",
      "Epoch 183/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0152 - mse: 5.1265e-04 - mae: 0.0152 - mape: 96.5828\n",
      "Epoch 184/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0152 - mse: 5.0526e-04 - mae: 0.0152 - mape: 96.0224\n",
      "Epoch 185/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0152 - mse: 5.1520e-04 - mae: 0.0152 - mape: 97.3911\n",
      "Epoch 186/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0152 - mse: 5.1079e-04 - mae: 0.0152 - mape: 96.4492\n",
      "Epoch 187/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0152 - mse: 4.9882e-04 - mae: 0.0152 - mape: 94.6625\n",
      "Epoch 188/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0152 - mse: 5.1630e-04 - mae: 0.0152 - mape: 97.4739\n",
      "Epoch 189/200\n",
      "1626/1626 [==============================] - 0s 40us/sample - loss: 0.0152 - mse: 5.0937e-04 - mae: 0.0152 - mape: 96.4403\n",
      "Epoch 190/200\n",
      "1626/1626 [==============================] - 0s 47us/sample - loss: 0.0151 - mse: 5.0474e-04 - mae: 0.0151 - mape: 95.7226\n",
      "Epoch 191/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0151 - mse: 5.1073e-04 - mae: 0.0151 - mape: 96.8728\n",
      "Epoch 192/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0151 - mse: 5.0983e-04 - mae: 0.0151 - mape: 97.1402\n",
      "Epoch 193/200\n",
      "1626/1626 [==============================] - 0s 39us/sample - loss: 0.0151 - mse: 5.0571e-04 - mae: 0.0151 - mape: 95.9781\n",
      "Epoch 194/200\n",
      "1626/1626 [==============================] - 0s 46us/sample - loss: 0.0151 - mse: 5.1177e-04 - mae: 0.0151 - mape: 96.9275\n",
      "Epoch 195/200\n",
      "1626/1626 [==============================] - 0s 41us/sample - loss: 0.0151 - mse: 5.0869e-04 - mae: 0.0151 - mape: 96.4076\n",
      "Epoch 196/200\n",
      "1626/1626 [==============================] - 0s 48us/sample - loss: 0.0151 - mse: 5.0267e-04 - mae: 0.0151 - mape: 95.6344\n",
      "Epoch 197/200\n",
      "1626/1626 [==============================] - 0s 38us/sample - loss: 0.0151 - mse: 5.0887e-04 - mae: 0.0151 - mape: 96.9749\n",
      "Epoch 198/200\n",
      "1626/1626 [==============================] - 0s 42us/sample - loss: 0.0151 - mse: 5.1155e-04 - mae: 0.0151 - mape: 96.9679\n",
      "Epoch 199/200\n",
      "1626/1626 [==============================] - 0s 44us/sample - loss: 0.0151 - mse: 5.1087e-04 - mae: 0.0151 - mape: 96.5313\n",
      "Epoch 200/200\n",
      "1626/1626 [==============================] - 0s 43us/sample - loss: 0.0151 - mse: 5.0921e-04 - mae: 0.0151 - mape: 96.2857\n",
      "Status: Current part: 1 out of : 5 parts.\n",
      "Heights to iterate over: [10]\n",
      "Train on 1225 samples\n",
      "Epoch 1/200\n",
      "1225/1225 [==============================] - 0s 281us/sample - loss: 0.2920 - mse: 0.0905 - mae: 0.2920 - mape: 110.9766\n",
      "Epoch 2/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.2862 - mse: 0.0871 - mae: 0.2862 - mape: 108.6335\n",
      "Epoch 3/200\n",
      "1225/1225 [==============================] - 0s 37us/sample - loss: 0.2804 - mse: 0.0838 - mae: 0.2804 - mape: 106.2469\n",
      "Epoch 4/200\n",
      "1225/1225 [==============================] - 0s 37us/sample - loss: 0.2744 - mse: 0.0805 - mae: 0.2744 - mape: 103.7887\n",
      "Epoch 5/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.2680 - mse: 0.0770 - mae: 0.2680 - mape: 101.2002\n",
      "Epoch 6/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.2613 - mse: 0.0735 - mae: 0.2613 - mape: 98.4592\n",
      "Epoch 7/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.2540 - mse: 0.0697 - mae: 0.2540 - mape: 95.5079\n",
      "Epoch 8/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.2462 - mse: 0.0658 - mae: 0.2462 - mape: 92.3241\n",
      "Epoch 9/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.2377 - mse: 0.0616 - mae: 0.2377 - mape: 88.8516\n",
      "Epoch 10/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.2282 - mse: 0.0572 - mae: 0.2282 - mape: 84.9975\n",
      "Epoch 11/200\n",
      "1225/1225 [==============================] - 0s 38us/sample - loss: 0.2178 - mse: 0.0526 - mae: 0.2178 - mape: 80.7408\n",
      "Epoch 12/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.2062 - mse: 0.0476 - mae: 0.2062 - mape: 76.0204\n",
      "Epoch 13/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.1933 - mse: 0.0425 - mae: 0.1933 - mape: 70.7843\n",
      "Epoch 14/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.1789 - mse: 0.0371 - mae: 0.1789 - mape: 64.9343\n",
      "Epoch 15/200\n",
      "1225/1225 [==============================] - 0s 52us/sample - loss: 0.1629 - mse: 0.0316 - mae: 0.1629 - mape: 58.4678\n",
      "Epoch 16/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.1451 - mse: 0.0261 - mae: 0.1451 - mape: 51.2003\n",
      "Epoch 17/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.1252 - mse: 0.0206 - mae: 0.1252 - mape: 43.1351\n",
      "Epoch 18/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.1041 - mse: 0.0156 - mae: 0.1041 - mape: 34.6915\n",
      "Epoch 19/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0872 - mse: 0.0116 - mae: 0.0872 - mape: 28.7591\n",
      "Epoch 20/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0764 - mse: 0.0090 - mae: 0.0764 - mape: 25.6338\n",
      "Epoch 21/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0698 - mse: 0.0072 - mae: 0.0698 - mape: 24.2177\n",
      "Epoch 22/200\n",
      "1225/1225 [==============================] - 0s 53us/sample - loss: 0.0661 - mse: 0.0061 - mae: 0.0661 - mape: 23.8790\n",
      "Epoch 23/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0641 - mse: 0.0055 - mae: 0.0641 - mape: 23.8783\n",
      "Epoch 24/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0632 - mse: 0.0052 - mae: 0.0632 - mape: 24.2092\n",
      "Epoch 25/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0627 - mse: 0.0050 - mae: 0.0627 - mape: 24.4186\n",
      "Epoch 26/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0624 - mse: 0.0048 - mae: 0.0624 - mape: 24.6910\n",
      "Epoch 27/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0621 - mse: 0.0048 - mae: 0.0621 - mape: 24.8460\n",
      "Epoch 28/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0618 - mse: 0.0047 - mae: 0.0618 - mape: 25.0764\n",
      "Epoch 29/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0614 - mse: 0.0046 - mae: 0.0614 - mape: 25.3812\n",
      "Epoch 30/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0610 - mse: 0.0046 - mae: 0.0610 - mape: 25.6563\n",
      "Epoch 31/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0607 - mse: 0.0046 - mae: 0.0607 - mape: 25.9309\n",
      "Epoch 32/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0605 - mse: 0.0046 - mae: 0.0605 - mape: 26.2491\n",
      "Epoch 33/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0604 - mse: 0.0047 - mae: 0.0604 - mape: 26.4838\n",
      "Epoch 34/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0604 - mse: 0.0047 - mae: 0.0604 - mape: 26.4632\n",
      "Epoch 35/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0604 - mse: 0.0047 - mae: 0.0604 - mape: 26.7087\n",
      "Epoch 36/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0603 - mse: 0.0047 - mae: 0.0603 - mape: 26.6693\n",
      "Epoch 37/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0603 - mse: 0.0047 - mae: 0.0603 - mape: 26.7641\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0603 - mse: 0.0047 - mae: 0.0603 - mape: 26.7193\n",
      "Epoch 39/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0603 - mse: 0.0048 - mae: 0.0603 - mape: 26.9045\n",
      "Epoch 40/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0603 - mse: 0.0047 - mae: 0.0603 - mape: 26.7720\n",
      "Epoch 41/200\n",
      "1225/1225 [==============================] - 0s 37us/sample - loss: 0.0603 - mse: 0.0048 - mae: 0.0603 - mape: 26.8314\n",
      "Epoch 42/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0603 - mse: 0.0048 - mae: 0.0603 - mape: 26.8216\n",
      "Epoch 43/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.8193\n",
      "Epoch 44/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0602 - mse: 0.0047 - mae: 0.0602 - mape: 26.8000\n",
      "Epoch 45/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0602 - mse: 0.0047 - mae: 0.0602 - mape: 26.7958\n",
      "Epoch 46/200\n",
      "1225/1225 [==============================] - 0s 58us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.9312\n",
      "Epoch 47/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.9483\n",
      "Epoch 48/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.8663\n",
      "Epoch 49/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0603 - mse: 0.0048 - mae: 0.0603 - mape: 27.0141\n",
      "Epoch 50/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.8420\n",
      "Epoch 51/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0602 - mse: 0.0047 - mae: 0.0602 - mape: 26.8338\n",
      "Epoch 52/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0602 - mse: 0.0048 - mae: 0.0602 - mape: 26.8957\n",
      "Epoch 53/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.8898\n",
      "Epoch 54/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.9372\n",
      "Epoch 55/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.9295\n",
      "Epoch 56/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.9943\n",
      "Epoch 57/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.8945\n",
      "Epoch 58/200\n",
      "1225/1225 [==============================] - 0s 37us/sample - loss: 0.0601 - mse: 0.0048 - mae: 0.0601 - mape: 26.9940\n",
      "Epoch 59/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0601 - mse: 0.0047 - mae: 0.0601 - mape: 26.8610\n",
      "Epoch 60/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0601 - mse: 0.0047 - mae: 0.0601 - mape: 26.7384\n",
      "Epoch 61/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0600 - mse: 0.0047 - mae: 0.0600 - mape: 26.8765\n",
      "Epoch 62/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 27.0752\n",
      "Epoch 63/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 27.0944\n",
      "Epoch 64/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 27.0540\n",
      "Epoch 65/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0600 - mse: 0.0047 - mae: 0.0600 - mape: 26.9153\n",
      "Epoch 66/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 26.9577\n",
      "Epoch 67/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 27.0181\n",
      "Epoch 68/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0600 - mse: 0.0047 - mae: 0.0600 - mape: 26.9047\n",
      "Epoch 69/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0600 - mse: 0.0048 - mae: 0.0600 - mape: 26.9763\n",
      "Epoch 70/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 27.0998\n",
      "Epoch 71/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 26.9713\n",
      "Epoch 72/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 27.0100\n",
      "Epoch 73/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 26.9949\n",
      "Epoch 74/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 27.1129\n",
      "Epoch 75/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 27.1109\n",
      "Epoch 76/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.1271\n",
      "Epoch 77/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0599 - mse: 0.0048 - mae: 0.0599 - mape: 27.1940\n",
      "Epoch 78/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.1176\n",
      "Epoch 79/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.1039\n",
      "Epoch 80/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.0898\n",
      "Epoch 81/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0598 - mse: 0.0047 - mae: 0.0598 - mape: 27.0056\n",
      "Epoch 82/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.1117\n",
      "Epoch 83/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0598 - mse: 0.0048 - mae: 0.0598 - mape: 27.1249\n",
      "Epoch 84/200\n",
      "1225/1225 [==============================] - 0s 45us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.2050\n",
      "Epoch 85/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.1699\n",
      "Epoch 86/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.0934\n",
      "Epoch 87/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0597 - mse: 0.0049 - mae: 0.0597 - mape: 27.3484\n",
      "Epoch 88/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.1663\n",
      "Epoch 89/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.2705\n",
      "Epoch 90/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0597 - mse: 0.0048 - mae: 0.0597 - mape: 27.2477\n",
      "Epoch 91/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0597 - mse: 0.0049 - mae: 0.0597 - mape: 27.3487\n",
      "Epoch 92/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0596 - mse: 0.0048 - mae: 0.0596 - mape: 27.2014\n",
      "Epoch 93/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0596 - mse: 0.0048 - mae: 0.0596 - mape: 27.1955\n",
      "Epoch 94/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0596 - mse: 0.0048 - mae: 0.0596 - mape: 27.2420\n",
      "Epoch 95/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0596 - mse: 0.0049 - mae: 0.0596 - mape: 27.3479\n",
      "Epoch 96/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0596 - mse: 0.0048 - mae: 0.0596 - mape: 27.1315\n",
      "Epoch 97/200\n",
      "1225/1225 [==============================] - 0s 38us/sample - loss: 0.0596 - mse: 0.0049 - mae: 0.0596 - mape: 27.4814\n",
      "Epoch 98/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0595 - mse: 0.0049 - mae: 0.0595 - mape: 27.3552\n",
      "Epoch 99/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0595 - mse: 0.0049 - mae: 0.0595 - mape: 27.4482\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0595 - mse: 0.0048 - mae: 0.0595 - mape: 27.1677\n",
      "Epoch 101/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0595 - mse: 0.0049 - mae: 0.0595 - mape: 27.4177\n",
      "Epoch 102/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0595 - mse: 0.0048 - mae: 0.0595 - mape: 27.2849\n",
      "Epoch 103/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0594 - mse: 0.0048 - mae: 0.0594 - mape: 27.2556\n",
      "Epoch 104/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0594 - mse: 0.0049 - mae: 0.0594 - mape: 27.4588\n",
      "Epoch 105/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0594 - mse: 0.0048 - mae: 0.0594 - mape: 27.3143\n",
      "Epoch 106/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0594 - mse: 0.0049 - mae: 0.0594 - mape: 27.5325\n",
      "Epoch 107/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0594 - mse: 0.0049 - mae: 0.0594 - mape: 27.4901\n",
      "Epoch 108/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0593 - mse: 0.0049 - mae: 0.0593 - mape: 27.3975\n",
      "Epoch 109/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0593 - mse: 0.0049 - mae: 0.0593 - mape: 27.3919\n",
      "Epoch 110/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0593 - mse: 0.0049 - mae: 0.0593 - mape: 27.4912\n",
      "Epoch 111/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0593 - mse: 0.0049 - mae: 0.0593 - mape: 27.5570\n",
      "Epoch 112/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0593 - mse: 0.0048 - mae: 0.0593 - mape: 27.3249\n",
      "Epoch 113/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0592 - mse: 0.0049 - mae: 0.0592 - mape: 27.4517\n",
      "Epoch 114/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0592 - mse: 0.0048 - mae: 0.0592 - mape: 27.3524\n",
      "Epoch 115/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0592 - mse: 0.0049 - mae: 0.0592 - mape: 27.4253\n",
      "Epoch 116/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0592 - mse: 0.0049 - mae: 0.0592 - mape: 27.5314\n",
      "Epoch 117/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0593 - mse: 0.0048 - mae: 0.0593 - mape: 27.3223\n",
      "Epoch 118/200\n",
      "1225/1225 [==============================] - 0s 38us/sample - loss: 0.0591 - mse: 0.0049 - mae: 0.0591 - mape: 27.4492\n",
      "Epoch 119/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0591 - mse: 0.0050 - mae: 0.0591 - mape: 27.5919\n",
      "Epoch 120/200\n",
      "1225/1225 [==============================] - 0s 41us/sample - loss: 0.0591 - mse: 0.0049 - mae: 0.0591 - mape: 27.5487\n",
      "Epoch 121/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0591 - mse: 0.0049 - mae: 0.0591 - mape: 27.5220\n",
      "Epoch 122/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0591 - mse: 0.0050 - mae: 0.0591 - mape: 27.7416\n",
      "Epoch 123/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0591 - mse: 0.0050 - mae: 0.0591 - mape: 27.5894\n",
      "Epoch 124/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0590 - mse: 0.0049 - mae: 0.0590 - mape: 27.4735\n",
      "Epoch 125/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0590 - mse: 0.0050 - mae: 0.0590 - mape: 27.6002\n",
      "Epoch 126/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0590 - mse: 0.0051 - mae: 0.0590 - mape: 27.8154\n",
      "Epoch 127/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0590 - mse: 0.0051 - mae: 0.0590 - mape: 27.8006\n",
      "Epoch 128/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0589 - mse: 0.0051 - mae: 0.0589 - mape: 27.7790\n",
      "Epoch 129/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0589 - mse: 0.0050 - mae: 0.0589 - mape: 27.6557\n",
      "Epoch 130/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0589 - mse: 0.0049 - mae: 0.0589 - mape: 27.5730\n",
      "Epoch 131/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0589 - mse: 0.0050 - mae: 0.0589 - mape: 27.5998\n",
      "Epoch 132/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0589 - mse: 0.0051 - mae: 0.0589 - mape: 27.8679\n",
      "Epoch 133/200\n",
      "1225/1225 [==============================] - 0s 39us/sample - loss: 0.0589 - mse: 0.0049 - mae: 0.0589 - mape: 27.5220\n",
      "Epoch 134/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0588 - mse: 0.0050 - mae: 0.0588 - mape: 27.7376\n",
      "Epoch 135/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0588 - mse: 0.0050 - mae: 0.0588 - mape: 27.7216\n",
      "Epoch 136/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0588 - mse: 0.0052 - mae: 0.0588 - mape: 27.9575\n",
      "Epoch 137/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0588 - mse: 0.0050 - mae: 0.0588 - mape: 27.5820\n",
      "Epoch 138/200\n",
      "1225/1225 [==============================] - 0s 53us/sample - loss: 0.0587 - mse: 0.0051 - mae: 0.0587 - mape: 27.8136\n",
      "Epoch 139/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0587 - mse: 0.0051 - mae: 0.0587 - mape: 27.7833\n",
      "Epoch 140/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0587 - mse: 0.0051 - mae: 0.0587 - mape: 27.8180\n",
      "Epoch 141/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0586 - mse: 0.0051 - mae: 0.0586 - mape: 27.8527\n",
      "Epoch 142/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0586 - mse: 0.0050 - mae: 0.0586 - mape: 27.6334\n",
      "Epoch 143/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0587 - mse: 0.0052 - mae: 0.0587 - mape: 27.9307\n",
      "Epoch 144/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0586 - mse: 0.0050 - mae: 0.0586 - mape: 27.6683\n",
      "Epoch 145/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0586 - mse: 0.0051 - mae: 0.0586 - mape: 27.8610\n",
      "Epoch 146/200\n",
      "1225/1225 [==============================] - 0s 51us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.8357\n",
      "Epoch 147/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.7953\n",
      "Epoch 148/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.8914\n",
      "Epoch 149/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.7877\n",
      "Epoch 150/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0585 - mse: 0.0050 - mae: 0.0585 - mape: 27.7115\n",
      "Epoch 151/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.8096\n",
      "Epoch 152/200\n",
      "1225/1225 [==============================] - 0s 51us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.8129\n",
      "Epoch 153/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0584 - mse: 0.0051 - mae: 0.0584 - mape: 27.8189\n",
      "Epoch 154/200\n",
      "1225/1225 [==============================] - 0s 40us/sample - loss: 0.0584 - mse: 0.0051 - mae: 0.0584 - mape: 27.8165\n",
      "Epoch 155/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0584 - mse: 0.0050 - mae: 0.0584 - mape: 27.6341\n",
      "Epoch 156/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0584 - mse: 0.0051 - mae: 0.0584 - mape: 27.8354\n",
      "Epoch 157/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0584 - mse: 0.0052 - mae: 0.0584 - mape: 27.9868\n",
      "Epoch 158/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0584 - mse: 0.0051 - mae: 0.0584 - mape: 27.8044\n",
      "Epoch 159/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0584 - mse: 0.0050 - mae: 0.0584 - mape: 27.6836\n",
      "Epoch 160/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0584 - mse: 0.0051 - mae: 0.0584 - mape: 27.7747\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.8512\n",
      "Epoch 162/200\n",
      "1225/1225 [==============================] - 0s 56us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.7841\n",
      "Epoch 163/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.7580\n",
      "Epoch 164/200\n",
      "1225/1225 [==============================] - 0s 51us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.8481\n",
      "Epoch 165/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.8006\n",
      "Epoch 166/200\n",
      "1225/1225 [==============================] - 0s 52us/sample - loss: 0.0585 - mse: 0.0051 - mae: 0.0585 - mape: 27.9044\n",
      "Epoch 167/200\n",
      "1225/1225 [==============================] - 0s 61us/sample - loss: 0.0583 - mse: 0.0049 - mae: 0.0583 - mape: 27.5846\n",
      "Epoch 168/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.7905\n",
      "Epoch 169/200\n",
      "1225/1225 [==============================] - 0s 69us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.7641\n",
      "Epoch 170/200\n",
      "1225/1225 [==============================] - 0s 51us/sample - loss: 0.0583 - mse: 0.0052 - mae: 0.0583 - mape: 27.94240s - loss: 0.0588 - mse: 0.0052 - mae: 0.0588 - mape: 28.105\n",
      "Epoch 171/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0583 - mse: 0.0050 - mae: 0.0583 - mape: 27.7523\n",
      "Epoch 172/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0583 - mse: 0.0050 - mae: 0.0583 - mape: 27.6135\n",
      "Epoch 173/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0583 - mse: 0.0052 - mae: 0.0583 - mape: 27.9716\n",
      "Epoch 174/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.6842\n",
      "Epoch 175/200\n",
      "1225/1225 [==============================] - 0s 44us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8095\n",
      "Epoch 176/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.7563\n",
      "Epoch 177/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0583 - mse: 0.0051 - mae: 0.0583 - mape: 27.8400\n",
      "Epoch 178/200\n",
      "1225/1225 [==============================] - 0s 43us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8195\n",
      "Epoch 179/200\n",
      "1225/1225 [==============================] - 0s 49us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.6784\n",
      "Epoch 180/200\n",
      "1225/1225 [==============================] - 0s 60us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8969\n",
      "Epoch 181/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.7118\n",
      "Epoch 182/200\n",
      "1225/1225 [==============================] - 0s 55us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.7271\n",
      "Epoch 183/200\n",
      "1225/1225 [==============================] - 0s 46us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8898\n",
      "Epoch 184/200\n",
      "1225/1225 [==============================] - 0s 58us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8602\n",
      "Epoch 185/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.7857\n",
      "Epoch 186/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8042\n",
      "Epoch 187/200\n",
      "1225/1225 [==============================] - 0s 51us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8363\n",
      "Epoch 188/200\n",
      "1225/1225 [==============================] - 0s 48us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.8046\n",
      "Epoch 189/200\n",
      "1225/1225 [==============================] - 0s 52us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.7482\n",
      "Epoch 190/200\n",
      "1225/1225 [==============================] - 0s 55us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.7771\n",
      "Epoch 191/200\n",
      "1225/1225 [==============================] - 0s 47us/sample - loss: 0.0581 - mse: 0.0051 - mae: 0.0581 - mape: 27.7889\n",
      "Epoch 192/200\n",
      "1225/1225 [==============================] - 0s 50us/sample - loss: 0.0582 - mse: 0.0050 - mae: 0.0582 - mape: 27.6895\n",
      "Epoch 193/200\n",
      "1225/1225 [==============================] - 0s 42us/sample - loss: 0.0582 - mse: 0.0051 - mae: 0.0582 - mape: 27.7899\n",
      "Epoch 194/200\n",
      "1056/1225 [========================>.....] - ETA: 0s - loss: 0.0587 - mse: 0.0052 - mae: 0.0587 - mape: 28.1927"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "q_implicit_N_parts_possibilities = 0.99- np.array(range(N_plot_finess))/N_plot_finess\n",
    "\n",
    "# Get Performance Metric\n",
    "for inplicit_N_parts_loop in range(N_plot_finess):\n",
    "    # Implicitly Set: Current Number of Parts\n",
    "    q_implicit_N_parts_loop = q_implicit_N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    # Run Algos. 1+2\n",
    "    performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop = Ablate_PCNNs(q_implicit_N_parts_loop,data_y,X_train,X_test,y_test)\n",
    "    # Reshape\n",
    "    performance_Architope_loop = performance_Architope_loop.to_numpy().reshape([3,2,1])\n",
    "    Architope_Model_Complexity_full_loop = Architope_Model_Complexity_full_loop.to_numpy().reshape([1,5,1])\n",
    "\n",
    "    # Record\n",
    "    if inplicit_N_parts_loop == 0:\n",
    "        performance_Architope_history = performance_Architope_loop\n",
    "        Architope_Model_Complexity_history = Architope_Model_Complexity_full_loop\n",
    "        N_parts_Generated_by_Algo_2_history = N_parts_Generated_by_Algo_2_loop\n",
    "        N_params_architope_hist = N_params_architope_loop\n",
    "    else:\n",
    "        performance_Architope_history = np.concatenate((performance_Architope_history,performance_Architope_loop),axis=2)\n",
    "        Architope_Model_Complexity_history = np.concatenate((Architope_Model_Complexity_history,Architope_Model_Complexity_full_loop),axis=2)\n",
    "        N_parts_Generated_by_Algo_2_history = np.append(N_parts_Generated_by_Algo_2_history,N_parts_Generated_by_Algo_2_loop)\n",
    "        N_params_architope_hist = np.append(N_params_architope_hist,N_params_architope_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomization may produce duplicates; we remove these with the following snippet:\n",
    "get_unique_entries = np.unique(N_parts_Generated_by_Algo_2_history, return_index=True)[1]\n",
    "N_parts_Generated_by_Algo_2_history_report = N_parts_Generated_by_Algo_2_history[get_unique_entries]\n",
    "## Prediction Qualities\n",
    "performance_Architope_history_report_MAE_train = (performance_Architope_history[1,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MAE_test = (performance_Architope_history[1,1,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_train = (performance_Architope_history[0,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_test = (performance_Architope_history[0,1,:])[get_unique_entries]\n",
    "## Model Complexities\n",
    "L_Times = (Architope_Model_Complexity_history[:,0].reshape(-1,))[get_unique_entries]\n",
    "P_Times = (Architope_Model_Complexity_history[:,1].reshape(-1,))[get_unique_entries]\n",
    "N_Params = (N_params_architope_hist.reshape(-1,))[get_unique_entries]\n",
    "AIC_Like = (Architope_Model_Complexity_history[:,3].reshape(-1,))[get_unique_entries]\n",
    "Eff = (Architope_Model_Complexity_history[:,4].reshape(-1,))[get_unique_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MAE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MAE_test)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MAE_test___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MSE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MSE_test)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MSE___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"L-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"L-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_Times)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_L_Time___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"P-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"P-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_Times)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_P_Time___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"N. Params\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"N. Params\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_Params)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_N_Params___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC-Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"AIC-Like\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"AIC-Like\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         AIC_Like)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_AIC_Like___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Eff\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Eff\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         Eff)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Eff___Synthetic.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
