{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"PC-NNs\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50\n",
    "# Ablation Finess\n",
    "N_plot_finess = 15; min_parts_threshold = .6; max_parts_threshold = 0.85\n",
    "Fix_Neurons_Q = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "#================================================#\n",
      " Training Datasize: 599 and test datasize: 599.  \n",
      "#================================================#\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ablate_PCNNs(q_inplicit_N_parts,data_y,X_train,X_test,y_test):\n",
    "    #---------------------#\n",
    "    # Building Partitions #\n",
    "    #---------------------#\n",
    "\n",
    "    ############# Partitioner Begin #######\n",
    "    import time\n",
    "    partitioning_time_begin = time.time()\n",
    "    if Option_Function == 'SnP':\n",
    "        q_in_auto = q_inplicit_N_parts\n",
    "        Min_data_size_percentage_auto = .1\n",
    "        min_size_part = 100\n",
    "    else:\n",
    "        if Option_Function == 'crypto':\n",
    "            q_in_auto = .99\n",
    "            Min_data_size_percentage_auto = .3\n",
    "            min_size_part = 100\n",
    "        if Option_Function == 'Motivational_Example':\n",
    "            q_in_auto = q_inplicit_N_parts\n",
    "            Min_data_size_percentage_auto = .5\n",
    "            min_size_part = 10\n",
    "            # Partition Based on Y\n",
    "            holder_temp = data_y\n",
    "            data_y = X_train\n",
    "            X_train = holder_temp\n",
    "        else:\n",
    "            q_in_auto = .5\n",
    "            Min_data_size_percentage_auto = .3\n",
    "            min_size_part = 100\n",
    "\n",
    "    # Initialize Number of Parts currently generated\n",
    "    N_parts_generated = 0\n",
    "\n",
    "    # Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "    while N_parts_generated < 2:\n",
    "        # Generate Parts\n",
    "        X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                          q_in=q_in_auto, \n",
    "                                                                          X_train_in=X_train, \n",
    "                                                                          y_train_in=data_y, \n",
    "                                                                          CV_folds_failsafe=CV_folds,\n",
    "                                                                          min_size = min_size_part)\n",
    "\n",
    "        # Update Number of Parts\n",
    "        N_parts_generated = len(X_parts_list)\n",
    "        # Shuffle hyperparameters\n",
    "        Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "        q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "\n",
    "        # Update User\n",
    "        print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "\n",
    "    # Trash removal (removes empty parts)\n",
    "    X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "    y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "\n",
    "\n",
    "    # ICML Rebuttle Deadline = Coersion!\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "        holder_temp = y_parts_list\n",
    "        y_parts_list = X_parts_list\n",
    "        X_parts_list = holder_temp\n",
    "\n",
    "\n",
    "    partitioning_time = time.time() - partitioning_time_begin\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    # Record the number of parts:\n",
    "    N_parts_Generated_by_Algo_2 = len(X_parts_list)\n",
    "    ############# Partitioner End ########\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------#\n",
    "    # #### Building Training Predictions on each part\n",
    "    #-----------------------------------------------#\n",
    "    # - Train locally (on each \"naive part\")\n",
    "    # - Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "    # - Generate predictions on all of testing-set (will be selected between later using classifier)\n",
    "\n",
    "    # Time-Elapse (Start) for Training on Each Part #\n",
    "    Architope_partition_training_begin = time.time()\n",
    "    # Initialize running max for Parallel time\n",
    "    Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "    # Initialize N_parameter counter for Architope\n",
    "    N_params_Architope = 0\n",
    "\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Silly Coercsion for ICML rebuttle deadline timeline\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        Iteration_Length = len(X_parts_list) -1\n",
    "    else:\n",
    "        Iteration_Length = len(X_parts_list)\n",
    "\n",
    "\n",
    "    # Initialize Parameter Counter\n",
    "    N_params_tally = 0\n",
    "    # Train each part!\n",
    "    for current_part in range(Iteration_Length):\n",
    "        #==============#\n",
    "        # Timer(begin) #\n",
    "        #==============#\n",
    "        current_part_training_time_for_parallel_begin = time.time()\n",
    "\n",
    "\n",
    "        # Initializations #\n",
    "        #-----------------#\n",
    "        # Reload Grid\n",
    "        exec(open('Grid_Enhanced_Network.py').read())\n",
    "        # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "        current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "        current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "        if Fix_Neurons_Q == True:\n",
    "            current_height = np.maximum(current_height,current_height_threshold)/N_parts_Generated_by_Algo_2\n",
    "        current_height = current_height.astype(int).tolist()\n",
    "        param_grid_Vanilla_Nets['height'] = current_height\n",
    "        # Automatically Fix Input Dimension\n",
    "        param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "        param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "        \n",
    "        # Update Parameter Counter for PC-NNs (tally parameter count for sub-patterns)\n",
    "        N_params_tally += (current_height[0])*(param_grid_Vanilla_Nets['depth'][0])\n",
    "\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "        print('Heights to iterate over: '+str(current_height))\n",
    "\n",
    "        # Generate Prediction(s) on current Part #\n",
    "        #----------------------------------------#\n",
    "        # Failsafe (number of data-points)\n",
    "        CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "        # Train Network\n",
    "        y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                          n_jobs = n_jobs,\n",
    "                                                                                          n_iter = n_iter, \n",
    "                                                                                          param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                          X_train= X_parts_list[current_part], \n",
    "                                                                                          y_train=y_parts_list[current_part],\n",
    "                                                                                          X_test_partial=X_train,\n",
    "                                                                                          X_test=X_test,\n",
    "                                                                                          NOCV=True)\n",
    "        #put shape formats in order\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_train_full_loop.shape = (y_hat_train_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_test_full_loop.shape = (y_hat_test_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "            training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_train_full_loop\n",
    "            predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "            predictions_test = y_hat_test_full_loop\n",
    "            predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "\n",
    "\n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "        # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "            predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "            y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "            predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "\n",
    "        #============#\n",
    "        # Timer(end) #\n",
    "        #============#\n",
    "        current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "        Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "        #============---===============#\n",
    "\n",
    "        # N_parameter Counter (Update) #\n",
    "        #------------===---------------#\n",
    "        N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "    # Update User\n",
    "    #-------------#\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('----------------------------------------------------')\n",
    "    print('Feature Generation (Learning Phase): Score Generated')\n",
    "    print('----------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "\n",
    "    # Time-Elapsed Training on Each Part\n",
    "    Architope_partition_training = time.time() - Architope_partition_training_begin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------#\n",
    "    # Train Deep Zero-Sets #\n",
    "    #----------------------#\n",
    "    #### Deep Classifier\n",
    "    # Prepare Labels/Classes\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training_begin = time.time()\n",
    "    # Initialize Classes Labels\n",
    "    partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    # Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    # Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    #### Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary.\n",
    "    # Re-Load Hyper-parameter Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Re-Load Helper Function(s)\n",
    "    exec(open('Helper_Functions.py').read())\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]\n",
    "    ## Re-adjust heights\n",
    "    if Fix_Neurons_Q == True:\n",
    "        param_grid_Deep_Classifier['height'] = [int(max(round(param_grid_Deep_Classifier['height'][0]/N_parts_Generated_by_Algo_2,0),1))]\n",
    "\n",
    "    \n",
    "    # Update Parameter Counter for PC-NNs (tally parameter count for sub-patterns)\n",
    "    N_params_tally += (param_grid_Deep_Classifier['height'][0])*(param_grid_Deep_Classifier['depth'][0])\n",
    "    \n",
    "    #### Train Deep Classifier\n",
    "    # Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train.values, \n",
    "                                                                                                        y_train = partition_labels_training.values,\n",
    "                                                                                                        X_test = X_test.values)\n",
    "    # COMMENT: .values() is used to convert the Pandas Dataframes here, and not in the vanilla ffNNs, since the former is coded in Keras and the latter in tensorflow.  \n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin\n",
    "\n",
    "    ##### Get Binary Classes (Discontinuous Unit)\n",
    "    #Maps deep classifier's outputs $\\tilde{C}(x)\\triangleq \\hat{s}(x)$ to deep zero-sets $I_{(.5,1]}\\circ \\sigma_{\\mbox{sigmoid}}(\\tilde{C}(x))$.\n",
    "\n",
    "    # Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>.5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "    # Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > .5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)\n",
    "    #### Get PC-NN Prediction(s)\n",
    "    # Comuptes $\\sum_{n=1}^N \\, \\hat{f}(x)\\cdot I_{K_n}$\n",
    "    # Train\n",
    "    Architope_prediction_y_train = (predictions_train*predicted_classes_train).sum(axis=1)\n",
    "    # Test\n",
    "    Architope_prediction_y_test = (predictions_test*predicted_classes_test).sum(axis=1)\n",
    "\n",
    "\n",
    "    # Compute Peformance\n",
    "    performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "    # Update User\n",
    "    print(performance_Architope)\n",
    "\n",
    "    ### Model Complexity/Efficiency Metrics\n",
    "    # Compute Parameters for composite models #\n",
    "    #-----------------------------------------#\n",
    "    N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "    # Build AIC-like Metric #\n",
    "    #-----------------------#\n",
    "    AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "    AIC_like = np.round(AIC_like,3)\n",
    "    Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "    Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "    # Build Table #\n",
    "    #-------------#\n",
    "    Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "    # Write Required Training Time(s)\n",
    "    Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "    #--------------======---------------#\n",
    "    # Display Required Training Time(s) #\n",
    "    #--------------======---------------#\n",
    "    print(Architope_Model_Complexity_full)\n",
    "    \n",
    "    # Return Performance Metrics\n",
    "    return performance_Architope, Architope_Model_Complexity_full, N_parts_Generated_by_Algo_2, N_params_tally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform Ablation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.0\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "0.988313856427379\n",
      "0.986644407345576\n",
      "0.9833055091819699\n",
      "0.9816360601001669\n",
      "0.9799666110183639\n",
      "0.9782971619365609\n",
      "0.9766277128547579\n",
      "0.9749582637729549\n",
      "0.9732888146911519\n",
      "0.9716193656093489\n",
      "0.9699499165275459\n",
      "0.9682804674457429\n",
      "0.9666110183639399\n",
      "0.9649415692821369\n",
      "0.9632721202003339\n",
      "0.9616026711185309\n",
      "0.9549248747913188\n",
      "0.9482470784641068\n",
      "0.9449081803005008\n",
      "0.9432387312186978\n",
      "0.9415692821368948\n",
      "0.9398998330550918\n",
      "0.9365609348914858\n",
      "0.9348914858096828\n",
      "0.9332220367278798\n",
      "0.9298831385642737\n",
      "0.9282136894824707\n",
      "0.9265442404006677\n",
      "0.9248747913188647\n",
      "0.9232053422370617\n",
      "0.9215358931552587\n",
      "0.9198664440734557\n",
      "0.9181969949916527\n",
      "0.9165275459098498\n",
      "0.9148580968280468\n",
      "0.9131886477462438\n",
      "0.9115191986644408\n",
      "0.9098497495826378\n",
      "0.9048414023372288\n",
      "0.9031719532554258\n",
      "0.9015025041736227\n",
      "0.8998330550918197\n",
      "0.8981636060100167\n",
      "0.8964941569282137\n",
      "0.8948247078464107\n",
      "0.8931552587646077\n",
      "0.8914858096828047\n",
      "0.8898163606010017\n",
      "0.8881469115191987\n",
      "0.8864774624373957\n",
      "0.8848080133555927\n",
      "0.8797996661101837\n",
      "0.8781302170283807\n",
      "0.8764607679465777\n",
      "0.8697829716193656\n",
      "0.8681135225375626\n",
      "0.8664440734557596\n",
      "0.8647746243739566\n",
      "0.8631051752921536\n",
      "0.8614357262103506\n",
      "0.8597662771285476\n",
      "0.8580968280467446\n",
      "0.8564273789649416\n",
      "0.8547579298831386\n",
      "0.8530884808013356\n",
      "0.8514190317195326\n",
      "0.8497495826377296\n",
      "0.8480801335559266\n",
      "0.8464106844741235\n",
      "0.8447412353923205\n",
      "0.8430717863105175\n",
      "0.8414023372287145\n",
      "0.8397328881469115\n",
      "0.8380634390651085\n",
      "0.8363939899833055\n",
      "0.8347245409015025\n",
      "0.8330550918196995\n",
      "0.8313856427378965\n",
      "0.8297161936560935\n",
      "0.8280467445742905\n",
      "0.8263772954924875\n",
      "0.8247078464106845\n",
      "0.8230383973288815\n",
      "0.8213689482470785\n",
      "0.8196994991652755\n",
      "0.8180300500834724\n",
      "0.8163606010016694\n",
      "0.8146911519198664\n",
      "0.8113522537562604\n",
      "0.8096828046744574\n",
      "0.8080133555926544\n",
      "0.8063439065108514\n",
      "0.8046744574290484\n",
      "0.8030050083472454\n",
      "0.8013355592654424\n",
      "0.7996661101836394\n",
      "0.7979966611018364\n",
      "0.7946577629382304\n",
      "0.7929883138564274\n",
      "0.7913188647746243\n",
      "0.7896494156928213\n",
      "0.7879799666110183\n",
      "0.7846410684474123\n",
      "0.7829716193656093\n",
      "0.7813021702838063\n",
      "0.7796327212020033\n",
      "0.7779632721202003\n",
      "0.7762938230383973\n",
      "0.7746243739565943\n",
      "0.7729549248747913\n",
      "0.7712854757929883\n",
      "0.7696160267111853\n",
      "0.7679465776293823\n",
      "0.7662771285475793\n",
      "0.7646076794657763\n",
      "0.7629382303839732\n",
      "0.7612687813021702\n",
      "0.7595993322203672\n",
      "0.7579298831385642\n",
      "0.7562604340567612\n",
      "0.7545909849749582\n",
      "0.7529215358931552\n",
      "0.7512520868113522\n",
      "0.7495826377295493\n",
      "0.7479131886477463\n",
      "0.7462437395659433\n",
      "0.7445742904841403\n",
      "0.7429048414023373\n",
      "0.7412353923205343\n",
      "0.7395659432387313\n",
      "0.7378964941569283\n",
      "0.7362270450751253\n",
      "0.7345575959933222\n",
      "0.7328881469115192\n",
      "0.7312186978297162\n",
      "0.7295492487479132\n",
      "0.7278797996661102\n",
      "0.7262103505843072\n",
      "0.7245409015025042\n",
      "0.7228714524207012\n",
      "0.7212020033388982\n",
      "0.7178631051752922\n",
      "0.7161936560934892\n",
      "0.7145242070116862\n",
      "0.7128547579298832\n",
      "0.7111853088480802\n",
      "0.7095158597662772\n",
      "0.7078464106844741\n",
      "0.7061769616026711\n",
      "0.7045075125208681\n",
      "0.7028380634390651\n",
      "0.7011686143572621\n",
      "0.6994991652754591\n",
      "0.6978297161936561\n",
      "0.6961602671118531\n",
      "0.6944908180300501\n",
      "0.6928213689482471\n",
      "0.6911519198664441\n",
      "0.6894824707846411\n",
      "0.6878130217028381\n",
      "0.6861435726210351\n",
      "0.6844741235392321\n",
      "0.6828046744574291\n",
      "0.679465776293823\n",
      "0.67779632721202\n",
      "0.676126878130217\n",
      "0.674457429048414\n",
      "0.672787979966611\n",
      "0.671118530884808\n",
      "0.669449081803005\n",
      "0.666110183639399\n",
      "0.664440734557596\n",
      "0.662771285475793\n",
      "0.66110183639399\n",
      "0.659432387312187\n",
      "0.657762938230384\n",
      "0.656093489148581\n",
      "0.654424040066778\n",
      "0.6527545909849749\n",
      "0.6510851419031719\n",
      "0.6494156928213689\n",
      "0.6477462437395659\n",
      "0.6460767946577629\n",
      "0.6444073455759599\n",
      "0.6427378964941569\n",
      "0.6410684474123539\n",
      "0.6393989983305509\n",
      "0.6377295492487479\n",
      "0.6360601001669449\n",
      "0.6343906510851419\n",
      "0.6327212020033389\n",
      "0.6310517529215359\n",
      "0.6293823038397329\n",
      "0.6277128547579299\n",
      "0.6260434056761269\n",
      "0.6243739565943238\n",
      "0.6176961602671118\n",
      "0.6160267111853088\n",
      "0.6143572621035058\n",
      "0.6126878130217028\n",
      "0.6110183639398998\n",
      "0.6093489148580968\n",
      "0.6076794657762938\n",
      "0.6060100166944908\n",
      "0.6043405676126878\n",
      "0.6026711185308848\n",
      "0.6010016694490818\n",
      "0.5993322203672788\n",
      "0.5976627712854758\n",
      "0.5959933222036727\n",
      "0.5943238731218697\n",
      "0.5926544240400667\n",
      "0.5909849749582637\n",
      "0.5893155258764607\n",
      "0.5876460767946577\n",
      "0.5859766277128547\n",
      "0.5843071786310517\n",
      "0.5826377295492488\n",
      "0.5809682804674458\n",
      "0.5792988313856428\n",
      "0.5776293823038398\n",
      "0.5759599332220368\n",
      "0.5742904841402338\n",
      "0.5709515859766278\n",
      "0.5692821368948247\n",
      "0.5676126878130217\n",
      "0.5659432387312187\n",
      "0.5642737896494157\n",
      "0.5626043405676127\n",
      "0.5609348914858097\n",
      "0.5592654424040067\n",
      "0.5575959933222037\n",
      "0.5559265442404007\n",
      "0.5542570951585977\n",
      "0.5525876460767947\n",
      "0.5509181969949917\n",
      "0.5492487479131887\n",
      "0.5475792988313857\n",
      "0.5459098497495827\n",
      "0.5442404006677797\n",
      "0.5425709515859767\n",
      "0.5409015025041736\n",
      "0.5392320534223706\n",
      "0.5375626043405676\n",
      "0.5358931552587646\n",
      "0.5342237061769616\n",
      "0.5325542570951586\n",
      "0.5308848080133556\n",
      "0.5292153589315526\n",
      "0.5275459098497496\n",
      "0.5258764607679466\n",
      "0.5242070116861436\n",
      "0.5225375626043406\n",
      "0.5208681135225376\n",
      "0.5191986644407346\n",
      "0.5175292153589316\n",
      "0.5158597662771286\n",
      "0.5141903171953256\n",
      "0.5108514190317195\n",
      "0.5091819699499165\n",
      "0.5075125208681135\n",
      "0.5058430717863105\n",
      "0.5041736227045075\n",
      "0.5025041736227045\n",
      "0.5008347245409015\n",
      "0.4991652754590985\n",
      "0.4974958263772955\n",
      "0.4958263772954925\n",
      "0.4941569282136895\n",
      "0.49248747913188645\n",
      "0.49081803005008345\n",
      "0.48914858096828046\n",
      "0.48747913188647746\n",
      "0.48580968280467446\n",
      "0.48414023372287146\n",
      "0.48247078464106846\n",
      "0.48080133555926546\n",
      "0.4791318864774624\n",
      "0.4757929883138564\n",
      "0.4741235392320534\n",
      "0.4724540901502504\n",
      "0.4707846410684474\n",
      "0.4691151919866444\n",
      "0.4674457429048414\n",
      "0.4657762938230384\n",
      "0.46410684474123537\n",
      "0.46243739565943237\n",
      "0.4607679465776294\n",
      "0.4590984974958264\n",
      "0.4574290484140234\n",
      "0.4557595993322204\n",
      "0.4540901502504174\n",
      "0.4524207011686144\n",
      "0.4507512520868113\n",
      "0.44908180300500833\n",
      "0.44741235392320533\n",
      "0.44574290484140233\n",
      "0.44407345575959933\n",
      "0.44240400667779634\n",
      "0.44073455759599334\n",
      "0.43906510851419034\n",
      "0.4373956594323873\n",
      "0.4357262103505843\n",
      "0.4340567612687813\n",
      "0.4323873121869783\n",
      "0.4307178631051753\n",
      "0.4290484140233723\n",
      "0.4273789649415693\n",
      "0.4257095158597663\n",
      "0.4240400667779633\n",
      "0.42237061769616024\n",
      "0.42070116861435725\n",
      "0.41903171953255425\n",
      "0.41736227045075125\n",
      "0.41569282136894825\n",
      "0.41402337228714525\n",
      "0.41235392320534225\n",
      "0.41068447412353926\n",
      "0.4090150250417362\n",
      "0.4073455759599332\n",
      "0.4056761268781302\n",
      "0.4040066777963272\n",
      "0.4023372287145242\n",
      "0.4006677796327212\n",
      "0.3989983305509182\n",
      "0.3973288814691152\n",
      "0.39565943238731216\n",
      "0.39398998330550916\n",
      "0.39232053422370616\n",
      "0.39065108514190316\n",
      "0.38898163606010017\n",
      "0.38731218697829717\n",
      "0.38564273789649417\n",
      "0.38397328881469117\n",
      "0.3823038397328882\n",
      "0.3806343906510851\n",
      "0.3789649415692821\n",
      "0.3772954924874791\n",
      "0.3756260434056761\n",
      "0.3739565943238731\n",
      "0.3722871452420701\n",
      "0.37061769616026713\n",
      "0.36894824707846413\n",
      "0.3672787979966611\n",
      "0.3656093489148581\n",
      "0.3639398998330551\n",
      "0.3622704507512521\n",
      "0.3606010016694491\n",
      "0.3589315525876461\n",
      "0.3572621035058431\n",
      "0.3555926544240401\n",
      "0.35392320534223703\n",
      "0.35225375626043404\n",
      "0.35058430717863104\n",
      "0.34891485809682804\n",
      "0.34724540901502504\n",
      "0.34557595993322204\n",
      "0.34390651085141904\n",
      "0.34223706176961605\n",
      "0.34056761268781305\n",
      "0.33889816360601\n",
      "0.337228714524207\n",
      "0.335559265442404\n",
      "0.333889816360601\n",
      "0.332220367278798\n",
      "0.330550918196995\n",
      "0.328881469115192\n",
      "0.327212020033389\n",
      "0.32554257095158595\n",
      "0.32387312186978295\n",
      "0.32220367278797996\n",
      "0.32053422370617696\n",
      "0.31886477462437396\n",
      "0.31719532554257096\n",
      "0.31552587646076796\n",
      "0.31385642737896496\n",
      "0.3121869782971619\n",
      "0.3105175292153589\n",
      "0.3088480801335559\n",
      "0.3071786310517529\n",
      "0.3055091819699499\n",
      "0.3038397328881469\n",
      "0.3021702838063439\n",
      "0.3005008347245409\n",
      "0.2988313856427379\n",
      "0.29716193656093487\n",
      "0.29549248747913187\n",
      "0.2938230383973289\n",
      "0.2921535893155259\n",
      "0.2904841402337229\n",
      "0.2888146911519199\n",
      "0.2871452420701169\n",
      "0.2854757929883139\n",
      "0.2838063439065108\n",
      "0.28213689482470783\n",
      "0.28046744574290483\n",
      "0.27879799666110183\n",
      "0.27712854757929883\n",
      "0.27545909849749584\n",
      "0.27378964941569284\n",
      "0.27212020033388984\n",
      "0.2704507512520868\n",
      "0.2687813021702838\n",
      "0.2671118530884808\n",
      "0.2654424040066778\n",
      "0.2637729549248748\n",
      "0.2621035058430718\n",
      "0.2604340567612688\n",
      "0.2587646076794658\n",
      "0.2570951585976628\n",
      "0.25542570951585974\n",
      "0.25375626043405675\n",
      "0.25208681135225375\n",
      "0.25041736227045075\n",
      "0.24874791318864775\n",
      "0.24707846410684475\n",
      "0.24540901502504173\n",
      "0.24373956594323873\n",
      "0.24207011686143573\n",
      "0.24040066777963273\n",
      "0.2387312186978297\n",
      "0.2370617696160267\n",
      "0.2353923205342237\n",
      "0.2337228714524207\n",
      "0.23205342237061768\n",
      "0.2303839732888147\n",
      "0.2287145242070117\n",
      "0.2270450751252087\n",
      "0.22537562604340566\n",
      "0.22370617696160267\n",
      "0.22203672787979967\n",
      "0.22036727879799667\n",
      "0.21869782971619364\n",
      "0.21702838063439064\n",
      "0.21535893155258765\n",
      "0.21368948247078465\n",
      "0.21202003338898165\n",
      "0.21035058430717862\n",
      "0.20868113522537562\n",
      "0.20701168614357263\n",
      "0.20534223706176963\n",
      "0.2036727879799666\n",
      "0.2020033388981636\n",
      "0.2003338898163606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1986644407345576\n",
      "0.19699499165275458\n",
      "0.19532554257095158\n",
      "0.19365609348914858\n",
      "0.19198664440734559\n",
      "0.19031719532554256\n",
      "0.18864774624373956\n",
      "0.18697829716193656\n",
      "0.18530884808013356\n",
      "0.18363939899833054\n",
      "0.18196994991652754\n",
      "0.18030050083472454\n",
      "0.17863105175292154\n",
      "0.17696160267111852\n",
      "0.17529215358931552\n",
      "0.17362270450751252\n",
      "0.17195325542570952\n",
      "0.17028380634390652\n",
      "0.1686143572621035\n",
      "0.1669449081803005\n",
      "0.1652754590984975\n",
      "0.1636060100166945\n",
      "0.16193656093489148\n",
      "0.16026711185308848\n",
      "0.15859766277128548\n",
      "0.15692821368948248\n",
      "0.15525876460767946\n",
      "0.15358931552587646\n",
      "0.15191986644407346\n",
      "0.15025041736227046\n",
      "0.14858096828046743\n",
      "0.14691151919866444\n",
      "0.14524207011686144\n",
      "0.14357262103505844\n",
      "0.1419031719532554\n",
      "0.14023372287145242\n",
      "0.13856427378964942\n",
      "0.13689482470784642\n",
      "0.1352253756260434\n",
      "0.1335559265442404\n",
      "0.1318864774624374\n",
      "0.1302170283806344\n",
      "0.1285475792988314\n",
      "0.12687813021702837\n",
      "0.12520868113522537\n",
      "0.12353923205342238\n",
      "0.12186978297161936\n",
      "0.12020033388981637\n",
      "0.11853088480801335\n",
      "0.11686143572621036\n",
      "0.11519198664440734\n",
      "0.11352253756260434\n",
      "0.11185308848080133\n",
      "0.11018363939899833\n",
      "0.10851419031719532\n",
      "0.10684474123539232\n",
      "0.10517529215358931\n",
      "0.10350584307178631\n",
      "0.1018363939899833\n",
      "0.1001669449081803\n",
      "0.09849749582637729\n",
      "0.09682804674457429\n",
      "0.09515859766277128\n",
      "0.09348914858096828\n",
      "0.09181969949916527\n",
      "0.09015025041736227\n",
      "0.08848080133555926\n",
      "0.08681135225375626\n",
      "0.08514190317195326\n",
      "0.08347245409015025\n",
      "0.08180300500834725\n",
      "0.08013355592654424\n",
      "0.07846410684474124\n",
      "0.07679465776293823\n",
      "0.07512520868113523\n",
      "0.07345575959933222\n",
      "0.07178631051752922\n",
      "0.07011686143572621\n",
      "0.06844741235392321\n",
      "0.0667779632721202\n",
      "0.0651085141903172\n",
      "0.06343906510851419\n",
      "0.06176961602671119\n",
      "0.06010016694490818\n",
      "0.05843071786310518\n",
      "0.05676126878130217\n",
      "0.05509181969949917\n",
      "0.05342237061769616\n",
      "0.05175292153589316\n",
      "0.05008347245409015\n",
      "0.048414023372287146\n",
      "0.04674457429048414\n",
      "0.045075125208681135\n",
      "0.04340567612687813\n",
      "0.041736227045075125\n",
      "0.04006677796327212\n",
      "0.038397328881469114\n",
      "0.03672787979966611\n",
      "0.035058430717863104\n",
      "0.0333889816360601\n",
      "0.03171953255425709\n",
      "0.03005008347245409\n",
      "0.028380634390651086\n",
      "0.02671118530884808\n",
      "0.025041736227045076\n",
      "0.02337228714524207\n",
      "0.021702838063439065\n",
      "0.02003338898163606\n",
      "0.018363939899833055\n",
      "0.01669449081803005\n",
      "0.015025041736227046\n",
      "0.01335559265442404\n",
      "0.011686143572621035\n",
      "0.01001669449081803\n",
      "0.008347245409015025\n",
      "0.00667779632721202\n",
      "0.005008347245409015\n",
      "0.00333889816360601\n",
      "0.001669449081803005\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n",
      "0.9849749582637729\n",
      "0.9833055091819699\n",
      "0.9782971619365609\n",
      "0.9766277128547579\n",
      "0.9749582637729549\n",
      "0.9732888146911519\n",
      "0.9716193656093489\n",
      "0.9699499165275459\n",
      "0.9682804674457429\n",
      "0.9666110183639399\n",
      "0.9632721202003339\n",
      "0.9616026711185309\n",
      "0.9599332220367279\n",
      "0.9582637729549248\n",
      "0.9549248747913188\n",
      "0.9532554257095158\n",
      "0.9432387312186978\n",
      "0.9348914858096828\n",
      "0.9332220367278798\n",
      "0.9315525876460768\n",
      "0.9298831385642737\n",
      "0.9282136894824707\n",
      "0.9248747913188647\n",
      "0.9232053422370617\n",
      "0.9181969949916527\n",
      "0.9165275459098498\n",
      "0.9148580968280468\n",
      "0.9131886477462438\n",
      "0.9115191986644408\n",
      "0.9098497495826378\n",
      "0.9081803005008348\n",
      "0.9048414023372288\n",
      "0.9031719532554258\n",
      "0.9015025041736227\n",
      "0.8981636060100167\n",
      "0.8964941569282137\n",
      "0.8948247078464107\n",
      "0.8864774624373957\n",
      "0.8848080133555927\n",
      "0.8831385642737897\n",
      "0.8814691151919867\n",
      "0.8781302170283807\n",
      "0.8764607679465777\n",
      "0.8747913188647746\n",
      "0.8731218697829716\n",
      "0.8714524207011686\n",
      "0.8681135225375626\n",
      "0.8664440734557596\n",
      "0.8631051752921536\n",
      "0.8580968280467446\n",
      "0.8547579298831386\n",
      "0.8530884808013356\n",
      "0.8430717863105175\n",
      "0.8414023372287145\n",
      "0.8397328881469115\n",
      "0.8380634390651085\n",
      "0.8363939899833055\n",
      "0.8347245409015025\n",
      "0.8330550918196995\n",
      "0.8313856427378965\n",
      "0.8297161936560935\n",
      "0.8280467445742905\n",
      "0.8263772954924875\n",
      "0.8247078464106845\n",
      "0.8230383973288815\n",
      "0.8213689482470785\n",
      "0.8196994991652755\n",
      "0.8180300500834724\n",
      "0.8163606010016694\n",
      "0.8146911519198664\n",
      "0.8130217028380634\n",
      "0.8113522537562604\n",
      "0.8096828046744574\n",
      "0.8080133555926544\n",
      "0.8063439065108514\n",
      "0.8046744574290484\n",
      "0.8030050083472454\n",
      "0.8013355592654424\n",
      "0.7996661101836394\n",
      "0.7979966611018364\n",
      "0.7963272120200334\n",
      "0.7946577629382304\n",
      "0.7929883138564274\n",
      "0.7913188647746243\n",
      "0.7896494156928213\n",
      "0.7879799666110183\n",
      "0.7863105175292153\n",
      "0.7813021702838063\n",
      "0.7796327212020033\n",
      "0.7746243739565943\n",
      "0.7729549248747913\n",
      "0.7712854757929883\n",
      "0.7696160267111853\n",
      "0.7679465776293823\n",
      "0.7646076794657763\n",
      "0.7629382303839732\n",
      "0.7612687813021702\n",
      "0.7595993322203672\n",
      "0.7579298831385642\n",
      "0.7562604340567612\n",
      "0.7545909849749582\n",
      "0.7529215358931552\n",
      "0.7512520868113522\n",
      "0.7495826377295493\n",
      "0.7479131886477463\n",
      "0.7462437395659433\n",
      "0.7445742904841403\n",
      "0.7429048414023373\n",
      "0.7412353923205343\n",
      "0.7395659432387313\n",
      "0.7378964941569283\n",
      "0.7362270450751253\n",
      "0.7345575959933222\n",
      "0.7328881469115192\n",
      "0.7312186978297162\n",
      "0.7295492487479132\n",
      "0.7278797996661102\n",
      "0.7262103505843072\n",
      "0.7245409015025042\n",
      "0.7228714524207012\n",
      "0.7212020033388982\n",
      "0.7195325542570952\n",
      "0.7178631051752922\n",
      "0.7161936560934892\n",
      "0.7145242070116862\n",
      "0.7128547579298832\n",
      "0.7111853088480802\n",
      "0.7095158597662772\n",
      "0.7078464106844741\n",
      "0.7061769616026711\n",
      "0.7045075125208681\n",
      "0.7011686143572621\n",
      "0.6994991652754591\n",
      "0.6978297161936561\n",
      "0.6961602671118531\n",
      "0.6944908180300501\n",
      "0.6928213689482471\n",
      "0.6894824707846411\n",
      "0.6878130217028381\n",
      "0.6861435726210351\n",
      "0.6844741235392321\n",
      "0.6828046744574291\n",
      "0.6811352253756261\n",
      "0.679465776293823\n",
      "0.67779632721202\n",
      "0.676126878130217\n",
      "0.674457429048414\n",
      "0.672787979966611\n",
      "0.669449081803005\n",
      "0.667779632721202\n",
      "0.666110183639399\n",
      "0.664440734557596\n",
      "0.662771285475793\n",
      "0.66110183639399\n",
      "0.659432387312187\n",
      "0.657762938230384\n",
      "0.656093489148581\n",
      "0.654424040066778\n",
      "0.6510851419031719\n",
      "0.6494156928213689\n",
      "0.6477462437395659\n",
      "0.6460767946577629\n",
      "0.6444073455759599\n",
      "0.6427378964941569\n",
      "0.6410684474123539\n",
      "0.6377295492487479\n",
      "0.6360601001669449\n",
      "0.6343906510851419\n",
      "0.6327212020033389\n",
      "0.6310517529215359\n",
      "0.6293823038397329\n",
      "0.6277128547579299\n",
      "0.6260434056761269\n",
      "0.6243739565943238\n",
      "0.6227045075125208\n",
      "0.6210350584307178\n",
      "0.6193656093489148\n",
      "0.6176961602671118\n",
      "0.6160267111853088\n",
      "0.6143572621035058\n",
      "0.6126878130217028\n",
      "0.6110183639398998\n",
      "0.6093489148580968\n",
      "0.6076794657762938\n",
      "0.6060100166944908\n",
      "0.6043405676126878\n",
      "0.6026711185308848\n",
      "0.6010016694490818\n",
      "0.5993322203672788\n",
      "0.5976627712854758\n",
      "0.5959933222036727\n",
      "0.5943238731218697\n",
      "0.5926544240400667\n",
      "0.5909849749582637\n",
      "0.5893155258764607\n",
      "0.5876460767946577\n",
      "0.5859766277128547\n",
      "0.5843071786310517\n",
      "0.5826377295492488\n",
      "0.5809682804674458\n",
      "0.5792988313856428\n",
      "0.5776293823038398\n",
      "0.5759599332220368\n",
      "0.5742904841402338\n",
      "0.5726210350584308\n",
      "0.5709515859766278\n",
      "0.5692821368948247\n",
      "0.5676126878130217\n",
      "0.5659432387312187\n",
      "0.5642737896494157\n",
      "0.5626043405676127\n",
      "0.5592654424040067\n",
      "0.5575959933222037\n",
      "0.5559265442404007\n",
      "0.5542570951585977\n",
      "0.5525876460767947\n",
      "0.5509181969949917\n",
      "0.5492487479131887\n",
      "0.5475792988313857\n",
      "0.5459098497495827\n",
      "0.5442404006677797\n",
      "0.5425709515859767\n",
      "0.5409015025041736\n",
      "0.5392320534223706\n",
      "0.5375626043405676\n",
      "0.5358931552587646\n",
      "0.5342237061769616\n",
      "0.5325542570951586\n",
      "0.5308848080133556\n",
      "0.5292153589315526\n",
      "0.5275459098497496\n",
      "0.5258764607679466\n",
      "0.5242070116861436\n",
      "0.5225375626043406\n",
      "0.5208681135225376\n",
      "0.5191986644407346\n",
      "0.5175292153589316\n",
      "0.5158597662771286\n",
      "0.5125208681135225\n",
      "0.5108514190317195\n",
      "0.5091819699499165\n",
      "0.5075125208681135\n",
      "0.5058430717863105\n",
      "0.5041736227045075\n",
      "0.5025041736227045\n",
      "0.4991652754590985\n",
      "0.4974958263772955\n",
      "0.4958263772954925\n",
      "0.4941569282136895\n",
      "0.49248747913188645\n",
      "0.49081803005008345\n",
      "0.48914858096828046\n",
      "0.48747913188647746\n",
      "0.48580968280467446\n",
      "0.48414023372287146\n",
      "0.48080133555926546\n",
      "0.4791318864774624\n",
      "0.4774624373956594\n",
      "0.4757929883138564\n",
      "0.4741235392320534\n",
      "0.4724540901502504\n",
      "0.4707846410684474\n",
      "0.4691151919866444\n",
      "0.4657762938230384\n",
      "0.46410684474123537\n",
      "0.46243739565943237\n",
      "0.4607679465776294\n",
      "0.4590984974958264\n",
      "0.4574290484140234\n",
      "0.4557595993322204\n",
      "0.4540901502504174\n",
      "0.4524207011686144\n",
      "0.4507512520868113\n",
      "0.44908180300500833\n",
      "0.44741235392320533\n",
      "0.44574290484140233\n",
      "0.44407345575959933\n",
      "0.44240400667779634\n",
      "0.44073455759599334\n",
      "0.43906510851419034\n",
      "0.4373956594323873\n",
      "0.4357262103505843\n",
      "0.4340567612687813\n",
      "0.4323873121869783\n",
      "0.4307178631051753\n",
      "0.4290484140233723\n",
      "0.4273789649415693\n",
      "0.4257095158597663\n",
      "0.4240400667779633\n",
      "0.42237061769616024\n",
      "0.42070116861435725\n",
      "0.41736227045075125\n",
      "0.41402337228714525\n",
      "0.41235392320534225\n",
      "0.41068447412353926\n",
      "0.4090150250417362\n",
      "0.4073455759599332\n",
      "0.4056761268781302\n",
      "0.4040066777963272\n",
      "0.4023372287145242\n",
      "0.4006677796327212\n",
      "0.3989983305509182\n",
      "0.3973288814691152\n",
      "0.39565943238731216\n",
      "0.39398998330550916\n",
      "0.39232053422370616\n",
      "0.39065108514190316\n",
      "0.38898163606010017\n",
      "0.38731218697829717\n",
      "0.38564273789649417\n",
      "0.38397328881469117\n",
      "0.3823038397328882\n",
      "0.3806343906510851\n",
      "0.3789649415692821\n",
      "0.3772954924874791\n",
      "0.3756260434056761\n",
      "0.3739565943238731\n",
      "0.3722871452420701\n",
      "0.37061769616026713\n",
      "0.36894824707846413\n",
      "0.3672787979966611\n",
      "0.3639398998330551\n",
      "0.3622704507512521\n",
      "0.3606010016694491\n",
      "0.3589315525876461\n",
      "0.3572621035058431\n",
      "0.3555926544240401\n",
      "0.35392320534223703\n",
      "0.35225375626043404\n",
      "0.35058430717863104\n",
      "0.34891485809682804\n",
      "0.34724540901502504\n",
      "0.34557595993322204\n",
      "0.34390651085141904\n",
      "0.34223706176961605\n",
      "0.34056761268781305\n",
      "0.33889816360601\n",
      "0.337228714524207\n",
      "0.335559265442404\n",
      "0.333889816360601\n",
      "0.332220367278798\n",
      "0.330550918196995\n",
      "0.328881469115192\n",
      "0.327212020033389\n",
      "0.32554257095158595\n",
      "0.32387312186978295\n",
      "0.32220367278797996\n",
      "0.32053422370617696\n",
      "0.31886477462437396\n",
      "0.31719532554257096\n",
      "0.31552587646076796\n",
      "0.31385642737896496\n",
      "0.3121869782971619\n",
      "0.3105175292153589\n",
      "0.3088480801335559\n",
      "0.3071786310517529\n",
      "0.3055091819699499\n",
      "0.3038397328881469\n",
      "0.3021702838063439\n",
      "0.3005008347245409\n",
      "0.2988313856427379\n",
      "0.29716193656093487\n",
      "0.29549248747913187\n",
      "0.2938230383973289\n",
      "0.2921535893155259\n",
      "0.2904841402337229\n",
      "0.2888146911519199\n",
      "0.2871452420701169\n",
      "0.2854757929883139\n",
      "0.2838063439065108\n",
      "0.28213689482470783\n",
      "0.28046744574290483\n",
      "0.27879799666110183\n",
      "0.27712854757929883\n",
      "0.27545909849749584\n",
      "0.27378964941569284\n",
      "0.27212020033388984\n",
      "0.2704507512520868\n",
      "0.2687813021702838\n",
      "0.2671118530884808\n",
      "0.2654424040066778\n",
      "0.2637729549248748\n",
      "0.2621035058430718\n",
      "0.2604340567612688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2587646076794658\n",
      "0.2570951585976628\n",
      "0.25542570951585974\n",
      "0.25375626043405675\n",
      "0.25208681135225375\n",
      "0.25041736227045075\n",
      "0.24874791318864775\n",
      "0.24707846410684475\n",
      "0.24540901502504173\n",
      "0.24373956594323873\n",
      "0.24207011686143573\n",
      "0.24040066777963273\n",
      "0.2387312186978297\n",
      "0.2370617696160267\n",
      "0.2353923205342237\n",
      "0.2337228714524207\n",
      "0.23205342237061768\n",
      "0.2303839732888147\n",
      "0.2287145242070117\n",
      "0.2270450751252087\n",
      "0.22537562604340566\n",
      "0.22370617696160267\n",
      "0.22203672787979967\n",
      "0.22036727879799667\n",
      "0.21869782971619364\n",
      "0.21702838063439064\n",
      "0.21535893155258765\n",
      "0.21368948247078465\n",
      "0.21202003338898165\n",
      "0.21035058430717862\n",
      "0.20868113522537562\n",
      "0.20701168614357263\n",
      "0.20534223706176963\n",
      "0.2036727879799666\n",
      "0.2020033388981636\n",
      "0.2003338898163606\n",
      "0.1986644407345576\n",
      "0.19699499165275458\n",
      "0.19532554257095158\n",
      "0.19365609348914858\n",
      "0.19198664440734559\n",
      "0.19031719532554256\n",
      "0.18864774624373956\n",
      "0.18697829716193656\n",
      "0.18530884808013356\n",
      "0.18363939899833054\n",
      "0.18196994991652754\n",
      "0.18030050083472454\n",
      "0.17863105175292154\n",
      "0.17696160267111852\n",
      "0.17529215358931552\n",
      "0.17362270450751252\n",
      "0.17195325542570952\n",
      "0.17028380634390652\n",
      "0.1686143572621035\n",
      "0.1669449081803005\n",
      "0.1652754590984975\n",
      "0.1636060100166945\n",
      "0.16193656093489148\n",
      "0.16026711185308848\n",
      "0.15859766277128548\n",
      "0.15692821368948248\n",
      "0.15525876460767946\n",
      "0.15358931552587646\n",
      "0.15191986644407346\n",
      "0.15025041736227046\n",
      "0.14858096828046743\n",
      "0.14691151919866444\n",
      "0.14524207011686144\n",
      "0.14357262103505844\n",
      "0.1419031719532554\n",
      "0.14023372287145242\n",
      "0.13856427378964942\n",
      "0.13689482470784642\n",
      "0.1352253756260434\n",
      "0.1335559265442404\n",
      "0.1318864774624374\n",
      "0.1302170283806344\n",
      "0.1285475792988314\n",
      "0.12687813021702837\n",
      "0.12520868113522537\n",
      "0.12353923205342238\n",
      "0.12186978297161936\n",
      "0.12020033388981637\n",
      "0.11853088480801335\n",
      "0.11686143572621036\n",
      "0.11519198664440734\n",
      "0.11352253756260434\n",
      "0.11185308848080133\n",
      "0.11018363939899833\n",
      "0.10851419031719532\n",
      "0.10684474123539232\n",
      "0.10517529215358931\n",
      "0.10350584307178631\n",
      "0.1018363939899833\n",
      "0.1001669449081803\n",
      "0.09849749582637729\n",
      "0.09682804674457429\n",
      "0.09515859766277128\n",
      "0.09348914858096828\n",
      "0.09181969949916527\n",
      "0.09015025041736227\n",
      "0.08848080133555926\n",
      "0.08681135225375626\n",
      "0.08514190317195326\n",
      "0.08347245409015025\n",
      "0.08180300500834725\n",
      "0.08013355592654424\n",
      "0.07846410684474124\n",
      "0.07679465776293823\n",
      "0.07512520868113523\n",
      "0.07345575959933222\n",
      "0.07178631051752922\n",
      "0.07011686143572621\n",
      "0.06844741235392321\n",
      "0.0667779632721202\n",
      "0.0651085141903172\n",
      "0.06343906510851419\n",
      "0.06176961602671119\n",
      "0.06010016694490818\n",
      "0.05843071786310518\n",
      "0.05676126878130217\n",
      "0.05509181969949917\n",
      "0.05342237061769616\n",
      "0.05175292153589316\n",
      "0.05008347245409015\n",
      "0.048414023372287146\n",
      "0.04674457429048414\n",
      "0.045075125208681135\n",
      "0.04340567612687813\n",
      "0.041736227045075125\n",
      "0.04006677796327212\n",
      "0.038397328881469114\n",
      "0.03672787979966611\n",
      "0.035058430717863104\n",
      "0.0333889816360601\n",
      "0.03171953255425709\n",
      "0.03005008347245409\n",
      "0.028380634390651086\n",
      "0.02671118530884808\n",
      "0.025041736227045076\n",
      "0.02337228714524207\n",
      "0.021702838063439065\n",
      "0.02003338898163606\n",
      "0.018363939899833055\n",
      "0.01669449081803005\n",
      "0.015025041736227046\n",
      "0.01335559265442404\n",
      "0.011686143572621035\n",
      "0.01001669449081803\n",
      "0.008347245409015025\n",
      "0.00667779632721202\n",
      "0.005008347245409015\n",
      "0.00333889816360601\n",
      "0.001669449081803005\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n",
      "0.9732888146911519\n",
      "0.9716193656093489\n",
      "0.9649415692821369\n",
      "0.9632721202003339\n",
      "0.9616026711185309\n",
      "0.9599332220367279\n",
      "0.9582637729549248\n",
      "0.9532554257095158\n",
      "0.9515859766277128\n",
      "0.9499165275459098\n",
      "0.9415692821368948\n",
      "0.9398998330550918\n",
      "0.9382303839732888\n",
      "0.9365609348914858\n",
      "0.9348914858096828\n",
      "0.9148580968280468\n",
      "0.9015025041736227\n",
      "0.8981636060100167\n",
      "0.8881469115191987\n",
      "0.8864774624373957\n",
      "0.8848080133555927\n",
      "0.8831385642737897\n",
      "0.8781302170283807\n",
      "0.8764607679465777\n",
      "0.8747913188647746\n",
      "0.8714524207011686\n",
      "0.8697829716193656\n",
      "0.8681135225375626\n",
      "0.8631051752921536\n",
      "0.8614357262103506\n",
      "0.8597662771285476\n",
      "0.8564273789649416\n",
      "0.8547579298831386\n",
      "0.8530884808013356\n",
      "0.8480801335559266\n",
      "0.8464106844741235\n",
      "0.8447412353923205\n",
      "0.8430717863105175\n",
      "0.8414023372287145\n",
      "0.8397328881469115\n",
      "0.8380634390651085\n",
      "0.8363939899833055\n",
      "0.8330550918196995\n",
      "0.8313856427378965\n",
      "0.8247078464106845\n",
      "0.8213689482470785\n",
      "0.8196994991652755\n",
      "0.8130217028380634\n",
      "0.8113522537562604\n",
      "0.8096828046744574\n",
      "0.8080133555926544\n",
      "0.8063439065108514\n",
      "0.8046744574290484\n",
      "0.8030050083472454\n",
      "0.8013355592654424\n",
      "0.7996661101836394\n",
      "0.7979966611018364\n",
      "0.7963272120200334\n",
      "0.7946577629382304\n",
      "0.7929883138564274\n",
      "0.7913188647746243\n",
      "0.7896494156928213\n",
      "0.7879799666110183\n",
      "0.7863105175292153\n",
      "0.7846410684474123\n",
      "0.7829716193656093\n",
      "0.7813021702838063\n",
      "0.7796327212020033\n",
      "0.7779632721202003\n",
      "0.7762938230383973\n",
      "0.7746243739565943\n",
      "0.7729549248747913\n",
      "0.7712854757929883\n",
      "0.7679465776293823\n",
      "0.7662771285475793\n",
      "0.7646076794657763\n",
      "0.7629382303839732\n",
      "0.7612687813021702\n",
      "0.7595993322203672\n",
      "0.7579298831385642\n",
      "0.7529215358931552\n",
      "0.7512520868113522\n",
      "0.7429048414023373\n",
      "0.7412353923205343\n",
      "0.7395659432387313\n",
      "0.7378964941569283\n",
      "0.7362270450751253\n",
      "0.7328881469115192\n",
      "0.7312186978297162\n",
      "0.7295492487479132\n",
      "0.7262103505843072\n",
      "0.7228714524207012\n",
      "0.7212020033388982\n",
      "0.7178631051752922\n",
      "0.7161936560934892\n",
      "0.7145242070116862\n",
      "0.7128547579298832\n",
      "0.7095158597662772\n",
      "0.7078464106844741\n",
      "0.7061769616026711\n",
      "0.7045075125208681\n",
      "0.7028380634390651\n",
      "0.7011686143572621\n",
      "0.6994991652754591\n",
      "0.6978297161936561\n",
      "0.6961602671118531\n",
      "0.6944908180300501\n",
      "0.6928213689482471\n",
      "0.6911519198664441\n",
      "0.6894824707846411\n",
      "0.6878130217028381\n",
      "0.6861435726210351\n",
      "0.6844741235392321\n",
      "0.6828046744574291\n",
      "0.6811352253756261\n",
      "0.679465776293823\n",
      "0.67779632721202\n",
      "0.676126878130217\n",
      "0.674457429048414\n",
      "0.672787979966611\n",
      "0.671118530884808\n",
      "0.669449081803005\n",
      "0.667779632721202\n",
      "0.666110183639399\n",
      "0.664440734557596\n",
      "0.662771285475793\n",
      "0.66110183639399\n",
      "0.659432387312187\n",
      "0.657762938230384\n",
      "0.656093489148581\n",
      "0.654424040066778\n",
      "0.6527545909849749\n",
      "0.6510851419031719\n",
      "0.6494156928213689\n",
      "0.6477462437395659\n",
      "0.6460767946577629\n",
      "0.6444073455759599\n",
      "0.6410684474123539\n",
      "0.6377295492487479\n",
      "0.6360601001669449\n",
      "0.6343906510851419\n",
      "0.6327212020033389\n",
      "0.6310517529215359\n",
      "0.6293823038397329\n",
      "0.6277128547579299\n",
      "0.6260434056761269\n",
      "0.6243739565943238\n",
      "0.6227045075125208\n",
      "0.6210350584307178\n",
      "0.6193656093489148\n",
      "0.6176961602671118\n",
      "0.6160267111853088\n",
      "0.6143572621035058\n",
      "0.6110183639398998\n",
      "0.6093489148580968\n",
      "0.6076794657762938\n",
      "0.6060100166944908\n",
      "0.6043405676126878\n",
      "0.6026711185308848\n",
      "0.6010016694490818\n",
      "0.5993322203672788\n",
      "0.5976627712854758\n",
      "0.5959933222036727\n",
      "0.5943238731218697\n",
      "0.5926544240400667\n",
      "0.5909849749582637\n",
      "0.5893155258764607\n",
      "0.5876460767946577\n",
      "0.5859766277128547\n",
      "0.5843071786310517\n",
      "0.5826377295492488\n",
      "0.5809682804674458\n",
      "0.5792988313856428\n",
      "0.5759599332220368\n",
      "0.5742904841402338\n",
      "0.5726210350584308\n",
      "0.5709515859766278\n",
      "0.5692821368948247\n",
      "0.5676126878130217\n",
      "0.5659432387312187\n",
      "0.5642737896494157\n",
      "0.5626043405676127\n",
      "0.5609348914858097\n",
      "0.5592654424040067\n",
      "0.5575959933222037\n",
      "0.5559265442404007\n",
      "0.5542570951585977\n",
      "0.5525876460767947\n",
      "0.5509181969949917\n",
      "0.5492487479131887\n",
      "0.5475792988313857\n",
      "0.5459098497495827\n",
      "0.5442404006677797\n",
      "0.5425709515859767\n",
      "0.5409015025041736\n",
      "0.5392320534223706\n",
      "0.5375626043405676\n",
      "0.5358931552587646\n",
      "0.5342237061769616\n",
      "0.5325542570951586\n",
      "0.5308848080133556\n",
      "0.5292153589315526\n",
      "0.5275459098497496\n",
      "0.5258764607679466\n",
      "0.5242070116861436\n",
      "0.5225375626043406\n",
      "0.5208681135225376\n",
      "0.5191986644407346\n",
      "0.5175292153589316\n",
      "0.5158597662771286\n",
      "0.5141903171953256\n",
      "0.5125208681135225\n",
      "0.5108514190317195\n",
      "0.5075125208681135\n",
      "0.5058430717863105\n",
      "0.5041736227045075\n",
      "0.5025041736227045\n",
      "0.5008347245409015\n",
      "0.4991652754590985\n",
      "0.4974958263772955\n",
      "0.4958263772954925\n",
      "0.4941569282136895\n",
      "0.49248747913188645\n",
      "0.49081803005008345\n",
      "0.48914858096828046\n",
      "0.48747913188647746\n",
      "0.48414023372287146\n",
      "0.48247078464106846\n",
      "0.48080133555926546\n",
      "0.4791318864774624\n",
      "0.4774624373956594\n",
      "0.4757929883138564\n",
      "0.4741235392320534\n",
      "0.4724540901502504\n",
      "0.4707846410684474\n",
      "0.4657762938230384\n",
      "0.46410684474123537\n",
      "0.4607679465776294\n",
      "0.4590984974958264\n",
      "0.4557595993322204\n",
      "0.4540901502504174\n",
      "0.4524207011686144\n",
      "0.4507512520868113\n",
      "0.44741235392320533\n",
      "0.44574290484140233\n",
      "0.44407345575959933\n",
      "0.44240400667779634\n",
      "0.44073455759599334\n",
      "0.43906510851419034\n",
      "0.4373956594323873\n",
      "0.4357262103505843\n",
      "0.4340567612687813\n",
      "0.4323873121869783\n",
      "0.4307178631051753\n",
      "0.4290484140233723\n",
      "0.4273789649415693\n",
      "0.4257095158597663\n",
      "0.4240400667779633\n",
      "0.42237061769616024\n",
      "0.42070116861435725\n",
      "0.41903171953255425\n",
      "0.41736227045075125\n",
      "0.41569282136894825\n",
      "0.41402337228714525\n",
      "0.41235392320534225\n",
      "0.41068447412353926\n",
      "0.4090150250417362\n",
      "0.4073455759599332\n",
      "0.4056761268781302\n",
      "0.4040066777963272\n",
      "0.4023372287145242\n",
      "0.4006677796327212\n",
      "0.3989983305509182\n",
      "0.3973288814691152\n",
      "0.39565943238731216\n",
      "0.39398998330550916\n",
      "0.39065108514190316\n",
      "0.38898163606010017\n",
      "0.38731218697829717\n",
      "0.38564273789649417\n",
      "0.38397328881469117\n",
      "0.3823038397328882\n",
      "0.3806343906510851\n",
      "0.3789649415692821\n",
      "0.3772954924874791\n",
      "0.3756260434056761\n",
      "0.3739565943238731\n",
      "0.3722871452420701\n",
      "0.37061769616026713\n",
      "0.36894824707846413\n",
      "0.3672787979966611\n",
      "0.3656093489148581\n",
      "0.3639398998330551\n",
      "0.3622704507512521\n",
      "0.3606010016694491\n",
      "0.3555926544240401\n",
      "0.35392320534223703\n",
      "0.35225375626043404\n",
      "0.35058430717863104\n",
      "0.34891485809682804\n",
      "0.34724540901502504\n",
      "0.34557595993322204\n",
      "0.34390651085141904\n",
      "0.34223706176961605\n",
      "0.34056761268781305\n",
      "0.33889816360601\n",
      "0.337228714524207\n",
      "0.335559265442404\n",
      "0.333889816360601\n",
      "0.332220367278798\n",
      "0.330550918196995\n",
      "0.328881469115192\n",
      "0.327212020033389\n",
      "0.32554257095158595\n",
      "0.32387312186978295\n",
      "0.32220367278797996\n",
      "0.32053422370617696\n",
      "0.31886477462437396\n",
      "0.31719532554257096\n",
      "0.31552587646076796\n",
      "0.31385642737896496\n",
      "0.3121869782971619\n",
      "0.3105175292153589\n",
      "0.3088480801335559\n",
      "0.3071786310517529\n",
      "0.3055091819699499\n",
      "0.3038397328881469\n",
      "0.3021702838063439\n",
      "0.3005008347245409\n",
      "0.2988313856427379\n",
      "0.29716193656093487\n",
      "0.29549248747913187\n",
      "0.2938230383973289\n",
      "0.2921535893155259\n",
      "0.2904841402337229\n",
      "0.2888146911519199\n",
      "0.2871452420701169\n",
      "0.2854757929883139\n",
      "0.2838063439065108\n",
      "0.28213689482470783\n",
      "0.28046744574290483\n",
      "0.27879799666110183\n",
      "0.27712854757929883\n",
      "0.27545909849749584\n",
      "0.27378964941569284\n",
      "0.27212020033388984\n",
      "0.2704507512520868\n",
      "0.2687813021702838\n",
      "0.2671118530884808\n",
      "0.2654424040066778\n",
      "0.2637729549248748\n",
      "0.2621035058430718\n",
      "0.2604340567612688\n",
      "0.2587646076794658\n",
      "0.2570951585976628\n",
      "0.25542570951585974\n",
      "0.25375626043405675\n",
      "0.25208681135225375\n",
      "0.25041736227045075\n",
      "0.24874791318864775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24707846410684475\n",
      "0.24540901502504173\n",
      "0.24373956594323873\n",
      "0.24207011686143573\n",
      "0.24040066777963273\n",
      "0.2387312186978297\n",
      "0.2370617696160267\n",
      "0.2353923205342237\n",
      "0.2337228714524207\n",
      "0.23205342237061768\n",
      "0.2303839732888147\n",
      "0.2287145242070117\n",
      "0.2270450751252087\n",
      "0.22537562604340566\n",
      "0.22370617696160267\n",
      "0.22203672787979967\n",
      "0.22036727879799667\n",
      "0.21869782971619364\n",
      "0.21702838063439064\n",
      "0.21535893155258765\n",
      "0.21368948247078465\n",
      "0.21202003338898165\n",
      "0.21035058430717862\n",
      "0.20868113522537562\n",
      "0.20701168614357263\n",
      "0.20534223706176963\n",
      "0.2036727879799666\n",
      "0.2020033388981636\n",
      "0.2003338898163606\n",
      "0.1986644407345576\n",
      "0.19699499165275458\n",
      "0.19532554257095158\n",
      "0.19365609348914858\n",
      "0.19198664440734559\n",
      "0.19031719532554256\n",
      "0.18864774624373956\n",
      "0.18697829716193656\n",
      "0.18530884808013356\n",
      "0.18363939899833054\n",
      "0.18196994991652754\n",
      "0.18030050083472454\n",
      "0.17863105175292154\n",
      "0.17696160267111852\n",
      "0.17529215358931552\n",
      "0.17362270450751252\n",
      "0.17195325542570952\n",
      "0.17028380634390652\n",
      "0.1686143572621035\n",
      "0.1669449081803005\n",
      "0.1652754590984975\n",
      "0.1636060100166945\n",
      "0.16193656093489148\n",
      "0.16026711185308848\n",
      "0.15859766277128548\n",
      "0.15692821368948248\n",
      "0.15525876460767946\n",
      "0.15358931552587646\n",
      "0.15191986644407346\n",
      "0.15025041736227046\n",
      "0.14858096828046743\n",
      "0.14691151919866444\n",
      "0.14524207011686144\n",
      "0.14357262103505844\n",
      "0.1419031719532554\n",
      "0.14023372287145242\n",
      "0.13856427378964942\n",
      "0.13689482470784642\n",
      "0.1352253756260434\n",
      "0.1335559265442404\n",
      "0.1318864774624374\n",
      "0.1302170283806344\n",
      "0.1285475792988314\n",
      "0.12687813021702837\n",
      "0.12520868113522537\n",
      "0.12353923205342238\n",
      "0.12186978297161936\n",
      "0.12020033388981637\n",
      "0.11853088480801335\n",
      "0.11686143572621036\n",
      "0.11519198664440734\n",
      "0.11352253756260434\n",
      "0.11185308848080133\n",
      "0.11018363939899833\n",
      "0.10851419031719532\n",
      "0.10684474123539232\n",
      "0.10517529215358931\n",
      "0.10350584307178631\n",
      "0.1018363939899833\n",
      "0.1001669449081803\n",
      "0.09849749582637729\n",
      "0.09682804674457429\n",
      "0.09515859766277128\n",
      "0.09348914858096828\n",
      "0.09181969949916527\n",
      "0.09015025041736227\n",
      "0.08848080133555926\n",
      "0.08681135225375626\n",
      "0.08514190317195326\n",
      "0.08347245409015025\n",
      "0.08180300500834725\n",
      "0.08013355592654424\n",
      "0.07846410684474124\n",
      "0.07679465776293823\n",
      "0.07512520868113523\n",
      "0.07345575959933222\n",
      "0.07178631051752922\n",
      "0.07011686143572621\n",
      "0.06844741235392321\n",
      "0.0667779632721202\n",
      "0.0651085141903172\n",
      "0.06343906510851419\n",
      "0.06176961602671119\n",
      "0.06010016694490818\n",
      "0.05843071786310518\n",
      "0.05676126878130217\n",
      "0.05509181969949917\n",
      "0.05342237061769616\n",
      "0.05175292153589316\n",
      "0.05008347245409015\n",
      "0.048414023372287146\n",
      "0.04674457429048414\n",
      "0.045075125208681135\n",
      "0.04340567612687813\n",
      "0.041736227045075125\n",
      "0.04006677796327212\n",
      "0.038397328881469114\n",
      "0.03672787979966611\n",
      "0.035058430717863104\n",
      "0.0333889816360601\n",
      "0.03171953255425709\n",
      "0.03005008347245409\n",
      "0.028380634390651086\n",
      "0.02671118530884808\n",
      "0.025041736227045076\n",
      "0.02337228714524207\n",
      "0.021702838063439065\n",
      "0.02003338898163606\n",
      "0.018363939899833055\n",
      "0.01669449081803005\n",
      "0.015025041736227046\n",
      "0.01335559265442404\n",
      "0.011686143572621035\n",
      "0.01001669449081803\n",
      "0.008347245409015025\n",
      "0.00667779632721202\n",
      "0.005008347245409015\n",
      "0.00333889816360601\n",
      "0.001669449081803005\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n",
      "0.9549248747913188\n",
      "0.9532554257095158\n",
      "0.9449081803005008\n",
      "0.9432387312186978\n",
      "0.9415692821368948\n",
      "0.9382303839732888\n",
      "0.9365609348914858\n",
      "0.9298831385642737\n",
      "0.9282136894824707\n",
      "0.9265442404006677\n",
      "0.9131886477462438\n",
      "0.9115191986644408\n",
      "0.9098497495826378\n",
      "0.9081803005008348\n",
      "0.9065108514190318\n",
      "0.8797996661101837\n",
      "0.8614357262103506\n",
      "0.8547579298831386\n",
      "0.8414023372287145\n",
      "0.8397328881469115\n",
      "0.8380634390651085\n",
      "0.8363939899833055\n",
      "0.8247078464106845\n",
      "0.8213689482470785\n",
      "0.8196994991652755\n",
      "0.8113522537562604\n",
      "0.8063439065108514\n",
      "0.7963272120200334\n",
      "0.7913188647746243\n",
      "0.7896494156928213\n",
      "0.7879799666110183\n",
      "0.7846410684474123\n",
      "0.7829716193656093\n",
      "0.7813021702838063\n",
      "0.7779632721202003\n",
      "0.7746243739565943\n",
      "0.7729549248747913\n",
      "0.7612687813021702\n",
      "0.7562604340567612\n",
      "0.7545909849749582\n",
      "0.7529215358931552\n",
      "0.7512520868113522\n",
      "0.7495826377295493\n",
      "0.7479131886477463\n",
      "0.7462437395659433\n",
      "0.7445742904841403\n",
      "0.7429048414023373\n",
      "0.7412353923205343\n",
      "0.7395659432387313\n",
      "0.7378964941569283\n",
      "0.7362270450751253\n",
      "0.7345575959933222\n",
      "0.7328881469115192\n",
      "0.7312186978297162\n",
      "0.7295492487479132\n",
      "0.7278797996661102\n",
      "0.7262103505843072\n",
      "0.7212020033388982\n",
      "0.7145242070116862\n",
      "0.7128547579298832\n",
      "0.7095158597662772\n",
      "0.7078464106844741\n",
      "0.7061769616026711\n",
      "0.7011686143572621\n",
      "0.6994991652754591\n",
      "0.6978297161936561\n",
      "0.6961602671118531\n",
      "0.6944908180300501\n",
      "0.6911519198664441\n",
      "0.6894824707846411\n",
      "0.679465776293823\n",
      "0.67779632721202\n",
      "0.676126878130217\n",
      "0.674457429048414\n",
      "0.672787979966611\n",
      "0.671118530884808\n",
      "0.666110183639399\n",
      "0.664440734557596\n",
      "0.662771285475793\n",
      "0.66110183639399\n",
      "0.659432387312187\n",
      "0.657762938230384\n",
      "0.656093489148581\n",
      "0.654424040066778\n",
      "0.6527545909849749\n",
      "0.6510851419031719\n",
      "0.6494156928213689\n",
      "0.6477462437395659\n",
      "0.6460767946577629\n",
      "0.6444073455759599\n",
      "0.6427378964941569\n",
      "0.6410684474123539\n",
      "0.6393989983305509\n",
      "0.6377295492487479\n",
      "0.6360601001669449\n",
      "0.6343906510851419\n",
      "0.6327212020033389\n",
      "0.6310517529215359\n",
      "0.6293823038397329\n",
      "0.6277128547579299\n",
      "0.6260434056761269\n",
      "0.6243739565943238\n",
      "0.6227045075125208\n",
      "0.6210350584307178\n",
      "0.6193656093489148\n",
      "0.6176961602671118\n",
      "0.6160267111853088\n",
      "0.6143572621035058\n",
      "0.6126878130217028\n",
      "0.6110183639398998\n",
      "0.6093489148580968\n",
      "0.6076794657762938\n",
      "0.6060100166944908\n",
      "0.6043405676126878\n",
      "0.6026711185308848\n",
      "0.6010016694490818\n",
      "0.5993322203672788\n",
      "0.5976627712854758\n",
      "0.5959933222036727\n",
      "0.5943238731218697\n",
      "0.5926544240400667\n",
      "0.5909849749582637\n",
      "0.5893155258764607\n",
      "0.5876460767946577\n",
      "0.5859766277128547\n",
      "0.5843071786310517\n",
      "0.5826377295492488\n",
      "0.5809682804674458\n",
      "0.5792988313856428\n",
      "0.5776293823038398\n",
      "0.5759599332220368\n",
      "0.5742904841402338\n",
      "0.5692821368948247\n",
      "0.5659432387312187\n",
      "0.5642737896494157\n",
      "0.5626043405676127\n",
      "0.5609348914858097\n",
      "0.5592654424040067\n",
      "0.5575959933222037\n",
      "0.5559265442404007\n",
      "0.5542570951585977\n",
      "0.5525876460767947\n",
      "0.5509181969949917\n",
      "0.5492487479131887\n",
      "0.5475792988313857\n",
      "0.5459098497495827\n",
      "0.5442404006677797\n",
      "0.5425709515859767\n",
      "0.5392320534223706\n",
      "0.5375626043405676\n",
      "0.5358931552587646\n",
      "0.5342237061769616\n",
      "0.5325542570951586\n",
      "0.5308848080133556\n",
      "0.5292153589315526\n",
      "0.5275459098497496\n",
      "0.5258764607679466\n",
      "0.5242070116861436\n",
      "0.5225375626043406\n",
      "0.5208681135225376\n",
      "0.5191986644407346\n",
      "0.5175292153589316\n",
      "0.5158597662771286\n",
      "0.5141903171953256\n",
      "0.5125208681135225\n",
      "0.5108514190317195\n",
      "0.5091819699499165\n",
      "0.5075125208681135\n",
      "0.5008347245409015\n",
      "0.4991652754590985\n",
      "0.4974958263772955\n",
      "0.4958263772954925\n",
      "0.4941569282136895\n",
      "0.49248747913188645\n",
      "0.49081803005008345\n",
      "0.48914858096828046\n",
      "0.48747913188647746\n",
      "0.48580968280467446\n",
      "0.48414023372287146\n",
      "0.48247078464106846\n",
      "0.48080133555926546\n",
      "0.4791318864774624\n",
      "0.4757929883138564\n",
      "0.4741235392320534\n",
      "0.4707846410684474\n",
      "0.4691151919866444\n",
      "0.4657762938230384\n",
      "0.46410684474123537\n",
      "0.4607679465776294\n",
      "0.4574290484140234\n",
      "0.4557595993322204\n",
      "0.4540901502504174\n",
      "0.4507512520868113\n",
      "0.44908180300500833\n",
      "0.44741235392320533\n",
      "0.44574290484140233\n",
      "0.44407345575959933\n",
      "0.44240400667779634\n",
      "0.4373956594323873\n",
      "0.4357262103505843\n",
      "0.4340567612687813\n",
      "0.4323873121869783\n",
      "0.4307178631051753\n",
      "0.4290484140233723\n",
      "0.4273789649415693\n",
      "0.4240400667779633\n",
      "0.42070116861435725\n",
      "0.41903171953255425\n",
      "0.41736227045075125\n",
      "0.41569282136894825\n",
      "0.41402337228714525\n",
      "0.41068447412353926\n",
      "0.4090150250417362\n",
      "0.4073455759599332\n",
      "0.4040066777963272\n",
      "0.4023372287145242\n",
      "0.4006677796327212\n",
      "0.3989983305509182\n",
      "0.3973288814691152\n",
      "0.39565943238731216\n",
      "0.39398998330550916\n",
      "0.39232053422370616\n",
      "0.39065108514190316\n",
      "0.38898163606010017\n",
      "0.38731218697829717\n",
      "0.38564273789649417\n",
      "0.38397328881469117\n",
      "0.3823038397328882\n",
      "0.3806343906510851\n",
      "0.3789649415692821\n",
      "0.3772954924874791\n",
      "0.3756260434056761\n",
      "0.3739565943238731\n",
      "0.3722871452420701\n",
      "0.37061769616026713\n",
      "0.36894824707846413\n",
      "0.3672787979966611\n",
      "0.3656093489148581\n",
      "0.3639398998330551\n",
      "0.3622704507512521\n",
      "0.3606010016694491\n",
      "0.3589315525876461\n",
      "0.3572621035058431\n",
      "0.3555926544240401\n",
      "0.35392320534223703\n",
      "0.35225375626043404\n",
      "0.35058430717863104\n",
      "0.34724540901502504\n",
      "0.34557595993322204\n",
      "0.34390651085141904\n",
      "0.34223706176961605\n",
      "0.34056761268781305\n",
      "0.33889816360601\n",
      "0.337228714524207\n",
      "0.335559265442404\n",
      "0.333889816360601\n",
      "0.332220367278798\n",
      "0.330550918196995\n",
      "0.328881469115192\n",
      "0.327212020033389\n",
      "0.32554257095158595\n",
      "0.32387312186978295\n",
      "0.32220367278797996\n",
      "0.32053422370617696\n",
      "0.31886477462437396\n",
      "0.31719532554257096\n",
      "0.31552587646076796\n",
      "0.31385642737896496\n",
      "0.3121869782971619\n",
      "0.3105175292153589\n",
      "0.3088480801335559\n",
      "0.3071786310517529\n",
      "0.3055091819699499\n",
      "0.3038397328881469\n",
      "0.3021702838063439\n",
      "0.3005008347245409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2988313856427379\n",
      "0.29716193656093487\n",
      "0.29549248747913187\n",
      "0.2938230383973289\n",
      "0.2921535893155259\n",
      "0.2904841402337229\n",
      "0.2888146911519199\n",
      "0.2871452420701169\n",
      "0.2854757929883139\n",
      "0.2838063439065108\n",
      "0.28213689482470783\n",
      "0.28046744574290483\n",
      "0.27879799666110183\n",
      "0.27712854757929883\n",
      "0.27545909849749584\n",
      "0.27378964941569284\n",
      "0.27212020033388984\n",
      "0.2704507512520868\n",
      "0.2687813021702838\n",
      "0.2671118530884808\n",
      "0.2654424040066778\n",
      "0.2637729549248748\n",
      "0.2621035058430718\n",
      "0.2604340567612688\n",
      "0.2587646076794658\n",
      "0.2570951585976628\n",
      "0.25542570951585974\n",
      "0.25375626043405675\n",
      "0.25208681135225375\n",
      "0.25041736227045075\n",
      "0.24874791318864775\n",
      "0.24707846410684475\n",
      "0.24540901502504173\n",
      "0.24373956594323873\n",
      "0.24207011686143573\n",
      "0.24040066777963273\n",
      "0.2387312186978297\n",
      "0.2370617696160267\n",
      "0.2353923205342237\n",
      "0.2337228714524207\n",
      "0.23205342237061768\n",
      "0.2303839732888147\n",
      "0.2287145242070117\n",
      "0.2270450751252087\n",
      "0.22537562604340566\n",
      "0.22370617696160267\n",
      "0.22203672787979967\n",
      "0.22036727879799667\n",
      "0.21869782971619364\n",
      "0.21702838063439064\n",
      "0.21535893155258765\n",
      "0.21368948247078465\n",
      "0.21202003338898165\n",
      "0.21035058430717862\n",
      "0.20868113522537562\n",
      "0.20701168614357263\n",
      "0.20534223706176963\n",
      "0.2036727879799666\n",
      "0.2020033388981636\n",
      "0.2003338898163606\n",
      "0.1986644407345576\n",
      "0.19699499165275458\n",
      "0.19532554257095158\n",
      "0.19365609348914858\n",
      "0.19198664440734559\n",
      "0.19031719532554256\n",
      "0.18864774624373956\n",
      "0.18697829716193656\n",
      "0.18530884808013356\n",
      "0.18363939899833054\n",
      "0.18196994991652754\n",
      "0.18030050083472454\n",
      "0.17863105175292154\n",
      "0.17696160267111852\n",
      "0.17529215358931552\n",
      "0.17362270450751252\n",
      "0.17195325542570952\n",
      "0.17028380634390652\n",
      "0.1686143572621035\n",
      "0.1669449081803005\n",
      "0.1652754590984975\n",
      "0.1636060100166945\n",
      "0.16193656093489148\n",
      "0.16026711185308848\n",
      "0.15859766277128548\n",
      "0.15692821368948248\n",
      "0.15525876460767946\n",
      "0.15358931552587646\n",
      "0.15191986644407346\n",
      "0.15025041736227046\n",
      "0.14858096828046743\n",
      "0.14691151919866444\n",
      "0.14524207011686144\n",
      "0.14357262103505844\n",
      "0.1419031719532554\n",
      "0.14023372287145242\n",
      "0.13856427378964942\n",
      "0.13689482470784642\n",
      "0.1352253756260434\n",
      "0.1335559265442404\n",
      "0.1318864774624374\n",
      "0.1302170283806344\n",
      "0.1285475792988314\n",
      "0.12687813021702837\n",
      "0.12520868113522537\n",
      "0.12353923205342238\n",
      "0.12186978297161936\n",
      "0.12020033388981637\n",
      "0.11853088480801335\n",
      "0.11686143572621036\n",
      "0.11519198664440734\n",
      "0.11352253756260434\n",
      "0.11185308848080133\n",
      "0.11018363939899833\n",
      "0.10851419031719532\n",
      "0.10684474123539232\n",
      "0.10517529215358931\n",
      "0.10350584307178631\n",
      "0.1018363939899833\n",
      "0.1001669449081803\n",
      "0.09849749582637729\n",
      "0.09682804674457429\n",
      "0.09515859766277128\n",
      "0.09348914858096828\n",
      "0.09181969949916527\n",
      "0.09015025041736227\n",
      "0.08848080133555926\n",
      "0.08681135225375626\n",
      "0.08514190317195326\n",
      "0.08347245409015025\n",
      "0.08180300500834725\n",
      "0.08013355592654424\n",
      "0.07846410684474124\n",
      "0.07679465776293823\n",
      "0.07512520868113523\n",
      "0.07345575959933222\n",
      "0.07178631051752922\n",
      "0.07011686143572621\n",
      "0.06844741235392321\n",
      "0.0667779632721202\n",
      "0.0651085141903172\n",
      "0.06343906510851419\n",
      "0.06176961602671119\n",
      "0.06010016694490818\n",
      "0.05843071786310518\n",
      "0.05676126878130217\n",
      "0.05509181969949917\n",
      "0.05342237061769616\n",
      "0.05175292153589316\n",
      "0.05008347245409015\n",
      "0.048414023372287146\n",
      "0.04674457429048414\n",
      "0.045075125208681135\n",
      "0.04340567612687813\n",
      "0.041736227045075125\n",
      "0.04006677796327212\n",
      "0.038397328881469114\n",
      "0.03672787979966611\n",
      "0.035058430717863104\n",
      "0.0333889816360601\n",
      "0.03171953255425709\n",
      "0.03005008347245409\n",
      "0.028380634390651086\n",
      "0.02671118530884808\n",
      "0.025041736227045076\n",
      "0.02337228714524207\n",
      "0.021702838063439065\n",
      "0.02003338898163606\n",
      "0.018363939899833055\n",
      "0.01669449081803005\n",
      "0.015025041736227046\n",
      "0.01335559265442404\n",
      "0.011686143572621035\n",
      "0.01001669449081803\n",
      "0.008347245409015025\n",
      "0.00667779632721202\n",
      "0.005008347245409015\n",
      "0.00333889816360601\n",
      "0.001669449081803005\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n",
      "0.9215358931552587\n",
      "0.9198664440734557\n",
      "0.8848080133555927\n",
      "0.8831385642737897\n",
      "0.8814691151919867\n",
      "0.8781302170283807\n",
      "0.8747913188647746\n",
      "0.8681135225375626\n",
      "0.8664440734557596\n",
      "0.8647746243739566\n",
      "0.8447412353923205\n",
      "0.8397328881469115\n",
      "0.8380634390651085\n",
      "0.8363939899833055\n",
      "0.8347245409015025\n",
      "0.8013355592654424\n",
      "0.7996661101836394\n",
      "0.7963272120200334\n",
      "0.7929883138564274\n",
      "0.7712854757929883\n",
      "0.7679465776293823\n",
      "0.7662771285475793\n",
      "0.7495826377295493\n",
      "0.7378964941569283\n",
      "0.7312186978297162\n",
      "0.7295492487479132\n",
      "0.7228714524207012\n",
      "0.7212020033388982\n",
      "0.7195325542570952\n",
      "0.7111853088480802\n",
      "0.7095158597662772\n",
      "0.7028380634390651\n",
      "0.7011686143572621\n",
      "0.6961602671118531\n",
      "0.6928213689482471\n",
      "0.6894824707846411\n",
      "0.6878130217028381\n",
      "0.6861435726210351\n",
      "0.6844741235392321\n",
      "0.6828046744574291\n",
      "0.6811352253756261\n",
      "0.679465776293823\n",
      "0.67779632721202\n",
      "0.676126878130217\n",
      "0.674457429048414\n",
      "0.672787979966611\n",
      "0.671118530884808\n",
      "0.669449081803005\n",
      "0.667779632721202\n",
      "0.662771285475793\n",
      "0.66110183639399\n",
      "0.656093489148581\n",
      "0.6527545909849749\n",
      "0.6510851419031719\n",
      "0.6494156928213689\n",
      "0.6477462437395659\n",
      "0.6460767946577629\n",
      "0.6444073455759599\n",
      "0.6410684474123539\n",
      "0.6393989983305509\n",
      "0.6343906510851419\n",
      "0.6293823038397329\n",
      "0.6277128547579299\n",
      "0.6260434056761269\n",
      "0.6243739565943238\n",
      "0.6227045075125208\n",
      "0.6210350584307178\n",
      "0.6193656093489148\n",
      "0.6176961602671118\n",
      "0.6160267111853088\n",
      "0.6143572621035058\n",
      "0.6126878130217028\n",
      "0.6110183639398998\n",
      "0.6043405676126878\n",
      "0.6026711185308848\n",
      "0.6010016694490818\n",
      "0.5993322203672788\n",
      "0.5976627712854758\n",
      "0.5959933222036727\n",
      "0.5943238731218697\n",
      "0.5926544240400667\n",
      "0.5909849749582637\n",
      "0.5859766277128547\n",
      "0.5843071786310517\n",
      "0.5826377295492488\n",
      "0.5809682804674458\n",
      "0.5792988313856428\n",
      "0.5776293823038398\n",
      "0.5742904841402338\n",
      "0.5726210350584308\n",
      "0.5709515859766278\n",
      "0.5692821368948247\n",
      "0.5676126878130217\n",
      "0.5659432387312187\n",
      "0.5642737896494157\n",
      "0.5626043405676127\n",
      "0.5609348914858097\n",
      "0.5592654424040067\n",
      "0.5575959933222037\n",
      "0.5542570951585977\n",
      "0.5525876460767947\n",
      "0.5509181969949917\n",
      "0.5492487479131887\n",
      "0.5475792988313857\n",
      "0.5459098497495827\n",
      "0.5425709515859767\n",
      "0.5409015025041736\n",
      "0.5292153589315526\n",
      "0.5275459098497496\n",
      "0.5258764607679466\n",
      "0.5242070116861436\n",
      "0.5225375626043406\n",
      "0.5208681135225376\n",
      "0.5191986644407346\n",
      "0.5175292153589316\n",
      "0.5158597662771286\n",
      "0.5141903171953256\n",
      "0.5125208681135225\n",
      "0.5108514190317195\n",
      "0.5091819699499165\n",
      "0.5075125208681135\n",
      "0.5058430717863105\n",
      "0.5041736227045075\n",
      "0.5025041736227045\n",
      "0.5008347245409015\n",
      "0.4991652754590985\n",
      "0.4958263772954925\n",
      "0.4941569282136895\n",
      "0.49248747913188645\n",
      "0.49081803005008345\n",
      "0.48914858096828046\n",
      "0.48747913188647746\n",
      "0.48580968280467446\n",
      "0.48414023372287146\n",
      "0.48247078464106846\n",
      "0.48080133555926546\n",
      "0.4774624373956594\n",
      "0.4757929883138564\n",
      "0.4741235392320534\n",
      "0.4724540901502504\n",
      "0.4707846410684474\n",
      "0.4691151919866444\n",
      "0.4674457429048414\n",
      "0.46243739565943237\n",
      "0.4607679465776294\n",
      "0.4590984974958264\n",
      "0.4574290484140234\n",
      "0.4557595993322204\n",
      "0.4540901502504174\n",
      "0.4524207011686144\n",
      "0.4507512520868113\n",
      "0.44908180300500833\n",
      "0.44407345575959933\n",
      "0.44240400667779634\n",
      "0.44073455759599334\n",
      "0.43906510851419034\n",
      "0.4357262103505843\n",
      "0.4340567612687813\n",
      "0.4307178631051753\n",
      "0.4273789649415693\n",
      "0.4257095158597663\n",
      "0.4240400667779633\n",
      "0.41903171953255425\n",
      "0.41736227045075125\n",
      "0.41569282136894825\n",
      "0.41235392320534225\n",
      "0.41068447412353926\n",
      "0.4090150250417362\n",
      "0.4073455759599332\n",
      "0.4056761268781302\n",
      "0.4040066777963272\n",
      "0.4023372287145242\n",
      "0.4006677796327212\n",
      "0.3989983305509182\n",
      "0.3973288814691152\n",
      "0.39565943238731216\n",
      "0.39398998330550916\n",
      "0.39065108514190316\n",
      "0.38898163606010017\n",
      "0.38731218697829717\n",
      "0.38564273789649417\n",
      "0.38397328881469117\n",
      "0.3823038397328882\n",
      "0.3806343906510851\n",
      "0.3789649415692821\n",
      "0.3772954924874791\n",
      "0.3756260434056761\n",
      "0.3739565943238731\n",
      "0.3722871452420701\n",
      "0.37061769616026713\n",
      "0.36894824707846413\n",
      "0.3672787979966611\n",
      "0.3656093489148581\n",
      "0.3639398998330551\n",
      "0.3622704507512521\n",
      "0.3606010016694491\n",
      "0.3589315525876461\n",
      "0.3572621035058431\n",
      "0.3555926544240401\n",
      "0.35058430717863104\n",
      "0.34891485809682804\n",
      "0.34724540901502504\n",
      "0.34557595993322204\n",
      "0.34390651085141904\n",
      "0.34223706176961605\n",
      "0.33889816360601\n",
      "0.337228714524207\n",
      "0.335559265442404\n",
      "0.333889816360601\n",
      "0.332220367278798\n",
      "0.330550918196995\n",
      "0.327212020033389\n",
      "0.32554257095158595\n",
      "0.32387312186978295\n",
      "0.32220367278797996\n",
      "0.32053422370617696\n",
      "0.31886477462437396\n",
      "0.31719532554257096\n",
      "0.31552587646076796\n",
      "0.31385642737896496\n",
      "0.3121869782971619\n",
      "0.3105175292153589\n",
      "0.3088480801335559\n",
      "0.3055091819699499\n",
      "0.3038397328881469\n",
      "0.3021702838063439\n",
      "0.3005008347245409\n",
      "0.2988313856427379\n",
      "0.29716193656093487\n",
      "0.29549248747913187\n",
      "0.2938230383973289\n",
      "0.2921535893155259\n",
      "0.2904841402337229\n",
      "0.2888146911519199\n",
      "0.2871452420701169\n",
      "0.2854757929883139\n",
      "0.2838063439065108\n",
      "0.28213689482470783\n",
      "0.28046744574290483\n",
      "0.27879799666110183\n",
      "0.27712854757929883\n",
      "0.27545909849749584\n",
      "0.27378964941569284\n",
      "0.27212020033388984\n",
      "0.2704507512520868\n",
      "0.2687813021702838\n",
      "0.2671118530884808\n",
      "0.2654424040066778\n",
      "0.2637729549248748\n",
      "0.2621035058430718\n",
      "0.2604340567612688\n",
      "0.2587646076794658\n",
      "0.2570951585976628\n",
      "0.25542570951585974\n",
      "0.25375626043405675\n",
      "0.25208681135225375\n",
      "0.25041736227045075\n",
      "0.24874791318864775\n",
      "0.24707846410684475\n",
      "0.24540901502504173\n",
      "0.24373956594323873\n",
      "0.24207011686143573\n",
      "0.24040066777963273\n",
      "0.2387312186978297\n",
      "0.2370617696160267\n",
      "0.2353923205342237\n",
      "0.2337228714524207\n",
      "0.23205342237061768\n",
      "0.2303839732888147\n",
      "0.2287145242070117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2270450751252087\n",
      "0.22537562604340566\n",
      "0.22370617696160267\n",
      "0.22203672787979967\n",
      "0.22036727879799667\n",
      "0.21869782971619364\n",
      "0.21702838063439064\n",
      "0.21535893155258765\n",
      "0.21368948247078465\n",
      "0.21202003338898165\n",
      "0.21035058430717862\n",
      "0.20868113522537562\n",
      "0.20701168614357263\n",
      "0.20534223706176963\n",
      "0.2036727879799666\n",
      "0.2020033388981636\n",
      "0.2003338898163606\n",
      "0.1986644407345576\n",
      "0.19699499165275458\n",
      "0.19532554257095158\n",
      "0.19365609348914858\n",
      "0.19198664440734559\n",
      "0.19031719532554256\n",
      "0.18864774624373956\n",
      "0.18697829716193656\n",
      "0.18530884808013356\n",
      "0.18363939899833054\n",
      "0.18196994991652754\n",
      "0.18030050083472454\n",
      "0.17863105175292154\n",
      "0.17696160267111852\n",
      "0.17529215358931552\n",
      "0.17362270450751252\n",
      "0.17195325542570952\n",
      "0.17028380634390652\n",
      "0.1686143572621035\n",
      "0.1669449081803005\n",
      "0.1652754590984975\n",
      "0.1636060100166945\n",
      "0.16193656093489148\n",
      "0.16026711185308848\n",
      "0.15859766277128548\n",
      "0.15692821368948248\n",
      "0.15525876460767946\n",
      "0.15358931552587646\n",
      "0.15191986644407346\n",
      "0.15025041736227046\n",
      "0.14858096828046743\n",
      "0.14691151919866444\n",
      "0.14524207011686144\n",
      "0.14357262103505844\n",
      "0.1419031719532554\n",
      "0.14023372287145242\n",
      "0.13856427378964942\n",
      "0.13689482470784642\n",
      "0.1352253756260434\n",
      "0.1335559265442404\n",
      "0.1318864774624374\n",
      "0.1302170283806344\n",
      "0.1285475792988314\n",
      "0.12687813021702837\n",
      "0.12520868113522537\n",
      "0.12353923205342238\n",
      "0.12186978297161936\n",
      "0.12020033388981637\n",
      "0.11853088480801335\n",
      "0.11686143572621036\n",
      "0.11519198664440734\n",
      "0.11352253756260434\n",
      "0.11185308848080133\n",
      "0.11018363939899833\n",
      "0.10851419031719532\n",
      "0.10684474123539232\n",
      "0.10517529215358931\n",
      "0.10350584307178631\n",
      "0.1018363939899833\n",
      "0.1001669449081803\n",
      "0.09849749582637729\n",
      "0.09682804674457429\n",
      "0.09515859766277128\n",
      "0.09348914858096828\n",
      "0.09181969949916527\n",
      "0.09015025041736227\n",
      "0.08848080133555926\n",
      "0.08681135225375626\n",
      "0.08514190317195326\n",
      "0.08347245409015025\n",
      "0.08180300500834725\n",
      "0.08013355592654424\n",
      "0.07846410684474124\n",
      "0.07679465776293823\n",
      "0.07512520868113523\n",
      "0.07345575959933222\n",
      "0.07178631051752922\n",
      "0.07011686143572621\n",
      "0.06844741235392321\n",
      "0.0667779632721202\n",
      "0.0651085141903172\n",
      "0.06343906510851419\n",
      "0.06176961602671119\n",
      "0.06010016694490818\n",
      "0.05843071786310518\n",
      "0.05676126878130217\n",
      "0.05509181969949917\n",
      "0.05342237061769616\n",
      "0.05175292153589316\n",
      "0.05008347245409015\n",
      "0.048414023372287146\n",
      "0.04674457429048414\n",
      "0.045075125208681135\n",
      "0.04340567612687813\n",
      "0.041736227045075125\n",
      "0.04006677796327212\n",
      "0.038397328881469114\n",
      "0.03672787979966611\n",
      "0.035058430717863104\n",
      "0.0333889816360601\n",
      "0.03171953255425709\n",
      "0.03005008347245409\n",
      "0.028380634390651086\n",
      "0.02671118530884808\n",
      "0.025041736227045076\n",
      "0.02337228714524207\n",
      "0.021702838063439065\n",
      "0.02003338898163606\n",
      "0.018363939899833055\n",
      "0.01669449081803005\n",
      "0.015025041736227046\n",
      "0.01335559265442404\n",
      "0.011686143572621035\n",
      "0.01001669449081803\n",
      "0.008347245409015025\n",
      "0.00667779632721202\n",
      "0.005008347245409015\n",
      "0.00333889816360601\n",
      "0.001669449081803005\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "q_implicit_N_parts_possibilities = np.linspace(min_parts_threshold,max_parts_threshold,N_plot_finess)\n",
    "\n",
    "# Get Performance Metric\n",
    "for inplicit_N_parts_loop in range(N_plot_finess):\n",
    "    ### UPDATE USER ###\n",
    "    print('--------------------------------------')\n",
    "    print('--------------------------------------')\n",
    "    print('--------------------------------------')\n",
    "    print('Ablation Completion Percentage:',(inplicit_N_parts_loop/N_plot_finess))\n",
    "    print('--------------------------------------')\n",
    "    print('--------------------------------------')\n",
    "    print('--------------------------------------')\n",
    "    \n",
    "    # Implicitly Set: Current Number of Parts\n",
    "    q_implicit_N_parts_loop = q_implicit_N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    # Run Algos. 1+2\n",
    "    performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop = Ablate_PCNNs(q_implicit_N_parts_loop,data_y,X_train,X_test,y_test)\n",
    "    # Reshape\n",
    "    performance_Architope_loop = performance_Architope_loop.to_numpy().reshape([3,2,1])\n",
    "    Architope_Model_Complexity_full_loop = Architope_Model_Complexity_full_loop.to_numpy().reshape([1,5,1])\n",
    "\n",
    "    # Record\n",
    "    if inplicit_N_parts_loop == 0:\n",
    "        performance_Architope_history = performance_Architope_loop\n",
    "        Architope_Model_Complexity_history = Architope_Model_Complexity_full_loop\n",
    "        N_parts_Generated_by_Algo_2_history = N_parts_Generated_by_Algo_2_loop\n",
    "        N_params_architope_hist = N_params_architope_loop\n",
    "    else:\n",
    "        performance_Architope_history = np.concatenate((performance_Architope_history,performance_Architope_loop),axis=2)\n",
    "        Architope_Model_Complexity_history = np.concatenate((Architope_Model_Complexity_history,Architope_Model_Complexity_full_loop),axis=2)\n",
    "        N_parts_Generated_by_Algo_2_history = np.append(N_parts_Generated_by_Algo_2_history,N_parts_Generated_by_Algo_2_loop)\n",
    "        N_params_architope_hist = np.append(N_params_architope_hist,N_params_architope_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomization may produce duplicates; we remove these with the following snippet:\n",
    "get_unique_entries = np.unique(N_parts_Generated_by_Algo_2_history, return_index=True)[1]\n",
    "N_parts_Generated_by_Algo_2_history_report = N_parts_Generated_by_Algo_2_history[get_unique_entries]\n",
    "## Prediction Qualities\n",
    "performance_Architope_history_report_MAE_train = (performance_Architope_history[1,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MAE_test = (performance_Architope_history[1,1,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_train = (performance_Architope_history[0,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_test = (performance_Architope_history[0,1,:])[get_unique_entries]\n",
    "## Model Complexities\n",
    "L_Times = (Architope_Model_Complexity_history[:,0].reshape(-1,))[get_unique_entries]\n",
    "P_Times = (Architope_Model_Complexity_history[:,1].reshape(-1,))[get_unique_entries]\n",
    "N_Params = (N_params_architope_hist.reshape(-1,))[get_unique_entries]\n",
    "AIC_Like = (Architope_Model_Complexity_history[:,3].reshape(-1,))[get_unique_entries]\n",
    "Eff = (Architope_Model_Complexity_history[:,4].reshape(-1,))[get_unique_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MAE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MAE_test)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MAE_test___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MSE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MSE_test)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MSE___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"L-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"L-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_Times)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_L_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"P-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"P-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_Times)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_P_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"N. Params\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"N. Params\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_Params)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_N_Params___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC-Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"AIC-Like\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"AIC-Like\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         AIC_Like)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_AIC_Like___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Eff\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Eff\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         Eff)\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Eff___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Fix_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
