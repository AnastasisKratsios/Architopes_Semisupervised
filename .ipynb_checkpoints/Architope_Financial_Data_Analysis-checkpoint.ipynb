{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  5001\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 10\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6660667866426715\n",
      "0.42451509698060386\n",
      "0.2501499700059988\n",
      "0.047590481903619274\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    \n",
    "# Trash removal (removes empty parts)\n",
    "X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "    \n",
    "    \n",
    "# ICML Rebuttle Deadline = Coersion!\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 5.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 5 parts.\n",
      "Heights to iterate over: [134]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   33.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   33.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0013 - mae: 0.0255 - mape: 120.2631\n",
      "Epoch 2/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 5.6579e-04 - mae: 0.0173 - mape: 101.4748\n",
      "Epoch 3/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 5.6677e-04 - mae: 0.0173 - mape: 90.1361\n",
      "Epoch 4/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 5.5594e-04 - mae: 0.0169 - mape: 99.9301\n",
      "Epoch 5/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 5.4875e-04 - mae: 0.0167 - mape: 101.6354\n",
      "Epoch 6/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 5.4017e-04 - mae: 0.0167 - mape: 91.3048\n",
      "Epoch 7/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 5.4448e-04 - mae: 0.0160 - mape: 98.7992\n",
      "Epoch 8/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 5.4081e-04 - mae: 0.0167 - mape: 101.4256\n",
      "Epoch 9/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 5.3611e-04 - mae: 0.0162 - mape: 95.7999\n",
      "Epoch 10/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 5.3747e-04 - mae: 0.0160 - mape: 100.7789\n",
      "Epoch 11/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 5.2388e-04 - mae: 0.0163 - mape: 94.6198\n",
      "Epoch 12/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 5.1653e-04 - mae: 0.0154 - mape: 96.8896\n",
      "Epoch 13/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 4.8081e-04 - mae: 0.0151 - mape: 87.5088\n",
      "Epoch 14/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 4.2891e-04 - mae: 0.0133 - mape: 69.3115\n",
      "Epoch 15/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 1.9536e-04 - mae: 0.0073 - mape: 38.6704\n",
      "Epoch 16/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 1.6759e-04 - mae: 0.0072 - mape: 45.2188\n",
      "Epoch 17/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 1.6160e-04 - mae: 0.0068 - mape: 49.5879\n",
      "Epoch 18/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 1.6380e-04 - mae: 0.0067 - mape: 39.2471\n",
      "Epoch 19/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 1.5796e-04 - mae: 0.0062 - mape: 37.8628\n",
      "Epoch 20/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 1.6064e-04 - mae: 0.0068 - mape: 41.5606\n",
      "Epoch 21/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 1.5917e-04 - mae: 0.0063 - mape: 38.6539\n",
      "Epoch 22/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 1.5915e-04 - mae: 0.0067 - mape: 41.7540\n",
      "Epoch 23/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 1.5208e-04 - mae: 0.0065 - mape: 45.2722\n",
      "Epoch 24/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 1.5419e-04 - mae: 0.0064 - mape: 43.9374\n",
      "Epoch 25/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 1.5517e-04 - mae: 0.0068 - mape: 44.3698\n",
      "Epoch 26/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 1.5461e-04 - mae: 0.0066 - mape: 43.1748\n",
      "Epoch 27/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5332e-04 - mae: 0.0062 - mape: 44.9700\n",
      "Epoch 28/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5789e-04 - mae: 0.0062 - mape: 41.5961\n",
      "Epoch 29/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 1.5827e-04 - mae: 0.0064 - mape: 38.7493\n",
      "Epoch 30/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.6383e-04 - mae: 0.0060 - mape: 36.5133\n",
      "Epoch 31/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.6501e-04 - mae: 0.0062 - mape: 34.2621\n",
      "Epoch 32/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 1.5494e-04 - mae: 0.0067 - mape: 40.4205\n",
      "Epoch 33/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.5340e-04 - mae: 0.0061 - mape: 38.9227\n",
      "Epoch 34/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.6467e-04 - mae: 0.0061 - mape: 35.4495\n",
      "Epoch 35/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.5469e-04 - mae: 0.0061 - mape: 38.4236\n",
      "Epoch 36/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 1.6609e-04 - mae: 0.0064 - mape: 37.3435\n",
      "Epoch 37/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5670e-04 - mae: 0.0062 - mape: 40.0040\n",
      "Epoch 38/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5570e-04 - mae: 0.0059 - mape: 36.7114\n",
      "Epoch 39/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.6083e-04 - mae: 0.0060 - mape: 34.4974\n",
      "Epoch 40/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 1.6491e-04 - mae: 0.0064 - mape: 37.0400\n",
      "Epoch 41/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5765e-04 - mae: 0.0062 - mape: 40.5131\n",
      "Epoch 42/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5892e-04 - mae: 0.0062 - mape: 37.8248\n",
      "Epoch 43/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 1.6038e-04 - mae: 0.0063 - mape: 40.9255\n",
      "Epoch 44/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.6058e-04 - mae: 0.0061 - mape: 34.8256\n",
      "Epoch 45/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 1.6175e-04 - mae: 0.0064 - mape: 38.9534\n",
      "Epoch 46/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.6006e-04 - mae: 0.0062 - mape: 37.8230\n",
      "Epoch 47/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 1.6117e-04 - mae: 0.0065 - mape: 39.4442\n",
      "Epoch 48/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 1.6009e-04 - mae: 0.0063 - mape: 40.9590\n",
      "Epoch 49/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.5473e-04 - mae: 0.0060 - mape: 42.7849\n",
      "Epoch 50/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.5964e-04 - mae: 0.0060 - mape: 35.6151\n",
      "Epoch 51/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.6448e-04 - mae: 0.0057 - mape: 34.3784\n",
      "Epoch 52/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.5823e-04 - mae: 0.0062 - mape: 44.1279\n",
      "Epoch 53/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.5698e-04 - mae: 0.0061 - mape: 38.4292\n",
      "Epoch 54/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.6077e-04 - mae: 0.0059 - mape: 34.4900\n",
      "Epoch 55/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.5859e-04 - mae: 0.0061 - mape: 38.7862\n",
      "Epoch 56/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 1.5859e-04 - mae: 0.0058 - mape: 37.0454\n",
      "Epoch 57/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 1.5774e-04 - mae: 0.0061 - mape: 40.0564\n",
      "Epoch 58/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5268e-04 - mae: 0.0059 - mape: 39.3612\n",
      "Epoch 59/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.6426e-04 - mae: 0.0059 - mape: 33.5303\n",
      "Epoch 60/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.6153e-04 - mae: 0.0059 - mape: 35.0805\n",
      "Epoch 61/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 1.5451e-04 - mae: 0.0060 - mape: 39.5421\n",
      "Epoch 62/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 1.5761e-04 - mae: 0.0060 - mape: 38.5123\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 1.5584e-04 - mae: 0.0060 - mape: 37.3001\n",
      "Epoch 64/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 1.5896e-04 - mae: 0.0059 - mape: 36.3919\n",
      "Epoch 65/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 1.6308e-04 - mae: 0.0062 - mape: 35.8413\n",
      "Epoch 66/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.5639e-04 - mae: 0.0061 - mape: 39.5744\n",
      "Epoch 67/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.5761e-04 - mae: 0.0060 - mape: 38.3087\n",
      "Epoch 68/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5576e-04 - mae: 0.0057 - mape: 38.7716\n",
      "Epoch 69/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.6178e-04 - mae: 0.0059 - mape: 40.6024\n",
      "Epoch 70/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5579e-04 - mae: 0.0059 - mape: 38.7716\n",
      "Epoch 71/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.5937e-04 - mae: 0.0058 - mape: 36.6543\n",
      "Epoch 72/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 1.6310e-04 - mae: 0.0061 - mape: 36.8086\n",
      "Epoch 73/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5375e-04 - mae: 0.0057 - mape: 38.0077\n",
      "Epoch 74/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.6712e-04 - mae: 0.0059 - mape: 34.0634\n",
      "Epoch 75/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 1.5053e-04 - mae: 0.0057 - mape: 40.6500\n",
      "Epoch 76/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.5729e-04 - mae: 0.0058 - mape: 37.5903\n",
      "Epoch 77/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.6009e-04 - mae: 0.0058 - mape: 36.6582\n",
      "Epoch 78/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5627e-04 - mae: 0.0059 - mape: 40.2057\n",
      "Epoch 79/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.6040e-04 - mae: 0.0058 - mape: 35.8533\n",
      "Epoch 80/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5564e-04 - mae: 0.0059 - mape: 37.8344\n",
      "Epoch 81/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.5773e-04 - mae: 0.0060 - mape: 38.9461\n",
      "Epoch 82/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 1.5667e-04 - mae: 0.0061 - mape: 39.3398\n",
      "Epoch 83/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.5186e-04 - mae: 0.0060 - mape: 41.4881\n",
      "Epoch 84/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 1.5119e-04 - mae: 0.0061 - mape: 43.0482\n",
      "Epoch 85/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.5675e-04 - mae: 0.0056 - mape: 37.8641\n",
      "Epoch 86/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 1.5631e-04 - mae: 0.0058 - mape: 36.6303\n",
      "Epoch 87/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.5075e-04 - mae: 0.0058 - mape: 42.9782\n",
      "Epoch 88/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 1.5365e-04 - mae: 0.0059 - mape: 40.2520\n",
      "Epoch 89/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5568e-04 - mae: 0.0057 - mape: 37.8822\n",
      "Epoch 90/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 1.5273e-04 - mae: 0.0056 - mape: 39.4694\n",
      "Epoch 91/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.5242e-04 - mae: 0.0058 - mape: 40.6734\n",
      "Epoch 92/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.5626e-04 - mae: 0.0056 - mape: 38.2277\n",
      "Epoch 93/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 1.5663e-04 - mae: 0.0059 - mape: 37.8841\n",
      "Epoch 94/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.4830e-04 - mae: 0.0060 - mape: 44.2111\n",
      "Epoch 95/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5116e-04 - mae: 0.0057 - mape: 41.7541\n",
      "Epoch 96/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 1.5616e-04 - mae: 0.0060 - mape: 38.5997\n",
      "Epoch 97/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4668e-04 - mae: 0.0055 - mape: 41.3447\n",
      "Epoch 98/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.5863e-04 - mae: 0.0056 - mape: 37.3545\n",
      "Epoch 99/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5231e-04 - mae: 0.0057 - mape: 39.5211\n",
      "Epoch 100/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.5123e-04 - mae: 0.0056 - mape: 40.9141\n",
      "Epoch 101/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.5241e-04 - mae: 0.0056 - mape: 40.6969\n",
      "Epoch 102/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5532e-04 - mae: 0.0057 - mape: 38.4591\n",
      "Epoch 103/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5480e-04 - mae: 0.0057 - mape: 41.3624\n",
      "Epoch 104/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.4610e-04 - mae: 0.0057 - mape: 42.8784\n",
      "Epoch 105/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.5090e-04 - mae: 0.0057 - mape: 41.4843\n",
      "Epoch 106/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0057 - mse: 1.5165e-04 - mae: 0.0057 - mape: 43.6921A: 0s - loss: 0.0064 - mse: 1.6842e-04 - mae: 0.0064 - mape: 71\n",
      "Epoch 107/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 1.5023e-04 - mae: 0.0056 - mape: 39.6336\n",
      "Epoch 108/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4307e-04 - mae: 0.0055 - mape: 44.0108\n",
      "Epoch 109/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.5353e-04 - mae: 0.0055 - mape: 40.2383\n",
      "Epoch 110/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.5003e-04 - mae: 0.0054 - mape: 42.2788\n",
      "Epoch 111/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 1.4812e-04 - mae: 0.0060 - mape: 45.3373\n",
      "Epoch 112/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4262e-04 - mae: 0.0054 - mape: 44.5808\n",
      "Epoch 113/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4964e-04 - mae: 0.0054 - mape: 42.4878\n",
      "Epoch 114/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4958e-04 - mae: 0.0054 - mape: 41.5089\n",
      "Epoch 115/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4967e-04 - mae: 0.0054 - mape: 42.4906\n",
      "Epoch 116/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4494e-04 - mae: 0.0054 - mape: 44.2624\n",
      "Epoch 117/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.5070e-04 - mae: 0.0055 - mape: 42.4754\n",
      "Epoch 118/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4721e-04 - mae: 0.0056 - mape: 45.5799\n",
      "Epoch 119/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4939e-04 - mae: 0.0056 - mape: 42.6331\n",
      "Epoch 120/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4414e-04 - mae: 0.0055 - mape: 44.6585\n",
      "Epoch 121/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4889e-04 - mae: 0.0055 - mape: 42.7508\n",
      "Epoch 122/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4474e-04 - mae: 0.0056 - mape: 46.8680\n",
      "Epoch 123/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 1.4570e-04 - mae: 0.0058 - mape: 47.3804\n",
      "Epoch 124/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4413e-04 - mae: 0.0055 - mape: 48.2913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4503e-04 - mae: 0.0056 - mape: 45.4374\n",
      "Epoch 126/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.4119e-04 - mae: 0.0057 - mape: 48.3661\n",
      "Epoch 127/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4417e-04 - mae: 0.0055 - mape: 47.8886\n",
      "Epoch 128/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4658e-04 - mae: 0.0055 - mape: 43.9782\n",
      "Epoch 129/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4467e-04 - mae: 0.0055 - mape: 45.2705\n",
      "Epoch 130/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.4651e-04 - mae: 0.0057 - mape: 46.5748\n",
      "Epoch 131/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4248e-04 - mae: 0.0056 - mape: 47.8114\n",
      "Epoch 132/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4393e-04 - mae: 0.0056 - mape: 49.4054\n",
      "Epoch 133/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4162e-04 - mae: 0.0055 - mape: 47.9577\n",
      "Epoch 134/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4267e-04 - mae: 0.0055 - mape: 47.3676\n",
      "Epoch 135/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4483e-04 - mae: 0.0055 - mape: 46.5604\n",
      "Epoch 136/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4157e-04 - mae: 0.0054 - mape: 48.1097\n",
      "Epoch 137/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4661e-04 - mae: 0.0055 - mape: 45.5550\n",
      "Epoch 138/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4292e-04 - mae: 0.0055 - mape: 47.9739\n",
      "Epoch 139/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4331e-04 - mae: 0.0054 - mape: 46.7501\n",
      "Epoch 140/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.4718e-04 - mae: 0.0053 - mape: 45.1314\n",
      "Epoch 141/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4205e-04 - mae: 0.0056 - mape: 48.2842\n",
      "Epoch 142/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4548e-04 - mae: 0.0056 - mape: 46.5876\n",
      "Epoch 143/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4410e-04 - mae: 0.0056 - mape: 45.2190\n",
      "Epoch 144/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4068e-04 - mae: 0.0054 - mape: 49.0538\n",
      "Epoch 145/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4363e-04 - mae: 0.0055 - mape: 45.9226\n",
      "Epoch 146/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4232e-04 - mae: 0.0056 - mape: 48.5336\n",
      "Epoch 147/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4502e-04 - mae: 0.0054 - mape: 45.0857\n",
      "Epoch 148/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.3788e-04 - mae: 0.0053 - mape: 48.8653\n",
      "Epoch 149/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.4630e-04 - mae: 0.0053 - mape: 44.2668\n",
      "Epoch 150/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4144e-04 - mae: 0.0055 - mape: 49.2176\n",
      "Epoch 151/200\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 1.4417e-04 - mae: 0.0054 - mape: 47.7264\n",
      "Epoch 152/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4429e-04 - mae: 0.0054 - mape: 46.7994\n",
      "Epoch 153/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4483e-04 - mae: 0.0055 - mape: 47.4723\n",
      "Epoch 154/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4374e-04 - mae: 0.0055 - mape: 46.8439\n",
      "Epoch 155/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.3974e-04 - mae: 0.0055 - mape: 51.1508\n",
      "Epoch 156/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4504e-04 - mae: 0.0056 - mape: 46.6109\n",
      "Epoch 157/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.3962e-04 - mae: 0.0054 - mape: 50.7772\n",
      "Epoch 158/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4342e-04 - mae: 0.0054 - mape: 47.0769\n",
      "Epoch 159/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4576e-04 - mae: 0.0055 - mape: 46.3895\n",
      "Epoch 160/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4144e-04 - mae: 0.0054 - mape: 48.7082\n",
      "Epoch 161/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4115e-04 - mae: 0.0054 - mape: 46.5441\n",
      "Epoch 162/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4727e-04 - mae: 0.0054 - mape: 43.2094\n",
      "Epoch 163/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4399e-04 - mae: 0.0055 - mape: 46.8940\n",
      "Epoch 164/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.4440e-04 - mae: 0.0053 - mape: 46.6212\n",
      "Epoch 165/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4848e-04 - mae: 0.0054 - mape: 44.0028\n",
      "Epoch 166/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.3813e-04 - mae: 0.0055 - mape: 50.6850\n",
      "Epoch 167/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4370e-04 - mae: 0.0056 - mape: 49.9700\n",
      "Epoch 168/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4731e-04 - mae: 0.0056 - mape: 44.5956\n",
      "Epoch 169/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4105e-04 - mae: 0.0054 - mape: 48.2120\n",
      "Epoch 170/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4649e-04 - mae: 0.0056 - mape: 47.1830\n",
      "Epoch 171/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4410e-04 - mae: 0.0054 - mape: 45.7381\n",
      "Epoch 172/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0054 - mse: 1.4299e-04 - mae: 0.0054 - mape: 47.7037\n",
      "Epoch 173/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4080e-04 - mae: 0.0054 - mape: 48.7878\n",
      "Epoch 174/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4821e-04 - mae: 0.0054 - mape: 43.0574\n",
      "Epoch 175/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4057e-04 - mae: 0.0055 - mape: 48.5809\n",
      "Epoch 176/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4328e-04 - mae: 0.0055 - mape: 43.6657\n",
      "Epoch 177/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 1.4276e-04 - mae: 0.0056 - mape: 51.3613\n",
      "Epoch 178/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4281e-04 - mae: 0.0054 - mape: 47.1925\n",
      "Epoch 179/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4273e-04 - mae: 0.0055 - mape: 48.8621\n",
      "Epoch 180/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4325e-04 - mae: 0.0055 - mape: 48.5111\n",
      "Epoch 181/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 1.4248e-04 - mae: 0.0055 - mape: 50.4616\n",
      "Epoch 182/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4206e-04 - mae: 0.0055 - mape: 47.8452\n",
      "Epoch 183/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4353e-04 - mae: 0.0055 - mape: 46.5624\n",
      "Epoch 184/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4302e-04 - mae: 0.0056 - mape: 49.3699\n",
      "Epoch 185/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4173e-04 - mae: 0.0056 - mape: 49.3454\n",
      "Epoch 186/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.3848e-04 - mae: 0.0055 - mape: 49.0492\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 1.4382e-04 - mae: 0.0055 - mape: 49.0902\n",
      "Epoch 188/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4409e-04 - mae: 0.0056 - mape: 48.2422\n",
      "Epoch 189/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.4100e-04 - mae: 0.0053 - mape: 48.8465\n",
      "Epoch 190/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4518e-04 - mae: 0.0054 - mape: 45.1645\n",
      "Epoch 191/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4432e-04 - mae: 0.0056 - mape: 46.3321\n",
      "Epoch 192/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4411e-04 - mae: 0.0054 - mape: 45.0891\n",
      "Epoch 193/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4027e-04 - mae: 0.0055 - mape: 47.6311\n",
      "Epoch 194/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4362e-04 - mae: 0.0055 - mape: 45.2549\n",
      "Epoch 195/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4242e-04 - mae: 0.0054 - mape: 48.8006\n",
      "Epoch 196/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.4442e-04 - mae: 0.0056 - mape: 46.6704\n",
      "Epoch 197/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 1.4481e-04 - mae: 0.0053 - mape: 44.4018\n",
      "Epoch 198/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 1.4431e-04 - mae: 0.0057 - mape: 47.2400\n",
      "Epoch 199/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 1.4106e-04 - mae: 0.0055 - mape: 47.2691\n",
      "Epoch 200/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 1.4217e-04 - mae: 0.0054 - mape: 47.5707\n",
      "313/313 [==============================] - 0s 894us/step\n",
      "313/313 [==============================] - 0s 783us/step\n",
      "Status: Current part: 1 out of : 5 parts.\n",
      "Heights to iterate over: [85]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0904 - mse: 0.0143 - mae: 0.0904 - mape: 35.5383\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0593 - mse: 0.0049 - mae: 0.0593 - mape: 26.0790\n",
      "Epoch 3/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0050 - mae: 0.0573 - mape: 26.4290\n",
      "Epoch 4/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0048 - mae: 0.0567 - mape: 25.9516\n",
      "Epoch 5/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0047 - mae: 0.0569 - mape: 25.8080\n",
      "Epoch 6/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0048 - mae: 0.0567 - mape: 25.9974\n",
      "Epoch 7/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0580 - mse: 0.0047 - mae: 0.0580 - mape: 25.8029\n",
      "Epoch 8/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0046 - mae: 0.0571 - mape: 25.6880\n",
      "Epoch 9/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0048 - mae: 0.0563 - mape: 25.9606\n",
      "Epoch 10/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0048 - mae: 0.0572 - mape: 25.7976\n",
      "Epoch 11/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0581 - mse: 0.0048 - mae: 0.0581 - mape: 25.0421\n",
      "Epoch 12/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0047 - mae: 0.0576 - mape: 25.6732\n",
      "Epoch 13/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0047 - mae: 0.0576 - mape: 25.2582\n",
      "Epoch 14/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0616 - mse: 0.0054 - mae: 0.0616 - mape: 26.1867\n",
      "Epoch 15/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0046 - mae: 0.0581 - mape: 24.8017\n",
      "Epoch 16/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0050 - mae: 0.0572 - mape: 26.3340\n",
      "Epoch 17/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0047 - mae: 0.0572 - mape: 25.8757\n",
      "Epoch 18/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0048 - mae: 0.0564 - mape: 25.9228\n",
      "Epoch 19/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0047 - mae: 0.0579 - mape: 25.7584\n",
      "Epoch 20/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0046 - mae: 0.0573 - mape: 25.4875\n",
      "Epoch 21/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0048 - mae: 0.0567 - mape: 26.0173\n",
      "Epoch 22/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0047 - mae: 0.0563 - mape: 25.7544\n",
      "Epoch 23/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0047 - mae: 0.0563 - mape: 25.8024\n",
      "Epoch 24/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0047 - mae: 0.0560 - mape: 25.7427\n",
      "Epoch 25/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0047 - mae: 0.0569 - mape: 25.8459\n",
      "Epoch 26/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0047 - mae: 0.0562 - mape: 25.7975\n",
      "Epoch 27/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0047 - mae: 0.0564 - mape: 25.7190\n",
      "Epoch 28/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0049 - mae: 0.0569 - mape: 26.0666\n",
      "Epoch 29/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0046 - mae: 0.0565 - mape: 25.6550\n",
      "Epoch 30/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0047 - mae: 0.0571 - mape: 25.8973\n",
      "Epoch 31/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0046 - mae: 0.0568 - mape: 25.5481\n",
      "Epoch 32/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0562 - mse: 0.0048 - mae: 0.0562 - mape: 25.8033\n",
      "Epoch 33/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0048 - mae: 0.0561 - mape: 25.9583\n",
      "Epoch 34/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0047 - mae: 0.0557 - mape: 25.7205\n",
      "Epoch 35/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0047 - mae: 0.0558 - mape: 25.7482\n",
      "Epoch 36/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0575 - mse: 0.0046 - mae: 0.0575 - mape: 25.4899\n",
      "Epoch 37/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0046 - mae: 0.0564 - mape: 25.5570\n",
      "Epoch 38/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0047 - mae: 0.0563 - mape: 25.7219\n",
      "Epoch 39/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0568 - mse: 0.0047 - mae: 0.0568 - mape: 25.9382\n",
      "Epoch 40/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0047 - mae: 0.0560 - mape: 25.7232\n",
      "Epoch 41/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0047 - mae: 0.0556 - mape: 25.6177\n",
      "Epoch 42/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0047 - mae: 0.0561 - mape: 25.8146\n",
      "Epoch 43/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0048 - mae: 0.0563 - mape: 25.9498\n",
      "Epoch 44/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0044 - mae: 0.0565 - mape: 24.9620\n",
      "Epoch 45/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0047 - mae: 0.0553 - mape: 25.5088\n",
      "Epoch 46/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0041 - mae: 0.0533 - mape: 24.0530\n",
      "Epoch 47/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0024 - mae: 0.0410 - mape: 17.9198\n",
      "Epoch 48/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0216 - mse: 9.3860e-04 - mae: 0.0216 - mape: 8.3354\n",
      "Epoch 49/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 6.7638e-04 - mae: 0.0167 - mape: 6.5594\n",
      "Epoch 50/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 7.3228e-04 - mae: 0.0172 - mape: 6.7681\n",
      "Epoch 51/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 6.7630e-04 - mae: 0.0159 - mape: 6.1516\n",
      "Epoch 52/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 6.3908e-04 - mae: 0.0157 - mape: 6.1702\n",
      "Epoch 53/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 6.4000e-04 - mae: 0.0153 - mape: 6.0217\n",
      "Epoch 54/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 6.6917e-04 - mae: 0.0157 - mape: 6.0391\n",
      "Epoch 55/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 6.7013e-04 - mae: 0.0160 - mape: 6.1929\n",
      "Epoch 56/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 6.7443e-04 - mae: 0.0154 - mape: 5.9988\n",
      "Epoch 57/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 6.8403e-04 - mae: 0.0154 - mape: 5.9846\n",
      "Epoch 58/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 6.7787e-04 - mae: 0.0154 - mape: 5.9857\n",
      "Epoch 59/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 6.9581e-04 - mae: 0.0162 - mape: 6.1988\n",
      "Epoch 60/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 6.8758e-04 - mae: 0.0154 - mape: 5.9894\n",
      "Epoch 61/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 6.6096e-04 - mae: 0.0148 - mape: 5.7447\n",
      "Epoch 62/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 6.8847e-04 - mae: 0.0154 - mape: 5.9794\n",
      "Epoch 63/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 6.9518e-04 - mae: 0.0151 - mape: 5.8422\n",
      "Epoch 64/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 6.8791e-04 - mae: 0.0149 - mape: 5.7745\n",
      "Epoch 65/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 7.1806e-04 - mae: 0.0159 - mape: 6.0294\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 7.2365e-04 - mae: 0.0150 - mape: 5.7813\n",
      "Epoch 67/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 6.8597e-04 - mae: 0.0152 - mape: 5.8620\n",
      "Epoch 68/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 7.0230e-04 - mae: 0.0158 - mape: 6.0448\n",
      "Epoch 69/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 6.8287e-04 - mae: 0.0154 - mape: 5.9519\n",
      "Epoch 70/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 7.0127e-04 - mae: 0.0156 - mape: 5.9994\n",
      "Epoch 71/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 7.1568e-04 - mae: 0.0155 - mape: 5.9162\n",
      "Epoch 72/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 7.0061e-04 - mae: 0.0150 - mape: 5.7227\n",
      "Epoch 73/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 6.8826e-04 - mae: 0.0150 - mape: 5.8548\n",
      "Epoch 74/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 7.4009e-04 - mae: 0.0151 - mape: 5.7487\n",
      "Epoch 75/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 7.1102e-04 - mae: 0.0149 - mape: 5.6906\n",
      "Epoch 76/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 7.0510e-04 - mae: 0.0152 - mape: 5.8336\n",
      "Epoch 77/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 6.8111e-04 - mae: 0.0146 - mape: 5.6338\n",
      "Epoch 78/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 6.9566e-04 - mae: 0.0151 - mape: 5.7471\n",
      "Epoch 79/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 6.8781e-04 - mae: 0.0148 - mape: 5.6995\n",
      "Epoch 80/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 6.8919e-04 - mae: 0.0148 - mape: 5.6594\n",
      "Epoch 81/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 7.0771e-04 - mae: 0.0150 - mape: 5.8056\n",
      "Epoch 82/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 7.2970e-04 - mae: 0.0163 - mape: 6.1392\n",
      "Epoch 83/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 7.0446e-04 - mae: 0.0149 - mape: 5.7840\n",
      "Epoch 84/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 7.1259e-04 - mae: 0.0151 - mape: 5.7596\n",
      "Epoch 85/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 6.9229e-04 - mae: 0.0152 - mape: 5.8290\n",
      "Epoch 86/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 6.8859e-04 - mae: 0.0147 - mape: 5.6456\n",
      "Epoch 87/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 7.0008e-04 - mae: 0.0149 - mape: 5.7102\n",
      "Epoch 88/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 7.5628e-04 - mae: 0.0153 - mape: 5.8842\n",
      "Epoch 89/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 7.0472e-04 - mae: 0.0148 - mape: 5.6221\n",
      "Epoch 90/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 7.1636e-04 - mae: 0.0148 - mape: 5.6779\n",
      "Epoch 91/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 6.8597e-04 - mae: 0.0150 - mape: 5.7899\n",
      "Epoch 92/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 7.0426e-04 - mae: 0.0149 - mape: 5.6872\n",
      "Epoch 93/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 6.7853e-04 - mae: 0.0143 - mape: 5.5723\n",
      "Epoch 94/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.8876e-04 - mae: 0.0145 - mape: 5.5691\n",
      "Epoch 95/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 7.0098e-04 - mae: 0.0150 - mape: 5.7414\n",
      "Epoch 96/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 7.1756e-04 - mae: 0.0158 - mape: 5.9636\n",
      "Epoch 97/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 6.9209e-04 - mae: 0.0154 - mape: 5.8603\n",
      "Epoch 98/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.7965e-04 - mae: 0.0145 - mape: 5.6032\n",
      "Epoch 99/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 6.8134e-04 - mae: 0.0142 - mape: 5.4670\n",
      "Epoch 100/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 6.6615e-04 - mae: 0.0147 - mape: 5.6798\n",
      "Epoch 101/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 6.8121e-04 - mae: 0.0146 - mape: 5.5931\n",
      "Epoch 102/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.8238e-04 - mae: 0.0144 - mape: 5.5127\n",
      "Epoch 103/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 6.9021e-04 - mae: 0.0148 - mape: 5.6374\n",
      "Epoch 104/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.5235e-04 - mae: 0.0144 - mape: 5.5926\n",
      "Epoch 105/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 6.7045e-04 - mae: 0.0143 - mape: 5.5236\n",
      "Epoch 106/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.7845e-04 - mae: 0.0145 - mape: 5.5416\n",
      "Epoch 107/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 7.0157e-04 - mae: 0.0144 - mape: 5.5226\n",
      "Epoch 108/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 7.1288e-04 - mae: 0.0148 - mape: 5.6201\n",
      "Epoch 109/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 6.7296e-04 - mae: 0.0149 - mape: 5.7376\n",
      "Epoch 110/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.7679e-04 - mae: 0.0144 - mape: 5.5340\n",
      "Epoch 111/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 6.8480e-04 - mae: 0.0147 - mape: 5.6356\n",
      "Epoch 112/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 6.8971e-04 - mae: 0.0150 - mape: 5.7451\n",
      "Epoch 113/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.7539e-04 - mae: 0.0145 - mape: 5.5503\n",
      "Epoch 114/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.9496e-04 - mae: 0.0145 - mape: 5.5430\n",
      "Epoch 115/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.6735e-04 - mae: 0.0144 - mape: 5.5206\n",
      "Epoch 116/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.5833e-04 - mae: 0.0145 - mape: 5.5507\n",
      "Epoch 117/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.9133e-04 - mae: 0.0145 - mape: 5.5474\n",
      "Epoch 118/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.8295e-04 - mae: 0.0144 - mape: 5.5267\n",
      "Epoch 119/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 6.6738e-04 - mae: 0.0141 - mape: 5.4306\n",
      "Epoch 120/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 6.5827e-04 - mae: 0.0142 - mape: 5.4874\n",
      "Epoch 121/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 6.4599e-04 - mae: 0.0140 - mape: 5.4129\n",
      "Epoch 122/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 6.8058e-04 - mae: 0.0142 - mape: 5.4297\n",
      "Epoch 123/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 6.3868e-04 - mae: 0.0139 - mape: 5.3932\n",
      "Epoch 124/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.7283e-04 - mae: 0.0145 - mape: 5.5475\n",
      "Epoch 125/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 6.7446e-04 - mae: 0.0148 - mape: 5.6425\n",
      "Epoch 126/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 6.5512e-04 - mae: 0.0142 - mape: 5.4475\n",
      "Epoch 127/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.4561e-04 - mae: 0.0145 - mape: 5.5761\n",
      "Epoch 128/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 6.6230e-04 - mae: 0.0143 - mape: 5.5418\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 6.6087e-04 - mae: 0.0140 - mape: 5.3532\n",
      "Epoch 130/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 6.4716e-04 - mae: 0.0145 - mape: 5.6457\n",
      "Epoch 131/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 6.4635e-04 - mae: 0.0147 - mape: 5.6261\n",
      "Epoch 132/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 6.4206e-04 - mae: 0.0142 - mape: 5.4494\n",
      "Epoch 133/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 6.4365e-04 - mae: 0.0140 - mape: 5.3854\n",
      "Epoch 134/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 6.3341e-04 - mae: 0.0138 - mape: 5.3308\n",
      "Epoch 135/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 6.4055e-04 - mae: 0.0141 - mape: 5.4047\n",
      "Epoch 136/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0135 - mse: 6.2555e-04 - mae: 0.0135 - mape: 5.2475\n",
      "Epoch 137/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 6.3550e-04 - mae: 0.0138 - mape: 5.3127\n",
      "Epoch 138/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 6.1765e-04 - mae: 0.0138 - mape: 5.3682\n",
      "Epoch 139/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 6.1224e-04 - mae: 0.0140 - mape: 5.4096\n",
      "Epoch 140/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 6.3804e-04 - mae: 0.0148 - mape: 5.5934\n",
      "Epoch 141/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 6.5102e-04 - mae: 0.0140 - mape: 5.3787\n",
      "Epoch 142/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 6.2349e-04 - mae: 0.0138 - mape: 5.3077\n",
      "Epoch 143/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 6.3609e-04 - mae: 0.0137 - mape: 5.2734\n",
      "Epoch 144/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 6.3096e-04 - mae: 0.0145 - mape: 5.5903\n",
      "Epoch 145/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 6.1960e-04 - mae: 0.0138 - mape: 5.3112\n",
      "Epoch 146/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 6.1399e-04 - mae: 0.0136 - mape: 5.2823\n",
      "Epoch 147/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 6.0101e-04 - mae: 0.0136 - mape: 5.2658\n",
      "Epoch 148/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 6.1988e-04 - mae: 0.0134 - mape: 5.1626\n",
      "Epoch 149/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 5.9960e-04 - mae: 0.0136 - mape: 5.3040\n",
      "Epoch 150/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 6.0383e-04 - mae: 0.0139 - mape: 5.3921\n",
      "Epoch 151/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 6.2326e-04 - mae: 0.0144 - mape: 5.4726\n",
      "Epoch 152/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 6.0418e-04 - mae: 0.0136 - mape: 5.2573\n",
      "Epoch 153/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 5.8452e-04 - mae: 0.0136 - mape: 5.3082\n",
      "Epoch 154/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 6.1987e-04 - mae: 0.0137 - mape: 5.2096\n",
      "Epoch 155/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 5.8550e-04 - mae: 0.0138 - mape: 5.3683\n",
      "Epoch 156/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 6.2275e-04 - mae: 0.0138 - mape: 5.2635\n",
      "Epoch 157/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 6.1586e-04 - mae: 0.0139 - mape: 5.2983\n",
      "Epoch 158/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 5.9569e-04 - mae: 0.0134 - mape: 5.1676\n",
      "Epoch 159/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 5.8854e-04 - mae: 0.0138 - mape: 5.3289\n",
      "Epoch 160/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 5.8568e-04 - mae: 0.0134 - mape: 5.1442\n",
      "Epoch 161/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 5.7792e-04 - mae: 0.0132 - mape: 5.1302\n",
      "Epoch 162/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 5.8556e-04 - mae: 0.0135 - mape: 5.2224\n",
      "Epoch 163/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 5.9516e-04 - mae: 0.0137 - mape: 5.2460\n",
      "Epoch 164/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 5.7642e-04 - mae: 0.0131 - mape: 5.0727\n",
      "Epoch 165/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 5.7157e-04 - mae: 0.0130 - mape: 5.0193\n",
      "Epoch 166/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 5.7653e-04 - mae: 0.0134 - mape: 5.1347\n",
      "Epoch 167/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 5.6312e-04 - mae: 0.0134 - mape: 5.1772\n",
      "Epoch 168/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 5.7396e-04 - mae: 0.0133 - mape: 5.1117\n",
      "Epoch 169/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 5.9928e-04 - mae: 0.0135 - mape: 5.1576\n",
      "Epoch 170/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 5.5543e-04 - mae: 0.0132 - mape: 5.1083\n",
      "Epoch 171/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 5.7582e-04 - mae: 0.0137 - mape: 5.2048\n",
      "Epoch 172/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 5.5571e-04 - mae: 0.0133 - mape: 5.1173\n",
      "Epoch 173/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 5.6056e-04 - mae: 0.0131 - mape: 5.0567\n",
      "Epoch 174/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 5.7263e-04 - mae: 0.0133 - mape: 5.1215\n",
      "Epoch 175/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 5.7969e-04 - mae: 0.0136 - mape: 5.2139\n",
      "Epoch 176/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.3055e-04 - mae: 0.0129 - mape: 4.9832\n",
      "Epoch 177/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 5.3054e-04 - mae: 0.0128 - mape: 4.9678\n",
      "Epoch 178/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 5.8179e-04 - mae: 0.0131 - mape: 5.0324\n",
      "Epoch 179/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 5.3333e-04 - mae: 0.0127 - mape: 4.8915\n",
      "Epoch 180/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.2516e-04 - mae: 0.0129 - mape: 4.9980\n",
      "Epoch 181/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 5.2800e-04 - mae: 0.0127 - mape: 4.9193\n",
      "Epoch 182/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.5267e-04 - mae: 0.0129 - mape: 4.9504\n",
      "Epoch 183/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 5.2573e-04 - mae: 0.0133 - mape: 5.1998\n",
      "Epoch 184/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 5.5351e-04 - mae: 0.0130 - mape: 4.9374\n",
      "Epoch 185/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 5.3244e-04 - mae: 0.0128 - mape: 4.9241\n",
      "Epoch 186/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 5.1664e-04 - mae: 0.0128 - mape: 4.9296\n",
      "Epoch 187/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.4005e-04 - mae: 0.0129 - mape: 4.9269\n",
      "Epoch 188/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.2491e-04 - mae: 0.0129 - mape: 4.9645\n",
      "Epoch 189/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 5.4436e-04 - mae: 0.0132 - mape: 4.9700\n",
      "Epoch 190/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 5.1937e-04 - mae: 0.0126 - mape: 4.8412\n",
      "Epoch 191/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 5.0838e-04 - mae: 0.0129 - mape: 4.9228\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 5.1584e-04 - mae: 0.0125 - mape: 4.8472\n",
      "Epoch 193/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 5.0760e-04 - mae: 0.0124 - mape: 4.7547\n",
      "Epoch 194/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 4.9704e-04 - mae: 0.0123 - mape: 4.7436\n",
      "Epoch 195/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 4.8508e-04 - mae: 0.0124 - mape: 4.7510\n",
      "Epoch 196/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 5.1722e-04 - mae: 0.0124 - mape: 4.7063\n",
      "Epoch 197/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 4.8432e-04 - mae: 0.0123 - mape: 4.7107\n",
      "Epoch 198/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 5.1255e-04 - mae: 0.0126 - mape: 4.8374\n",
      "Epoch 199/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 4.8543e-04 - mae: 0.0121 - mape: 4.6471\n",
      "Epoch 200/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 5.1346e-04 - mae: 0.0127 - mape: 4.8274\n",
      "313/313 [==============================] - 0s 779us/step\n",
      "313/313 [==============================] - 0s 787us/step\n",
      "Status: Current part: 2 out of : 5 parts.\n",
      "Heights to iterate over: [51]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   14.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.2801 - mse: 0.1173 - mae: 0.2801 - mape: 56.0991\n",
      "Epoch 2/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0030 - mae: 0.0470 - mape: 9.6794\n",
      "Epoch 3/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0449 - mse: 0.0029 - mae: 0.0449 - mape: 9.3527\n",
      "Epoch 4/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0024 - mae: 0.0417 - mape: 8.6995\n",
      "Epoch 5/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0025 - mae: 0.0414 - mape: 8.6618\n",
      "Epoch 6/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0388 - mse: 0.0023 - mae: 0.0388 - mape: 8.2141\n",
      "Epoch 7/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0382 - mse: 0.0023 - mae: 0.0382 - mape: 8.0752\n",
      "Epoch 8/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0022 - mae: 0.0380 - mape: 8.0018\n",
      "Epoch 9/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 7.6986\n",
      "Epoch 10/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0022 - mae: 0.0373 - mape: 7.8247\n",
      "Epoch 11/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0371 - mse: 0.0021 - mae: 0.0371 - mape: 7.7959\n",
      "Epoch 12/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0021 - mae: 0.0369 - mape: 7.7253\n",
      "Epoch 13/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0021 - mae: 0.0373 - mape: 7.7906\n",
      "Epoch 14/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7201\n",
      "Epoch 15/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5039\n",
      "Epoch 16/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5200\n",
      "Epoch 17/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4987\n",
      "Epoch 18/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.7123\n",
      "Epoch 19/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.5957\n",
      "Epoch 20/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5786\n",
      "Epoch 21/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0375 - mse: 0.0022 - mae: 0.0375 - mape: 7.8494\n",
      "Epoch 22/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0021 - mae: 0.0370 - mape: 7.7595\n",
      "Epoch 23/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5215\n",
      "Epoch 24/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5904\n",
      "Epoch 25/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0021 - mae: 0.0374 - mape: 7.7152\n",
      "Epoch 26/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7006\n",
      "Epoch 27/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5414\n",
      "Epoch 28/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.5980\n",
      "Epoch 29/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5911\n",
      "Epoch 30/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5765\n",
      "Epoch 31/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5328\n",
      "Epoch 32/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0021 - mae: 0.0372 - mape: 7.7221\n",
      "Epoch 33/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.6527\n",
      "Epoch 34/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0020 - mae: 0.0365 - mape: 7.6466\n",
      "Epoch 35/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0374 - mse: 0.0021 - mae: 0.0374 - mape: 7.8129\n",
      "Epoch 36/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4963\n",
      "Epoch 37/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4716\n",
      "Epoch 38/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5734\n",
      "Epoch 39/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4900\n",
      "Epoch 40/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4974\n",
      "Epoch 41/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.6304\n",
      "Epoch 42/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5486\n",
      "Epoch 43/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6278\n",
      "Epoch 44/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0021 - mae: 0.0372 - mape: 7.7343\n",
      "Epoch 45/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0021 - mae: 0.0365 - mape: 7.6528\n",
      "Epoch 46/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0374 - mse: 0.0022 - mae: 0.0374 - mape: 7.7988\n",
      "Epoch 47/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5001\n",
      "Epoch 48/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0020 - mae: 0.0365 - mape: 7.6125\n",
      "Epoch 49/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5791\n",
      "Epoch 50/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0020 - mae: 0.0368 - mape: 7.6979\n",
      "Epoch 51/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5338\n",
      "Epoch 52/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5405\n",
      "Epoch 53/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0021 - mae: 0.0374 - mape: 7.7930\n",
      "Epoch 54/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6242\n",
      "Epoch 55/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4922\n",
      "Epoch 56/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.5050\n",
      "Epoch 57/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4297\n",
      "Epoch 58/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5420\n",
      "Epoch 59/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.6496\n",
      "Epoch 60/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4804\n",
      "Epoch 61/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4703\n",
      "Epoch 62/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0371 - mse: 0.0021 - mae: 0.0371 - mape: 7.7569\n",
      "Epoch 63/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5502\n",
      "Epoch 64/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5938\n",
      "Epoch 65/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5475\n",
      "Epoch 66/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.5114\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0020 - mae: 0.0367 - mape: 7.6471\n",
      "Epoch 68/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5629\n",
      "Epoch 69/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5096\n",
      "Epoch 70/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4982\n",
      "Epoch 71/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4444\n",
      "Epoch 72/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.6190\n",
      "Epoch 73/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4705\n",
      "Epoch 74/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7121\n",
      "Epoch 75/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5184\n",
      "Epoch 76/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4956\n",
      "Epoch 77/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5214\n",
      "Epoch 78/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0021 - mae: 0.0369 - mape: 7.6956\n",
      "Epoch 79/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.6542\n",
      "Epoch 80/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.5052\n",
      "Epoch 81/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0020 - mae: 0.0367 - mape: 7.6418\n",
      "Epoch 82/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6122\n",
      "Epoch 83/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5803\n",
      "Epoch 84/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5883\n",
      "Epoch 85/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4841\n",
      "Epoch 86/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5597\n",
      "Epoch 87/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5440\n",
      "Epoch 88/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5375\n",
      "Epoch 89/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4432\n",
      "Epoch 90/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.6037\n",
      "Epoch 91/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0021 - mae: 0.0372 - mape: 7.7600\n",
      "Epoch 92/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0022 - mae: 0.0376 - mape: 7.8417\n",
      "Epoch 93/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.6981\n",
      "Epoch 94/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0369 - mse: 0.0021 - mae: 0.0369 - mape: 7.6914\n",
      "Epoch 95/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4469\n",
      "Epoch 96/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5383\n",
      "Epoch 97/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0020 - mae: 0.0365 - mape: 7.6330\n",
      "Epoch 98/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.6216\n",
      "Epoch 99/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4457\n",
      "Epoch 100/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4845\n",
      "Epoch 101/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5601\n",
      "Epoch 102/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0020 - mae: 0.0365 - mape: 7.6222\n",
      "Epoch 103/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5096\n",
      "Epoch 104/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5080\n",
      "Epoch 105/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6035\n",
      "Epoch 106/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6261\n",
      "Epoch 107/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5915\n",
      "Epoch 108/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4688\n",
      "Epoch 109/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5346\n",
      "Epoch 110/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5254\n",
      "Epoch 111/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5292\n",
      "Epoch 112/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4916\n",
      "Epoch 113/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5114\n",
      "Epoch 114/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.6156\n",
      "Epoch 115/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4543\n",
      "Epoch 116/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.6580\n",
      "Epoch 117/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5390\n",
      "Epoch 118/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5366\n",
      "Epoch 119/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0371 - mse: 0.0021 - mae: 0.0371 - mape: 7.7566\n",
      "Epoch 120/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5255\n",
      "Epoch 121/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5306\n",
      "Epoch 122/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5706\n",
      "Epoch 123/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0020 - mae: 0.0368 - mape: 7.6733\n",
      "Epoch 124/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5206\n",
      "Epoch 125/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5771\n",
      "Epoch 126/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.4884\n",
      "Epoch 127/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5755\n",
      "Epoch 128/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5412\n",
      "Epoch 129/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5147\n",
      "Epoch 130/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0021 - mae: 0.0367 - mape: 7.6768\n",
      "Epoch 131/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4959\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5292\n",
      "Epoch 133/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4650\n",
      "Epoch 134/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0369 - mse: 0.0020 - mae: 0.0369 - mape: 7.6539\n",
      "Epoch 135/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5060\n",
      "Epoch 136/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4806\n",
      "Epoch 137/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4662\n",
      "Epoch 138/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.5893\n",
      "Epoch 139/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4709\n",
      "Epoch 140/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4706\n",
      "Epoch 141/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6351\n",
      "Epoch 142/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0364 - mse: 0.0020 - mae: 0.0364 - mape: 7.6212\n",
      "Epoch 143/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5637\n",
      "Epoch 144/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5865\n",
      "Epoch 145/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5194\n",
      "Epoch 146/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4557\n",
      "Epoch 147/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.6280\n",
      "Epoch 148/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0021 - mae: 0.0369 - mape: 7.6899\n",
      "Epoch 149/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5867\n",
      "Epoch 150/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5070\n",
      "Epoch 151/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.4658\n",
      "Epoch 152/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5697\n",
      "Epoch 153/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0021 - mae: 0.0368 - mape: 7.7336\n",
      "Epoch 154/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4982\n",
      "Epoch 155/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.4993\n",
      "Epoch 156/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4821\n",
      "Epoch 157/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.4788\n",
      "Epoch 158/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5606\n",
      "Epoch 159/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5616\n",
      "Epoch 160/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5774\n",
      "Epoch 161/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0020 - mae: 0.0361 - mape: 7.5322\n",
      "Epoch 162/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5123\n",
      "Epoch 163/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5349\n",
      "Epoch 164/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.5025\n",
      "Epoch 165/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0021 - mae: 0.0372 - mape: 7.7695\n",
      "Epoch 166/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0020 - mae: 0.0363 - mape: 7.5970\n",
      "Epoch 167/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4561\n",
      "Epoch 168/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4864\n",
      "Epoch 169/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4827\n",
      "Epoch 170/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4655\n",
      "Epoch 171/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.4690\n",
      "Epoch 172/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.4970\n",
      "Epoch 173/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.5387\n",
      "Epoch 174/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5069\n",
      "Epoch 175/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.4463\n",
      "Epoch 176/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4286\n",
      "Epoch 177/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5469\n",
      "Epoch 178/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4634\n",
      "Epoch 179/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0019 - mae: 0.0359 - mape: 7.4779\n",
      "Epoch 180/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0020 - mae: 0.0366 - mape: 7.6699\n",
      "Epoch 181/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4562\n",
      "Epoch 182/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5158\n",
      "Epoch 183/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4808\n",
      "Epoch 184/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0019 - mae: 0.0355 - mape: 7.4357\n",
      "Epoch 185/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0020 - mae: 0.0356 - mape: 7.4806\n",
      "Epoch 186/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4763\n",
      "Epoch 187/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4977\n",
      "Epoch 188/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0020 - mae: 0.0358 - mape: 7.5068\n",
      "Epoch 189/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4941\n",
      "Epoch 190/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0019 - mae: 0.0356 - mape: 7.4294\n",
      "Epoch 191/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4991\n",
      "Epoch 192/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0019 - mae: 0.0358 - mape: 7.4818\n",
      "Epoch 193/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4965\n",
      "Epoch 194/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0020 - mae: 0.0365 - mape: 7.6559\n",
      "Epoch 195/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4751\n",
      "Epoch 196/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0019 - mae: 0.0357 - mape: 7.4681\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0020 - mae: 0.0360 - mape: 7.5316\n",
      "Epoch 198/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0362 - mse: 0.0020 - mae: 0.0362 - mape: 7.5855\n",
      "Epoch 199/200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.0357 - mse: 0.0020 - mae: 0.0357 - mape: 7.4691\n",
      "Epoch 200/200\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0020 - mae: 0.0359 - mape: 7.4968\n",
      "313/313 [==============================] - 0s 769us/step\n",
      "313/313 [==============================] - 0s 797us/step\n",
      "Status: Current part: 3 out of : 5 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   15.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4310 - mse: 0.2830 - mae: 0.4310 - mape: 55.2268\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0031 - mae: 0.0438 - mape: 5.8021\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0030 - mae: 0.0435 - mape: 5.7567\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0029 - mae: 0.0425 - mape: 5.6227\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0030 - mae: 0.0427 - mape: 5.6651\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0030 - mae: 0.0435 - mape: 5.7386\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0029 - mae: 0.0417 - mape: 5.5611\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0030 - mae: 0.0428 - mape: 5.6952\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4746\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5576\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4714\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5200\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5543\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5392\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0030 - mae: 0.0439 - mape: 5.8308\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0424 - mse: 0.0029 - mae: 0.0424 - mape: 5.6556\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0447 - mse: 0.0031 - mae: 0.0447 - mape: 5.9173\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0451 - mse: 0.0032 - mae: 0.0451 - mape: 5.9729\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.5965\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5312\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0029 - mae: 0.0431 - mape: 5.7277\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0027 - mae: 0.0413 - mape: 5.5015\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0029 - mae: 0.0421 - mape: 5.6189\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0424 - mse: 0.0029 - mae: 0.0424 - mape: 5.6453\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0028 - mae: 0.0428 - mape: 5.6834\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5870\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0030 - mae: 0.0439 - mape: 5.8216\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0435 - mse: 0.0030 - mae: 0.0435 - mape: 5.7736\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0027 - mae: 0.0414 - mape: 5.5198\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0031 - mae: 0.0448 - mape: 5.9339\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5126\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6305\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0029 - mae: 0.0426 - mape: 5.6598\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0030 - mae: 0.0433 - mape: 5.7612\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0028 - mae: 0.0420 - mape: 5.5923\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5431\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0027 - mae: 0.0413 - mape: 5.5149\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5091\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5193\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5630\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5664\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0029 - mae: 0.0423 - mape: 5.6358\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4926\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0441 - mse: 0.0030 - mae: 0.0441 - mape: 5.8408\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.6132\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0029 - mae: 0.0431 - mape: 5.7236\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5700\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0029 - mae: 0.0424 - mape: 5.6568\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.6268\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0029 - mae: 0.0415 - mape: 5.5607\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0030 - mae: 0.0437 - mape: 5.7966\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0031 - mae: 0.0443 - mape: 5.8780\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0029 - mae: 0.0426 - mape: 5.6781\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5438\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5931\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5856\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0029 - mae: 0.0421 - mape: 5.6169\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.6037\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0029 - mae: 0.0428 - mape: 5.7084\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0029 - mae: 0.0430 - mape: 5.7173\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5239\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0027 - mae: 0.0414 - mape: 5.5139\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0433 - mse: 0.0029 - mae: 0.0433 - mape: 5.7407\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0029 - mae: 0.0427 - mape: 5.6728\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0029 - mae: 0.0427 - mape: 5.6881\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0030 - mae: 0.0439 - mape: 5.8016\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6339\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0029 - mae: 0.0429 - mape: 5.7073\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5716\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0446 - mse: 0.0031 - mae: 0.0446 - mape: 5.9314\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4866\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5597\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0027 - mae: 0.0412 - mape: 5.4974\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0027 - mae: 0.0411 - mape: 5.4853\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5639\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0029 - mae: 0.0431 - mape: 5.7084\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0028 - mae: 0.0408 - mape: 5.4682\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5020\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0028 - mae: 0.0410 - mape: 5.4897\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5974\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5296\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5869\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5375\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.5040\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0029 - mae: 0.0426 - mape: 5.6722\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5902\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5944\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0028 - mae: 0.0424 - mape: 5.6457\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.5022\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5916\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.5915\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0424 - mse: 0.0028 - mae: 0.0424 - mape: 5.6457\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5475\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0030 - mae: 0.0448 - mape: 5.9413\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0030 - mae: 0.0428 - mape: 5.7242\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0031 - mae: 0.0439 - mape: 5.8512\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5162\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5765\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0030 - mae: 0.0431 - mape: 5.7012\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.6093\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5919\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5341\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5400\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0029 - mae: 0.0417 - mape: 5.5818\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5070\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0031 - mae: 0.0442 - mape: 5.8486\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0029 - mae: 0.0427 - mape: 5.6935\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0027 - mae: 0.0411 - mape: 5.5016\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5278\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0029 - mae: 0.0419 - mape: 5.6051\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5298\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5630\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5193\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0029 - mae: 0.0436 - mape: 5.7639\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0029 - mae: 0.0425 - mape: 5.6607\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.6151\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6320\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0029 - mae: 0.0434 - mape: 5.7601\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5008\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6172\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0409 - mse: 0.0028 - mae: 0.0409 - mape: 5.4811\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0029 - mae: 0.0418 - mape: 5.5840\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5904\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.5930\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5336\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5237\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5369\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0029 - mae: 0.0428 - mape: 5.6827\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0029 - mae: 0.0422 - mape: 5.6365\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.5062\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0029 - mae: 0.0419 - mape: 5.5951\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0030 - mae: 0.0431 - mape: 5.7462\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0030 - mae: 0.0441 - mape: 5.8578\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0030 - mae: 0.0439 - mape: 5.8336\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0027 - mae: 0.0420 - mape: 5.5856\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0032 - mae: 0.0447 - mape: 5.9265\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5612\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0029 - mae: 0.0423 - mape: 5.6438\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0029 - mae: 0.0426 - mape: 5.6888\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.5917\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5737\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5559\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0028 - mae: 0.0412 - mape: 5.5170\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5525\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.6224\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5430\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5487\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5509\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5552\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5612\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0029 - mae: 0.0422 - mape: 5.6082\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0027 - mae: 0.0415 - mape: 5.5363\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.5963\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0029 - mae: 0.0418 - mape: 5.5905\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5831\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5366\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0028 - mae: 0.0422 - mape: 5.6167\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0028 - mae: 0.0410 - mape: 5.4817\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0029 - mae: 0.0422 - mape: 5.6405\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5511\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0029 - mae: 0.0416 - mape: 5.5575\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4897\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0027 - mae: 0.0414 - mape: 5.5146\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0029 - mae: 0.0422 - mape: 5.6307\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5781\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6363\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0028 - mae: 0.0419 - mape: 5.5761\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0031 - mae: 0.0436 - mape: 5.8004\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5508\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5623\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4969\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0027 - mae: 0.0420 - mape: 5.5799\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6271\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5374\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0029 - mae: 0.0416 - mape: 5.5699\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5605\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 5.5403\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5720\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 5.5237\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5325\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5460\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5752\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5418\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.4832\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0030 - mae: 0.0428 - mape: 5.7077\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0029 - mae: 0.0430 - mape: 5.7139\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0028 - mae: 0.0420 - mape: 5.6088\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0028 - mae: 0.0420 - mape: 5.5872\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0028 - mae: 0.0411 - mape: 5.5009\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0029 - mae: 0.0431 - mape: 5.7408\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0028 - mae: 0.0416 - mape: 5.5555\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 5.5661\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0028 - mae: 0.0425 - mape: 5.6484\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 5.5291\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0028 - mae: 0.0421 - mape: 5.6142\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 5.6288\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0027 - mae: 0.0420 - mape: 5.5824\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0029 - mae: 0.0423 - mape: 5.6403\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0029 - mae: 0.0432 - mape: 5.7229\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0028 - mae: 0.0418 - mape: 5.5894\n",
      "313/313 [==============================] - 0s 837us/step\n",
      "313/313 [==============================] - 0s 871us/step\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Silly Coercsion for ICML rebuttle deadline timeline\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    Iteration_Length = len(X_parts_list) -1\n",
    "else:\n",
    "    Iteration_Length = len(X_parts_list)\n",
    "\n",
    "    \n",
    "# Train each part!\n",
    "for current_part in range(Iteration_Length):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.6437\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.7652\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.7568\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.7530\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.7564\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.7584\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.7530\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.7580\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.7558\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.7590\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.7636\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.7658\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.7702\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.7742\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.7726\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.7746\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.7748\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.7816\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2351 - accuracy: 0.7812\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2335 - accuracy: 0.7870\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.7878\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.7868\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2293 - accuracy: 0.7976\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2276 - accuracy: 0.7910\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.7980\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2251 - accuracy: 0.7924\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.7984\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.7980\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.8056\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.8046\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2162 - accuracy: 0.8042\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.8116\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.8160\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.8134\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2089 - accuracy: 0.8200\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.8184\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.8194\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2050 - accuracy: 0.8256\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.8266\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.8306\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.8316\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.8330\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.8472\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.8478\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.8454\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.8532\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1933 - accuracy: 0.8562\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.8596\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.8562\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.8668\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.8698\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.8720\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.8756\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.8658\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.8706\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.8748\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.8792\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.8822\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.8862\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.8850\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.8838\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.8930\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.8894\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.8928\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.8900\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.8906\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.8904\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.8948\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1730 - accuracy: 0.8962\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.8976\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.8960\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.8948\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.8956\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.8978\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.8998\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9014\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9004\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1678 - accuracy: 0.8982\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.8974\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9022\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9020\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9036\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1645 - accuracy: 0.9056\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.8984\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9078\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9028\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9024\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9026\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9008\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9078\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9070\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9070\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1589 - accuracy: 0.9052\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1591 - accuracy: 0.9110\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9068\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9096\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9074\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1567 - accuracy: 0.9108\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9116\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9136\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9088\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9128\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9100\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1545 - accuracy: 0.9062\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9050\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9122\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9108\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1512 - accuracy: 0.9144\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9146\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9120\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1495 - accuracy: 0.9148\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9156\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1484 - accuracy: 0.9136\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9178\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9118\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9172\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9112\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9154\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9180\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1445 - accuracy: 0.9160\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9142\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9162\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9156\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9134\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9158\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9138\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1414 - accuracy: 0.9140\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1412 - accuracy: 0.9126\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.9156\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9140\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.9120\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9170\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9174\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9184\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9198\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1353 - accuracy: 0.9172\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1358 - accuracy: 0.9168\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9182\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9152\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9208\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9200\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1336 - accuracy: 0.9140\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9198\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.9162\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9218\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1284 - accuracy: 0.9216\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9204\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1278 - accuracy: 0.9188\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9178\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1265 - accuracy: 0.9218\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9126\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9186\n",
      "Epoch 153/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9210\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9168\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9184\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9174\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9194\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9210\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9182\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1204 - accuracy: 0.9202\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1217 - accuracy: 0.9184\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9204\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9234\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9226\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1176 - accuracy: 0.9224\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9222\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1173 - accuracy: 0.9206\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9220\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9252\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.9200\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9212\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1159 - accuracy: 0.9184\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9196\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9198\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9226\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9212\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9230\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9214\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9226\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1099 - accuracy: 0.9246\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9222\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9236\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9212\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9206\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9204\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9218\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9234\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9232\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9216: 0s - loss: 0.1089 - accuracy: 0.\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9206\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9230\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9228\n",
      "Epoch 193/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.9246\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9232\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.9226\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1057 - accuracy: 0.9220\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.9256\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9224\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.9212\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9282\n",
      "WARNING:tensorflow:From /scratch/users/kratsioa/.local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "313/313 [==============================] - 0s 941us/step\n",
      "313/313 [==============================] - 0s 853us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.025058   0.025058\n",
      "MSE    0.002315   0.002315\n",
      "MAPE  20.738972  20.738972\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       L-time     P-time  N_params_expt   AIC-like    Eff\n",
      "0  200.655593  77.722954          42270  84547.373  0.267\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=2020,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.5, 1.0, 10, 100, 1000],\n",
       "                                        'penalty': ['none', 'l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2020, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.051364   0.051364\n",
      "MSE    0.008650   0.008650\n",
      "MAPE  38.331292  38.331292\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Performance\n",
      "          train       test\n",
      "MAE    0.061911   0.061911\n",
      "MSE    0.006215   0.006215\n",
      "MAPE  87.408119  87.408119\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Partition: Generated!...Feature Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1000 - mse: 0.0164 - mae: 0.1000 - mape: 193.6359\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0757 - mse: 0.0087 - mae: 0.0757 - mape: 138.4070\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0081 - mae: 0.0473 - mape: 30.6346\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0082 - mae: 0.0452 - mape: 23.3192\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0082 - mae: 0.0478 - mape: 26.2319\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0448 - mse: 0.0082 - mae: 0.0448 - mape: 21.5138\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0466 - mse: 0.0082 - mae: 0.0466 - mape: 23.5089\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0082 - mae: 0.0438 - mape: 21.4933\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0457 - mse: 0.0081 - mae: 0.0457 - mape: 20.9405\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0449 - mse: 0.0081 - mae: 0.0449 - mape: 21.4485\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0447 - mse: 0.0082 - mae: 0.0447 - mape: 21.5259\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0082 - mae: 0.0437 - mape: 21.0560\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0458 - mse: 0.0082 - mae: 0.0458 - mape: 22.9300\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0082 - mae: 0.0438 - mape: 20.4404\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0450 - mse: 0.0082 - mae: 0.0450 - mape: 22.9747\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0445 - mse: 0.0081 - mae: 0.0445 - mape: 25.3690\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0081 - mae: 0.0438 - mape: 20.2987\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0447 - mse: 0.0082 - mae: 0.0447 - mape: 20.3176\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0437 - mse: 0.0082 - mae: 0.0437 - mape: 21.9053\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 21.6693\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0437 - mse: 0.0081 - mae: 0.0437 - mape: 21.7344\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0446 - mse: 0.0082 - mae: 0.0446 - mape: 21.7627\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0439 - mse: 0.0082 - mae: 0.0439 - mape: 21.7409\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0436 - mse: 0.0082 - mae: 0.0436 - mape: 20.4950\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0443 - mse: 0.0081 - mae: 0.0443 - mape: 22.2139\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0447 - mse: 0.0081 - mae: 0.0447 - mape: 20.5844\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.5159\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0437 - mse: 0.0082 - mae: 0.0437 - mape: 20.2716\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0082 - mae: 0.0438 - mape: 20.5851\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0437 - mse: 0.0081 - mae: 0.0437 - mape: 20.0357\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0081 - mae: 0.0440 - mape: 21.7117\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.3294\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0082 - mae: 0.0446 - mape: 20.8744\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0082 - mae: 0.0442 - mape: 22.6897\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0433 - mse: 0.0082 - mae: 0.0433 - mape: 19.6033\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0441 - mse: 0.0082 - mae: 0.0441 - mape: 20.0849\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0441 - mse: 0.0081 - mae: 0.0441 - mape: 20.3071\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0441 - mse: 0.0081 - mae: 0.0441 - mape: 19.9305\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 19.7948\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 18.6351\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0442 - mse: 0.0081 - mae: 0.0442 - mape: 21.0928\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 21.6016\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 20.5601\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0442 - mse: 0.0082 - mae: 0.0442 - mape: 20.4265\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0439 - mse: 0.0082 - mae: 0.0439 - mape: 21.9530\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.3529\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0439 - mse: 0.0082 - mae: 0.0439 - mape: 21.5001\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 21.8434\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 19.7300\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 21.4257\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0440 - mse: 0.0082 - mae: 0.0440 - mape: 21.0087\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 18.9865\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.2729\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 20.2287\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 19.0403\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0447 - mse: 0.0081 - mae: 0.0447 - mape: 21.5812\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 20.0376\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.5001\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0436 - mse: 0.0082 - mae: 0.0436 - mape: 21.6236\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.7743\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.6425\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 20.1472\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.6252\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.6433\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 20.1829\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.2320\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.9494\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 19.4310\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.6416\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.7209\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 20.3930\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.2295\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 20.2082\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 20.0208\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 22.1187\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0082 - mae: 0.0438 - mape: 21.2355\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 19.0202\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 19.3395\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0433 - mse: 0.0082 - mae: 0.0433 - mape: 21.5253\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 20.1330\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 18.4155\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.1641\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 19.4293\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.9312\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.6960\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 19.3484\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 18.5848\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 19.3263\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 19.1132\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 19.2368\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 20.8757\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.7688\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 21.0567\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 20.4085\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 19.8644\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.4952\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 19.3156\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.8174\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.7849\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 20.7160\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.5671\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.3721\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0436 - mse: 0.0082 - mae: 0.0436 - mape: 19.5448\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.0425\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 20.7889\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0436 - mse: 0.0082 - mae: 0.0436 - mape: 18.6288\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0082 - mae: 0.0435 - mape: 18.2394\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 18.7541\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 19.1816\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 18.9885\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.6795\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0436 - mse: 0.0082 - mae: 0.0436 - mape: 18.7625\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.2548\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 19.6793\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.9606\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 17.8557\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.3273\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.0832\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.0993\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 18.3031\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 17.9641\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.3651\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.5581\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.8862\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.8677\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 18.4453\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.9696\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0083 - mae: 0.0425 - mape: 18.2710\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 19.0111\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.2430\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.8308\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.7642\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.2547\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.3229\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.8370\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 17.9881\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 19.6766\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.0735\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 17.9426\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 19.0045\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.5591\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.3558\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0082 - mae: 0.0434 - mape: 17.7817\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 17.8294\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 17.7563\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.9666\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.1066\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 19.0813\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 19.0434\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.3924\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 17.4920\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 17.4792\n",
      "Epoch 153/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 17.5599\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 19.8768\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 19.0022\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.3256\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.4576\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.0479\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.6343\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.5553\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 18.1440\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.2017\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.6718\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 20.2110\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.0667\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 17.9866\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 19.4326\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0422 - mse: 0.0082 - mae: 0.0422 - mape: 17.7387\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.7489\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 18.4536\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 17.7884\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0428 - mse: 0.0082 - mae: 0.0428 - mape: 18.0159\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 17.9193\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 18.7101\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 18.0497\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 17.9931\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 17.9568\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0082 - mae: 0.0432 - mape: 18.6104\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 17.6068\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 20.0587\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0082 - mae: 0.0430 - mape: 19.2369\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.9645\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0082 - mae: 0.0425 - mape: 18.7497\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 18.3513\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 17.9851\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - mse: 0.0082 - mae: 0.0426 - mape: 17.5978\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.7158\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.9939\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 18.0094\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0422 - mse: 0.0082 - mae: 0.0422 - mape: 17.8889\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0431 - mse: 0.0082 - mae: 0.0431 - mape: 19.1262\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 17.6731\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 18.0428\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.2491\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 19.2168\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0424 - mse: 0.0082 - mae: 0.0424 - mape: 20.3085\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0082 - mae: 0.0427 - mape: 18.5996\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0429 - mse: 0.0082 - mae: 0.0429 - mape: 18.6645\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0422 - mse: 0.0082 - mae: 0.0422 - mape: 17.6465\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0423 - mse: 0.0082 - mae: 0.0423 - mape: 17.3606\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vanilla ffNNs\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Vanilla ffNNs\n",
      "           train        test\n",
      "MAE     0.043142    0.043142\n",
      "MSE     0.008482    0.008482\n",
      "MAPE  685.720393  685.720393\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preliminary table: Required Training Times\n",
      "   Architope  Architope-logistic Vanilla ffNN  Bagged ffNN\n",
      "0    378.703             206.977      193.874      201.296\n",
      "0    255.770              84.044            -       78.363\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 70 parameters.\n",
      "          train       test\n",
      "MAE    0.105796   0.105796\n",
      "MSE    0.014667   0.014667\n",
      "MAPE  37.346306  37.346306\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n",
      "                   In-Line (L-Time) Parallel (P-Time)\n",
      "Vanilla ffNN                193.874                 -\n",
      "Grad.Bstd Rand.F              0.314                 -\n",
      "Bagged ffNN                 201.296            78.363\n",
      "Architope-logistic          206.977            84.044\n",
      "Architope                   378.703            255.77\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       MSE        MAPE\n",
      "ffNN      0.043142  0.008482  685.720393\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061911  0.006215   87.408119\n",
      "ffNN-lgt  0.051364  0.008650   38.331292\n",
      "tope      0.025058  0.002315   20.738972\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like    Eff\n",
      "Vanilla ffNN                193.874                 -  40801  81608.287  0.458\n",
      "Grad.Bstd Rand.F              0.314                 -     70    144.492  0.449\n",
      "Bagged ffNN                 201.296            78.363  31571  63147.564  0.641\n",
      "Architope-logistic          206.977            84.044  31574  63153.938  0.532\n",
      "Architope                   378.703            255.77  42270  84547.373  0.267\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "#-------------------#\n",
      " PERFORMANCE SUMMARY:\n",
      "#-------------------#\n",
      " \n",
      " \n",
      "#===================#\n",
      " Individual Metrics: \n",
      "#======-============#\n",
      " \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Architope (Full)\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.025058   0.025058\n",
      "MSE    0.002315   0.002315\n",
      "MAPE  20.738972  20.738972\n",
      "----------------------------------------\n",
      "Architope - Naive Logistic\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.051364   0.051364\n",
      "MSE    0.008650   0.008650\n",
      "MAPE  38.331292  38.331292\n",
      "----------------------------------------\n",
      "Vanilla ffNN\n",
      "----------------------------------------\n",
      "           train        test\n",
      "MAE     0.043142    0.043142\n",
      "MSE     0.008482    0.008482\n",
      "MAPE  685.720393  685.720393\n",
      "----------------------------------------\n",
      "Bagged ffNN\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.061911   0.061911\n",
      "MSE    0.006215   0.006215\n",
      "MAPE  87.408119  87.408119\n",
      "----------------------------------------\n",
      "Gradient Boosted Random Forest Regressor\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.105796   0.105796\n",
      "MSE    0.014667   0.014667\n",
      "MAPE  37.346306  37.346306\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#==================#\n",
      " Overview  Metrics : \n",
      "#==================#\n",
      " \n",
      "----------------------------------------\n",
      "Training Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE        MAPE\n",
      "ffNN      0.043142  0.008482  685.720393\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061911  0.006215   87.408119\n",
      "ffNN-lgt  0.051364  0.008650   38.331292\n",
      "tope      0.025058  0.002315   20.738972\n",
      "----------------------------------------\n",
      "Testing Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE        MAPE\n",
      "ffNN      0.043142  0.008482  685.720393\n",
      "GBRF      0.105796  0.014667   37.346306\n",
      "ffNN-bag  0.061911  0.006215   87.408119\n",
      "ffNN-lgt  0.051364  0.008650   38.331292\n",
      "tope      0.025058  0.002315   20.738972\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#====================#\n",
      " Efficiency Metrics: \n",
      "#====================#\n",
      " \n",
      "Model Training Times:\n",
      "----------------------------------------\n",
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like    Eff\n",
      "Vanilla ffNN                193.874                 -  40801  81608.287  0.458\n",
      "Grad.Bstd Rand.F              0.314                 -     70    144.492  0.449\n",
      "Bagged ffNN                 201.296            78.363  31571  63147.564  0.641\n",
      "Architope-logistic          206.977            84.044  31574  63153.938  0.532\n",
      "Architope                   378.703            255.77  42270  84547.373  0.267\n",
      " \n",
      " \n",
      "😃😃 Have a great day!! 😃😃 \n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('😃😃 Have a great day!! 😃😃 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "plt.scatter(x_1,y_1,color='orange',label=r'$f_1(x)$',linestyle='--')\n",
    "plt.scatter(x_2,y_2,color='blue',label=r'$f_2(x)$',linestyle='--')\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'gray',linestyle=\"--\",  label='ffNN')\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'black',linestyle=\"--\",  label='tope')\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Model Predictions\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/DEMO.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
