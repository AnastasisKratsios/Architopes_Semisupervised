{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 0.95\n",
    "min_height = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "#================================================#\n",
      " Training Datasize: 569 and test datasize: 30.  \n",
      "#================================================#\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "exec(open('Financial_Data_Preprocessor.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8488576449912126\n",
      "0.8471001757469244\n",
      "0.680140597539543\n",
      "0.6274165202108963\n",
      "0.5992970123022847\n",
      "0.5553602811950791\n",
      "0.4973637961335677\n",
      "0.43409490333919154\n",
      "0.3602811950790861\n",
      "0.3427065026362039\n",
      "0.3374340949033392\n",
      "0.3233743409490334\n",
      "0.30579964850615116\n",
      "0.27943760984182775\n",
      "0.26362038664323373\n",
      "0.2565905096660808\n",
      "0.23550087873462214\n",
      "0.23374340949033393\n",
      "0.23198594024604569\n",
      "0.21616871704745166\n",
      "0.2038664323374341\n",
      "0.18980667838312829\n",
      "0.18453427065026362\n",
      "0.1704745166959578\n",
      "0.15992970123022848\n",
      "0.15114235500878734\n",
      "0.14938488576449913\n",
      "0.14586994727592267\n",
      "0.140597539543058\n",
      "0.13532513181019332\n",
      "0.1335676625659051\n",
      "0.13181019332161686\n",
      "0.1265377855887522\n",
      "0.12478031634446397\n",
      "0.12302284710017575\n",
      "0.12126537785588752\n",
      "0.11775043936731107\n",
      "0.11247803163444639\n",
      "0.10720562390158173\n",
      "0.10193321616871705\n",
      "0.09666080843585237\n",
      "0.09490333919156414\n",
      "0.09314586994727592\n",
      "0.0913884007029877\n",
      "0.08963093145869948\n",
      "0.08787346221441125\n",
      "0.0843585237258348\n",
      "0.08084358523725835\n",
      "0.07381370826010544\n",
      "0.07205623901581722\n",
      "0.0632688927943761\n",
      "0.05975395430579965\n",
      "0.05799648506151142\n",
      "0.056239015817223195\n",
      "0.054481546572934976\n",
      "0.05272407732864675\n",
      "0.050966608084358524\n",
      "0.0492091388400703\n",
      "0.04745166959578207\n",
      "0.043936731107205626\n",
      "0.0421792618629174\n",
      "0.040421792618629174\n",
      "0.03866432337434095\n",
      "0.03690685413005272\n",
      "0.0351493848857645\n",
      "0.033391915641476276\n",
      "0.03163444639718805\n",
      "0.029876977152899824\n",
      "0.028119507908611598\n",
      "0.026362038664323375\n",
      "0.02460456942003515\n",
      "0.0210896309314587\n",
      "0.019332161687170474\n",
      "0.01757469244288225\n",
      "0.015817223198594025\n",
      "0.014059753954305799\n",
      "0.012302284710017574\n",
      "0.01054481546572935\n",
      "0.008787346221441126\n",
      "0.007029876977152899\n",
      "0.005272407732864675\n",
      "0.0035149384885764497\n",
      "0.0017574692442882249\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 1.\n",
      "0.81195079086116\n",
      "0.8101933216168717\n",
      "0.6379613356766256\n",
      "0.5852372583479789\n",
      "0.5272407732864675\n",
      "0.46572934973637964\n",
      "0.3936731107205624\n",
      "0.3233743409490334\n",
      "0.30404217926186294\n",
      "0.29876977152899825\n",
      "0.27768014059753954\n",
      "0.2530755711775044\n",
      "0.22671353251318102\n",
      "0.21616871704745166\n",
      "0.19332161687170474\n",
      "0.19156414762741653\n",
      "0.18629173989455183\n",
      "0.1757469244288225\n",
      "0.17223198594024605\n",
      "0.15817223198594024\n",
      "0.1546572934973638\n",
      "0.14762741652021089\n",
      "0.13884007029876977\n",
      "0.1335676625659051\n",
      "0.1282952548330404\n",
      "0.12302284710017575\n",
      "0.12126537785588752\n",
      "0.11599297012302284\n",
      "0.11423550087873462\n",
      "0.11247803163444639\n",
      "0.11072056239015818\n",
      "0.10720562390158173\n",
      "0.10193321616871705\n",
      "0.09666080843585237\n",
      "0.0913884007029877\n",
      "0.08787346221441125\n",
      "0.08611599297012303\n",
      "0.0843585237258348\n",
      "0.08260105448154657\n",
      "0.07908611599297012\n",
      "0.07381370826010544\n",
      "0.07205623901581722\n",
      "0.06502636203866433\n",
      "0.061511423550087874\n",
      "0.05799648506151142\n",
      "0.056239015817223195\n",
      "0.054481546572934976\n",
      "0.050966608084358524\n",
      "0.0492091388400703\n",
      "0.04745166959578207\n",
      "0.04569420035149385\n",
      "0.043936731107205626\n",
      "0.040421792618629174\n",
      "0.03866432337434095\n",
      "0.03690685413005272\n",
      "0.0351493848857645\n",
      "0.033391915641476276\n",
      "0.03163444639718805\n",
      "0.029876977152899824\n",
      "0.028119507908611598\n",
      "0.026362038664323375\n",
      "0.02460456942003515\n",
      "0.022847100175746926\n",
      "0.0210896309314587\n",
      "0.01757469244288225\n",
      "0.015817223198594025\n",
      "0.014059753954305799\n",
      "0.012302284710017574\n",
      "0.01054481546572935\n",
      "0.008787346221441126\n",
      "0.007029876977152899\n",
      "0.005272407732864675\n",
      "0.0035149384885764497\n",
      "0.0017574692442882249\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 2.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = 100)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 2.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 2 parts.\n",
      "Heights to iterate over: [100]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5275 - mse: 0.4832 - mae: 0.5275 - mape: 106.0957\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5107 - mse: 0.4577 - mae: 0.5107 - mape: 106.7326\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4990 - mse: 0.4415 - mae: 0.4990 - mape: 124.2955\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4861 - mse: 0.4238 - mae: 0.4861 - mape: 128.1505\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4816 - mse: 0.4141 - mae: 0.4816 - mape: 131.8015\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4775 - mse: 0.4074 - mae: 0.4775 - mape: 130.6390\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4745 - mse: 0.4035 - mae: 0.4745 - mape: 127.0497\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4717 - mse: 0.3994 - mae: 0.4717 - mape: 124.8295\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4706 - mse: 0.3972 - mae: 0.4706 - mape: 129.8875\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4680 - mse: 0.3927 - mae: 0.4680 - mape: 133.9772\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4662 - mse: 0.3887 - mae: 0.4662 - mape: 137.5027\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4648 - mse: 0.3866 - mae: 0.4648 - mape: 138.7927\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4631 - mse: 0.3845 - mae: 0.4631 - mape: 140.1259\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4624 - mse: 0.3819 - mae: 0.4624 - mape: 142.8466\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4601 - mse: 0.3788 - mae: 0.4601 - mape: 143.8226\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3776 - mae: 0.4588 - mape: 143.4020\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4570 - mse: 0.3751 - mae: 0.4570 - mape: 144.5367\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4558 - mse: 0.3729 - mae: 0.4558 - mape: 147.2957\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4543 - mse: 0.3717 - mae: 0.4543 - mape: 145.7769\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4530 - mse: 0.3703 - mae: 0.4530 - mape: 146.4568\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4505 - mse: 0.3673 - mae: 0.4505 - mape: 147.0406\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4491 - mse: 0.3660 - mae: 0.4491 - mape: 149.3991\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4473 - mse: 0.3634 - mae: 0.4473 - mape: 151.7787\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4461 - mse: 0.3620 - mae: 0.4461 - mape: 152.5490\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4444 - mse: 0.3600 - mae: 0.4444 - mape: 155.2392\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4431 - mse: 0.3583 - mae: 0.4431 - mape: 159.6845\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4414 - mse: 0.3568 - mae: 0.4414 - mape: 160.1257\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4404 - mse: 0.3549 - mae: 0.4404 - mape: 163.2776\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4397 - mse: 0.3546 - mae: 0.4397 - mape: 161.1844\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4385 - mse: 0.3525 - mae: 0.4385 - mape: 160.9169\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4385 - mse: 0.3527 - mae: 0.4385 - mape: 164.5435\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4369 - mse: 0.3513 - mae: 0.4369 - mape: 166.2202\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4361 - mse: 0.3498 - mae: 0.4361 - mape: 168.4663\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4350 - mse: 0.3489 - mae: 0.4350 - mape: 170.9608\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4359 - mse: 0.3493 - mae: 0.4359 - mape: 167.8039\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4351 - mse: 0.3485 - mae: 0.4351 - mape: 169.6117\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4332 - mse: 0.3473 - mae: 0.4332 - mape: 168.9700\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4321 - mse: 0.3465 - mae: 0.4321 - mape: 167.1201\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4313 - mse: 0.3460 - mae: 0.4313 - mape: 167.5942\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4312 - mse: 0.3459 - mae: 0.4312 - mape: 169.4926\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4304 - mse: 0.3462 - mae: 0.4304 - mape: 166.4697\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4304 - mse: 0.3467 - mae: 0.4304 - mape: 164.1818\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4290 - mse: 0.3463 - mae: 0.4290 - mape: 163.1608\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4278 - mse: 0.3446 - mae: 0.4278 - mape: 167.8928\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4278 - mse: 0.3456 - mae: 0.4278 - mape: 165.1241\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4260 - mse: 0.3435 - mae: 0.4260 - mape: 164.2635\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4254 - mse: 0.3434 - mae: 0.4254 - mape: 168.9904\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4253 - mse: 0.3432 - mae: 0.4253 - mape: 170.6505\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4238 - mse: 0.3417 - mae: 0.4238 - mape: 169.3808\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4235 - mse: 0.3415 - mae: 0.4235 - mape: 166.5399\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4231 - mse: 0.3420 - mae: 0.4231 - mape: 164.0639\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4217 - mse: 0.3408 - mae: 0.4217 - mape: 163.3528\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4211 - mse: 0.3410 - mae: 0.4211 - mape: 166.0545\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4195 - mse: 0.3396 - mae: 0.4195 - mape: 165.7998\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4200 - mse: 0.3395 - mae: 0.4200 - mape: 160.4625\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4202 - mse: 0.3393 - mae: 0.4202 - mape: 165.3867\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4191 - mse: 0.3389 - mae: 0.4191 - mape: 166.5239\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4195 - mse: 0.3390 - mae: 0.4195 - mape: 165.1875\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4180 - mse: 0.3379 - mae: 0.4180 - mape: 165.3356\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4168 - mse: 0.3370 - mae: 0.4168 - mape: 162.6159\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4164 - mse: 0.3380 - mae: 0.4164 - mape: 155.4229\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4156 - mse: 0.3374 - mae: 0.4156 - mape: 154.9820\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4141 - mse: 0.3367 - mae: 0.4141 - mape: 155.8255\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4141 - mse: 0.3362 - mae: 0.4141 - mape: 157.3849\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4140 - mse: 0.3358 - mae: 0.4140 - mape: 158.6628\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4131 - mse: 0.3348 - mae: 0.4131 - mape: 156.1867\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123 - mse: 0.3335 - mae: 0.4123 - mape: 155.8302\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4116 - mse: 0.3326 - mae: 0.4116 - mape: 155.0137\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4115 - mse: 0.3325 - mae: 0.4115 - mape: 156.3826\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4111 - mse: 0.3326 - mae: 0.4111 - mape: 155.1869\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4106 - mse: 0.3323 - mae: 0.4106 - mape: 153.6581\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4095 - mse: 0.3314 - mae: 0.4095 - mape: 153.6680\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4095 - mse: 0.3311 - mae: 0.4095 - mape: 152.5810\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4089 - mse: 0.3308 - mae: 0.4089 - mape: 153.0632\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4090 - mse: 0.3304 - mae: 0.4090 - mape: 152.7749\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4093 - mse: 0.3312 - mae: 0.4093 - mape: 152.6661\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4076 - mse: 0.3295 - mae: 0.4076 - mape: 152.1735\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4085 - mse: 0.3295 - mae: 0.4085 - mape: 151.6024\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4075 - mse: 0.3289 - mae: 0.4075 - mape: 153.4314\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4066 - mse: 0.3281 - mae: 0.4066 - mape: 151.6852\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4060 - mse: 0.3280 - mae: 0.4060 - mape: 150.4578\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4055 - mse: 0.3277 - mae: 0.4055 - mape: 149.6552\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4056 - mse: 0.3273 - mae: 0.4056 - mape: 149.6977\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4054 - mse: 0.3272 - mae: 0.4054 - mape: 150.7225\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4044 - mse: 0.3263 - mae: 0.4044 - mape: 150.0525\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4048 - mse: 0.3263 - mae: 0.4048 - mape: 150.1214\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4036 - mse: 0.3257 - mae: 0.4036 - mape: 148.1933\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4050 - mse: 0.3254 - mae: 0.4050 - mape: 153.3540\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4044 - mse: 0.3251 - mae: 0.4044 - mape: 150.2450\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4037 - mse: 0.3262 - mae: 0.4037 - mape: 148.0401\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4033 - mse: 0.3232 - mae: 0.4033 - mape: 154.3432\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4027 - mse: 0.3227 - mae: 0.4027 - mape: 150.0881\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4013 - mse: 0.3226 - mae: 0.4013 - mape: 151.9438\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4024 - mse: 0.3224 - mae: 0.4024 - mape: 153.4056\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4022 - mse: 0.3219 - mae: 0.4022 - mape: 154.3389\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4016 - mse: 0.3215 - mae: 0.4016 - mape: 155.8920\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3995 - mse: 0.3206 - mae: 0.3995 - mape: 150.0729\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4011 - mse: 0.3207 - mae: 0.4011 - mape: 147.9182\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3999 - mse: 0.3199 - mae: 0.3999 - mape: 150.8857\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3990 - mse: 0.3199 - mae: 0.3990 - mape: 150.1698\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Status: Current part: 1 out of : 2 parts.\n",
      "Heights to iterate over: [100]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8366 - mse: 1.7447 - mae: 0.8366 - mape: 53348.6875\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6640 - mse: 0.9713 - mae: 0.6640 - mape: 746550.3125\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5917 - mse: 0.7407 - mae: 0.5917 - mape: 1289923.8750\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5652 - mse: 0.6724 - mae: 0.5652 - mape: 1579528.6250\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5535 - mse: 0.6507 - mae: 0.5535 - mape: 1535288.8750\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5478 - mse: 0.6259 - mae: 0.5478 - mape: 1655690.6250\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5451 - mse: 0.6175 - mae: 0.5451 - mape: 1553847.2500\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5383 - mse: 0.6292 - mae: 0.5383 - mape: 1331761.2500\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5236 - mse: 0.5797 - mae: 0.5236 - mape: 1470510.2500\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5160 - mse: 0.5808 - mae: 0.5160 - mape: 1399156.6250\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5109 - mse: 0.5647 - mae: 0.5109 - mape: 1405267.2500\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5163 - mse: 0.5711 - mae: 0.5163 - mape: 1485354.0000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5123 - mse: 0.5670 - mae: 0.5123 - mape: 1506081.3750\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4996 - mse: 0.5516 - mae: 0.4996 - mape: 1490344.3750\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4957 - mse: 0.5228 - mae: 0.4957 - mape: 1542737.3750\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4950 - mse: 0.5339 - mae: 0.4950 - mape: 1418943.1250\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4885 - mse: 0.4992 - mae: 0.4885 - mape: 1549317.0000\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4952 - mse: 0.5208 - mae: 0.4952 - mape: 1524401.8750\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4903 - mse: 0.5109 - mae: 0.4903 - mape: 1722067.3750\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4778 - mse: 0.4927 - mae: 0.4778 - mape: 1506949.2500\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4808 - mse: 0.5083 - mae: 0.4808 - mape: 1371807.8750\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4822 - mse: 0.4969 - mae: 0.4822 - mape: 1640392.1250\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4770 - mse: 0.4980 - mae: 0.4770 - mape: 1554823.8750\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4762 - mse: 0.4871 - mae: 0.4762 - mape: 1700389.8750\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4737 - mse: 0.4788 - mae: 0.4737 - mape: 1636516.3750\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4723 - mse: 0.4750 - mae: 0.4723 - mape: 1611002.3750\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4716 - mse: 0.4753 - mae: 0.4716 - mape: 1598339.5000\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4648 - mse: 0.4651 - mae: 0.4648 - mape: 1620921.1250\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4668 - mse: 0.4625 - mae: 0.4668 - mape: 1653123.2500\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4780 - mse: 0.4842 - mae: 0.4780 - mape: 1697415.1250\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4664 - mse: 0.4637 - mae: 0.4664 - mape: 1649729.1250\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4619 - mse: 0.4594 - mae: 0.4619 - mape: 1786397.1250\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4659 - mse: 0.4691 - mae: 0.4659 - mape: 1652098.2500\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4640 - mse: 0.4668 - mae: 0.4640 - mape: 1692393.5000\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4604 - mse: 0.4567 - mae: 0.4604 - mape: 1710257.2500\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4622 - mse: 0.4672 - mae: 0.4622 - mape: 1633526.7500\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4586 - mse: 0.4535 - mae: 0.4586 - mape: 1844803.2500\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4517 - mse: 0.4419 - mae: 0.4517 - mape: 1731987.7500\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4544 - mse: 0.4342 - mae: 0.4544 - mape: 1839000.0000\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4510 - mse: 0.4397 - mae: 0.4510 - mape: 1785344.1250\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4500 - mse: 0.4346 - mae: 0.4500 - mape: 1877968.3750\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4570 - mse: 0.4409 - mae: 0.4570 - mape: 1791001.3750\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4526 - mse: 0.4381 - mae: 0.4526 - mape: 1835118.7500\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4596 - mse: 0.4535 - mae: 0.4596 - mape: 1857489.6250\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4500 - mse: 0.4334 - mae: 0.4500 - mape: 1701533.5000\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4556 - mse: 0.4360 - mae: 0.4556 - mape: 1904235.1250\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4507 - mse: 0.4392 - mae: 0.4507 - mape: 1804393.5000\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4427 - mse: 0.4174 - mae: 0.4427 - mape: 1837095.5000\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4384 - mse: 0.4169 - mae: 0.4384 - mape: 1993678.2500\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4406 - mse: 0.4163 - mae: 0.4406 - mape: 1995634.2500\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4365 - mse: 0.4147 - mae: 0.4365 - mape: 1991326.7500\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4361 - mse: 0.4058 - mae: 0.4361 - mape: 1971897.3750\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4381 - mse: 0.4158 - mae: 0.4381 - mape: 1866098.7500\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4440 - mse: 0.4252 - mae: 0.4440 - mape: 1974219.5000\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4334 - mse: 0.4148 - mae: 0.4334 - mape: 2044418.3750\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4398 - mse: 0.4194 - mae: 0.4398 - mape: 1981865.3750\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4356 - mse: 0.4044 - mae: 0.4356 - mape: 2194293.7500\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4350 - mse: 0.4071 - mae: 0.4350 - mape: 2043895.3750\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4262 - mse: 0.4047 - mae: 0.4262 - mape: 2053078.0000\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4311 - mse: 0.4063 - mae: 0.4311 - mape: 2124202.0000\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4358 - mse: 0.4103 - mae: 0.4358 - mape: 1946560.1250\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4280 - mse: 0.4061 - mae: 0.4280 - mape: 2141372.2500\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4250 - mse: 0.4024 - mae: 0.4250 - mape: 2055467.3750\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4261 - mse: 0.4021 - mae: 0.4261 - mape: 1923013.1250\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4260 - mse: 0.4057 - mae: 0.4260 - mape: 2023108.0000\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4250 - mse: 0.4013 - mae: 0.4250 - mape: 2048055.0000\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4326 - mse: 0.4046 - mae: 0.4326 - mape: 2042896.5000\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4270 - mse: 0.4043 - mae: 0.4270 - mape: 2194088.0000\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4326 - mse: 0.4046 - mae: 0.4326 - mape: 1961918.6250\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4223 - mse: 0.3933 - mae: 0.4223 - mape: 2243348.5000\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4206 - mse: 0.3948 - mae: 0.4206 - mape: 2077721.6250\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4312 - mse: 0.4120 - mae: 0.4312 - mape: 2087967.5000\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4238 - mse: 0.4072 - mae: 0.4238 - mape: 2104337.7500\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4178 - mse: 0.3869 - mae: 0.4178 - mape: 2244634.5000\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4280 - mse: 0.4011 - mae: 0.4280 - mape: 1945539.7500\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4226 - mse: 0.4013 - mae: 0.4226 - mape: 2289770.2500\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4155 - mse: 0.3827 - mae: 0.4155 - mape: 2252431.5000\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4225 - mse: 0.3945 - mae: 0.4225 - mape: 2131551.5000\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4154 - mse: 0.3849 - mae: 0.4154 - mape: 2123407.2500\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4155 - mse: 0.3864 - mae: 0.4155 - mape: 2181182.0000\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4084 - mse: 0.3802 - mae: 0.4084 - mape: 2163762.7500\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4204 - mse: 0.3963 - mae: 0.4204 - mape: 2104782.2500\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4082 - mse: 0.3816 - mae: 0.4082 - mape: 2203924.0000\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4109 - mse: 0.3783 - mae: 0.4109 - mape: 2229058.0000\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4113 - mse: 0.3838 - mae: 0.4113 - mape: 2110107.0000\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4089 - mse: 0.3779 - mae: 0.4089 - mape: 2159685.5000\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4131 - mse: 0.3859 - mae: 0.4131 - mape: 2194021.5000\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4107 - mse: 0.3817 - mae: 0.4107 - mape: 2391670.2500\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4109 - mse: 0.3843 - mae: 0.4109 - mape: 2108579.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4104 - mse: 0.3813 - mae: 0.4104 - mape: 2354053.7500\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4226 - mse: 0.4009 - mae: 0.4226 - mape: 2083425.0000\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4110 - mse: 0.3801 - mae: 0.4110 - mape: 1999157.7500\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4125 - mse: 0.3794 - mae: 0.4125 - mape: 2258881.2500\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4036 - mse: 0.3741 - mae: 0.4036 - mape: 2359956.7500\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4036 - mse: 0.3748 - mae: 0.4036 - mape: 2298881.5000\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4042 - mse: 0.3775 - mae: 0.4042 - mape: 2239373.7500\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4015 - mse: 0.3709 - mae: 0.4015 - mape: 2130379.5000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4095 - mse: 0.3766 - mae: 0.4095 - mape: 2101056.5000\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4041 - mse: 0.3758 - mae: 0.4041 - mape: 2021906.1250\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4124 - mse: 0.3827 - mae: 0.4124 - mape: 2188134.0000\n",
      "36/36 [==============================] - 0s 578us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for current_part in range(len(X_parts_list)):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 977us/step - loss: 2.7509 - accuracy: 0.6397\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0832 - accuracy: 0.6485\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6064 - accuracy: 0.6432\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3024 - accuracy: 0.6520\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1208 - accuracy: 0.6309\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0080 - accuracy: 0.6221\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9321 - accuracy: 0.6274\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8675 - accuracy: 0.6221\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8104 - accuracy: 0.6292\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7666 - accuracy: 0.6450\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6503\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.6608\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6643\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.6626\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.6573\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6573\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6591\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6573\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6538\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6538\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6538\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6591\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6696\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6678\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6573\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.6626\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6626\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6626\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6626\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6626\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6608\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6591\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6678\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6626\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.6626\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6591\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.6591\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6608\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6608\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6608\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6626\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6626\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6661\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6626\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6573\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 929us/step - loss: 0.6239 - accuracy: 0.6661\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 924us/step - loss: 0.6213 - accuracy: 0.6643\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 916us/step - loss: 0.6215 - accuracy: 0.6608\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 928us/step - loss: 0.6198 - accuracy: 0.6608\n",
      "WARNING:tensorflow:From /scratch/users/kratsioa/.local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "36/36 [==============================] - 0s 522us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           train        test\n",
      "MAE     0.423321    1.897151\n",
      "MSE     0.383702    8.363579\n",
      "MAPE  822.262696  394.777291\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      L-time     P-time  N_params_expt   AIC-like     Eff\n",
      "0  19.428742  11.732281          22880  45758.719  19.044\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=2020,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.5, 1.0, 10, 100, 1000],\n",
       "                                        'penalty': ['none', 'l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2020, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           train        test\n",
      "MAE     0.420366    1.931274\n",
      "MSE     0.388265    8.007072\n",
      "MAPE  822.709545  720.852433\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Performance\n",
      "            train        test\n",
      "MAE      0.411647    2.014077\n",
      "MSE      0.363448    8.744918\n",
      "MAPE  1191.359813  502.712451\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Partition: Generated!...Feature Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8384 - mse: 1.4701 - mae: 0.8384 - mape: 168871.2500\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6099 - mse: 0.8257 - mae: 0.6099 - mape: 358539.1875\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5515 - mse: 0.6257 - mae: 0.5515 - mape: 975803.9375\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5446 - mse: 0.6182 - mae: 0.5446 - mape: 1042981.3125\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5478 - mse: 0.6317 - mae: 0.5478 - mape: 1062233.1250\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5290 - mse: 0.5729 - mae: 0.5290 - mape: 1184859.2500\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5282 - mse: 0.5851 - mae: 0.5282 - mape: 1118357.0000\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5190 - mse: 0.5494 - mae: 0.5190 - mape: 1148595.7500\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5107 - mse: 0.5427 - mae: 0.5107 - mape: 1177954.0000\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5021 - mse: 0.5280 - mae: 0.5021 - mape: 1183692.3750\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5030 - mse: 0.5239 - mae: 0.5030 - mape: 1070148.8750\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4923 - mse: 0.5090 - mae: 0.4923 - mape: 1218912.3750\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4938 - mse: 0.5225 - mae: 0.4938 - mape: 1145090.7500\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4858 - mse: 0.4905 - mae: 0.4858 - mape: 1243014.8750\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4843 - mse: 0.4904 - mae: 0.4843 - mape: 1106569.6250\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4847 - mse: 0.4902 - mae: 0.4847 - mape: 1242563.3750\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4862 - mse: 0.4834 - mae: 0.4862 - mape: 1262007.2500\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4818 - mse: 0.4835 - mae: 0.4818 - mape: 1301005.0000\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4858 - mse: 0.4906 - mae: 0.4858 - mape: 1231690.5000\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4734 - mse: 0.4675 - mae: 0.4734 - mape: 1357046.5000\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4733 - mse: 0.4719 - mae: 0.4733 - mape: 1223109.3750\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4722 - mse: 0.4616 - mae: 0.4722 - mape: 1312060.3750\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4724 - mse: 0.4714 - mae: 0.4724 - mape: 1240284.6250\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4717 - mse: 0.4621 - mae: 0.4717 - mape: 1274399.0000\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4678 - mse: 0.4556 - mae: 0.4678 - mape: 1363706.3750\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4629 - mse: 0.4486 - mae: 0.4629 - mape: 1317939.2500\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4688 - mse: 0.4511 - mae: 0.4688 - mape: 1462890.1250\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4612 - mse: 0.4492 - mae: 0.4612 - mape: 1282067.1250\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4671 - mse: 0.4589 - mae: 0.4671 - mape: 1361415.2500\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4650 - mse: 0.4441 - mae: 0.4650 - mape: 1407482.2500\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4604 - mse: 0.4378 - mae: 0.4604 - mape: 1437711.0000\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4617 - mse: 0.4323 - mae: 0.4617 - mape: 1440198.8750\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4581 - mse: 0.4433 - mae: 0.4581 - mape: 1314341.0000\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4531 - mse: 0.4247 - mae: 0.4531 - mape: 1492417.8750\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4596 - mse: 0.4380 - mae: 0.4596 - mape: 1347327.0000\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4534 - mse: 0.4251 - mae: 0.4534 - mape: 1458795.7500\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4529 - mse: 0.4254 - mae: 0.4529 - mape: 1454050.6250\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4499 - mse: 0.4208 - mae: 0.4499 - mape: 1615006.2500\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4565 - mse: 0.4371 - mae: 0.4565 - mape: 1418684.0000\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4497 - mse: 0.4217 - mae: 0.4497 - mape: 1621950.3750\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4482 - mse: 0.4201 - mae: 0.4482 - mape: 1496156.8750\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4493 - mse: 0.4211 - mae: 0.4493 - mape: 1425931.7500\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4547 - mse: 0.4230 - mae: 0.4547 - mape: 1573436.1250\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4422 - mse: 0.4081 - mae: 0.4422 - mape: 1490943.2500\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4488 - mse: 0.4233 - mae: 0.4488 - mape: 1601649.0000\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4410 - mse: 0.4056 - mae: 0.4410 - mape: 1673918.5000\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4495 - mse: 0.4290 - mae: 0.4495 - mape: 1447737.5000\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4437 - mse: 0.4017 - mae: 0.4437 - mape: 1759915.2500\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4518 - mse: 0.4290 - mae: 0.4518 - mape: 1644651.8750\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4408 - mse: 0.4048 - mae: 0.4408 - mape: 1709661.3750\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4379 - mse: 0.4053 - mae: 0.4379 - mape: 1717049.1250\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4384 - mse: 0.4003 - mae: 0.4384 - mape: 1726683.5000\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4406 - mse: 0.4041 - mae: 0.4406 - mape: 1628577.3750\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4446 - mse: 0.4045 - mae: 0.4446 - mape: 1857085.2500\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4368 - mse: 0.4017 - mae: 0.4368 - mape: 1656828.3750\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4315 - mse: 0.3959 - mae: 0.4315 - mape: 1741060.8750\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4359 - mse: 0.3983 - mae: 0.4359 - mape: 1949150.7500\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4354 - mse: 0.4046 - mae: 0.4354 - mape: 1809198.0000\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4334 - mse: 0.3961 - mae: 0.4334 - mape: 1763646.7500\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4321 - mse: 0.3919 - mae: 0.4321 - mape: 1600668.0000\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4324 - mse: 0.3871 - mae: 0.4324 - mape: 1694006.3750\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4312 - mse: 0.3973 - mae: 0.4312 - mape: 1866011.5000\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4309 - mse: 0.3895 - mae: 0.4309 - mape: 1696431.7500\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4291 - mse: 0.3880 - mae: 0.4291 - mape: 1784709.1250\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4369 - mse: 0.3994 - mae: 0.4369 - mape: 1737749.2500\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4318 - mse: 0.3886 - mae: 0.4318 - mape: 1756447.8750\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4247 - mse: 0.3856 - mae: 0.4247 - mape: 1629912.3750\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4242 - mse: 0.3821 - mae: 0.4242 - mape: 1830136.8750\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4258 - mse: 0.3871 - mae: 0.4258 - mape: 1726404.2500\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4294 - mse: 0.3934 - mae: 0.4294 - mape: 1840945.8750\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4199 - mse: 0.3743 - mae: 0.4199 - mape: 1761642.6250\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4224 - mse: 0.3826 - mae: 0.4224 - mape: 1916532.7500\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4222 - mse: 0.3808 - mae: 0.4222 - mape: 1828149.3750\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4228 - mse: 0.3801 - mae: 0.4228 - mape: 1924660.2500\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4202 - mse: 0.3792 - mae: 0.4202 - mape: 1728270.8750\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4266 - mse: 0.3907 - mae: 0.4266 - mape: 1867232.1250\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4275 - mse: 0.3880 - mae: 0.4275 - mape: 1940935.5000\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4252 - mse: 0.3827 - mae: 0.4252 - mape: 2056187.2500\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4168 - mse: 0.3776 - mae: 0.4168 - mape: 1843050.2500\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4200 - mse: 0.3781 - mae: 0.4200 - mape: 1767143.8750\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4214 - mse: 0.3790 - mae: 0.4214 - mape: 1789288.2500\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4184 - mse: 0.3768 - mae: 0.4184 - mape: 1794052.5000\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4215 - mse: 0.3832 - mae: 0.4215 - mape: 1934778.0000\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4256 - mse: 0.3764 - mae: 0.4256 - mape: 1829173.2500\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4354 - mse: 0.3980 - mae: 0.4354 - mape: 2105225.2500\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4231 - mse: 0.3785 - mae: 0.4231 - mape: 1845316.6250\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4209 - mse: 0.3752 - mae: 0.4209 - mape: 1810841.0000\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4145 - mse: 0.3742 - mae: 0.4145 - mape: 1881778.1250\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4189 - mse: 0.3759 - mae: 0.4189 - mape: 1712238.6250\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4192 - mse: 0.3715 - mae: 0.4192 - mape: 1854946.7500\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4185 - mse: 0.3744 - mae: 0.4185 - mape: 2065505.6250\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4175 - mse: 0.3719 - mae: 0.4175 - mape: 1798574.0000\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4201 - mse: 0.3787 - mae: 0.4201 - mape: 1784445.0000\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4191 - mse: 0.3710 - mae: 0.4191 - mape: 1935826.1250\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4206 - mse: 0.3738 - mae: 0.4206 - mape: 1819766.2500\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4176 - mse: 0.3739 - mae: 0.4176 - mape: 1636542.6250\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4138 - mse: 0.3717 - mae: 0.4138 - mape: 1746413.6250\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4147 - mse: 0.3679 - mae: 0.4147 - mape: 1929394.0000\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4124 - mse: 0.3632 - mae: 0.4124 - mape: 1961140.8750\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4118 - mse: 0.3658 - mae: 0.4118 - mape: 1742925.6250\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vanilla ffNNs\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Vanilla ffNNs\n",
      "           train        test\n",
      "MAE     0.417691    2.093317\n",
      "MSE     0.368440    9.139662\n",
      "MAPE  365.484540  477.593871\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preliminary table: Required Training Times\n",
      "   Architope  Architope-logistic Vanilla ffNN  Bagged ffNN\n",
      "0     25.357              20.809       10.999       20.049\n",
      "0     17.660              13.113            -       12.353\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 770 parameters.\n",
      "           train         test\n",
      "MAE     0.575619     2.314576\n",
      "MSE     0.712950    10.257699\n",
      "MAPE  506.959828  1522.775412\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0859s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n",
      "                   In-Line (L-Time) Parallel (P-Time)\n",
      "Vanilla ffNN                 10.999                 -\n",
      "Grad.Bstd Rand.F              0.151                 -\n",
      "Bagged ffNN                  20.049            12.353\n",
      "Architope-logistic           20.809            13.113\n",
      "Architope                    25.357             17.66\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       MSE         MAPE\n",
      "ffNN      0.417691  0.368440   365.484540\n",
      "GBRF      0.575619  0.712950   506.959828\n",
      "ffNN-bag  0.411647  0.363448  1191.359813\n",
      "ffNN-lgt  0.420366  0.388265   822.709545\n",
      "tope      0.423321  0.383702   822.262696\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like  \\\n",
      "Vanilla ffNN                 10.999                 -  11401  22800.523   \n",
      "Grad.Bstd Rand.F              0.151                 -    770   1538.322   \n",
      "Bagged ffNN                  20.049            12.353  22805  45608.600   \n",
      "Architope-logistic           20.809            13.113  22814  45626.684   \n",
      "Architope                    25.357             17.66  22880  45758.719   \n",
      "\n",
      "                       Eff  \n",
      "Vanilla ffNN        19.555  \n",
      "Grad.Bstd Rand.F    15.384  \n",
      "Bagged ffNN         20.211  \n",
      "Architope-logistic  19.381  \n",
      "Architope           19.044  \n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "#-------------------#\n",
      " PERFORMANCE SUMMARY:\n",
      "#-------------------#\n",
      " \n",
      " \n",
      "#===================#\n",
      " Individual Metrics: \n",
      "#======-============#\n",
      " \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Architope (Full)\n",
      "----------------------------------------\n",
      "           train        test\n",
      "MAE     0.423321    1.897151\n",
      "MSE     0.383702    8.363579\n",
      "MAPE  822.262696  394.777291\n",
      "----------------------------------------\n",
      "Architope - Naive Logistic\n",
      "----------------------------------------\n",
      "           train        test\n",
      "MAE     0.420366    1.931274\n",
      "MSE     0.388265    8.007072\n",
      "MAPE  822.709545  720.852433\n",
      "----------------------------------------\n",
      "Vanilla ffNN\n",
      "----------------------------------------\n",
      "           train        test\n",
      "MAE     0.417691    2.093317\n",
      "MSE     0.368440    9.139662\n",
      "MAPE  365.484540  477.593871\n",
      "----------------------------------------\n",
      "Bagged ffNN\n",
      "----------------------------------------\n",
      "            train        test\n",
      "MAE      0.411647    2.014077\n",
      "MSE      0.363448    8.744918\n",
      "MAPE  1191.359813  502.712451\n",
      "----------------------------------------\n",
      "Gradient Boosted Random Forest Regressor\n",
      "----------------------------------------\n",
      "           train         test\n",
      "MAE     0.575619     2.314576\n",
      "MSE     0.712950    10.257699\n",
      "MAPE  506.959828  1522.775412\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#==================#\n",
      " Overview  Metrics : \n",
      "#==================#\n",
      " \n",
      "----------------------------------------\n",
      "Training Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE         MAPE\n",
      "ffNN      0.417691  0.368440   365.484540\n",
      "GBRF      0.575619  0.712950   506.959828\n",
      "ffNN-bag  0.411647  0.363448  1191.359813\n",
      "ffNN-lgt  0.420366  0.388265   822.709545\n",
      "tope      0.423321  0.383702   822.262696\n",
      "----------------------------------------\n",
      "Testing Performance: \n",
      "----------------------------------------\n",
      "               MAE        MSE         MAPE\n",
      "ffNN      2.093317   9.139662   477.593871\n",
      "GBRF      2.314576  10.257699  1522.775412\n",
      "ffNN-bag  2.014077   8.744918   502.712451\n",
      "ffNN-lgt  1.931274   8.007072   720.852433\n",
      "tope      1.897151   8.363579   394.777291\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#====================#\n",
      " Efficiency Metrics: \n",
      "#====================#\n",
      " \n",
      "Model Training Times:\n",
      "----------------------------------------\n",
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like  \\\n",
      "Vanilla ffNN                 10.999                 -  11401  22800.523   \n",
      "Grad.Bstd Rand.F              0.151                 -    770   1538.322   \n",
      "Bagged ffNN                  20.049            12.353  22805  45608.600   \n",
      "Architope-logistic           20.809            13.113  22814  45626.684   \n",
      "Architope                    25.357             17.66  22880  45758.719   \n",
      "\n",
      "                       Eff  \n",
      "Vanilla ffNN        19.555  \n",
      "Grad.Bstd Rand.F    15.384  \n",
      "Bagged ffNN         20.211  \n",
      "Architope-logistic  19.381  \n",
      "Architope           19.044  \n",
      " \n",
      " \n",
      "😃😃 Have a great day!! 😃😃 \n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('😃😃 Have a great day!! 😃😃 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
