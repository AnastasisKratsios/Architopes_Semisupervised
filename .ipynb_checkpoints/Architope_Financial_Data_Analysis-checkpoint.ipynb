{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Architope (Financial Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .2\n",
    "N = 1000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  1000\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print((N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "#                 y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 20\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659\n",
      "0.454\n",
      "0.302\n",
      "0.178\n",
      "0.028\n",
      "0.0\n",
      "The_parts_listhe number of parts are: 7.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regernerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')\n",
    "    \n",
    "# Trash removal (removes empty parts)\n",
    "X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "    \n",
    "    \n",
    "# ICML Rebuttle Deadline = Coersion!\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 6.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part\n",
    "- Train locally (on each \"naive part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapse (Start) for Training on Each Part\n",
    "Architope_partition_training_begin = time.time()\n",
    "# Initialize running max for Parallel time\n",
    "Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "# Initialize N_parameter counter for Architope\n",
    "N_params_Architope = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Current part: 0 out of : 6 parts.\n",
      "Heights to iterate over: [66]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4950 - mse: 0.6443 - mae: 0.4950 - mape: 3668.1726\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1467 - mse: 0.0283 - mae: 0.1467 - mape: 977.4575\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1963 - mse: 0.0568 - mae: 0.1963 - mape: 1474.2837\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1421 - mse: 0.0294 - mae: 0.1421 - mape: 984.3519\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0682 - mse: 0.0063 - mae: 0.0682 - mape: 537.5481\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0034 - mae: 0.0463 - mape: 347.5682\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0019 - mae: 0.0368 - mape: 278.5499\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0021 - mae: 0.0379 - mape: 265.5023\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0261 - mse: 0.0010 - mae: 0.0261 - mape: 172.9690\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0012 - mae: 0.0285 - mape: 204.1216\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 9.1139e-04 - mae: 0.0244 - mape: 176.1336\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0300 - mse: 0.0013 - mae: 0.0300 - mape: 270.6250\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0012 - mae: 0.0274 - mape: 171.1703\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0013 - mae: 0.0292 - mape: 204.7859\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0015 - mae: 0.0320 - mape: 263.9020\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 6.7253e-04 - mae: 0.0214 - mape: 169.9815\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0020 - mae: 0.0337 - mape: 232.7813\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 8.6908e-04 - mae: 0.0237 - mape: 174.6692\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0010 - mae: 0.0264 - mape: 209.6056\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 6.6391e-04 - mae: 0.0211 - mape: 157.9558\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 8.7093e-04 - mae: 0.0238 - mape: 189.9225\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0010 - mae: 0.0267 - mape: 213.3821\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0011 - mae: 0.0274 - mape: 225.2880\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0012 - mae: 0.0278 - mape: 187.6208\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0212 - mse: 7.1959e-04 - mae: 0.0212 - mape: 151.9825\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 7.8174e-04 - mae: 0.0227 - mape: 156.5769\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0012 - mae: 0.0284 - mape: 218.6122\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0011 - mae: 0.0270 - mape: 196.7553\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0318 - mse: 0.0015 - mae: 0.0318 - mape: 241.4543\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0014 - mae: 0.0309 - mape: 229.1414\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0263 - mse: 0.0011 - mae: 0.0263 - mape: 196.4706\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0011 - mae: 0.0270 - mape: 174.1406\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0015 - mae: 0.0314 - mape: 226.0241\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0011 - mae: 0.0273 - mape: 231.5229\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 5.8226e-04 - mae: 0.0201 - mape: 131.9894\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 8.2824e-04 - mae: 0.0221 - mape: 190.7310\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0016 - mae: 0.0322 - mape: 243.5120\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 6.4976e-04 - mae: 0.0203 - mape: 148.5567\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0018 - mae: 0.0372 - mape: 308.4724\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 8.1043e-04 - mae: 0.0230 - mape: 141.2811\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 7.4734e-04 - mae: 0.0220 - mape: 168.6636\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0018 - mae: 0.0353 - mape: 273.0258\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0016 - mae: 0.0338 - mape: 271.1580\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0016 - mae: 0.0332 - mape: 233.6675\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 5.4253e-04 - mae: 0.0190 - mape: 163.3105\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0312 - mse: 0.0014 - mae: 0.0312 - mape: 271.1914\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 9.1178e-04 - mae: 0.0244 - mape: 213.9992\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 4.0119e-04 - mae: 0.0163 - mape: 125.2817\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0016 - mae: 0.0332 - mape: 264.0931\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0213 - mse: 6.7866e-04 - mae: 0.0213 - mape: 135.8336\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 5.0110e-04 - mae: 0.0182 - mape: 149.2013\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 6.6533e-04 - mae: 0.0206 - mape: 204.6855\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 9.2069e-04 - mae: 0.0255 - mape: 203.0222\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0275 - mse: 0.0011 - mae: 0.0275 - mape: 231.9270\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0293 - mse: 0.0013 - mae: 0.0293 - mape: 230.5845\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0015 - mae: 0.0316 - mape: 231.9457\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 6.7864e-04 - mae: 0.0210 - mape: 144.9384\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 6.9585e-04 - mae: 0.0214 - mape: 171.2181\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0015 - mae: 0.0313 - mape: 271.1978\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0012 - mae: 0.0280 - mape: 159.4449\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 7.4235e-04 - mae: 0.0218 - mape: 152.1843\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 5.3068e-04 - mae: 0.0181 - mape: 114.1312\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0016 - mae: 0.0294 - mape: 248.0701\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0021 - mae: 0.0389 - mape: 289.4004\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0016 - mae: 0.0327 - mape: 266.2002\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0020 - mae: 0.0384 - mape: 317.5008\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0276 - mse: 0.0012 - mae: 0.0276 - mape: 193.4094\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 3.2937e-04 - mae: 0.0143 - mape: 133.2447\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 5.4485e-04 - mae: 0.0174 - mape: 141.8206\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 4.3029e-04 - mae: 0.0166 - mape: 126.6364\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0235 - mse: 7.9597e-04 - mae: 0.0235 - mape: 190.8404\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0242 - mse: 8.4886e-04 - mae: 0.0242 - mape: 171.7217\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0322 - mse: 0.0015 - mae: 0.0322 - mape: 264.8888\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0255 - mse: 9.6124e-04 - mae: 0.0255 - mape: 170.3366\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0236 - mse: 8.1109e-04 - mae: 0.0236 - mape: 158.0767\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 5.9142e-04 - mae: 0.0194 - mape: 133.4777\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0254 - mse: 8.9814e-04 - mae: 0.0254 - mape: 198.3513\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0269 - mse: 0.0011 - mae: 0.0269 - mape: 198.4695\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 4.1777e-04 - mae: 0.0152 - mape: 122.4764\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 2.4006e-04 - mae: 0.0121 - mape: 95.0418\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 4.3375e-04 - mae: 0.0162 - mape: 122.6530\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 8.5707e-04 - mae: 0.0238 - mape: 204.3045\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0013 - mae: 0.0307 - mape: 244.0603\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0302 - mse: 0.0013 - mae: 0.0302 - mape: 251.1508\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 3.2063e-04 - mae: 0.0138 - mape: 68.3778\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0264 - mse: 9.3534e-04 - mae: 0.0264 - mape: 220.6161\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0267 - mse: 9.6395e-04 - mae: 0.0267 - mape: 193.2965\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 5.3788e-04 - mae: 0.0197 - mape: 175.5277\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 4.8107e-04 - mae: 0.0178 - mape: 133.8848\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 4.2412e-04 - mae: 0.0178 - mape: 164.6358\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 7.0441e-04 - mae: 0.0217 - mape: 180.9388\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 3.6261e-04 - mae: 0.0152 - mape: 115.0409\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 9.8980e-04 - mae: 0.0250 - mape: 208.3366\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 1.5408e-04 - mae: 0.0099 - mape: 76.4627\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0011 - mae: 0.0273 - mape: 259.8239\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 5.7888e-04 - mae: 0.0195 - mape: 163.5145\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0304 - mse: 0.0013 - mae: 0.0304 - mape: 223.7575\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0298 - mse: 0.0012 - mae: 0.0298 - mape: 241.4068\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0222 - mse: 6.8513e-04 - mae: 0.0222 - mape: 168.0223\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 3.4146e-04 - mae: 0.0155 - mape: 143.4138\n",
      "63/63 [==============================] - 0s 563us/step\n",
      "63/63 [==============================] - 0s 544us/step\n",
      "Status: Current part: 1 out of : 6 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4754 - mse: 0.5242 - mae: 0.4754 - mape: 203.2173\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2530 - mse: 0.0883 - mae: 0.2530 - mape: 105.3694\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0808 - mse: 0.0090 - mae: 0.0808 - mape: 34.6016\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0032 - mae: 0.0452 - mape: 19.3880\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0050 - mae: 0.0573 - mape: 25.5278\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0045 - mae: 0.0533 - mape: 23.9192\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0028 - mae: 0.0429 - mape: 19.0400\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0031 - mae: 0.0446 - mape: 20.3951\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0040 - mae: 0.0516 - mape: 22.2018\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0042 - mae: 0.0535 - mape: 23.7635\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0692 - mse: 0.0072 - mae: 0.0692 - mape: 30.5545\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0081 - mae: 0.0772 - mape: 32.9900\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0092 - mae: 0.0831 - mape: 34.6774\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0738 - mse: 0.0082 - mae: 0.0738 - mape: 31.4499\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0034 - mae: 0.0484 - mape: 20.7885\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0506 - mse: 0.0042 - mae: 0.0506 - mape: 21.6001\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0105 - mae: 0.0872 - mape: 37.2709\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0404 - mse: 0.0025 - mae: 0.0404 - mape: 17.9750\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0441 - mse: 0.0029 - mae: 0.0441 - mape: 19.2550\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0053 - mae: 0.0599 - mape: 25.5193\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1032 - mse: 0.0176 - mae: 0.1032 - mape: 43.6844\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0031 - mae: 0.0446 - mape: 19.8753\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0621 - mse: 0.0053 - mae: 0.0621 - mape: 26.2309\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0028 - mae: 0.0414 - mape: 18.8765\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0022 - mae: 0.0370 - mape: 16.7552\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0029 - mae: 0.0430 - mape: 19.2081\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0410 - mse: 0.0027 - mae: 0.0410 - mape: 18.5979\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0027 - mae: 0.0416 - mape: 18.7492\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0026 - mae: 0.0394 - mape: 17.4879\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0028 - mae: 0.0432 - mape: 18.9052\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0032 - mae: 0.0471 - mape: 20.6715\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0471 - mse: 0.0034 - mae: 0.0471 - mape: 20.7484\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0027 - mae: 0.0423 - mape: 18.5700\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0021 - mae: 0.0375 - mape: 16.5780\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0479 - mse: 0.0037 - mae: 0.0479 - mape: 20.7826\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0386 - mse: 0.0024 - mae: 0.0386 - mape: 17.1913\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0396 - mse: 0.0024 - mae: 0.0396 - mape: 17.7899\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0026 - mae: 0.0420 - mape: 18.8270\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0031 - mae: 0.0465 - mape: 19.9454\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0032 - mae: 0.0463 - mape: 20.3613\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0035 - mae: 0.0479 - mape: 21.3213\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0537 - mse: 0.0043 - mae: 0.0537 - mape: 23.7581\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0080 - mae: 0.0725 - mape: 31.3057\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0049 - mae: 0.0577 - mape: 24.8980\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0519 - mse: 0.0042 - mae: 0.0519 - mape: 22.4957\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0030 - mae: 0.0453 - mape: 20.1617\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0033 - mae: 0.0476 - mape: 20.8266\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0051 - mae: 0.0574 - mape: 25.5653\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0035 - mae: 0.0478 - mape: 21.0943\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0637 - mse: 0.0060 - mae: 0.0637 - mape: 27.0558\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0039 - mae: 0.0502 - mape: 22.3552\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0069 - mae: 0.0697 - mape: 29.7666\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0717 - mse: 0.0113 - mae: 0.0717 - mape: 31.4910\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0037 - mae: 0.0491 - mape: 21.0482\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0021 - mae: 0.0356 - mape: 15.7368\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0402 - mse: 0.0026 - mae: 0.0402 - mape: 17.9240\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0544 - mse: 0.0043 - mae: 0.0544 - mape: 23.5275\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0441 - mse: 0.0030 - mae: 0.0441 - mape: 19.2272\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0024 - mae: 0.0395 - mape: 16.8290\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0021 - mae: 0.0363 - mape: 16.3777\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0021 - mae: 0.0373 - mape: 16.7797\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0019 - mae: 0.0344 - mape: 15.5464\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0023 - mae: 0.0373 - mape: 16.6551\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0402 - mse: 0.0025 - mae: 0.0402 - mape: 18.0248\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0339 - mse: 0.0018 - mae: 0.0339 - mape: 14.7632\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0339 - mse: 0.0019 - mae: 0.0339 - mape: 15.3093\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0024 - mae: 0.0387 - mape: 17.3067\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 9.5252e-04 - mae: 0.0248 - mape: 11.4147\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0028 - mae: 0.0420 - mape: 18.0954\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0032 - mae: 0.0466 - mape: 19.4139\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0027 - mae: 0.0421 - mape: 17.8989\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0024 - mae: 0.0386 - mape: 16.4437\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0350 - mse: 0.0020 - mae: 0.0350 - mape: 15.7182\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0014 - mae: 0.0297 - mape: 14.0056\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 9.6181e-04 - mae: 0.0248 - mape: 11.4831\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0023 - mae: 0.0382 - mape: 16.1504\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0025 - mae: 0.0393 - mape: 17.2950\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0507 - mse: 0.0054 - mae: 0.0507 - mape: 21.3812\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0377 - mse: 0.0023 - mae: 0.0377 - mape: 16.4310\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0025 - mae: 0.0393 - mape: 17.3277\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0334 - mse: 0.0017 - mae: 0.0334 - mape: 15.3595\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0033 - mae: 0.0469 - mape: 19.8679\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0038 - mae: 0.0505 - mape: 22.1780\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0028 - mae: 0.0432 - mape: 18.7956\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0348 - mse: 0.0018 - mae: 0.0348 - mape: 15.2281\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0013 - mae: 0.0286 - mape: 12.9944\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0010 - mae: 0.0250 - mape: 11.0397\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 8.7734e-04 - mae: 0.0232 - mape: 10.6107\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0026 - mae: 0.0416 - mape: 18.1473\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 8.2779e-04 - mae: 0.0225 - mape: 10.0984\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0029 - mae: 0.0447 - mape: 19.1573\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0294 - mse: 0.0013 - mae: 0.0294 - mape: 12.8067\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0014 - mae: 0.0309 - mape: 13.1556\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0010 - mae: 0.0252 - mape: 11.2723\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 7.6641e-04 - mae: 0.0218 - mape: 10.0071\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0024 - mae: 0.0323 - mape: 14.1685\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0012 - mae: 0.0276 - mape: 12.6100\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 9.5012e-04 - mae: 0.0258 - mape: 11.4401\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 7.3352e-04 - mae: 0.0193 - mape: 9.1888\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0259 - mse: 9.7934e-04 - mae: 0.0259 - mape: 11.4205\n",
      "63/63 [==============================] - 0s 767us/step\n",
      "63/63 [==============================] - 0s 661us/step\n",
      "Status: Current part: 2 out of : 6 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6152 - mse: 0.7393 - mae: 0.6152 - mape: 140.1918\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1238 - mse: 0.0251 - mae: 0.1238 - mape: 27.9439\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0082 - mae: 0.0685 - mape: 15.4294\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1640 - mse: 0.0353 - mae: 0.1640 - mape: 36.5058\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0807 - mse: 0.0098 - mae: 0.0807 - mape: 18.2913\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0694 - mse: 0.0068 - mae: 0.0694 - mape: 15.4846\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0598 - mse: 0.0054 - mae: 0.0598 - mape: 13.6168\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.0150 - mae: 0.1051 - mape: 23.3963\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0876 - mse: 0.0135 - mae: 0.0876 - mape: 20.2131\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0670 - mse: 0.0066 - mae: 0.0670 - mape: 14.9309\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0458 - mse: 0.0031 - mae: 0.0458 - mape: 10.4022\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0034 - mae: 0.0468 - mape: 10.7347\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0035 - mae: 0.0490 - mape: 11.2021\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0025 - mae: 0.0393 - mape: 8.9431\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0053 - mae: 0.0613 - mape: 13.8726\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0071 - mae: 0.0722 - mape: 16.4369\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0047 - mae: 0.0571 - mape: 13.0365\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0026 - mae: 0.0390 - mape: 9.1014\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0029 - mae: 0.0419 - mape: 9.5233\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0057 - mae: 0.0621 - mape: 14.0535\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0576 - mse: 0.0049 - mae: 0.0576 - mape: 13.2445\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0023 - mae: 0.0375 - mape: 8.5680\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0506 - mse: 0.0036 - mae: 0.0506 - mape: 11.4043\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0028 - mae: 0.0423 - mape: 9.4651\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0030 - mae: 0.0442 - mape: 10.2185\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0024 - mae: 0.0392 - mape: 8.9861\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0034 - mae: 0.0474 - mape: 10.9527\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0028 - mae: 0.0428 - mape: 9.9472\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0035 - mae: 0.0489 - mape: 10.9732\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0026 - mae: 0.0391 - mape: 9.0518\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0030 - mae: 0.0442 - mape: 10.1902\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0038 - mae: 0.0492 - mape: 11.5175\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0026 - mae: 0.0416 - mape: 9.4669\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0583 - mse: 0.0049 - mae: 0.0583 - mape: 13.3279\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0052 - mae: 0.0559 - mape: 12.3746\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0028 - mae: 0.0448 - mape: 10.1882\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0025 - mae: 0.0407 - mape: 9.2771\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0030 - mae: 0.0447 - mape: 9.9368\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0026 - mae: 0.0390 - mape: 9.1326\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0317 - mse: 0.0017 - mae: 0.0317 - mape: 7.4083\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0021 - mae: 0.0355 - mape: 8.1774\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0025 - mae: 0.0400 - mape: 9.2498\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - mse: 0.0018 - mae: 0.0322 - mape: 7.4835\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0020 - mae: 0.0344 - mape: 7.9284\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0025 - mae: 0.0380 - mape: 8.9613\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0024 - mae: 0.0393 - mape: 9.1154\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0021 - mae: 0.0364 - mape: 8.2390\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0344 - mse: 0.0018 - mae: 0.0344 - mape: 7.8891\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0017 - mae: 0.0319 - mape: 7.3612\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0017 - mae: 0.0325 - mape: 7.4551\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0024 - mae: 0.0401 - mape: 8.9654\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0017 - mae: 0.0314 - mape: 7.2301\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0030 - mae: 0.0426 - mape: 9.8474\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0024 - mae: 0.0411 - mape: 9.4572\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0034 - mae: 0.0488 - mape: 11.1063\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0032 - mae: 0.0458 - mape: 10.5645\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0046 - mae: 0.0558 - mape: 12.6338\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0049 - mae: 0.0557 - mape: 12.8394\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0712 - mse: 0.0077 - mae: 0.0712 - mape: 16.2608\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0056 - mae: 0.0637 - mape: 14.3322\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0778 - mse: 0.0087 - mae: 0.0778 - mape: 17.5045\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0539 - mse: 0.0047 - mae: 0.0539 - mape: 12.4001\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0039 - mae: 0.0499 - mape: 11.6014\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0398 - mse: 0.0024 - mae: 0.0398 - mape: 9.2480\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0045 - mae: 0.0551 - mape: 12.5132\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0045 - mae: 0.0521 - mape: 11.5233\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0631 - mse: 0.0056 - mae: 0.0631 - mape: 14.0813\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0045 - mae: 0.0545 - mape: 12.1548\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0691 - mse: 0.0076 - mae: 0.0691 - mape: 15.6946\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0049 - mae: 0.0567 - mape: 12.7975\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0611 - mse: 0.0059 - mae: 0.0611 - mape: 13.8586\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0840 - mse: 0.0123 - mae: 0.0840 - mape: 18.6111\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0921 - mse: 0.0130 - mae: 0.0921 - mape: 21.0129\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1173 - mse: 0.0184 - mae: 0.1173 - mape: 26.1411\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3007 - mse: 0.2118 - mae: 0.3007 - mape: 67.1147\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0424 - mse: 9.7991 - mae: 2.0424 - mape: 457.2450\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1641 - mse: 0.0835 - mae: 0.1641 - mape: 37.1048\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0037 - mae: 0.0503 - mape: 11.6521\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0391 - mse: 0.0025 - mae: 0.0391 - mape: 8.7840\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0030 - mae: 0.0447 - mape: 10.0065\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0014 - mae: 0.0280 - mape: 6.6394\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0017 - mae: 0.0316 - mape: 7.4037\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0291 - mse: 0.0015 - mae: 0.0291 - mape: 6.7790\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0017 - mae: 0.0318 - mape: 7.2495\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0022 - mae: 0.0351 - mape: 8.1507\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0021 - mae: 0.0362 - mape: 8.1970\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0018 - mae: 0.0333 - mape: 7.6439\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0016 - mae: 0.0305 - mape: 7.1799\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0012 - mae: 0.0263 - mape: 6.2631\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0012 - mae: 0.0268 - mape: 6.3232\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267 - mape: 6.3002\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0016 - mae: 0.0308 - mape: 7.1446\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0283 - mse: 0.0014 - mae: 0.0283 - mape: 6.6657\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0272 - mse: 0.0013 - mae: 0.0272 - mape: 6.4012\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0013 - mae: 0.0273 - mape: 6.4512\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0014 - mae: 0.0288 - mape: 6.7254\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0011 - mae: 0.0241 - mape: 5.7346\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0013 - mae: 0.0277 - mape: 6.5022\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0011 - mae: 0.0245 - mape: 5.8080\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0015 - mae: 0.0302 - mape: 7.0029\n",
      "63/63 [==============================] - 0s 581us/step\n",
      "63/63 [==============================] - 0s 633us/step\n",
      "Status: Current part: 3 out of : 6 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7772 - mse: 1.1787 - mae: 0.7772 - mape: 124.0540\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3378 - mse: 0.2092 - mae: 0.3378 - mape: 54.9308\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1919 - mse: 0.0530 - mae: 0.1919 - mape: 30.7811\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1893 - mse: 0.0472 - mae: 0.1893 - mape: 30.3705\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2029 - mse: 0.0556 - mae: 0.2029 - mape: 32.5023\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1813 - mse: 0.0414 - mae: 0.1813 - mape: 29.1335\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1742 - mse: 0.0392 - mae: 0.1742 - mape: 28.1509\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0074 - mae: 0.0704 - mape: 11.2147\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0607 - mse: 0.0059 - mae: 0.0607 - mape: 9.3995\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0035 - mae: 0.0449 - mape: 7.0376\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0057 - mae: 0.0622 - mape: 9.7459\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0050 - mae: 0.0552 - mape: 8.6448\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0038 - mae: 0.0456 - mape: 7.0398\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0036 - mae: 0.0445 - mape: 6.8734\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0031 - mae: 0.0419 - mape: 6.4775\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0029 - mae: 0.0395 - mape: 6.1301\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0035 - mae: 0.0450 - mape: 6.9496\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0037 - mae: 0.0511 - mape: 8.1137\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0065 - mae: 0.0628 - mape: 9.7287\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0044 - mae: 0.0518 - mape: 8.0266\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0038 - mae: 0.0476 - mape: 7.4925\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0658 - mse: 0.0055 - mae: 0.0658 - mape: 10.7400\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0042 - mae: 0.0547 - mape: 8.6708\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0073 - mae: 0.0685 - mape: 11.0121\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0040 - mae: 0.0484 - mape: 7.5742\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0552 - mse: 0.0046 - mae: 0.0552 - mape: 8.7735\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0050 - mae: 0.0590 - mape: 9.3637\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0543 - mse: 0.0049 - mae: 0.0543 - mape: 8.4113\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0065 - mae: 0.0694 - mape: 11.1732\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0034 - mae: 0.0470 - mape: 7.3656\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0039 - mae: 0.0499 - mape: 7.7692\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0032 - mae: 0.0439 - mape: 6.8403\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0050 - mae: 0.0570 - mape: 8.9910\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0457 - mse: 0.0036 - mae: 0.0457 - mape: 7.2064\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0057 - mae: 0.0621 - mape: 9.9621\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1011 - mse: 0.0148 - mae: 0.1011 - mape: 16.0112\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0909 - mse: 0.0134 - mae: 0.0909 - mape: 14.5173\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0044 - mae: 0.0539 - mape: 8.4839\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0047 - mae: 0.0513 - mape: 7.9005\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0031 - mae: 0.0411 - mape: 6.3852\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0033 - mae: 0.0437 - mape: 6.7751\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0699 - mse: 0.0072 - mae: 0.0699 - mape: 11.0928\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0523 - mse: 0.0042 - mae: 0.0523 - mape: 8.2641\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0462 - mse: 0.0035 - mae: 0.0462 - mape: 7.1659\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0047 - mae: 0.0541 - mape: 8.3787\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0030 - mae: 0.0452 - mape: 7.0991\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0031 - mae: 0.0428 - mape: 6.6780\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0028 - mae: 0.0380 - mape: 5.8728\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0029 - mae: 0.0399 - mape: 6.1397\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0035 - mae: 0.0428 - mape: 6.5364\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0044 - mae: 0.0518 - mape: 8.0420\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0458 - mse: 0.0035 - mae: 0.0458 - mape: 7.1195\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0029 - mae: 0.0387 - mape: 5.9745\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0030 - mae: 0.0415 - mape: 6.4311\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0033 - mae: 0.0433 - mape: 6.7704\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0402 - mse: 0.0030 - mae: 0.0402 - mape: 6.2019\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0402 - mse: 0.0028 - mae: 0.0402 - mape: 6.3003\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0028 - mae: 0.0380 - mape: 5.8572\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0036 - mae: 0.0474 - mape: 7.4156\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0028 - mae: 0.0417 - mape: 6.5239\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0031 - mae: 0.0432 - mape: 6.7133\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0038 - mae: 0.0504 - mape: 7.9418\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0044 - mae: 0.0546 - mape: 8.5974\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0480 - mse: 0.0038 - mae: 0.0480 - mape: 7.5187\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0032 - mae: 0.0436 - mape: 6.7596\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0033 - mae: 0.0453 - mape: 7.0872\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0033 - mae: 0.0442 - mape: 6.9273\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0031 - mae: 0.0402 - mape: 6.2128\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0030 - mae: 0.0396 - mape: 6.1366\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0028 - mae: 0.0384 - mape: 5.9319\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0385 - mse: 0.0028 - mae: 0.0385 - mape: 5.9706\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0034 - mae: 0.0430 - mape: 6.6603\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0032 - mae: 0.0432 - mape: 6.6945\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0029 - mae: 0.0418 - mape: 6.5610\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0030 - mae: 0.0407 - mape: 6.3160\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0028 - mae: 0.0384 - mape: 5.9571\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0391 - mse: 0.0029 - mae: 0.0391 - mape: 6.0348\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0383 - mse: 0.0027 - mae: 0.0383 - mape: 5.9529\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0031 - mae: 0.0402 - mape: 6.1863\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0031 - mae: 0.0416 - mape: 6.4754\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0391 - mse: 0.0028 - mae: 0.0391 - mape: 6.1052\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0030 - mae: 0.0385 - mape: 5.8961\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0028 - mae: 0.0378 - mape: 5.8344\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0028 - mae: 0.0381 - mape: 5.9285\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0029 - mae: 0.0400 - mape: 6.1739\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0028 - mae: 0.0386 - mape: 5.9610\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0029 - mae: 0.0382 - mape: 5.8691\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0031 - mae: 0.0417 - mape: 6.4644\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0028 - mae: 0.0385 - mape: 5.9554\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0030 - mae: 0.0415 - mape: 6.4670\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0029 - mae: 0.0392 - mape: 6.0397\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0029 - mae: 0.0387 - mape: 5.9753\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0387 - mse: 0.0028 - mae: 0.0387 - mape: 6.0031\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0404 - mse: 0.0030 - mae: 0.0404 - mape: 6.2031\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0383 - mse: 0.0029 - mae: 0.0383 - mape: 5.9023\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0387 - mse: 0.0029 - mae: 0.0387 - mape: 5.9902\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0030 - mae: 0.0412 - mape: 6.3666\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0030 - mae: 0.0408 - mape: 6.3352\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0030 - mae: 0.0411 - mape: 6.3557\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0043 - mae: 0.0545 - mape: 8.6080\n",
      "63/63 [==============================] - 0s 559us/step\n",
      "63/63 [==============================] - 0s 586us/step\n",
      "Status: Current part: 4 out of : 6 parts.\n",
      "Heights to iterate over: [50]\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8829 - mse: 2.6529 - mae: 0.8829 - mape: 105.6625\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1473 - mse: 0.0459 - mae: 0.1473 - mape: 17.6075\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0928 - mse: 0.0121 - mae: 0.0928 - mape: 11.0928\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0645 - mse: 0.0065 - mae: 0.0645 - mape: 7.7478\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0050 - mae: 0.0595 - mape: 7.0995\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0054 - mae: 0.0591 - mape: 6.9945\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0472 - mse: 0.0033 - mae: 0.0472 - mape: 5.6239\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0031 - mae: 0.0450 - mape: 5.3478\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0027 - mae: 0.0421 - mape: 4.9896\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0028 - mae: 0.0413 - mape: 4.8451\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0031 - mae: 0.0449 - mape: 5.2780\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - mse: 0.0040 - mae: 0.0521 - mape: 6.2455\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0027 - mae: 0.0410 - mape: 4.8216\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0031 - mae: 0.0431 - mape: 5.0710\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0498 - mse: 0.0037 - mae: 0.0498 - mape: 5.9484\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 4.8831\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0028 - mae: 0.0415 - mape: 4.8835\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0031 - mae: 0.0450 - mape: 5.3333\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0454 - mse: 0.0031 - mae: 0.0454 - mape: 5.4035\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0033 - mae: 0.0456 - mape: 5.3992\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0039 - mae: 0.0516 - mape: 6.1349\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0036 - mae: 0.0486 - mape: 5.7603\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0503 - mse: 0.0037 - mae: 0.0503 - mape: 5.9867\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0032 - mae: 0.0456 - mape: 5.4298\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0034 - mae: 0.0469 - mape: 5.5377\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0034 - mae: 0.0477 - mape: 5.6695\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0028 - mae: 0.0430 - mape: 5.0971\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0027 - mae: 0.0413 - mape: 4.8808\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0419 - mse: 0.0029 - mae: 0.0419 - mape: 4.9289\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0034 - mae: 0.0467 - mape: 5.5442\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0411 - mse: 0.0027 - mae: 0.0411 - mape: 4.8573\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0485 - mse: 0.0036 - mae: 0.0485 - mape: 5.7488\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0030 - mae: 0.0431 - mape: 5.0590\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0030 - mae: 0.0430 - mape: 5.0650\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0026 - mae: 0.0405 - mape: 4.7858\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0030 - mae: 0.0429 - mape: 5.0442\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0029 - mae: 0.0432 - mape: 5.1170\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0033 - mae: 0.0473 - mape: 5.6445\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0038 - mae: 0.0501 - mape: 5.9841\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0035 - mae: 0.0491 - mape: 5.8823\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0032 - mae: 0.0460 - mape: 5.4803\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0032 - mae: 0.0449 - mape: 5.2748\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0027 - mae: 0.0417 - mape: 4.9369\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0027 - mae: 0.0425 - mape: 5.0807\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0029 - mae: 0.0429 - mape: 5.0606\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0029 - mae: 0.0439 - mape: 5.2225\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0032 - mae: 0.0453 - mape: 5.3812\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0029 - mae: 0.0426 - mape: 5.0156\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - mse: 0.0040 - mae: 0.0522 - mape: 6.2230\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0483 - mse: 0.0034 - mae: 0.0483 - mape: 5.6995\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0039 - mae: 0.0511 - mape: 6.1272\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0047 - mae: 0.0545 - mape: 6.4687\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0030 - mae: 0.0450 - mape: 5.3374\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0608 - mse: 0.0052 - mae: 0.0608 - mape: 7.2322\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0040 - mae: 0.0504 - mape: 6.0111\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0028 - mae: 0.0431 - mape: 5.1383\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0030 - mae: 0.0437 - mape: 5.2029\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0418 - mse: 0.0029 - mae: 0.0418 - mape: 4.9176\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0483 - mse: 0.0035 - mae: 0.0483 - mape: 5.7998\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0609 - mse: 0.0053 - mae: 0.0609 - mape: 7.2985\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0034 - mae: 0.0456 - mape: 5.3398\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0454 - mse: 0.0032 - mae: 0.0454 - mape: 5.4056\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0027 - mae: 0.0411 - mape: 4.8484\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0027 - mae: 0.0410 - mape: 4.8312\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0461 - mse: 0.0030 - mae: 0.0461 - mape: 5.4707\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0030 - mae: 0.0452 - mape: 5.4038\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0039 - mae: 0.0511 - mape: 6.1618\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0038 - mae: 0.0503 - mape: 6.0053\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0036 - mae: 0.0486 - mape: 5.7660\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0030 - mae: 0.0437 - mape: 5.1738\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0028 - mae: 0.0433 - mape: 5.1528\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0031 - mae: 0.0468 - mape: 5.6026\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0030 - mae: 0.0442 - mape: 5.2148\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0047 - mae: 0.0556 - mape: 6.7211\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0037 - mae: 0.0505 - mape: 6.0545\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0030 - mae: 0.0435 - mape: 5.1091\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0029 - mae: 0.0432 - mape: 5.1382\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0025 - mae: 0.0410 - mape: 4.8722\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0035 - mae: 0.0477 - mape: 5.6438\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0512 - mse: 0.0039 - mae: 0.0512 - mape: 6.0695\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0045 - mae: 0.0541 - mape: 6.4193\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0034 - mae: 0.0466 - mape: 5.5112\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0030 - mae: 0.0448 - mape: 5.3419\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0027 - mae: 0.0423 - mape: 5.0542\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0403 - mse: 0.0025 - mae: 0.0403 - mape: 4.7424\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0036 - mae: 0.0488 - mape: 5.7675\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0032 - mae: 0.0456 - mape: 5.3872\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0031 - mae: 0.0459 - mape: 5.4504\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0448 - mse: 0.0031 - mae: 0.0448 - mape: 5.2883\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0414 - mse: 0.0027 - mae: 0.0414 - mape: 4.8838\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0029 - mae: 0.0445 - mape: 5.3158\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - mse: 0.0037 - mae: 0.0516 - mape: 6.1583\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0539 - mse: 0.0045 - mae: 0.0539 - mape: 6.5032\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0032 - mae: 0.0464 - mape: 5.5493\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0035 - mae: 0.0479 - mape: 5.7229\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0632 - mse: 0.0058 - mae: 0.0632 - mape: 7.6180\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0769 - mse: 0.0078 - mae: 0.0769 - mape: 9.1439\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0068 - mae: 0.0691 - mape: 8.2520\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0494 - mse: 0.0038 - mae: 0.0494 - mape: 5.8260\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0030 - mae: 0.0444 - mape: 5.2629\n",
      "63/63 [==============================] - 0s 570us/step\n",
      "63/63 [==============================] - 0s 597us/step\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Silly Coercsion for ICML rebuttle deadline timeline\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    Iteration_Length = len(X_parts_list) -1\n",
    "else:\n",
    "    Iteration_Length = len(X_parts_list)\n",
    "\n",
    "    \n",
    "# Train each part!\n",
    "for current_part in range(Iteration_Length):\n",
    "    #==============#\n",
    "    # Timer(begin) #\n",
    "    #==============#\n",
    "    current_part_training_time_for_parallel_begin = time.time()\n",
    "    \n",
    "    \n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    # Reload Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "    current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "    current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "    current_height = np.maximum(current_height,current_height_threshold)\n",
    "    current_height = current_height.astype(int).tolist()\n",
    "    param_grid_Vanilla_Nets['height'] = current_height\n",
    "    # Automatically Fix Input Dimension\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "    param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    \n",
    "    # Update User #\n",
    "    #-------------#\n",
    "    print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "    print('Heights to iterate over: '+str(current_height))\n",
    "    \n",
    "    # Generate Prediction(s) on current Part #\n",
    "    #----------------------------------------#\n",
    "    # Failsafe (number of data-points)\n",
    "    CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "    # Train Network\n",
    "    y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                     n_jobs = n_jobs,\n",
    "                                                                                     n_iter = n_iter, \n",
    "                                                                                     param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                     X_train= X_parts_list[current_part], \n",
    "                                                                                     y_train=y_parts_list[current_part],\n",
    "                                                                                     X_test_partial=X_train,\n",
    "                                                                                     X_test=X_test)\n",
    "    \n",
    "    # Append predictions to data-frames\n",
    "    ## If first prediction we initialize data-frames\n",
    "    if current_part==0:\n",
    "        # Register quality\n",
    "        training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "        training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "\n",
    "        # Save Predictions\n",
    "        predictions_train = y_hat_train_full_loop\n",
    "        predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "        predictions_test = y_hat_test_full_loop\n",
    "        predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "        \n",
    "        \n",
    "    ## If not first prediction we append to already initialized dataframes\n",
    "    else:\n",
    "    # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Write Predictions \n",
    "        # Save Predictions\n",
    "        y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],1)\n",
    "        predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "        y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],1)\n",
    "        predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "        \n",
    "        # Evaluate Errors #\n",
    "        #-----------------#\n",
    "        # Training\n",
    "        prediction_errors = np.abs(y_hat_train_loop.reshape(-1,)-y_train)\n",
    "        training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "        \n",
    "    #============#\n",
    "    # Timer(end) #\n",
    "    #============#\n",
    "    current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "    Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "\n",
    "    #============---===============#\n",
    "    # N_parameter Counter (Update) #\n",
    "    #------------===---------------#\n",
    "    N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('----------------------------------------------------')\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "print('----------------------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training on Each Part\n",
    "Architope_partition_training = time.time() - Architope_partition_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes Labels\n",
    "partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "# Build Classes\n",
    "for part_column_i in range(1,(training_quality.shape[1])):\n",
    "    partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                           (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                          ],axis=1)\n",
    "# Convert to integers\n",
    "partition_labels_training = partition_labels_training+0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "param_grid_Deep_Classifier['output_dim'] = [partition_labels_training.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.2040\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.4220\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.5260\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.5600\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.5530\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.5530\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.5530\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.5530\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.5530\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.5530\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.5530\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.5660\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.5980\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.6060\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.6430\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.6350\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.6560\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.6590\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.6710\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.6770\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.6770\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.6740\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.6770\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.6840\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.6860\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.6890\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.6880\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.6890\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.6900\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.7040\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.7040\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.7020\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.7070\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.7080\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.7090\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.7120\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.7120\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.7150\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.7140\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.7160\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.7140\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.7130\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.7160\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.7140\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.7090\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.7110\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 975us/step - loss: 0.2848 - accuracy: 0.7130\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.7120\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.2837 - accuracy: 0.7140\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.7140\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.7140\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 939us/step - loss: 0.2822 - accuracy: 0.7060\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.7120\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.7160\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.7120\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.7120\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.7180\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.7130\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.7120\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 909us/step - loss: 0.2783 - accuracy: 0.7110\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2776 - accuracy: 0.7130\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.7120\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 984us/step - loss: 0.2771 - accuracy: 0.7100\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 985us/step - loss: 0.2762 - accuracy: 0.7170\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 956us/step - loss: 0.2758 - accuracy: 0.7140\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 957us/step - loss: 0.2754 - accuracy: 0.7140\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.7070\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.7150\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 943us/step - loss: 0.2743 - accuracy: 0.7090\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.7090\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.7130\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.7160\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.7080\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 955us/step - loss: 0.2723 - accuracy: 0.7140\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.7120\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.7130\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 970us/step - loss: 0.2712 - accuracy: 0.7120\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.7110\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.7120\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 985us/step - loss: 0.2701 - accuracy: 0.7110\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.7130\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.7080\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.7100\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 0.2687 - accuracy: 0.7130\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 973us/step - loss: 0.2683 - accuracy: 0.7130\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.7090\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.7170\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.7140\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 965us/step - loss: 0.2671 - accuracy: 0.7080\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 908us/step - loss: 0.2670 - accuracy: 0.7160\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 998us/step - loss: 0.2665 - accuracy: 0.7120\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 967us/step - loss: 0.2663 - accuracy: 0.7090\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 896us/step - loss: 0.2659 - accuracy: 0.7170\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.7060\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.7140\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.7140\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.7100\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.7110\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2641 - accuracy: 0.7130\n",
      "WARNING:tensorflow:From /scratch/users/kratsioa/.local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "63/63 [==============================] - 0s 841us/step\n",
      "63/63 [==============================] - 0s 611us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = partition_labels_training,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "# Testing Set\n",
    "Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.050523   0.050523\n",
      "MSE    0.007344   0.007344\n",
      "MAPE  45.582412  45.582412\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_Architope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       L-time    P-time  N_params_expt   AIC-like    Eff\n",
      "0  174.751157  10.88633          38357  76719.971  0.533\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l1', 'l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier and generating partition!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=2020,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.5, 1.0, 10, 100, 1000],\n",
       "                                        'penalty': ['none', 'l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2020, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train       test\n",
      "MAE    0.052239   0.052239\n",
      "MSE    0.008243   0.008243\n",
      "MAPE  50.169279  50.169279\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Performance\n",
      "          train       test\n",
      "MAE    0.053190   0.053190\n",
      "MSE    0.005452   0.005452\n",
      "MAPE  40.879830  40.879830\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Partition: Generated!...Feature Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5841 - mse: 1.8714 - mae: 0.5841 - mape: 1550.1173\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1253 - mse: 0.0234 - mae: 0.1253 - mape: 441.8713\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1172 - mse: 0.0213 - mae: 0.1172 - mape: 346.5518\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1644 - mse: 0.0430 - mae: 0.1644 - mape: 380.9887\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.0348 - mae: 0.1515 - mape: 406.3829\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1569 - mse: 0.0384 - mae: 0.1569 - mape: 451.1827\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.0284 - mae: 0.1335 - mape: 377.9533\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1310 - mse: 0.0271 - mae: 0.1310 - mape: 336.5372\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1104 - mse: 0.0199 - mae: 0.1104 - mape: 342.1992\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1297 - mse: 0.0265 - mae: 0.1297 - mape: 349.6907\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1376 - mse: 0.0294 - mae: 0.1376 - mape: 306.6767\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1132 - mse: 0.0196 - mae: 0.1132 - mape: 271.2170\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1143 - mse: 0.0208 - mae: 0.1143 - mape: 317.3046\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1116 - mse: 0.0217 - mae: 0.1116 - mape: 216.6267\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0987 - mse: 0.0149 - mae: 0.0987 - mape: 257.2202\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0102 - mae: 0.0746 - mape: 140.8517\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0095 - mae: 0.0720 - mape: 151.5028\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0819 - mse: 0.0116 - mae: 0.0819 - mape: 173.0390\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0812 - mse: 0.0114 - mae: 0.0812 - mape: 181.2901\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0083 - mae: 0.0658 - mape: 134.4983\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0094 - mae: 0.0710 - mape: 128.8637\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0637 - mse: 0.0083 - mae: 0.0637 - mape: 94.0558\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0092 - mae: 0.0709 - mape: 115.7425\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0090 - mae: 0.0673 - mape: 121.9261\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0074 - mae: 0.0570 - mape: 85.3168\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0721 - mse: 0.0099 - mae: 0.0721 - mape: 140.6817\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0072 - mae: 0.0569 - mape: 101.2443\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0674 - mse: 0.0087 - mae: 0.0674 - mape: 129.1716\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0645 - mse: 0.0081 - mae: 0.0645 - mape: 103.4046\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0903 - mse: 0.0141 - mae: 0.0903 - mape: 174.7189\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1009 - mse: 0.0158 - mae: 0.1009 - mape: 229.8097\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0917 - mse: 0.0143 - mae: 0.0917 - mape: 197.2565\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0668 - mse: 0.0094 - mae: 0.0668 - mape: 121.3057\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0079 - mae: 0.0621 - mape: 111.8092\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0652 - mse: 0.0085 - mae: 0.0652 - mape: 115.4594\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0587 - mse: 0.0080 - mae: 0.0587 - mape: 83.0605\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0078 - mae: 0.0629 - mape: 111.4215\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0074 - mae: 0.0558 - mape: 86.1884\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0561 - mse: 0.0072 - mae: 0.0561 - mape: 85.1638\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0639 - mse: 0.0086 - mae: 0.0639 - mape: 115.5730\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0596 - mse: 0.0078 - mae: 0.0596 - mape: 106.1252\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0689 - mse: 0.0091 - mae: 0.0689 - mape: 122.7879\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1354 - mse: 0.0390 - mae: 0.1354 - mape: 360.7178\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2726 - mse: 0.1226 - mae: 0.2726 - mape: 812.1800\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2646 - mse: 0.0995 - mae: 0.2646 - mape: 802.3166\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2670 - mse: 0.1033 - mae: 0.2670 - mape: 816.1765\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2630 - mse: 0.0990 - mae: 0.2630 - mape: 790.9464\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2661 - mse: 0.1018 - mae: 0.2661 - mape: 779.4989\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2662 - mse: 0.1002 - mae: 0.2662 - mape: 836.8411\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2635 - mse: 0.1010 - mae: 0.2635 - mape: 773.3995\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2664 - mse: 0.0995 - mae: 0.2664 - mape: 839.3192\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2707 - mse: 0.1083 - mae: 0.2707 - mape: 809.4139\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2635 - mse: 0.1063 - mae: 0.2635 - mape: 810.9203\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2660 - mse: 0.1017 - mae: 0.2660 - mape: 735.6030\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2668 - mse: 0.1045 - mae: 0.2668 - mape: 819.3259\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2681 - mse: 0.1024 - mae: 0.2681 - mape: 814.8817\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2717 - mse: 0.1085 - mae: 0.2717 - mape: 802.7912\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2644 - mse: 0.1009 - mae: 0.2644 - mape: 776.7663\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2642 - mse: 0.0993 - mae: 0.2642 - mape: 846.2117\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2672 - mse: 0.1013 - mae: 0.2672 - mape: 796.6034\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2636 - mse: 0.1001 - mae: 0.2636 - mape: 772.3809\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2626 - mse: 0.0990 - mae: 0.2626 - mape: 811.4690\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2658 - mse: 0.1015 - mae: 0.2658 - mape: 825.9586\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2669 - mse: 0.1014 - mae: 0.2669 - mape: 797.7055\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2674 - mse: 0.1032 - mae: 0.2674 - mape: 795.8715\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2623 - mse: 0.1003 - mae: 0.2623 - mape: 762.2710\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2649 - mse: 0.0995 - mae: 0.2649 - mape: 828.8630\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2628 - mse: 0.1002 - mae: 0.2628 - mape: 761.5408\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2629 - mse: 0.1013 - mae: 0.2629 - mape: 797.7484\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2656 - mse: 0.1016 - mae: 0.2656 - mape: 780.7732\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2639 - mse: 0.1028 - mae: 0.2639 - mape: 737.3598\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2743 - mse: 0.1108 - mae: 0.2743 - mape: 865.4903\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3528 - mse: 0.6111 - mae: 0.3528 - mape: 923.2253\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2691 - mse: 0.1054 - mae: 0.2691 - mape: 769.3867\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2642 - mse: 0.1003 - mae: 0.2642 - mape: 753.9996\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2628 - mse: 0.1014 - mae: 0.2628 - mape: 761.0485\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2669 - mse: 0.1023 - mae: 0.2669 - mape: 814.4521\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2636 - mse: 0.0985 - mae: 0.2636 - mape: 803.9444\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2649 - mse: 0.1003 - mae: 0.2649 - mape: 808.1616\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2657 - mse: 0.1009 - mae: 0.2657 - mape: 858.4091\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2630 - mse: 0.1020 - mae: 0.2630 - mape: 757.6464\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2665 - mse: 0.1017 - mae: 0.2665 - mape: 832.7935\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2736 - mse: 0.1065 - mae: 0.2736 - mape: 844.7693\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2644 - mse: 0.0989 - mae: 0.2644 - mape: 796.0746\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2652 - mse: 0.1021 - mae: 0.2652 - mape: 772.1880\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2690 - mse: 0.1006 - mae: 0.2690 - mape: 868.0975\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2679 - mse: 0.1059 - mae: 0.2679 - mape: 754.6315\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2654 - mse: 0.1039 - mae: 0.2654 - mape: 820.8609\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2622 - mse: 0.1002 - mae: 0.2622 - mape: 816.2466\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2709 - mse: 0.1027 - mae: 0.2709 - mape: 846.1215\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2666 - mse: 0.1049 - mae: 0.2666 - mape: 736.2471\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2660 - mse: 0.1026 - mae: 0.2660 - mape: 796.5355\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2741 - mse: 0.1183 - mae: 0.2741 - mape: 802.8522\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2630 - mse: 0.0983 - mae: 0.2630 - mape: 794.5262\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2649 - mse: 0.1031 - mae: 0.2649 - mape: 773.0342\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2660 - mse: 0.1010 - mae: 0.2660 - mape: 785.3781\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2645 - mse: 0.1013 - mae: 0.2645 - mape: 750.9714\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2663 - mse: 0.1028 - mae: 0.2663 - mape: 791.2017\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2671 - mse: 0.1027 - mae: 0.2671 - mape: 797.2701\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2647 - mse: 0.1002 - mae: 0.2647 - mape: 789.2443\n",
      "63/63 [==============================] - 0s 720us/step\n",
      "63/63 [==============================] - 0s 764us/step\n"
     ]
    }
   ],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                   n_jobs = n_jobs, \n",
    "                                                                                   n_iter = n_iter, \n",
    "                                                                                   param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                   X_train=X_train, \n",
    "                                                                                   y_train=data_y, \n",
    "                                                                                   X_test_partial=X_train,\n",
    "                                                                                   X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vanilla ffNNs\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written Bagged Vanilla ffNNs\n",
      "          train       test\n",
      "MAE    0.271821   0.271821\n",
      "MSE    0.094924   0.094924\n",
      "MAPE  64.590248  64.590248\n"
     ]
    }
   ],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preliminary table: Required Training Times\n",
      "   Architope  Architope-logistic Vanilla ffNN  Bagged ffNN\n",
      "0    209.346             175.580       17.155      174.884\n",
      "0     45.482              11.715            -       11.020\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 70 parameters.\n",
      "          train       test\n",
      "MAE    0.106589   0.106589\n",
      "MSE    0.015051   0.015051\n",
      "MAPE  38.065083  38.065083\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1037s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n",
      "                   In-Line (L-Time) Parallel (P-Time)\n",
      "Vanilla ffNN                 17.155                 -\n",
      "Grad.Bstd Rand.F               0.16                 -\n",
      "Bagged ffNN                 174.884             11.02\n",
      "Architope-logistic           175.58            11.715\n",
      "Architope                   209.346            45.482\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       MSE       MAPE\n",
      "ffNN      0.271821  0.094924  64.590248\n",
      "GBRF      0.106589  0.015051  38.065083\n",
      "ffNN-bag  0.053190  0.005452  40.879830\n",
      "ffNN-lgt  0.052239  0.008243  50.169279\n",
      "tope      0.050523  0.007344  45.582412\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like    Eff\n",
      "Vanilla ffNN                 17.155                 -  10401  20804.605  2.514\n",
      "Grad.Bstd Rand.F               0.16                 -     70    144.478  0.453\n",
      "Bagged ffNN                 174.884             11.02  38178  76361.868  0.561\n",
      "Architope-logistic           175.58            11.715  38182  76369.904  0.551\n",
      "Architope                   209.346            45.482  38357  76719.971  0.533\n"
     ]
    }
   ],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "#-------------------#\n",
      " PERFORMANCE SUMMARY:\n",
      "#-------------------#\n",
      " \n",
      " \n",
      "#===================#\n",
      " Individual Metrics: \n",
      "#======-============#\n",
      " \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Architope (Full)\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.050523   0.050523\n",
      "MSE    0.007344   0.007344\n",
      "MAPE  45.582412  45.582412\n",
      "----------------------------------------\n",
      "Architope - Naive Logistic\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.052239   0.052239\n",
      "MSE    0.008243   0.008243\n",
      "MAPE  50.169279  50.169279\n",
      "----------------------------------------\n",
      "Vanilla ffNN\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.271821   0.271821\n",
      "MSE    0.094924   0.094924\n",
      "MAPE  64.590248  64.590248\n",
      "----------------------------------------\n",
      "Bagged ffNN\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.053190   0.053190\n",
      "MSE    0.005452   0.005452\n",
      "MAPE  40.879830  40.879830\n",
      "----------------------------------------\n",
      "Gradient Boosted Random Forest Regressor\n",
      "----------------------------------------\n",
      "          train       test\n",
      "MAE    0.106589   0.106589\n",
      "MSE    0.015051   0.015051\n",
      "MAPE  38.065083  38.065083\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#==================#\n",
      " Overview  Metrics : \n",
      "#==================#\n",
      " \n",
      "----------------------------------------\n",
      "Training Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE       MAPE\n",
      "ffNN      0.271821  0.094924  64.590248\n",
      "GBRF      0.106589  0.015051  38.065083\n",
      "ffNN-bag  0.053190  0.005452  40.879830\n",
      "ffNN-lgt  0.052239  0.008243  50.169279\n",
      "tope      0.050523  0.007344  45.582412\n",
      "----------------------------------------\n",
      "Testing Performance: \n",
      "----------------------------------------\n",
      "               MAE       MSE       MAPE\n",
      "ffNN      0.271821  0.094924  64.590248\n",
      "GBRF      0.106589  0.015051  38.065083\n",
      "ffNN-bag  0.053190  0.005452  40.879830\n",
      "ffNN-lgt  0.052239  0.008243  50.169279\n",
      "tope      0.050523  0.007344  45.582412\n",
      "----------------------------------------\n",
      " \n",
      " \n",
      "#====================#\n",
      " Efficiency Metrics: \n",
      "#====================#\n",
      " \n",
      "Model Training Times:\n",
      "----------------------------------------\n",
      "                   In-Line (L-Time) Parallel (P-Time)  N_par   AIC_like    Eff\n",
      "Vanilla ffNN                 17.155                 -  10401  20804.605  2.514\n",
      "Grad.Bstd Rand.F               0.16                 -     70    144.478  0.453\n",
      "Bagged ffNN                 174.884             11.02  38178  76361.868  0.561\n",
      "Architope-logistic           175.58            11.715  38182  76369.904  0.551\n",
      "Architope                   209.346            45.482  38357  76719.971  0.533\n",
      " \n",
      " \n",
      " Have a great day!!  \n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' Have a great day!!  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "plt.scatter(x_1,y_1,color='orange',label=r'$f_1(x)$',linestyle='--')\n",
    "plt.scatter(x_2,y_2,color='blue',label=r'$f_2(x)$',linestyle='--')\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'gray',linestyle=\"--\",  label='ffNN')\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'black',linestyle=\"--\",  label='tope')\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Model Predictions\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/DEMO.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
