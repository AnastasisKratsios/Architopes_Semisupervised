{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Semi-Supervised Architope - for Reviews\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"PC-NNs\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1-(1/24)\n",
    "min_width = 100\n",
    "min_epochs = 100\n",
    "# Ablation Finess\n",
    "N_plot_finess = 8\n",
    "# min_parts_threshold = .001; max_parts_threshold = 0.9\n",
    "N_min_parts = 1; N_max_plots = 8\n",
    "Tied_Neurons_Q = True\n",
    "# Partition with Inputs (determine parts with domain) or outputs (determine parts with image)\n",
    "Partition_using_Inputs = True\n",
    "# Cuttoff Level\n",
    "gamma = .5\n",
    "# Softmax Layer instead of sigmoid\n",
    "softmax_layer = False #<- Just out of curiosity...but it doesn't perform many better IRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 10**4\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return np.exp(-x)\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# exec(open('Prepare_Data_California_Housing.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]\n",
    "sns.set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Partion Builder:\n",
    "Implements exactly Algorithm 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(X_in,\n",
    "                               y_in,\n",
    "                               N_parts_to_get=4):\n",
    "\n",
    "    # Compute Size of each part\n",
    "    size_part_reference = int(round(X_in.shape[0]/N_parts_to_get))\n",
    "\n",
    "    # Apply random bijection #\n",
    "    #------------------------#\n",
    "    ## Get random bijection indices\n",
    "    random_bijection_indices = np.random.choice(range(X_in.shape[0]),size=X_in.shape[0], replace=False)\n",
    "    ## Apply random bijections\n",
    "    X_in_shuffled = X_in[random_bijection_indices,:]\n",
    "    y_in_shuffled = y_in[random_bijection_indices,:]\n",
    "\n",
    "    # Initialize Lists #\n",
    "    #------------------#\n",
    "    X_parts = []\n",
    "    y_parts = []\n",
    "\n",
    "    for i_th_part_to_get in range(N_parts_to_get):\n",
    "        # Build random balls #\n",
    "        #--------------------#\n",
    "        ## Sample random radius\n",
    "        size_part = int(np.maximum(1,np.round(size_part_reference*np.random.uniform(low=.5,high=1.5,size=1)[0])))\n",
    "        ## Sample random point\n",
    "        X_center_loop_index = np.random.choice(range(X_in_shuffled.shape[0]),size=1, replace=False)\n",
    "        X_center_loop = X_in_shuffled[X_center_loop_index,:]\n",
    "        ## Compute Typical Distances from Center\n",
    "        distances_loop = X_center_loop-X_in_shuffled\n",
    "        distances_loop = np.linalg.norm(distances_loop, axis=1)\n",
    "\n",
    "        # Remove Random Ball from Dataset\n",
    "        if size_part <= len(distances_loop):\n",
    "            ## Identify indices\n",
    "            indices_smallest_to_random_ball = np.argsort(distances_loop)[:size_part]\n",
    "        else:\n",
    "            print('Final Loop')\n",
    "            indices_smallest_to_random_ball = np.array(range(X_in_shuffled.shape[0]))\n",
    "        ## Extract Parts\n",
    "        X_current_part_loop = X_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        y_current_part_loop = y_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        ## Append to List of Parts\n",
    "        X_parts.append(X_current_part_loop)\n",
    "        y_parts.append(y_current_part_loop)\n",
    "\n",
    "        # Remove Selected Entries From Array #\n",
    "        #------------------------------------#\n",
    "        X_in_shuffled = np.delete(X_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "        y_in_shuffled = np.delete(y_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "\n",
    "        # Failsafe if procedure has terminated\n",
    "        if X_in_shuffled.shape[0] == 0:\n",
    "            print('breaking early')\n",
    "            break\n",
    "    # Count Number of Parts Generated        \n",
    "    N_parts_generated = len(X_parts)\n",
    "    # Output Parts\n",
    "    return X_parts, y_parts, N_parts_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCNNs(N_parts,X_train,y_train,X_test,y_test):\n",
    "\n",
    "    # Initialization(s) #\n",
    "    #-------------------#\n",
    "    N_neurons = 0\n",
    "    L_timer = 0\n",
    "    P_timer = 0\n",
    "    Mean_Width_Subnetworks = 0\n",
    "\n",
    "    # Partitioner Begin #\n",
    "    #-------------------#\n",
    "    import time\n",
    "    partitioning_time_begin = time.time()\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Randomly Initialized Parts - Via Randomized Algorithm 2')\n",
    "    print('-------------------------------------------------------')\n",
    "    if Partition_using_Inputs == True:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(X_train.to_numpy(),\n",
    "                                                                                             y_train.reshape(-1,1),\n",
    "                                                                                             N_parts)\n",
    "    else:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(y_train.reshape(-1,1),\n",
    "                                                                                             X_train.to_numpy(),\n",
    "                                                                                             N_parts)\n",
    "    partitioning_time = time.time() - partitioning_time_begin\n",
    "    print('The_parts_listhe number of parts are: ' + str(N_parts_Generated_by_Algo_2)+'.')\n",
    "    ############# Partitioner End ########\n",
    "\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Training Sub-Networks on Each Randomly Generated Part')\n",
    "    print('-----------------------------------------------------')\n",
    "    # Time-Elapse (Start) for Training on Each Part #\n",
    "    PCNN_timer = time.time(); PCNN_timer = -math.inf; N_params_Architope = 0; N_params_tally = 0\n",
    "    # Remove Eager Execution Error(s)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Automatically Initialize Correct Input/Output Dimension(s)\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]; param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    # Decide if/or not to tie neuron numbers of sub-patterns together\n",
    "    if Tied_Neurons_Q == True:\n",
    "        param_grid_Vanilla_Nets['height'] = [int(np.maximum(round(param_grid_Vanilla_Nets['height'][0]/N_parts),min_width))]\n",
    "        param_grid_Vanilla_Nets['epochs'] = [int(np.maximum(round(param_grid_Vanilla_Nets['epochs'][0]/int(round(np.sqrt(N_parts)))),min_epochs))]\n",
    "#         param_grid_Deep_Classifier['height'] = [int(np.maximum(round(param_grid_Deep_Classifier['height'][0]/N_parts),min_width))]\n",
    "\n",
    "    for current_part in range(N_parts_Generated_by_Algo_2):\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('-----------------------------------------------------------')\n",
    "        print('Currently Training Part: '+str(current_part)+'/'+str(N_parts_Generated_by_Algo_2 )+'Total Parts.')\n",
    "        print('-----------------------------------------------------------')\n",
    "\n",
    "        # Timer for Part\n",
    "        part_training_timer = time.time()\n",
    "        # Get Data for Sub-Pattern\n",
    "        X_loop = pd.DataFrame(X_parts_list[current_part])\n",
    "        y_loop = (y_parts_list[current_part]).reshape(-1,)\n",
    "        # Train ffNN\n",
    "        y_hat_part_loop, y_hat_part_loop_test, N_neurons_PCNN_loop = build_ffNN(n_folds = 4, \n",
    "                                                                              n_jobs = n_jobs,\n",
    "                                                                              n_iter = n_iter, \n",
    "                                                                              param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                              X_train= X_loop, \n",
    "                                                                              y_train=y_loop,\n",
    "                                                                              X_test_partial=X_train,\n",
    "                                                                              X_test=X_test,\n",
    "                                                                              NOCV=True)\n",
    "        # Reshape y\n",
    "        ## Training\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop.shape = (y_hat_part_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        ## Testing\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop_test.shape = (y_hat_part_loop_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_part_loop-y_train)).reshape(y_hat_part_loop.shape[0],1)\n",
    "\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_part_loop.reshape(y_hat_part_loop.shape[0],1)\n",
    "            predictions_test = y_hat_part_loop_test.reshape(y_hat_part_loop_test.shape[0],1)\n",
    "\n",
    "\n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "        # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_part_loop.reshape(predictions_train.shape[0],1)\n",
    "            predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "            y_hat_test_loop = y_hat_part_loop_test.reshape(predictions_test.shape[0],1)\n",
    "            predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "\n",
    "        #==============================#\n",
    "        # Update Performance Metric(s) #\n",
    "        #==============================#\n",
    "        part_training_timer = time.time() - part_training_timer\n",
    "        # L-Time\n",
    "        L_timer += partitioning_time\n",
    "        # P-Time\n",
    "        P_timer = max(P_timer,part_training_timer)\n",
    "        # N. Params\n",
    "        N_neurons += N_neurons_PCNN_loop\n",
    "        # Mean Width for Sub-Network(s)\n",
    "        Mean_Width_Subnetworks += param_grid_Vanilla_Nets['height'][0]\n",
    "\n",
    "    # Take Mean of Width(s)\n",
    "    Mean_Width_Subnetworks = Mean_Width_Subnetworks/N_parts_Generated_by_Algo_2\n",
    "    print('-----------------------')\n",
    "    print('Training Deep Zero-Sets')\n",
    "    print('-----------------------')\n",
    "\n",
    "\n",
    "    # Time Elapsed for Training Deep Zero-Sets\n",
    "    Deep_Zero_Sets_timer = time.time()\n",
    "\n",
    "    ## Initialize Classes Labels\n",
    "    if softmax_layer == False:\n",
    "        # No pooling (classical)\n",
    "        partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "    else:\n",
    "        # Max Pooling\n",
    "#         partition_labels_training_integers = (training_quality == training_quality.min(axis=1)[:,None]).astype(int)\n",
    "        partition_labels_training_integers = np.apply_along_axis(softminn, 1, training_quality).astype(int)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    ## Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    ## Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    ## Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train.values, \n",
    "                                                                                                        y_train = partition_labels_training.values,\n",
    "                                                                                                        X_test = X_test.values)\n",
    "    # Get Binary Classes (Discontinuous Unit)\n",
    "    ## Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>gamma)*1).astype(int)\n",
    "    ## Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > gamma)*1).astype(int)\n",
    "    # Get PC-NN Prediction(s)\n",
    "    ## Train\n",
    "    PCNN_prediction_y_train = (predictions_train*predicted_classes_train).sum(axis=1)\n",
    "    ## Test\n",
    "    PCNN_prediction_y_test = (predictions_test*predicted_classes_test).sum(axis=1)\n",
    "\n",
    "    # End Timer\n",
    "    Deep_Zero_Sets_timer = time.time() - Deep_Zero_Sets_timer\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print('Computing Final Performance Metrics')\n",
    "    print('-----------------------------------')\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "\n",
    "    # Update Times\n",
    "    L_timer +=Deep_Zero_Sets_timer\n",
    "    P_timer +=Deep_Zero_Sets_timer\n",
    "    # Update Number of Neurons Used\n",
    "    N_neurons_subPatterns = N_neurons\n",
    "    N_neurons_deep_Zero_Sets = (param_grid_Deep_Classifier['height'][0])*(param_grid_Deep_Classifier['depth'][0])\n",
    "    N_neurons = N_neurons_deep_Zero_Sets + N_neurons_subPatterns\n",
    "\n",
    "\n",
    "\n",
    "    # Compute Peformance\n",
    "    performance_PCNN = reporter(y_train_hat_in=PCNN_prediction_y_train,y_test_hat_in=PCNN_prediction_y_test,\n",
    "                                y_train_in=y_train,\n",
    "                                y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_PCNN.to_latex((results_tables_path+\"PCNN_full_performance.tex\"))\n",
    "\n",
    "    # Update User\n",
    "    print(performance_PCNN)\n",
    "\n",
    "    ### Model Complexity/Efficiency Metrics\n",
    "    # Build AIC-like Metric #\n",
    "    #-----------------------#\n",
    "    AIC_like = 2*(N_neurons - np.log((performance_PCNN['test']['MAE'])))\n",
    "    AIC_like = np.round(AIC_like,3)\n",
    "    Efficiency = np.log(N_neurons) *(performance_PCNN['test']['MAE'])\n",
    "    Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "    # Build Table #\n",
    "    #-------------#\n",
    "    PCNN_Model_Complexity = pd.DataFrame({'L-time': [L_timer],\n",
    "                                               'P-time':[P_timer],\n",
    "                                               'N_params_expt': [N_neurons],\n",
    "                                               'AIC-like': [AIC_like],\n",
    "                                               'Eff': [Efficiency],\n",
    "                                               'N. Parts':[N_parts_Generated_by_Algo_2]})\n",
    "\n",
    "\n",
    "    # Write Required Training Time(s)\n",
    "    PCNN_Model_Complexity.to_latex((results_tables_path+\"PCNN_full_model_complexities.tex\"))\n",
    "\n",
    "    #--------------======---------------#\n",
    "    # Display Required Training Time(s) #\n",
    "    #--------------======---------------#\n",
    "    print(PCNN_Model_Complexity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    print('# ---- Getting Benchmarks ---- #')\n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training_begin = time.time()\n",
    "    \n",
    "    if N_parts > 1:\n",
    "        parameters = {'penalty': ['none'], 'C': [0.1]}\n",
    "        lr = LogisticRegression(random_state=2020)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=CV_folds, \n",
    "                                     n_repeats=n_iter, random_state=0)\n",
    "        classifier = RandomizedSearchCV(lr, \n",
    "                                        parameters, \n",
    "                                        random_state=2020)\n",
    "\n",
    "        # Initialize Classes Labels\n",
    "        partition_labels_training = np.argmin(training_quality,axis=-1)\n",
    "\n",
    "        # Train logistic Classifier\n",
    "        print(\"Training classifier and generating partition!\")\n",
    "\n",
    "        # Train Logistic Classifier #\n",
    "        #---------------------------#\n",
    "        # Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Train Classifier\n",
    "        classifier.fit(X_train, partition_labels_training)\n",
    "    if N_parts >1 :\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "        Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "        # Testing Set\n",
    "        predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "        Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, \n",
    "                                                                     predicted_classes_test_logistic_BM[:,None], \n",
    "                                                                     axis=1)\n",
    "    else:\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        Architope_prediction_y_train_logistic_BM = predictions_train\n",
    "\n",
    "        # Testing Set\n",
    "        Architope_prediction_y_test_logistic_BM = predictions_test\n",
    "        \n",
    "    # Extract Number of Parameters Logistic Regressor\n",
    "    if N_parts > 1:\n",
    "        N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)\n",
    "    else:\n",
    "        N_params_best_logistic = 1\n",
    "    N_params_best_logistic = N_params_best_logistic + N_neurons_subPatterns*N_parts\n",
    "        \n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin\n",
    "\n",
    "    #### Compute Performance\n",
    "    # Compute Peformance\n",
    "    performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                        y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                        y_train_in=y_train,\n",
    "                                        y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "    \n",
    "    # Return Output(s)\n",
    "    return performance_PCNN, PCNN_Model_Complexity, N_parts_Generated_by_Algo_2, N_neurons, N_neurons_subPatterns,N_neurons_deep_Zero_Sets, Mean_Width_Subnetworks, performance_architope_ffNN_logistic, N_params_best_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform Ablation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.0\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 1.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/1Total Parts.\n",
      "-----------------------------------------------------------\n",
      "WARNING:tensorflow:From /Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 299 samples\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 0s 1ms/sample - loss: 0.4648 - mse: 0.2326 - mae: 0.4648 - mape: 84.1234\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 410us/sample - loss: 0.4275 - mse: 0.1998 - mae: 0.4275 - mape: 76.8153\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 417us/sample - loss: 0.3901 - mse: 0.1699 - mae: 0.3901 - mape: 69.4586\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 433us/sample - loss: 0.3528 - mse: 0.1423 - mae: 0.3528 - mape: 62.2291\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 391us/sample - loss: 0.3153 - mse: 0.1177 - mae: 0.3153 - mape: 54.8971\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 580us/sample - loss: 0.2776 - mse: 0.0961 - mae: 0.2776 - mape: 47.5218\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 405us/sample - loss: 0.2398 - mse: 0.0772 - mae: 0.2398 - mape: 40.0740\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 374us/sample - loss: 0.2046 - mse: 0.0614 - mae: 0.2046 - mape: 33.3598\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 396us/sample - loss: 0.1815 - mse: 0.0493 - mae: 0.1815 - mape: 29.6646\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 381us/sample - loss: 0.1669 - mse: 0.0412 - mae: 0.1669 - mape: 27.7051\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 395us/sample - loss: 0.1565 - mse: 0.0353 - mae: 0.1565 - mape: 26.4990\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 352us/sample - loss: 0.1471 - mse: 0.0311 - mae: 0.1471 - mape: 25.3268\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 390us/sample - loss: 0.1395 - mse: 0.0279 - mae: 0.1395 - mape: 24.5787\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 382us/sample - loss: 0.1338 - mse: 0.0254 - mae: 0.1338 - mape: 24.1501\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 411us/sample - loss: 0.1298 - mse: 0.0238 - mae: 0.1298 - mape: 23.8830\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 412us/sample - loss: 0.1271 - mse: 0.0228 - mae: 0.1271 - mape: 23.7303\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 401us/sample - loss: 0.1253 - mse: 0.0221 - mae: 0.1253 - mape: 23.6785\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 391us/sample - loss: 0.1238 - mse: 0.0216 - mae: 0.1238 - mape: 23.5737\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.1224 - mse: 0.0211 - mae: 0.1224 - mape: 23.4054\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 395us/sample - loss: 0.1212 - mse: 0.0208 - mae: 0.1212 - mape: 23.2299\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 375us/sample - loss: 0.1201 - mse: 0.0204 - mae: 0.1201 - mape: 23.1013\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 354us/sample - loss: 0.1189 - mse: 0.0200 - mae: 0.1189 - mape: 22.9311\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 426us/sample - loss: 0.1179 - mse: 0.0197 - mae: 0.1179 - mape: 22.7424\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.1166 - mse: 0.0194 - mae: 0.1166 - mape: 22.5260\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 404us/sample - loss: 0.1155 - mse: 0.0191 - mae: 0.1155 - mape: 22.3261\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 437us/sample - loss: 0.1143 - mse: 0.0188 - mae: 0.1143 - mape: 22.0730\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.1131 - mse: 0.0184 - mae: 0.1131 - mape: 21.8557\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 385us/sample - loss: 0.1120 - mse: 0.0181 - mae: 0.1120 - mape: 21.6612\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 356us/sample - loss: 0.1108 - mse: 0.0178 - mae: 0.1108 - mape: 21.3902\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 396us/sample - loss: 0.1096 - mse: 0.0175 - mae: 0.1096 - mape: 21.1159\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 376us/sample - loss: 0.1084 - mse: 0.0173 - mae: 0.1084 - mape: 20.8786\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 397us/sample - loss: 0.1072 - mse: 0.0169 - mae: 0.1072 - mape: 20.6588\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 393us/sample - loss: 0.1060 - mse: 0.0167 - mae: 0.1060 - mape: 20.4043\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 374us/sample - loss: 0.1048 - mse: 0.0164 - mae: 0.1048 - mape: 20.1076\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.1035 - mse: 0.0162 - mae: 0.1035 - mape: 19.8504\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 363us/sample - loss: 0.1022 - mse: 0.0159 - mae: 0.1022 - mape: 19.6379\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 378us/sample - loss: 0.1010 - mse: 0.0156 - mae: 0.1010 - mape: 19.3559\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 373us/sample - loss: 0.0997 - mse: 0.0153 - mae: 0.0997 - mape: 19.1825\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 353us/sample - loss: 0.0985 - mse: 0.0151 - mae: 0.0985 - mape: 19.0318\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 377us/sample - loss: 0.0972 - mse: 0.0148 - mae: 0.0972 - mape: 18.7339\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 386us/sample - loss: 0.0959 - mse: 0.0146 - mae: 0.0959 - mape: 18.4354\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 363us/sample - loss: 0.0946 - mse: 0.0144 - mae: 0.0946 - mape: 18.1503\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 378us/sample - loss: 0.0932 - mse: 0.0141 - mae: 0.0932 - mape: 17.9424\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 379us/sample - loss: 0.0920 - mse: 0.0139 - mae: 0.0920 - mape: 17.8061\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 383us/sample - loss: 0.0907 - mse: 0.0137 - mae: 0.0907 - mape: 17.4966\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 374us/sample - loss: 0.0893 - mse: 0.0136 - mae: 0.0893 - mape: 17.1020\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 382us/sample - loss: 0.0881 - mse: 0.0134 - mae: 0.0881 - mape: 16.8281\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 382us/sample - loss: 0.0866 - mse: 0.0132 - mae: 0.0866 - mape: 16.6273\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 381us/sample - loss: 0.0854 - mse: 0.0129 - mae: 0.0854 - mape: 16.5091\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 381us/sample - loss: 0.0841 - mse: 0.0128 - mae: 0.0841 - mape: 16.2174\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 367us/sample - loss: 0.0826 - mse: 0.0127 - mae: 0.0826 - mape: 15.8133\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.0814 - mse: 0.0127 - mae: 0.0814 - mape: 15.4778\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 400us/sample - loss: 0.0800 - mse: 0.0125 - mae: 0.0800 - mape: 15.2466\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 468us/sample - loss: 0.0786 - mse: 0.0123 - mae: 0.0786 - mape: 15.0564\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 496us/sample - loss: 0.0773 - mse: 0.0122 - mae: 0.0773 - mape: 14.7921\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 470us/sample - loss: 0.0759 - mse: 0.0121 - mae: 0.0759 - mape: 14.4421\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 383us/sample - loss: 0.0747 - mse: 0.0121 - mae: 0.0747 - mape: 14.1732\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 400us/sample - loss: 0.0733 - mse: 0.0120 - mae: 0.0733 - mape: 13.9180\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 501us/sample - loss: 0.0720 - mse: 0.0119 - mae: 0.0720 - mape: 13.6868\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 587us/sample - loss: 0.0708 - mse: 0.0117 - mae: 0.0708 - mape: 13.5537\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 569us/sample - loss: 0.0693 - mse: 0.0116 - mae: 0.0693 - mape: 13.2578\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 528us/sample - loss: 0.0681 - mse: 0.0117 - mae: 0.0681 - mape: 12.8746\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 521us/sample - loss: 0.0666 - mse: 0.0117 - mae: 0.0666 - mape: 12.5915\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 440us/sample - loss: 0.0653 - mse: 0.0116 - mae: 0.0653 - mape: 12.4088\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 375us/sample - loss: 0.0639 - mse: 0.0115 - mae: 0.0639 - mape: 12.2201\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 394us/sample - loss: 0.0625 - mse: 0.0115 - mae: 0.0625 - mape: 11.9584\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 443us/sample - loss: 0.0610 - mse: 0.0115 - mae: 0.0610 - mape: 11.6454\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 454us/sample - loss: 0.0596 - mse: 0.0115 - mae: 0.0596 - mape: 11.3775\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 477us/sample - loss: 0.0581 - mse: 0.0116 - mae: 0.0581 - mape: 11.0715\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 453us/sample - loss: 0.0567 - mse: 0.0116 - mae: 0.0567 - mape: 10.7905\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 429us/sample - loss: 0.0552 - mse: 0.0117 - mae: 0.0552 - mape: 10.5052\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 390us/sample - loss: 0.0539 - mse: 0.0118 - mae: 0.0539 - mape: 10.2493\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 378us/sample - loss: 0.0524 - mse: 0.0118 - mae: 0.0524 - mape: 10.0215\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 359us/sample - loss: 0.0510 - mse: 0.0119 - mae: 0.0510 - mape: 9.6829\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.0498 - mse: 0.0118 - mae: 0.0498 - mape: 9.6168\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 383us/sample - loss: 0.0486 - mse: 0.0120 - mae: 0.0486 - mape: 9.3788\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 364us/sample - loss: 0.0478 - mse: 0.0120 - mae: 0.0478 - mape: 9.3234\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 361us/sample - loss: 0.0474 - mse: 0.0120 - mae: 0.0474 - mape: 9.3103\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 450us/sample - loss: 0.0472 - mse: 0.0121 - mae: 0.0472 - mape: 9.3167\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 405us/sample - loss: 0.0469 - mse: 0.0121 - mae: 0.0469 - mape: 9.2768\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 345us/sample - loss: 0.0468 - mse: 0.0122 - mae: 0.0468 - mape: 9.2773\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 372us/sample - loss: 0.0466 - mse: 0.0122 - mae: 0.0466 - mape: 9.2894\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 370us/sample - loss: 0.0466 - mse: 0.0122 - mae: 0.0466 - mape: 9.2936\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 408us/sample - loss: 0.0467 - mse: 0.0122 - mae: 0.0467 - mape: 9.3579\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 379us/sample - loss: 0.0465 - mse: 0.0122 - mae: 0.0465 - mape: 9.3510\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.0464 - mse: 0.0123 - mae: 0.0464 - mape: 9.3266\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 362us/sample - loss: 0.0467 - mse: 0.0123 - mae: 0.0467 - mape: 9.4559\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 398us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.3823\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 410us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.3975\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 393us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.3985\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 489us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.4290\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 425us/sample - loss: 0.0463 - mse: 0.0125 - mae: 0.0463 - mape: 9.4134\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 398us/sample - loss: 0.0463 - mse: 0.0125 - mae: 0.0463 - mape: 9.4406\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 375us/sample - loss: 0.0462 - mse: 0.0125 - mae: 0.0462 - mape: 9.4353\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 392us/sample - loss: 0.0462 - mse: 0.0125 - mae: 0.0462 - mape: 9.4207\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 377us/sample - loss: 0.0463 - mse: 0.0125 - mae: 0.0463 - mape: 9.4762\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 363us/sample - loss: 0.0463 - mse: 0.0126 - mae: 0.0463 - mape: 9.4591\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 395us/sample - loss: 0.0462 - mse: 0.0125 - mae: 0.0462 - mape: 9.4764\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 383us/sample - loss: 0.0463 - mse: 0.0125 - mae: 0.0463 - mape: 9.4870\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 389us/sample - loss: 0.0462 - mse: 0.0126 - mae: 0.0462 - mape: 9.4680\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 757us/sample - loss: 0.4746 - accuracy: 0.9231\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "          train       test\n",
      "MAE    0.114296   0.120937\n",
      "MSE    0.057219   0.061890\n",
      "MAPE  16.207068  17.422886\n",
      "     L-time     P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.062571  15.049183           2400  4804.225  0.941         1\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.125\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 2.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/2Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 168 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "168/168 [==============================] - 0s 2ms/sample - loss: 0.5443 - mse: 0.3097 - mae: 0.5443 - mape: 109.7395\n",
      "Epoch 2/100\n",
      "168/168 [==============================] - 0s 251us/sample - loss: 0.5382 - mse: 0.3031 - mae: 0.5382 - mape: 108.4511\n",
      "Epoch 3/100\n",
      "168/168 [==============================] - 0s 229us/sample - loss: 0.5320 - mse: 0.2966 - mae: 0.5320 - mape: 107.1523\n",
      "Epoch 4/100\n",
      "168/168 [==============================] - 0s 194us/sample - loss: 0.5259 - mse: 0.2901 - mae: 0.5259 - mape: 105.8551\n",
      "Epoch 5/100\n",
      "168/168 [==============================] - 0s 263us/sample - loss: 0.5198 - mse: 0.2837 - mae: 0.5198 - mape: 104.5677\n",
      "Epoch 6/100\n",
      "168/168 [==============================] - 0s 211us/sample - loss: 0.5136 - mse: 0.2774 - mae: 0.5136 - mape: 103.2772\n",
      "Epoch 7/100\n",
      "168/168 [==============================] - 0s 210us/sample - loss: 0.5075 - mse: 0.2712 - mae: 0.5075 - mape: 101.9677\n",
      "Epoch 8/100\n",
      "168/168 [==============================] - 0s 281us/sample - loss: 0.5014 - mse: 0.2650 - mae: 0.5014 - mape: 100.6681\n",
      "Epoch 9/100\n",
      "168/168 [==============================] - 0s 216us/sample - loss: 0.4952 - mse: 0.2589 - mae: 0.4952 - mape: 99.3761\n",
      "Epoch 10/100\n",
      "168/168 [==============================] - 0s 205us/sample - loss: 0.4890 - mse: 0.2529 - mae: 0.4890 - mape: 98.0717\n",
      "Epoch 11/100\n",
      "168/168 [==============================] - 0s 254us/sample - loss: 0.4829 - mse: 0.2469 - mae: 0.4829 - mape: 96.7743\n",
      "Epoch 12/100\n",
      "168/168 [==============================] - 0s 402us/sample - loss: 0.4767 - mse: 0.2411 - mae: 0.4767 - mape: 95.4589\n",
      "Epoch 13/100\n",
      "168/168 [==============================] - 0s 467us/sample - loss: 0.4705 - mse: 0.2353 - mae: 0.4705 - mape: 94.1617\n",
      "Epoch 14/100\n",
      "168/168 [==============================] - 0s 363us/sample - loss: 0.4643 - mse: 0.2295 - mae: 0.4643 - mape: 92.8503\n",
      "Epoch 15/100\n",
      "168/168 [==============================] - 0s 262us/sample - loss: 0.4581 - mse: 0.2238 - mae: 0.4581 - mape: 91.5389\n",
      "Epoch 16/100\n",
      "168/168 [==============================] - 0s 210us/sample - loss: 0.4519 - mse: 0.2182 - mae: 0.4519 - mape: 90.2134\n",
      "Epoch 17/100\n",
      "168/168 [==============================] - 0s 206us/sample - loss: 0.4457 - mse: 0.2127 - mae: 0.4457 - mape: 88.9016\n",
      "Epoch 18/100\n",
      "168/168 [==============================] - 0s 252us/sample - loss: 0.4394 - mse: 0.2071 - mae: 0.4394 - mape: 87.5876\n",
      "Epoch 19/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.4331 - mse: 0.2017 - mae: 0.4331 - mape: 86.2467\n",
      "Epoch 20/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.4268 - mse: 0.1963 - mae: 0.4268 - mape: 84.9266\n",
      "Epoch 21/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.4205 - mse: 0.1910 - mae: 0.4205 - mape: 83.5964\n",
      "Epoch 22/100\n",
      "168/168 [==============================] - 0s 217us/sample - loss: 0.4142 - mse: 0.1858 - mae: 0.4142 - mape: 82.2444\n",
      "Epoch 23/100\n",
      "168/168 [==============================] - 0s 197us/sample - loss: 0.4078 - mse: 0.1806 - mae: 0.4078 - mape: 80.8941\n",
      "Epoch 24/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.4014 - mse: 0.1755 - mae: 0.4014 - mape: 79.5527\n",
      "Epoch 25/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.3950 - mse: 0.1704 - mae: 0.3950 - mape: 78.2036\n",
      "Epoch 26/100\n",
      "168/168 [==============================] - 0s 328us/sample - loss: 0.3886 - mse: 0.1654 - mae: 0.3886 - mape: 76.8448\n",
      "Epoch 27/100\n",
      "168/168 [==============================] - 0s 452us/sample - loss: 0.3822 - mse: 0.1605 - mae: 0.3822 - mape: 75.4792\n",
      "Epoch 28/100\n",
      "168/168 [==============================] - 0s 227us/sample - loss: 0.3757 - mse: 0.1556 - mae: 0.3757 - mape: 74.1044\n",
      "Epoch 29/100\n",
      "168/168 [==============================] - 0s 244us/sample - loss: 0.3691 - mse: 0.1508 - mae: 0.3691 - mape: 72.7219\n",
      "Epoch 30/100\n",
      "168/168 [==============================] - 0s 220us/sample - loss: 0.3626 - mse: 0.1460 - mae: 0.3626 - mape: 71.3507\n",
      "Epoch 31/100\n",
      "168/168 [==============================] - 0s 218us/sample - loss: 0.3560 - mse: 0.1414 - mae: 0.3560 - mape: 69.9496\n",
      "Epoch 32/100\n",
      "168/168 [==============================] - 0s 275us/sample - loss: 0.3494 - mse: 0.1367 - mae: 0.3494 - mape: 68.5455\n",
      "Epoch 33/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.3427 - mse: 0.1321 - mae: 0.3427 - mape: 67.1511\n",
      "Epoch 34/100\n",
      "168/168 [==============================] - 0s 210us/sample - loss: 0.3361 - mse: 0.1277 - mae: 0.3361 - mape: 65.7300\n",
      "Epoch 35/100\n",
      "168/168 [==============================] - 0s 218us/sample - loss: 0.3293 - mse: 0.1233 - mae: 0.3293 - mape: 64.3122\n",
      "Epoch 36/100\n",
      "168/168 [==============================] - 0s 260us/sample - loss: 0.3226 - mse: 0.1189 - mae: 0.3226 - mape: 62.8951\n",
      "Epoch 37/100\n",
      "168/168 [==============================] - 0s 249us/sample - loss: 0.3158 - mse: 0.1146 - mae: 0.3158 - mape: 61.4444\n",
      "Epoch 38/100\n",
      "168/168 [==============================] - 0s 213us/sample - loss: 0.3090 - mse: 0.1104 - mae: 0.3090 - mape: 60.0104\n",
      "Epoch 39/100\n",
      "168/168 [==============================] - 0s 246us/sample - loss: 0.3021 - mse: 0.1062 - mae: 0.3021 - mape: 58.5629\n",
      "Epoch 40/100\n",
      "168/168 [==============================] - 0s 286us/sample - loss: 0.2952 - mse: 0.1022 - mae: 0.2952 - mape: 57.0969\n",
      "Epoch 41/100\n",
      "168/168 [==============================] - 0s 236us/sample - loss: 0.2883 - mse: 0.0982 - mae: 0.2883 - mape: 55.6354\n",
      "Epoch 42/100\n",
      "168/168 [==============================] - 0s 275us/sample - loss: 0.2813 - mse: 0.0943 - mae: 0.2813 - mape: 54.1567\n",
      "Epoch 43/100\n",
      "168/168 [==============================] - 0s 236us/sample - loss: 0.2743 - mse: 0.0904 - mae: 0.2743 - mape: 52.6706\n",
      "Epoch 44/100\n",
      "168/168 [==============================] - 0s 260us/sample - loss: 0.2672 - mse: 0.0866 - mae: 0.2672 - mape: 51.1784\n",
      "Epoch 45/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.2601 - mse: 0.0829 - mae: 0.2601 - mape: 49.6713\n",
      "Epoch 46/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.2529 - mse: 0.0793 - mae: 0.2529 - mape: 48.1539\n",
      "Epoch 47/100\n",
      "168/168 [==============================] - 0s 276us/sample - loss: 0.2457 - mse: 0.0757 - mae: 0.2457 - mape: 46.6405\n",
      "Epoch 48/100\n",
      "168/168 [==============================] - 0s 245us/sample - loss: 0.2384 - mse: 0.0723 - mae: 0.2384 - mape: 45.0937\n",
      "Epoch 49/100\n",
      "168/168 [==============================] - 0s 210us/sample - loss: 0.2311 - mse: 0.0689 - mae: 0.2311 - mape: 43.5564\n",
      "Epoch 50/100\n",
      "168/168 [==============================] - 0s 215us/sample - loss: 0.2238 - mse: 0.0656 - mae: 0.2238 - mape: 42.0043\n",
      "Epoch 51/100\n",
      "168/168 [==============================] - 0s 282us/sample - loss: 0.2163 - mse: 0.0624 - mae: 0.2163 - mape: 40.4297\n",
      "Epoch 52/100\n",
      "168/168 [==============================] - 0s 247us/sample - loss: 0.2089 - mse: 0.0592 - mae: 0.2089 - mape: 38.8801\n",
      "Epoch 53/100\n",
      "168/168 [==============================] - 0s 218us/sample - loss: 0.2014 - mse: 0.0563 - mae: 0.2014 - mape: 37.2748\n",
      "Epoch 54/100\n",
      "168/168 [==============================] - 0s 282us/sample - loss: 0.1938 - mse: 0.0534 - mae: 0.1938 - mape: 35.6650\n",
      "Epoch 55/100\n",
      "168/168 [==============================] - 0s 239us/sample - loss: 0.1862 - mse: 0.0506 - mae: 0.1862 - mape: 34.0583\n",
      "Epoch 56/100\n",
      "168/168 [==============================] - 0s 295us/sample - loss: 0.1786 - mse: 0.0478 - mae: 0.1786 - mape: 32.4400\n",
      "Epoch 57/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.1708 - mse: 0.0452 - mae: 0.1708 - mape: 30.8076\n",
      "Epoch 58/100\n",
      "168/168 [==============================] - 0s 298us/sample - loss: 0.1631 - mse: 0.0426 - mae: 0.1631 - mape: 29.1873\n",
      "Epoch 59/100\n",
      "168/168 [==============================] - 0s 283us/sample - loss: 0.1556 - mse: 0.0403 - mae: 0.1556 - mape: 27.5834\n",
      "Epoch 60/100\n",
      "168/168 [==============================] - 0s 310us/sample - loss: 0.1489 - mse: 0.0380 - mae: 0.1489 - mape: 26.2318\n",
      "Epoch 61/100\n",
      "168/168 [==============================] - 0s 213us/sample - loss: 0.1434 - mse: 0.0360 - mae: 0.1434 - mape: 25.1804\n",
      "Epoch 62/100\n",
      "168/168 [==============================] - 0s 279us/sample - loss: 0.1387 - mse: 0.0342 - mae: 0.1387 - mape: 24.2770\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 251us/sample - loss: 0.1347 - mse: 0.0326 - mae: 0.1347 - mape: 23.5345\n",
      "Epoch 64/100\n",
      "168/168 [==============================] - 0s 209us/sample - loss: 0.1311 - mse: 0.0313 - mae: 0.1311 - mape: 22.8828\n",
      "Epoch 65/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 0.1281 - mse: 0.0300 - mae: 0.1281 - mape: 22.3719\n",
      "Epoch 66/100\n",
      "168/168 [==============================] - 0s 268us/sample - loss: 0.1256 - mse: 0.0289 - mae: 0.1256 - mape: 21.9579\n",
      "Epoch 67/100\n",
      "168/168 [==============================] - 0s 219us/sample - loss: 0.1233 - mse: 0.0279 - mae: 0.1233 - mape: 21.5997\n",
      "Epoch 68/100\n",
      "168/168 [==============================] - 0s 276us/sample - loss: 0.1212 - mse: 0.0271 - mae: 0.1212 - mape: 21.2631\n",
      "Epoch 69/100\n",
      "168/168 [==============================] - 0s 273us/sample - loss: 0.1194 - mse: 0.0263 - mae: 0.1194 - mape: 20.9696\n",
      "Epoch 70/100\n",
      "168/168 [==============================] - 0s 222us/sample - loss: 0.1179 - mse: 0.0255 - mae: 0.1179 - mape: 20.7747\n",
      "Epoch 71/100\n",
      "168/168 [==============================] - 0s 280us/sample - loss: 0.1165 - mse: 0.0248 - mae: 0.1165 - mape: 20.5900\n",
      "Epoch 72/100\n",
      "168/168 [==============================] - 0s 245us/sample - loss: 0.1151 - mse: 0.0242 - mae: 0.1151 - mape: 20.4029\n",
      "Epoch 73/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.1140 - mse: 0.0236 - mae: 0.1140 - mape: 20.2669\n",
      "Epoch 74/100\n",
      "168/168 [==============================] - 0s 229us/sample - loss: 0.1130 - mse: 0.0231 - mae: 0.1130 - mape: 20.1544\n",
      "Epoch 75/100\n",
      "168/168 [==============================] - 0s 305us/sample - loss: 0.1120 - mse: 0.0226 - mae: 0.1120 - mape: 20.0389\n",
      "Epoch 76/100\n",
      "168/168 [==============================] - 0s 300us/sample - loss: 0.1112 - mse: 0.0222 - mae: 0.1112 - mape: 19.9474\n",
      "Epoch 77/100\n",
      "168/168 [==============================] - 0s 287us/sample - loss: 0.1105 - mse: 0.0218 - mae: 0.1105 - mape: 19.8795\n",
      "Epoch 78/100\n",
      "168/168 [==============================] - 0s 277us/sample - loss: 0.1099 - mse: 0.0215 - mae: 0.1099 - mape: 19.8175\n",
      "Epoch 79/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.1094 - mse: 0.0212 - mae: 0.1094 - mape: 19.7852\n",
      "Epoch 80/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.1089 - mse: 0.0209 - mae: 0.1089 - mape: 19.7451\n",
      "Epoch 81/100\n",
      "168/168 [==============================] - 0s 213us/sample - loss: 0.1085 - mse: 0.0207 - mae: 0.1085 - mape: 19.7189\n",
      "Epoch 82/100\n",
      "168/168 [==============================] - 0s 250us/sample - loss: 0.1081 - mse: 0.0204 - mae: 0.1081 - mape: 19.7017\n",
      "Epoch 83/100\n",
      "168/168 [==============================] - 0s 215us/sample - loss: 0.1078 - mse: 0.0202 - mae: 0.1078 - mape: 19.6897\n",
      "Epoch 84/100\n",
      "168/168 [==============================] - 0s 212us/sample - loss: 0.1076 - mse: 0.0201 - mae: 0.1076 - mape: 19.6967\n",
      "Epoch 85/100\n",
      "168/168 [==============================] - 0s 200us/sample - loss: 0.1073 - mse: 0.0199 - mae: 0.1073 - mape: 19.6741\n",
      "Epoch 86/100\n",
      "168/168 [==============================] - 0s 247us/sample - loss: 0.1071 - mse: 0.0198 - mae: 0.1071 - mape: 19.6672\n",
      "Epoch 87/100\n",
      "168/168 [==============================] - 0s 213us/sample - loss: 0.1069 - mse: 0.0197 - mae: 0.1069 - mape: 19.6536\n",
      "Epoch 88/100\n",
      "168/168 [==============================] - 0s 203us/sample - loss: 0.1067 - mse: 0.0196 - mae: 0.1067 - mape: 19.6448\n",
      "Epoch 89/100\n",
      "168/168 [==============================] - 0s 291us/sample - loss: 0.1065 - mse: 0.0194 - mae: 0.1065 - mape: 19.6340\n",
      "Epoch 90/100\n",
      "168/168 [==============================] - 0s 207us/sample - loss: 0.1063 - mse: 0.0193 - mae: 0.1063 - mape: 19.6322\n",
      "Epoch 91/100\n",
      "168/168 [==============================] - 0s 197us/sample - loss: 0.1061 - mse: 0.0191 - mae: 0.1061 - mape: 19.6353\n",
      "Epoch 92/100\n",
      "168/168 [==============================] - 0s 266us/sample - loss: 0.1058 - mse: 0.0190 - mae: 0.1058 - mape: 19.6333\n",
      "Epoch 93/100\n",
      "168/168 [==============================] - 0s 223us/sample - loss: 0.1056 - mse: 0.0189 - mae: 0.1056 - mape: 19.6141\n",
      "Epoch 94/100\n",
      "168/168 [==============================] - 0s 199us/sample - loss: 0.1054 - mse: 0.0187 - mae: 0.1054 - mape: 19.6136\n",
      "Epoch 95/100\n",
      "168/168 [==============================] - 0s 238us/sample - loss: 0.1051 - mse: 0.0186 - mae: 0.1051 - mape: 19.6101\n",
      "Epoch 96/100\n",
      "168/168 [==============================] - 0s 234us/sample - loss: 0.1049 - mse: 0.0185 - mae: 0.1049 - mape: 19.5995\n",
      "Epoch 97/100\n",
      "168/168 [==============================] - 0s 204us/sample - loss: 0.1047 - mse: 0.0184 - mae: 0.1047 - mape: 19.5885\n",
      "Epoch 98/100\n",
      "168/168 [==============================] - 0s 273us/sample - loss: 0.1045 - mse: 0.0183 - mae: 0.1045 - mape: 19.5880\n",
      "Epoch 99/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.1043 - mse: 0.0182 - mae: 0.1043 - mape: 19.5734\n",
      "Epoch 100/100\n",
      "168/168 [==============================] - 0s 227us/sample - loss: 0.1041 - mse: 0.0181 - mae: 0.1041 - mape: 19.5548\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/2Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 134 samples\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.6120 - mse: 0.3882 - mae: 0.6120 - mape: 102.0510\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 217us/sample - loss: 0.6072 - mse: 0.3824 - mae: 0.6072 - mape: 101.2130\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 228us/sample - loss: 0.6025 - mse: 0.3766 - mae: 0.6025 - mape: 100.3739\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 280us/sample - loss: 0.5977 - mse: 0.3709 - mae: 0.5977 - mape: 99.5287\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 233us/sample - loss: 0.5929 - mse: 0.3652 - mae: 0.5929 - mape: 98.6817\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 220us/sample - loss: 0.5882 - mse: 0.3595 - mae: 0.5882 - mape: 97.8447\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 261us/sample - loss: 0.5834 - mse: 0.3539 - mae: 0.5834 - mape: 97.0063\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 243us/sample - loss: 0.5786 - mse: 0.3484 - mae: 0.5786 - mape: 96.1557\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 220us/sample - loss: 0.5738 - mse: 0.3429 - mae: 0.5738 - mape: 95.2981\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 232us/sample - loss: 0.5690 - mse: 0.3374 - mae: 0.5690 - mape: 94.4638\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 214us/sample - loss: 0.5642 - mse: 0.3319 - mae: 0.5642 - mape: 93.6219\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 334us/sample - loss: 0.5594 - mse: 0.3265 - mae: 0.5594 - mape: 92.7651\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 286us/sample - loss: 0.5546 - mse: 0.3211 - mae: 0.5546 - mape: 91.9283\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.5498 - mse: 0.3158 - mae: 0.5498 - mape: 91.0659\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 300us/sample - loss: 0.5449 - mse: 0.3105 - mae: 0.5449 - mape: 90.2170\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 266us/sample - loss: 0.5401 - mse: 0.3053 - mae: 0.5401 - mape: 89.3580\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 254us/sample - loss: 0.5352 - mse: 0.3001 - mae: 0.5352 - mape: 88.5032\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 265us/sample - loss: 0.5304 - mse: 0.2949 - mae: 0.5304 - mape: 87.6454\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 330us/sample - loss: 0.5255 - mse: 0.2897 - mae: 0.5255 - mape: 86.7785\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 251us/sample - loss: 0.5206 - mse: 0.2846 - mae: 0.5206 - mape: 85.9213\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 333us/sample - loss: 0.5157 - mse: 0.2796 - mae: 0.5157 - mape: 85.0481\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 250us/sample - loss: 0.5108 - mse: 0.2745 - mae: 0.5108 - mape: 84.1827\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 223us/sample - loss: 0.5058 - mse: 0.2695 - mae: 0.5058 - mape: 83.3202\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 282us/sample - loss: 0.5009 - mse: 0.2645 - mae: 0.5009 - mape: 82.4488\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 262us/sample - loss: 0.4959 - mse: 0.2596 - mae: 0.4959 - mape: 81.5643\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.4910 - mse: 0.2547 - mae: 0.4910 - mape: 80.6921\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 269us/sample - loss: 0.4860 - mse: 0.2498 - mae: 0.4860 - mape: 79.8087\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 254us/sample - loss: 0.4809 - mse: 0.2450 - mae: 0.4809 - mape: 78.9166\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.4759 - mse: 0.2401 - mae: 0.4759 - mape: 78.0433\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 316us/sample - loss: 0.4709 - mse: 0.2353 - mae: 0.4709 - mape: 77.1455\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 439us/sample - loss: 0.4658 - mse: 0.2306 - mae: 0.4658 - mape: 76.2509\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 251us/sample - loss: 0.4607 - mse: 0.2258 - mae: 0.4607 - mape: 75.3693\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 223us/sample - loss: 0.4556 - mse: 0.2212 - mae: 0.4556 - mape: 74.4670\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 222us/sample - loss: 0.4505 - mse: 0.2165 - mae: 0.4505 - mape: 73.5606\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 228us/sample - loss: 0.4453 - mse: 0.2119 - mae: 0.4453 - mape: 72.6484\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 313us/sample - loss: 0.4402 - mse: 0.2074 - mae: 0.4402 - mape: 71.7272\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.4350 - mse: 0.2028 - mae: 0.4350 - mape: 70.8197\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 233us/sample - loss: 0.4298 - mse: 0.1984 - mae: 0.4298 - mape: 69.8915\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 326us/sample - loss: 0.4245 - mse: 0.1939 - mae: 0.4245 - mape: 68.9665\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.4193 - mse: 0.1894 - mae: 0.4193 - mape: 68.0509\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.4140 - mse: 0.1850 - mae: 0.4140 - mape: 67.1194\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 276us/sample - loss: 0.4087 - mse: 0.1807 - mae: 0.4087 - mape: 66.1796\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 273us/sample - loss: 0.4034 - mse: 0.1764 - mae: 0.4034 - mape: 65.2454\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.3980 - mse: 0.1721 - mae: 0.3980 - mape: 64.3013\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 254us/sample - loss: 0.3927 - mse: 0.1678 - mae: 0.3927 - mape: 63.3479\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 249us/sample - loss: 0.3872 - mse: 0.1636 - mae: 0.3872 - mape: 62.3952\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 304us/sample - loss: 0.3818 - mse: 0.1595 - mae: 0.3818 - mape: 61.4327\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 260us/sample - loss: 0.3764 - mse: 0.1553 - mae: 0.3764 - mape: 60.4668\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 234us/sample - loss: 0.3709 - mse: 0.1512 - mae: 0.3709 - mape: 59.5101\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 222us/sample - loss: 0.3654 - mse: 0.1472 - mae: 0.3654 - mape: 58.5284\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 298us/sample - loss: 0.3598 - mse: 0.1431 - mae: 0.3598 - mape: 57.5557\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 242us/sample - loss: 0.3543 - mse: 0.1392 - mae: 0.3543 - mape: 56.5731\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 222us/sample - loss: 0.3487 - mse: 0.1352 - mae: 0.3487 - mape: 55.5970\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 307us/sample - loss: 0.3430 - mse: 0.1314 - mae: 0.3430 - mape: 54.5874\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 286us/sample - loss: 0.3374 - mse: 0.1275 - mae: 0.3374 - mape: 53.5904\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 235us/sample - loss: 0.3317 - mse: 0.1237 - mae: 0.3317 - mape: 52.5872\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 311us/sample - loss: 0.3260 - mse: 0.1200 - mae: 0.3260 - mape: 51.5744\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 270us/sample - loss: 0.3202 - mse: 0.1162 - mae: 0.3202 - mape: 50.5726\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 231us/sample - loss: 0.3144 - mse: 0.1126 - mae: 0.3144 - mape: 49.5537\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 240us/sample - loss: 0.3086 - mse: 0.1089 - mae: 0.3086 - mape: 48.5309\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 295us/sample - loss: 0.3028 - mse: 0.1054 - mae: 0.3028 - mape: 47.4992\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 282us/sample - loss: 0.2969 - mse: 0.1019 - mae: 0.2969 - mape: 46.4430\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 258us/sample - loss: 0.2911 - mse: 0.0984 - mae: 0.2911 - mape: 45.4630\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 236us/sample - loss: 0.2859 - mse: 0.0950 - mae: 0.2859 - mape: 44.6270\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 342us/sample - loss: 0.2810 - mse: 0.0918 - mae: 0.2810 - mape: 43.8826\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 262us/sample - loss: 0.2763 - mse: 0.0888 - mae: 0.2763 - mape: 43.1975\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 265us/sample - loss: 0.2721 - mse: 0.0859 - mae: 0.2721 - mape: 42.6263\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 308us/sample - loss: 0.2678 - mse: 0.0832 - mae: 0.2678 - mape: 42.0161\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 258us/sample - loss: 0.2636 - mse: 0.0805 - mae: 0.2636 - mape: 41.4281\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 249us/sample - loss: 0.2594 - mse: 0.0779 - mae: 0.2594 - mape: 40.8389\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.2552 - mse: 0.0753 - mae: 0.2552 - mape: 40.2434\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 246us/sample - loss: 0.2510 - mse: 0.0728 - mae: 0.2510 - mape: 39.6576\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 284us/sample - loss: 0.2467 - mse: 0.0703 - mae: 0.2467 - mape: 39.0367\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 250us/sample - loss: 0.2423 - mse: 0.0677 - mae: 0.2423 - mape: 38.4232\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 228us/sample - loss: 0.2379 - mse: 0.0653 - mae: 0.2379 - mape: 37.8130\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 228us/sample - loss: 0.2334 - mse: 0.0628 - mae: 0.2334 - mape: 37.1781\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 330us/sample - loss: 0.2288 - mse: 0.0604 - mae: 0.2288 - mape: 36.5243\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 303us/sample - loss: 0.2244 - mse: 0.0580 - mae: 0.2244 - mape: 35.9177\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 270us/sample - loss: 0.2196 - mse: 0.0557 - mae: 0.2196 - mape: 35.2445\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.2150 - mse: 0.0534 - mae: 0.2150 - mape: 34.5986\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 235us/sample - loss: 0.2103 - mse: 0.0511 - mae: 0.2103 - mape: 33.9354\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 299us/sample - loss: 0.2057 - mse: 0.0490 - mae: 0.2057 - mape: 33.2928\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 274us/sample - loss: 0.2009 - mse: 0.0468 - mae: 0.2009 - mape: 32.6188\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 242us/sample - loss: 0.1962 - mse: 0.0447 - mae: 0.1962 - mape: 31.9525\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 314us/sample - loss: 0.1915 - mse: 0.0428 - mae: 0.1915 - mape: 31.3121\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 274us/sample - loss: 0.1868 - mse: 0.0409 - mae: 0.1868 - mape: 30.6350\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 263us/sample - loss: 0.1821 - mse: 0.0390 - mae: 0.1821 - mape: 29.9932\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 253us/sample - loss: 0.1772 - mse: 0.0371 - mae: 0.1772 - mape: 29.2970\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 324us/sample - loss: 0.1722 - mse: 0.0354 - mae: 0.1722 - mape: 28.5774\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 276us/sample - loss: 0.1674 - mse: 0.0336 - mae: 0.1674 - mape: 27.9191\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 245us/sample - loss: 0.1625 - mse: 0.0320 - mae: 0.1625 - mape: 27.2347\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 327us/sample - loss: 0.1575 - mse: 0.0304 - mae: 0.1575 - mape: 26.5309\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 262us/sample - loss: 0.1524 - mse: 0.0288 - mae: 0.1524 - mape: 25.8036\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 244us/sample - loss: 0.1473 - mse: 0.0274 - mae: 0.1473 - mape: 25.0928\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.1420 - mse: 0.0259 - mae: 0.1420 - mape: 24.3469\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 277us/sample - loss: 0.1373 - mse: 0.0246 - mae: 0.1373 - mape: 23.7020\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.1326 - mse: 0.0233 - mae: 0.1326 - mape: 23.0885\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 250us/sample - loss: 0.1280 - mse: 0.0221 - mae: 0.1280 - mape: 22.4491\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 229us/sample - loss: 0.1240 - mse: 0.0212 - mae: 0.1240 - mape: 21.9276\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 246us/sample - loss: 0.1204 - mse: 0.0202 - mae: 0.1204 - mape: 21.4799\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 859us/sample - loss: 0.6933 - accuracy: 0.5000\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "          train       test\n",
      "MAE    0.408407   0.408401\n",
      "MSE    0.219705   0.222832\n",
      "MAPE  42.265277  42.173135\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.389488  7.547385           2400  4801.791  3.179         2\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.25\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "Final Loop\n",
      "breaking early\n",
      "The_parts_listhe number of parts are: 3.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 174 samples\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 0s 2ms/sample - loss: 0.5520 - mse: 0.3180 - mae: 0.5520 - mape: 110.7847\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 0s 206us/sample - loss: 0.5510 - mse: 0.3169 - mae: 0.5510 - mape: 110.5812\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 0s 167us/sample - loss: 0.5500 - mse: 0.3159 - mae: 0.5500 - mape: 110.3787\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 0s 159us/sample - loss: 0.5491 - mse: 0.3148 - mae: 0.5491 - mape: 110.1754\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 0s 183us/sample - loss: 0.5481 - mse: 0.3137 - mae: 0.5481 - mape: 109.9750\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 0s 175us/sample - loss: 0.5471 - mse: 0.3127 - mae: 0.5471 - mape: 109.7690\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 0s 196us/sample - loss: 0.5462 - mse: 0.3116 - mae: 0.5462 - mape: 109.5654\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 0s 159us/sample - loss: 0.5452 - mse: 0.3106 - mae: 0.5452 - mape: 109.3651\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 0s 170us/sample - loss: 0.5442 - mse: 0.3095 - mae: 0.5442 - mape: 109.1588\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 0s 134us/sample - loss: 0.5433 - mse: 0.3085 - mae: 0.5433 - mape: 108.9559\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 0s 178us/sample - loss: 0.5423 - mse: 0.3074 - mae: 0.5423 - mape: 108.7535\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 0s 137us/sample - loss: 0.5413 - mse: 0.3064 - mae: 0.5413 - mape: 108.5488\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 0s 170us/sample - loss: 0.5404 - mse: 0.3053 - mae: 0.5404 - mape: 108.3432\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.5394 - mse: 0.3043 - mae: 0.5394 - mape: 108.1373\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 0s 176us/sample - loss: 0.5384 - mse: 0.3032 - mae: 0.5384 - mape: 107.9333\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 0s 139us/sample - loss: 0.5374 - mse: 0.3022 - mae: 0.5374 - mape: 107.7283\n",
      "Epoch 17/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.5364 - mse: 0.3011 - mae: 0.5364 - mape: 107.5230\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 0s 131us/sample - loss: 0.5355 - mse: 0.3001 - mae: 0.5355 - mape: 107.3170\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.5345 - mse: 0.2990 - mae: 0.5345 - mape: 107.1089\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 0s 162us/sample - loss: 0.5335 - mse: 0.2980 - mae: 0.5335 - mape: 106.9036\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 0s 154us/sample - loss: 0.5325 - mse: 0.2969 - mae: 0.5325 - mape: 106.6961\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 0s 156us/sample - loss: 0.5315 - mse: 0.2959 - mae: 0.5315 - mape: 106.4882\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.5305 - mse: 0.2949 - mae: 0.5305 - mape: 106.2788\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 0s 168us/sample - loss: 0.5295 - mse: 0.2938 - mae: 0.5295 - mape: 106.0697\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 0s 144us/sample - loss: 0.5285 - mse: 0.2927 - mae: 0.5285 - mape: 105.8625\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 0s 163us/sample - loss: 0.5275 - mse: 0.2917 - mae: 0.5275 - mape: 105.6514\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 0s 161us/sample - loss: 0.5265 - mse: 0.2906 - mae: 0.5265 - mape: 105.4415\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 174us/sample - loss: 0.5255 - mse: 0.2896 - mae: 0.5255 - mape: 105.2292\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 0s 173us/sample - loss: 0.5245 - mse: 0.2885 - mae: 0.5245 - mape: 105.0177\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 0s 152us/sample - loss: 0.5235 - mse: 0.2875 - mae: 0.5235 - mape: 104.8049\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 0s 145us/sample - loss: 0.5225 - mse: 0.2864 - mae: 0.5225 - mape: 104.5943\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.5215 - mse: 0.2854 - mae: 0.5215 - mape: 104.3804\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 0s 128us/sample - loss: 0.5205 - mse: 0.2843 - mae: 0.5205 - mape: 104.1671\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 0s 147us/sample - loss: 0.5194 - mse: 0.2832 - mae: 0.5194 - mape: 103.9524\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 0s 177us/sample - loss: 0.5184 - mse: 0.2822 - mae: 0.5184 - mape: 103.7371\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 0s 166us/sample - loss: 0.5174 - mse: 0.2811 - mae: 0.5174 - mape: 103.5214\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 0s 154us/sample - loss: 0.5163 - mse: 0.2801 - mae: 0.5163 - mape: 103.3030\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 0s 160us/sample - loss: 0.5153 - mse: 0.2790 - mae: 0.5153 - mape: 103.0867\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 0s 179us/sample - loss: 0.5143 - mse: 0.2779 - mae: 0.5143 - mape: 102.8667\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 0s 137us/sample - loss: 0.5132 - mse: 0.2769 - mae: 0.5132 - mape: 102.6478\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 0s 129us/sample - loss: 0.5122 - mse: 0.2758 - mae: 0.5122 - mape: 102.4282\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 0s 123us/sample - loss: 0.5111 - mse: 0.2748 - mae: 0.5111 - mape: 102.2058\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 0s 164us/sample - loss: 0.5101 - mse: 0.2737 - mae: 0.5101 - mape: 101.9885\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 0s 192us/sample - loss: 0.5090 - mse: 0.2726 - mae: 0.5090 - mape: 101.7639\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 0s 150us/sample - loss: 0.5080 - mse: 0.2715 - mae: 0.5080 - mape: 101.5405\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 0s 138us/sample - loss: 0.5069 - mse: 0.2704 - mae: 0.5069 - mape: 101.3181\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 0s 193us/sample - loss: 0.5058 - mse: 0.2694 - mae: 0.5058 - mape: 101.0923\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.5048 - mse: 0.2683 - mae: 0.5048 - mape: 100.8672\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 0s 160us/sample - loss: 0.5037 - mse: 0.2672 - mae: 0.5037 - mape: 100.6426\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.5026 - mse: 0.2661 - mae: 0.5026 - mape: 100.4165\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.5015 - mse: 0.2651 - mae: 0.5015 - mape: 100.1840\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 0s 194us/sample - loss: 0.5004 - mse: 0.2640 - mae: 0.5004 - mape: 99.9564\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 0s 141us/sample - loss: 0.4993 - mse: 0.2629 - mae: 0.4993 - mape: 99.7251\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 0s 171us/sample - loss: 0.4982 - mse: 0.2618 - mae: 0.4982 - mape: 99.4960\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 0s 132us/sample - loss: 0.4971 - mse: 0.2607 - mae: 0.4971 - mape: 99.2641\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 0s 170us/sample - loss: 0.4960 - mse: 0.2596 - mae: 0.4960 - mape: 99.0325\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 0s 141us/sample - loss: 0.4949 - mse: 0.2585 - mae: 0.4949 - mape: 98.7986\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 0s 171us/sample - loss: 0.4938 - mse: 0.2574 - mae: 0.4938 - mape: 98.5649\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 0s 136us/sample - loss: 0.4927 - mse: 0.2563 - mae: 0.4927 - mape: 98.3281\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 0s 123us/sample - loss: 0.4915 - mse: 0.2552 - mae: 0.4915 - mape: 98.0915\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 0s 139us/sample - loss: 0.4904 - mse: 0.2541 - mae: 0.4904 - mape: 97.8551\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 0s 178us/sample - loss: 0.4893 - mse: 0.2530 - mae: 0.4893 - mape: 97.6141\n",
      "Epoch 63/100\n",
      "174/174 [==============================] - 0s 149us/sample - loss: 0.4881 - mse: 0.2519 - mae: 0.4881 - mape: 97.3765\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 0s 147us/sample - loss: 0.4870 - mse: 0.2508 - mae: 0.4870 - mape: 97.1357\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.4858 - mse: 0.2496 - mae: 0.4858 - mape: 96.8930\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 0s 193us/sample - loss: 0.4847 - mse: 0.2485 - mae: 0.4847 - mape: 96.6488\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.4835 - mse: 0.2474 - mae: 0.4835 - mape: 96.4053\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 0s 168us/sample - loss: 0.4823 - mse: 0.2463 - mae: 0.4823 - mape: 96.1593\n",
      "Epoch 69/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.4812 - mse: 0.2452 - mae: 0.4812 - mape: 95.9147\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.4800 - mse: 0.2440 - mae: 0.4800 - mape: 95.6665\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 0s 162us/sample - loss: 0.4788 - mse: 0.2429 - mae: 0.4788 - mape: 95.4158\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 0s 196us/sample - loss: 0.4776 - mse: 0.2418 - mae: 0.4776 - mape: 95.1653\n",
      "Epoch 73/100\n",
      "174/174 [==============================] - 0s 145us/sample - loss: 0.4764 - mse: 0.2406 - mae: 0.4764 - mape: 94.9139\n",
      "Epoch 74/100\n",
      "174/174 [==============================] - 0s 168us/sample - loss: 0.4752 - mse: 0.2395 - mae: 0.4752 - mape: 94.6613\n",
      "Epoch 75/100\n",
      "174/174 [==============================] - 0s 124us/sample - loss: 0.4740 - mse: 0.2384 - mae: 0.4740 - mape: 94.4088\n",
      "Epoch 76/100\n",
      "174/174 [==============================] - 0s 177us/sample - loss: 0.4728 - mse: 0.2372 - mae: 0.4728 - mape: 94.1517\n",
      "Epoch 77/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.4716 - mse: 0.2361 - mae: 0.4716 - mape: 93.8938\n",
      "Epoch 78/100\n",
      "174/174 [==============================] - 0s 151us/sample - loss: 0.4703 - mse: 0.2349 - mae: 0.4703 - mape: 93.6369\n",
      "Epoch 79/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.4691 - mse: 0.2338 - mae: 0.4691 - mape: 93.3761\n",
      "Epoch 80/100\n",
      "174/174 [==============================] - 0s 175us/sample - loss: 0.4679 - mse: 0.2326 - mae: 0.4679 - mape: 93.1160\n",
      "Epoch 81/100\n",
      "174/174 [==============================] - 0s 157us/sample - loss: 0.4666 - mse: 0.2314 - mae: 0.4666 - mape: 92.8549\n",
      "Epoch 82/100\n",
      "174/174 [==============================] - 0s 161us/sample - loss: 0.4653 - mse: 0.2303 - mae: 0.4653 - mape: 92.5920\n",
      "Epoch 83/100\n",
      "174/174 [==============================] - 0s 136us/sample - loss: 0.4641 - mse: 0.2291 - mae: 0.4641 - mape: 92.3263\n",
      "Epoch 84/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.4628 - mse: 0.2280 - mae: 0.4628 - mape: 92.0582\n",
      "Epoch 85/100\n",
      "174/174 [==============================] - 0s 135us/sample - loss: 0.4615 - mse: 0.2268 - mae: 0.4615 - mape: 91.7920\n",
      "Epoch 86/100\n",
      "174/174 [==============================] - 0s 196us/sample - loss: 0.4603 - mse: 0.2256 - mae: 0.4603 - mape: 91.5215\n",
      "Epoch 87/100\n",
      "174/174 [==============================] - 0s 151us/sample - loss: 0.4590 - mse: 0.2244 - mae: 0.4590 - mape: 91.2542\n",
      "Epoch 88/100\n",
      "174/174 [==============================] - 0s 161us/sample - loss: 0.4577 - mse: 0.2233 - mae: 0.4577 - mape: 90.9787\n",
      "Epoch 89/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.4564 - mse: 0.2221 - mae: 0.4564 - mape: 90.7056\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 148us/sample - loss: 0.4551 - mse: 0.2209 - mae: 0.4551 - mape: 90.4315\n",
      "Epoch 91/100\n",
      "174/174 [==============================] - 0s 250us/sample - loss: 0.4537 - mse: 0.2197 - mae: 0.4537 - mape: 90.1530\n",
      "Epoch 92/100\n",
      "174/174 [==============================] - 0s 151us/sample - loss: 0.4524 - mse: 0.2185 - mae: 0.4524 - mape: 89.8743\n",
      "Epoch 93/100\n",
      "174/174 [==============================] - 0s 136us/sample - loss: 0.4511 - mse: 0.2173 - mae: 0.4511 - mape: 89.5967\n",
      "Epoch 94/100\n",
      "174/174 [==============================] - 0s 128us/sample - loss: 0.4498 - mse: 0.2161 - mae: 0.4498 - mape: 89.3131\n",
      "Epoch 95/100\n",
      "174/174 [==============================] - 0s 122us/sample - loss: 0.4484 - mse: 0.2149 - mae: 0.4484 - mape: 89.0328\n",
      "Epoch 96/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.4471 - mse: 0.2137 - mae: 0.4471 - mape: 88.7479\n",
      "Epoch 97/100\n",
      "174/174 [==============================] - 0s 168us/sample - loss: 0.4457 - mse: 0.2125 - mae: 0.4457 - mape: 88.4651\n",
      "Epoch 98/100\n",
      "174/174 [==============================] - 0s 139us/sample - loss: 0.4443 - mse: 0.2113 - mae: 0.4443 - mape: 88.1743\n",
      "Epoch 99/100\n",
      "174/174 [==============================] - 0s 136us/sample - loss: 0.4430 - mse: 0.2101 - mae: 0.4430 - mape: 87.8865\n",
      "Epoch 100/100\n",
      "174/174 [==============================] - 0s 126us/sample - loss: 0.4416 - mse: 0.2089 - mae: 0.4416 - mape: 87.5958\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 145 samples\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 0s 2ms/sample - loss: 0.5593 - mse: 0.3367 - mae: 0.5593 - mape: 99.2301\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 194us/sample - loss: 0.5585 - mse: 0.3359 - mae: 0.5585 - mape: 99.0800\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5578 - mse: 0.3350 - mae: 0.5578 - mape: 98.9324\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 156us/sample - loss: 0.5570 - mse: 0.3342 - mae: 0.5570 - mape: 98.7795\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 131us/sample - loss: 0.5563 - mse: 0.3333 - mae: 0.5563 - mape: 98.6282\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5555 - mse: 0.3325 - mae: 0.5555 - mape: 98.4794\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 162us/sample - loss: 0.5547 - mse: 0.3316 - mae: 0.5547 - mape: 98.3272\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 137us/sample - loss: 0.5540 - mse: 0.3308 - mae: 0.5540 - mape: 98.1789\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.5532 - mse: 0.3299 - mae: 0.5532 - mape: 98.0238\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 147us/sample - loss: 0.5525 - mse: 0.3291 - mae: 0.5525 - mape: 97.8703\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 151us/sample - loss: 0.5517 - mse: 0.3282 - mae: 0.5517 - mape: 97.7228\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 204us/sample - loss: 0.5509 - mse: 0.3274 - mae: 0.5509 - mape: 97.5689\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 163us/sample - loss: 0.5502 - mse: 0.3266 - mae: 0.5502 - mape: 97.4175\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 158us/sample - loss: 0.5494 - mse: 0.3257 - mae: 0.5494 - mape: 97.2658\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5486 - mse: 0.3249 - mae: 0.5486 - mape: 97.1135\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 170us/sample - loss: 0.5479 - mse: 0.3240 - mae: 0.5479 - mape: 96.9637\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 186us/sample - loss: 0.5471 - mse: 0.3232 - mae: 0.5471 - mape: 96.8108\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5463 - mse: 0.3224 - mae: 0.5463 - mape: 96.6583\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 169us/sample - loss: 0.5456 - mse: 0.3215 - mae: 0.5456 - mape: 96.5056\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 145us/sample - loss: 0.5448 - mse: 0.3207 - mae: 0.5448 - mape: 96.3528\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 147us/sample - loss: 0.5440 - mse: 0.3198 - mae: 0.5440 - mape: 96.2035\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 211us/sample - loss: 0.5433 - mse: 0.3190 - mae: 0.5433 - mape: 96.0480\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 178us/sample - loss: 0.5425 - mse: 0.3182 - mae: 0.5425 - mape: 95.8931\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 0s 179us/sample - loss: 0.5417 - mse: 0.3173 - mae: 0.5417 - mape: 95.7408\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5410 - mse: 0.3165 - mae: 0.5410 - mape: 95.5859\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 140us/sample - loss: 0.5402 - mse: 0.3156 - mae: 0.5402 - mape: 95.4304\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 151us/sample - loss: 0.5394 - mse: 0.3148 - mae: 0.5394 - mape: 95.2782\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 224us/sample - loss: 0.5386 - mse: 0.3140 - mae: 0.5386 - mape: 95.1244\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 188us/sample - loss: 0.5378 - mse: 0.3131 - mae: 0.5378 - mape: 94.9705\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5371 - mse: 0.3123 - mae: 0.5371 - mape: 94.8166\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.5363 - mse: 0.3114 - mae: 0.5363 - mape: 94.6603\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 217us/sample - loss: 0.5355 - mse: 0.3106 - mae: 0.5355 - mape: 94.5056\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 185us/sample - loss: 0.5347 - mse: 0.3098 - mae: 0.5347 - mape: 94.3500\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 165us/sample - loss: 0.5339 - mse: 0.3089 - mae: 0.5339 - mape: 94.1958\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 146us/sample - loss: 0.5331 - mse: 0.3081 - mae: 0.5331 - mape: 94.0367\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 160us/sample - loss: 0.5324 - mse: 0.3072 - mae: 0.5324 - mape: 93.8796\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 0s 157us/sample - loss: 0.5316 - mse: 0.3064 - mae: 0.5316 - mape: 93.7230\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 218us/sample - loss: 0.5308 - mse: 0.3056 - mae: 0.5308 - mape: 93.5629\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5300 - mse: 0.3047 - mae: 0.5300 - mape: 93.4078\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 0s 162us/sample - loss: 0.5292 - mse: 0.3038 - mae: 0.5292 - mape: 93.2524\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 0s 192us/sample - loss: 0.5284 - mse: 0.3030 - mae: 0.5284 - mape: 93.0915\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 206us/sample - loss: 0.5276 - mse: 0.3022 - mae: 0.5276 - mape: 92.9342\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 0s 172us/sample - loss: 0.5268 - mse: 0.3013 - mae: 0.5268 - mape: 92.7758\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5260 - mse: 0.3005 - mae: 0.5260 - mape: 92.6159\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5252 - mse: 0.2996 - mae: 0.5252 - mape: 92.4547\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 141us/sample - loss: 0.5244 - mse: 0.2988 - mae: 0.5244 - mape: 92.2940\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 135us/sample - loss: 0.5236 - mse: 0.2979 - mae: 0.5236 - mape: 92.1358\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5228 - mse: 0.2971 - mae: 0.5228 - mape: 91.9741\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 153us/sample - loss: 0.5219 - mse: 0.2962 - mae: 0.5219 - mape: 91.8112\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 194us/sample - loss: 0.5211 - mse: 0.2954 - mae: 0.5211 - mape: 91.6509\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 146us/sample - loss: 0.5203 - mse: 0.2945 - mae: 0.5203 - mape: 91.4873\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 166us/sample - loss: 0.5195 - mse: 0.2937 - mae: 0.5195 - mape: 91.3237\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.5187 - mse: 0.2928 - mae: 0.5187 - mape: 91.1599\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 158us/sample - loss: 0.5178 - mse: 0.2919 - mae: 0.5178 - mape: 90.9977\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 187us/sample - loss: 0.5170 - mse: 0.2911 - mae: 0.5170 - mape: 90.8315\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 146us/sample - loss: 0.5162 - mse: 0.2902 - mae: 0.5162 - mape: 90.6687\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 156us/sample - loss: 0.5154 - mse: 0.2894 - mae: 0.5154 - mape: 90.5010\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 127us/sample - loss: 0.5145 - mse: 0.2885 - mae: 0.5145 - mape: 90.3370\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 146us/sample - loss: 0.5137 - mse: 0.2876 - mae: 0.5137 - mape: 90.1750\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 177us/sample - loss: 0.5128 - mse: 0.2868 - mae: 0.5128 - mape: 90.0057\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5120 - mse: 0.2859 - mae: 0.5120 - mape: 89.8405\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 148us/sample - loss: 0.5112 - mse: 0.2850 - mae: 0.5112 - mape: 89.6695\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5103 - mse: 0.2842 - mae: 0.5103 - mape: 89.5027\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 142us/sample - loss: 0.5095 - mse: 0.2833 - mae: 0.5095 - mape: 89.3296\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 161us/sample - loss: 0.5086 - mse: 0.2824 - mae: 0.5086 - mape: 89.1641\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 208us/sample - loss: 0.5077 - mse: 0.2816 - mae: 0.5077 - mape: 88.9942\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 176us/sample - loss: 0.5069 - mse: 0.2807 - mae: 0.5069 - mape: 88.8202\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 147us/sample - loss: 0.5060 - mse: 0.2798 - mae: 0.5060 - mape: 88.6530\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 136us/sample - loss: 0.5052 - mse: 0.2789 - mae: 0.5052 - mape: 88.4803\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5043 - mse: 0.2781 - mae: 0.5043 - mape: 88.3074\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 192us/sample - loss: 0.5034 - mse: 0.2772 - mae: 0.5034 - mape: 88.1372\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.5025 - mse: 0.2763 - mae: 0.5025 - mape: 87.9599\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 148us/sample - loss: 0.5017 - mse: 0.2754 - mae: 0.5017 - mape: 87.7856\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5008 - mse: 0.2745 - mae: 0.5008 - mape: 87.6155\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.4999 - mse: 0.2736 - mae: 0.4999 - mape: 87.4382\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 151us/sample - loss: 0.4990 - mse: 0.2728 - mae: 0.4990 - mape: 87.2606\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 190us/sample - loss: 0.4981 - mse: 0.2719 - mae: 0.4981 - mape: 87.0856\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 164us/sample - loss: 0.4972 - mse: 0.2710 - mae: 0.4972 - mape: 86.9125\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.5447 - mse: 0.3107 - mae: 0.5447 - mape: 88.378 - 0s 146us/sample - loss: 0.4963 - mse: 0.2701 - mae: 0.4963 - mape: 86.7297\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 148us/sample - loss: 0.4954 - mse: 0.2692 - mae: 0.4954 - mape: 86.5499\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 203us/sample - loss: 0.4945 - mse: 0.2683 - mae: 0.4945 - mape: 86.3729\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 164us/sample - loss: 0.4936 - mse: 0.2674 - mae: 0.4936 - mape: 86.1949\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.4927 - mse: 0.2665 - mae: 0.4927 - mape: 86.0131\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 138us/sample - loss: 0.4918 - mse: 0.2656 - mae: 0.4918 - mape: 85.8321\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 154us/sample - loss: 0.4909 - mse: 0.2647 - mae: 0.4909 - mape: 85.6526\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 219us/sample - loss: 0.4900 - mse: 0.2638 - mae: 0.4900 - mape: 85.4711\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 165us/sample - loss: 0.4891 - mse: 0.2629 - mae: 0.4891 - mape: 85.2846\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 145us/sample - loss: 0.4881 - mse: 0.2620 - mae: 0.4881 - mape: 85.1013\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 164us/sample - loss: 0.4872 - mse: 0.2611 - mae: 0.4872 - mape: 84.9142\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.4863 - mse: 0.2601 - mae: 0.4863 - mape: 84.7276\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 153us/sample - loss: 0.4853 - mse: 0.2592 - mae: 0.4853 - mape: 84.5437\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 195us/sample - loss: 0.4844 - mse: 0.2583 - mae: 0.4844 - mape: 84.3578\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 158us/sample - loss: 0.4834 - mse: 0.2574 - mae: 0.4834 - mape: 84.1695\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.4825 - mse: 0.2565 - mae: 0.4825 - mape: 83.9784\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 161us/sample - loss: 0.4815 - mse: 0.2555 - mae: 0.4815 - mape: 83.7895\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 186us/sample - loss: 0.4806 - mse: 0.2546 - mae: 0.4806 - mape: 83.6010\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 160us/sample - loss: 0.4796 - mse: 0.2537 - mae: 0.4796 - mape: 83.4094\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 165us/sample - loss: 0.4786 - mse: 0.2528 - mae: 0.4786 - mape: 83.2180\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 133us/sample - loss: 0.4777 - mse: 0.2518 - mae: 0.4777 - mape: 83.0251\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 143us/sample - loss: 0.4767 - mse: 0.2509 - mae: 0.4767 - mape: 82.8335\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 97 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 0s 4ms/sample - loss: 0.6184 - mse: 0.4984 - mae: 0.6184 - mape: 218.8141\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 157us/sample - loss: 0.6180 - mse: 0.4977 - mae: 0.6180 - mape: 220.6869\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 181us/sample - loss: 0.6176 - mse: 0.4969 - mae: 0.6176 - mape: 222.4439\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 168us/sample - loss: 0.6172 - mse: 0.4962 - mae: 0.6172 - mape: 224.5940\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 163us/sample - loss: 0.6169 - mse: 0.4954 - mae: 0.6169 - mape: 226.3898\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 188us/sample - loss: 0.6165 - mse: 0.4947 - mae: 0.6165 - mape: 228.4490\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 181us/sample - loss: 0.6161 - mse: 0.4940 - mae: 0.6161 - mape: 230.2017\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 264us/sample - loss: 0.6157 - mse: 0.4932 - mae: 0.6157 - mape: 232.0643\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.6154 - mse: 0.4925 - mae: 0.6154 - mape: 233.4701\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 193us/sample - loss: 0.6150 - mse: 0.4918 - mae: 0.6150 - mape: 235.2350\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 189us/sample - loss: 0.6147 - mse: 0.4911 - mae: 0.6147 - mape: 237.0883\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 153us/sample - loss: 0.6144 - mse: 0.4905 - mae: 0.6144 - mape: 238.3655\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 144us/sample - loss: 0.6141 - mse: 0.4899 - mae: 0.6141 - mape: 240.3301\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 155us/sample - loss: 0.6138 - mse: 0.4893 - mae: 0.6138 - mape: 241.2894\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 165us/sample - loss: 0.6136 - mse: 0.4887 - mae: 0.6136 - mape: 243.5359\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 176us/sample - loss: 0.6133 - mse: 0.4880 - mae: 0.6133 - mape: 245.4211\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 249us/sample - loss: 0.6130 - mse: 0.4875 - mae: 0.6130 - mape: 246.2838\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 157us/sample - loss: 0.6128 - mse: 0.4869 - mae: 0.6128 - mape: 247.8689\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 200us/sample - loss: 0.6126 - mse: 0.4865 - mae: 0.6126 - mape: 248.6636\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 275us/sample - loss: 0.6124 - mse: 0.4860 - mae: 0.6124 - mape: 250.0343\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 209us/sample - loss: 0.6121 - mse: 0.4854 - mae: 0.6121 - mape: 251.1590\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 206us/sample - loss: 0.6118 - mse: 0.4848 - mae: 0.6118 - mape: 252.6106\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 268us/sample - loss: 0.6116 - mse: 0.4843 - mae: 0.6116 - mape: 254.5158\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 184us/sample - loss: 0.6113 - mse: 0.4836 - mae: 0.6113 - mape: 255.8649\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 158us/sample - loss: 0.6110 - mse: 0.4831 - mae: 0.6110 - mape: 257.3830\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 166us/sample - loss: 0.6108 - mse: 0.4825 - mae: 0.6108 - mape: 258.7059\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 152us/sample - loss: 0.6105 - mse: 0.4819 - mae: 0.6105 - mape: 260.1839\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 184us/sample - loss: 0.6103 - mse: 0.4813 - mae: 0.6103 - mape: 262.3391\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 203us/sample - loss: 0.6100 - mse: 0.4807 - mae: 0.6100 - mape: 263.3912\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 169us/sample - loss: 0.6097 - mse: 0.4800 - mae: 0.6097 - mape: 265.3733\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 168us/sample - loss: 0.6094 - mse: 0.4794 - mae: 0.6094 - mape: 266.7774\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 176us/sample - loss: 0.6091 - mse: 0.4787 - mae: 0.6091 - mape: 269.1876\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 174us/sample - loss: 0.6088 - mse: 0.4781 - mae: 0.6088 - mape: 270.6582\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 152us/sample - loss: 0.6086 - mse: 0.4776 - mae: 0.6086 - mape: 271.4819\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 232us/sample - loss: 0.6084 - mse: 0.4770 - mae: 0.6084 - mape: 273.0460\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 257us/sample - loss: 0.6081 - mse: 0.4765 - mae: 0.6081 - mape: 274.4445\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 185us/sample - loss: 0.6079 - mse: 0.4760 - mae: 0.6079 - mape: 276.0069\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 176us/sample - loss: 0.6076 - mse: 0.4754 - mae: 0.6076 - mape: 277.4796\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 184us/sample - loss: 0.6073 - mse: 0.4748 - mae: 0.6073 - mape: 279.0316\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 145us/sample - loss: 0.6071 - mse: 0.4742 - mae: 0.6071 - mape: 280.3903\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 159us/sample - loss: 0.6068 - mse: 0.4735 - mae: 0.6068 - mape: 282.1216\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 230us/sample - loss: 0.6065 - mse: 0.4729 - mae: 0.6065 - mape: 284.2069\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.6062 - mse: 0.4723 - mae: 0.6062 - mape: 285.8757\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 194us/sample - loss: 0.6060 - mse: 0.4718 - mae: 0.6060 - mape: 287.0381\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 164us/sample - loss: 0.6057 - mse: 0.4712 - mae: 0.6057 - mape: 288.6208\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 140us/sample - loss: 0.6054 - mse: 0.4706 - mae: 0.6054 - mape: 290.5952\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 178us/sample - loss: 0.6051 - mse: 0.4699 - mae: 0.6051 - mape: 291.9917\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 260us/sample - loss: 0.6048 - mse: 0.4692 - mae: 0.6048 - mape: 293.6477\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 152us/sample - loss: 0.6045 - mse: 0.4686 - mae: 0.6045 - mape: 295.1808\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 171us/sample - loss: 0.6042 - mse: 0.4679 - mae: 0.6042 - mape: 297.3230\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 177us/sample - loss: 0.6039 - mse: 0.4673 - mae: 0.6039 - mape: 298.5745\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 138us/sample - loss: 0.6037 - mse: 0.4668 - mae: 0.6037 - mape: 300.5165\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 153us/sample - loss: 0.6034 - mse: 0.4662 - mae: 0.6034 - mape: 301.5254\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 148us/sample - loss: 0.6031 - mse: 0.4656 - mae: 0.6031 - mape: 303.5633\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 159us/sample - loss: 0.6028 - mse: 0.4649 - mae: 0.6028 - mape: 305.4810\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 265us/sample - loss: 0.6025 - mse: 0.4642 - mae: 0.6025 - mape: 307.2724\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 218us/sample - loss: 0.6022 - mse: 0.4636 - mae: 0.6022 - mape: 309.1479\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 175us/sample - loss: 0.6019 - mse: 0.4629 - mae: 0.6019 - mape: 310.5872\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 156us/sample - loss: 0.6016 - mse: 0.4622 - mae: 0.6016 - mape: 312.1495\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 150us/sample - loss: 0.6013 - mse: 0.4615 - mae: 0.6013 - mape: 314.7015\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 145us/sample - loss: 0.6010 - mse: 0.4609 - mae: 0.6010 - mape: 315.6575\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 165us/sample - loss: 0.6007 - mse: 0.4604 - mae: 0.6007 - mape: 317.6043\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 211us/sample - loss: 0.6005 - mse: 0.4598 - mae: 0.6005 - mape: 319.1705\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 175us/sample - loss: 0.6002 - mse: 0.4591 - mae: 0.6002 - mape: 320.9498\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 0s 149us/sample - loss: 0.5999 - mse: 0.4585 - mae: 0.5999 - mape: 322.0248\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 0s 166us/sample - loss: 0.5996 - mse: 0.4578 - mae: 0.5996 - mape: 324.1521\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 0s 144us/sample - loss: 0.5993 - mse: 0.4572 - mae: 0.5993 - mape: 325.9224\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 0s 173us/sample - loss: 0.5991 - mse: 0.4568 - mae: 0.5991 - mape: 327.1108\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 0s 202us/sample - loss: 0.5989 - mse: 0.4563 - mae: 0.5989 - mape: 328.1028\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 0s 157us/sample - loss: 0.5986 - mse: 0.4558 - mae: 0.5986 - mape: 329.5710\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 0s 155us/sample - loss: 0.5984 - mse: 0.4552 - mae: 0.5984 - mape: 331.4449\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 0s 184us/sample - loss: 0.5981 - mse: 0.4546 - mae: 0.5981 - mape: 332.8232\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 0s 150us/sample - loss: 0.5978 - mse: 0.4539 - mae: 0.5978 - mape: 334.9580\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 143us/sample - loss: 0.5974 - mse: 0.4532 - mae: 0.5974 - mape: 336.0684\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 0s 142us/sample - loss: 0.5971 - mse: 0.4526 - mae: 0.5971 - mape: 338.5984\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 0s 145us/sample - loss: 0.5968 - mse: 0.4519 - mae: 0.5968 - mape: 340.4655\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 0s 137us/sample - loss: 0.5965 - mse: 0.4512 - mae: 0.5965 - mape: 342.0085\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.5962 - mse: 0.4506 - mae: 0.5962 - mape: 343.8620\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 0s 197us/sample - loss: 0.5959 - mse: 0.4500 - mae: 0.5959 - mape: 345.1326\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 0s 159us/sample - loss: 0.5957 - mse: 0.4495 - mae: 0.5957 - mape: 346.6838\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.5955 - mse: 0.4490 - mae: 0.5955 - mape: 347.5581\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.5952 - mse: 0.4485 - mae: 0.5952 - mape: 349.0723\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 0s 166us/sample - loss: 0.5950 - mse: 0.4479 - mae: 0.5950 - mape: 350.5617\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 0s 188us/sample - loss: 0.5947 - mse: 0.4474 - mae: 0.5947 - mape: 352.1595\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 0s 186us/sample - loss: 0.5945 - mse: 0.4469 - mae: 0.5945 - mape: 353.2386\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 0s 157us/sample - loss: 0.5943 - mse: 0.4465 - mae: 0.5943 - mape: 354.9998\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.5940 - mse: 0.4459 - mae: 0.5940 - mape: 355.8918\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 0s 158us/sample - loss: 0.5937 - mse: 0.4453 - mae: 0.5937 - mape: 357.8176\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 0s 144us/sample - loss: 0.5934 - mse: 0.4447 - mae: 0.5934 - mape: 359.5899\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.5931 - mse: 0.4440 - mae: 0.5931 - mape: 361.4079\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 0s 210us/sample - loss: 0.5928 - mse: 0.4433 - mae: 0.5928 - mape: 362.8999\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 0s 164us/sample - loss: 0.5925 - mse: 0.4427 - mae: 0.5925 - mape: 364.8322\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 0s 185us/sample - loss: 0.5921 - mse: 0.4420 - mae: 0.5921 - mape: 367.1363\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 0s 199us/sample - loss: 0.5918 - mse: 0.4413 - mae: 0.5918 - mape: 368.7198\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.5916 - mse: 0.4408 - mae: 0.5916 - mape: 370.2211\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 0s 166us/sample - loss: 0.5913 - mse: 0.4403 - mae: 0.5913 - mape: 371.4447\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 0s 160us/sample - loss: 0.5911 - mse: 0.4398 - mae: 0.5911 - mape: 373.3126\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 0s 166us/sample - loss: 0.5908 - mse: 0.4392 - mae: 0.5908 - mape: 374.6438\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 0s 200us/sample - loss: 0.5905 - mse: 0.4386 - mae: 0.5905 - mape: 376.6396\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 0s 233us/sample - loss: 0.5902 - mse: 0.4379 - mae: 0.5902 - mape: 377.8275\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 998us/sample - loss: 0.6546 - accuracy: 0.6667\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "    L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.79055  6.440673           1598  3197.158  4.135         3\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.375\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 4.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/4Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 139 samples\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 0s 2ms/sample - loss: 0.7055 - mse: 0.6127 - mae: 0.7055 - mape: 393.2725\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 0s 208us/sample - loss: 0.7050 - mse: 0.6120 - mae: 0.7050 - mape: 392.3264\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.7044 - mse: 0.6113 - mae: 0.7044 - mape: 390.8871\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 0s 124us/sample - loss: 0.7039 - mse: 0.6105 - mae: 0.7039 - mape: 389.7862\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 0s 114us/sample - loss: 0.7034 - mse: 0.6098 - mae: 0.7034 - mape: 388.5439\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.7029 - mse: 0.6091 - mae: 0.7029 - mape: 386.7795\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 0s 120us/sample - loss: 0.7023 - mse: 0.6083 - mae: 0.7023 - mape: 385.7029\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 0s 131us/sample - loss: 0.7018 - mse: 0.6076 - mae: 0.7018 - mape: 384.4466\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 0s 207us/sample - loss: 0.7013 - mse: 0.6068 - mae: 0.7013 - mape: 383.3578\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 0s 163us/sample - loss: 0.7008 - mse: 0.6061 - mae: 0.7008 - mape: 382.2468\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 0s 136us/sample - loss: 0.7002 - mse: 0.6054 - mae: 0.7002 - mape: 380.8527\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 0s 148us/sample - loss: 0.6997 - mse: 0.6046 - mae: 0.6997 - mape: 379.7260\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 0s 149us/sample - loss: 0.6992 - mse: 0.6039 - mae: 0.6992 - mape: 378.6386\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 0s 227us/sample - loss: 0.6987 - mse: 0.6032 - mae: 0.6987 - mape: 377.1844\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 0s 135us/sample - loss: 0.6981 - mse: 0.6024 - mae: 0.6981 - mape: 375.9846\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 0s 126us/sample - loss: 0.6976 - mse: 0.6017 - mae: 0.6976 - mape: 374.8856\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 0s 157us/sample - loss: 0.6971 - mse: 0.6010 - mae: 0.6971 - mape: 373.5781\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 0s 145us/sample - loss: 0.6966 - mse: 0.6002 - mae: 0.6966 - mape: 371.8610\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 0s 167us/sample - loss: 0.6960 - mse: 0.5995 - mae: 0.6960 - mape: 370.9090\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.6955 - mse: 0.5988 - mae: 0.6955 - mape: 369.3106\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 0s 135us/sample - loss: 0.6950 - mse: 0.5980 - mae: 0.6950 - mape: 368.3607\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 0s 116us/sample - loss: 0.6945 - mse: 0.5973 - mae: 0.6945 - mape: 366.9244\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 0s 119us/sample - loss: 0.6939 - mse: 0.5965 - mae: 0.6939 - mape: 365.5281\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 0s 118us/sample - loss: 0.6934 - mse: 0.5958 - mae: 0.6934 - mape: 364.5702\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 0s 123us/sample - loss: 0.6929 - mse: 0.5951 - mae: 0.6929 - mape: 362.7984\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 0s 129us/sample - loss: 0.6923 - mse: 0.5943 - mae: 0.6923 - mape: 362.0527\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 0s 215us/sample - loss: 0.6918 - mse: 0.5936 - mae: 0.6918 - mape: 360.6284\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 0s 151us/sample - loss: 0.6913 - mse: 0.5928 - mae: 0.6913 - mape: 359.3751\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 0s 133us/sample - loss: 0.6907 - mse: 0.5921 - mae: 0.6907 - mape: 358.0365\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 0s 118us/sample - loss: 0.6902 - mse: 0.5914 - mae: 0.6902 - mape: 357.1552\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 0s 153us/sample - loss: 0.6897 - mse: 0.5907 - mae: 0.6897 - mape: 355.5209\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 0s 157us/sample - loss: 0.6891 - mse: 0.5899 - mae: 0.6891 - mape: 354.0598\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 0s 157us/sample - loss: 0.6886 - mse: 0.5892 - mae: 0.6886 - mape: 352.9616\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 0s 151us/sample - loss: 0.6881 - mse: 0.5884 - mae: 0.6881 - mape: 351.6612\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 0s 128us/sample - loss: 0.6875 - mse: 0.5877 - mae: 0.6875 - mape: 350.2009\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 0s 172us/sample - loss: 0.6870 - mse: 0.5870 - mae: 0.6870 - mape: 349.2646\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 0s 184us/sample - loss: 0.6865 - mse: 0.5862 - mae: 0.6865 - mape: 347.8268\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 0s 141us/sample - loss: 0.6859 - mse: 0.5855 - mae: 0.6859 - mape: 346.8596\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.6854 - mse: 0.5848 - mae: 0.6854 - mape: 345.0905\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 0s 119us/sample - loss: 0.6848 - mse: 0.5840 - mae: 0.6848 - mape: 344.2871\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 0s 119us/sample - loss: 0.6843 - mse: 0.5833 - mae: 0.6843 - mape: 342.4893\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 0s 150us/sample - loss: 0.6838 - mse: 0.5825 - mae: 0.6838 - mape: 341.3459\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 0s 170us/sample - loss: 0.6832 - mse: 0.5818 - mae: 0.6832 - mape: 340.2233\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 0s 123us/sample - loss: 0.6827 - mse: 0.5811 - mae: 0.6827 - mape: 338.8086\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 0s 136us/sample - loss: 0.6821 - mse: 0.5803 - mae: 0.6821 - mape: 337.4515\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 0s 135us/sample - loss: 0.6816 - mse: 0.5796 - mae: 0.6816 - mape: 336.3062\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 0s 193us/sample - loss: 0.6811 - mse: 0.5788 - mae: 0.6811 - mape: 335.2088\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 0s 148us/sample - loss: 0.6805 - mse: 0.5781 - mae: 0.6805 - mape: 333.9139\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 0s 150us/sample - loss: 0.6800 - mse: 0.5774 - mae: 0.6800 - mape: 332.0875\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 0s 140us/sample - loss: 0.6794 - mse: 0.5766 - mae: 0.6794 - mape: 330.7969\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 0s 136us/sample - loss: 0.6789 - mse: 0.5759 - mae: 0.6789 - mape: 329.8148\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 0s 131us/sample - loss: 0.6783 - mse: 0.5751 - mae: 0.6783 - mape: 328.5048\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 0s 179us/sample - loss: 0.6778 - mse: 0.5744 - mae: 0.6778 - mape: 326.6841\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 0s 188us/sample - loss: 0.6772 - mse: 0.5736 - mae: 0.6772 - mape: 325.7253\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 0s 159us/sample - loss: 0.6767 - mse: 0.5729 - mae: 0.6767 - mape: 324.5421\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 0s 116us/sample - loss: 0.6761 - mse: 0.5721 - mae: 0.6761 - mape: 322.8831\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - 0s 120us/sample - loss: 0.6756 - mse: 0.5714 - mae: 0.6756 - mape: 321.6107\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 0s 158us/sample - loss: 0.6750 - mse: 0.5706 - mae: 0.6750 - mape: 320.4618\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 0s 213us/sample - loss: 0.6745 - mse: 0.5699 - mae: 0.6745 - mape: 319.1050\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 0s 139us/sample - loss: 0.6739 - mse: 0.5691 - mae: 0.6739 - mape: 317.7513\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 0s 135us/sample - loss: 0.6733 - mse: 0.5684 - mae: 0.6733 - mape: 316.2683\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 0s 123us/sample - loss: 0.6728 - mse: 0.5676 - mae: 0.6728 - mape: 314.7549\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 0s 116us/sample - loss: 0.6722 - mse: 0.5669 - mae: 0.6722 - mape: 313.3789\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 0s 179us/sample - loss: 0.6717 - mse: 0.5661 - mae: 0.6717 - mape: 312.7424\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 0s 140us/sample - loss: 0.6711 - mse: 0.5654 - mae: 0.6711 - mape: 311.3937\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 0s 147us/sample - loss: 0.6705 - mse: 0.5646 - mae: 0.6705 - mape: 309.8855\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.6700 - mse: 0.5638 - mae: 0.6700 - mape: 308.2241\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 0s 154us/sample - loss: 0.6694 - mse: 0.5631 - mae: 0.6694 - mape: 307.3599\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 0s 204us/sample - loss: 0.6688 - mse: 0.5623 - mae: 0.6688 - mape: 305.8328\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 0s 130us/sample - loss: 0.6683 - mse: 0.5616 - mae: 0.6683 - mape: 304.3219\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 0s 133us/sample - loss: 0.6677 - mse: 0.5608 - mae: 0.6677 - mape: 303.2574\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 0s 118us/sample - loss: 0.6671 - mse: 0.5600 - mae: 0.6671 - mape: 301.9854\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 0s 133us/sample - loss: 0.6666 - mse: 0.5593 - mae: 0.6666 - mape: 300.0360\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 0s 133us/sample - loss: 0.6660 - mse: 0.5585 - mae: 0.6660 - mape: 298.8952\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 0s 184us/sample - loss: 0.6654 - mse: 0.5578 - mae: 0.6654 - mape: 297.5328\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 0s 127us/sample - loss: 0.6648 - mse: 0.5570 - mae: 0.6648 - mape: 296.1053\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 0s 136us/sample - loss: 0.6643 - mse: 0.5562 - mae: 0.6643 - mape: 294.9260\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 0s 116us/sample - loss: 0.6637 - mse: 0.5555 - mae: 0.6637 - mape: 293.3647\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 0s 111us/sample - loss: 0.6631 - mse: 0.5547 - mae: 0.6631 - mape: 291.7861\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 0s 148us/sample - loss: 0.6625 - mse: 0.5539 - mae: 0.6625 - mape: 290.4329\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 0s 165us/sample - loss: 0.6619 - mse: 0.5531 - mae: 0.6619 - mape: 289.4018\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 0s 146us/sample - loss: 0.6614 - mse: 0.5524 - mae: 0.6614 - mape: 287.8656\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 0s 139us/sample - loss: 0.6608 - mse: 0.5516 - mae: 0.6608 - mape: 286.4476\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 0s 113us/sample - loss: 0.6602 - mse: 0.5508 - mae: 0.6602 - mape: 284.8594\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 0s 116us/sample - loss: 0.6596 - mse: 0.5500 - mae: 0.6596 - mape: 283.6273\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 0s 138us/sample - loss: 0.6590 - mse: 0.5493 - mae: 0.6590 - mape: 282.2172\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 0s 227us/sample - loss: 0.6584 - mse: 0.5485 - mae: 0.6584 - mape: 280.9934\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 0s 117us/sample - loss: 0.6578 - mse: 0.5477 - mae: 0.6578 - mape: 279.4373\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 0s 139us/sample - loss: 0.6572 - mse: 0.5469 - mae: 0.6572 - mape: 278.3458\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 0s 122us/sample - loss: 0.6566 - mse: 0.5462 - mae: 0.6566 - mape: 276.9462\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 0s 125us/sample - loss: 0.6560 - mse: 0.5454 - mae: 0.6560 - mape: 275.1841\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 0s 119us/sample - loss: 0.6554 - mse: 0.5446 - mae: 0.6554 - mape: 273.5091\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 0s 154us/sample - loss: 0.6548 - mse: 0.5438 - mae: 0.6548 - mape: 272.2937\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 0s 157us/sample - loss: 0.6542 - mse: 0.5430 - mae: 0.6542 - mape: 270.6771\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 0s 150us/sample - loss: 0.6536 - mse: 0.5422 - mae: 0.6536 - mape: 269.7696\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 0s 144us/sample - loss: 0.6530 - mse: 0.5414 - mae: 0.6530 - mape: 268.3825\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 0s 120us/sample - loss: 0.6524 - mse: 0.5406 - mae: 0.6524 - mape: 266.1617\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 0s 120us/sample - loss: 0.6518 - mse: 0.5398 - mae: 0.6518 - mape: 265.4686\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 0s 179us/sample - loss: 0.6512 - mse: 0.5390 - mae: 0.6512 - mape: 263.4823\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 0s 167us/sample - loss: 0.6506 - mse: 0.5383 - mae: 0.6506 - mape: 261.9923\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/4Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 98 samples\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 0s 3ms/sample - loss: 0.5688 - mse: 0.3259 - mae: 0.5688 - mape: 107.6633\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 111us/sample - loss: 0.5683 - mse: 0.3254 - mae: 0.5683 - mape: 107.5828\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 138us/sample - loss: 0.5679 - mse: 0.3249 - mae: 0.5679 - mape: 107.5024\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 141us/sample - loss: 0.5675 - mse: 0.3244 - mae: 0.5675 - mape: 107.4220\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 233us/sample - loss: 0.5671 - mse: 0.3240 - mae: 0.5671 - mape: 107.3416\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 168us/sample - loss: 0.5667 - mse: 0.3235 - mae: 0.5667 - mape: 107.2608\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 148us/sample - loss: 0.5662 - mse: 0.3230 - mae: 0.5662 - mape: 107.1804\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 145us/sample - loss: 0.5658 - mse: 0.3225 - mae: 0.5658 - mape: 107.1003\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 131us/sample - loss: 0.5654 - mse: 0.3221 - mae: 0.5654 - mape: 107.0201\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 152us/sample - loss: 0.5650 - mse: 0.3216 - mae: 0.5650 - mape: 106.9402\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 201us/sample - loss: 0.5646 - mse: 0.3211 - mae: 0.5646 - mape: 106.8600\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 162us/sample - loss: 0.5641 - mse: 0.3206 - mae: 0.5641 - mape: 106.7801\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 163us/sample - loss: 0.5637 - mse: 0.3202 - mae: 0.5637 - mape: 106.6998\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 171us/sample - loss: 0.5633 - mse: 0.3197 - mae: 0.5633 - mape: 106.6199\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 142us/sample - loss: 0.5629 - mse: 0.3192 - mae: 0.5629 - mape: 106.5396\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 192us/sample - loss: 0.5625 - mse: 0.3187 - mae: 0.5625 - mape: 106.4599\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 182us/sample - loss: 0.5620 - mse: 0.3183 - mae: 0.5620 - mape: 106.3803\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 220us/sample - loss: 0.5616 - mse: 0.3178 - mae: 0.5616 - mape: 106.3001\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 153us/sample - loss: 0.5612 - mse: 0.3173 - mae: 0.5612 - mape: 106.2201\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 150us/sample - loss: 0.5608 - mse: 0.3169 - mae: 0.5608 - mape: 106.1400\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 152us/sample - loss: 0.5604 - mse: 0.3164 - mae: 0.5604 - mape: 106.0603\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 137us/sample - loss: 0.5599 - mse: 0.3159 - mae: 0.5599 - mape: 105.9801\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 135us/sample - loss: 0.5595 - mse: 0.3154 - mae: 0.5595 - mape: 105.9005\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 194us/sample - loss: 0.5591 - mse: 0.3150 - mae: 0.5591 - mape: 105.8205\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 227us/sample - loss: 0.5587 - mse: 0.3145 - mae: 0.5587 - mape: 105.7405\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 140us/sample - loss: 0.5583 - mse: 0.3140 - mae: 0.5583 - mape: 105.6607\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 182us/sample - loss: 0.5578 - mse: 0.3136 - mae: 0.5578 - mape: 105.5807\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 219us/sample - loss: 0.5574 - mse: 0.3131 - mae: 0.5574 - mape: 105.5012\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 158us/sample - loss: 0.5570 - mse: 0.3126 - mae: 0.5570 - mape: 105.4210\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 161us/sample - loss: 0.5566 - mse: 0.3122 - mae: 0.5566 - mape: 105.3410\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 186us/sample - loss: 0.5562 - mse: 0.3117 - mae: 0.5562 - mape: 105.2612\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 219us/sample - loss: 0.5557 - mse: 0.3112 - mae: 0.5557 - mape: 105.1808\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 133us/sample - loss: 0.5553 - mse: 0.3108 - mae: 0.5553 - mape: 105.1008\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 163us/sample - loss: 0.5549 - mse: 0.3103 - mae: 0.5549 - mape: 105.0210\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 144us/sample - loss: 0.5545 - mse: 0.3098 - mae: 0.5545 - mape: 104.9405\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 131us/sample - loss: 0.5541 - mse: 0.3094 - mae: 0.5541 - mape: 104.8603\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 138us/sample - loss: 0.5536 - mse: 0.3089 - mae: 0.5536 - mape: 104.7798\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 185us/sample - loss: 0.5532 - mse: 0.3084 - mae: 0.5532 - mape: 104.6994\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 158us/sample - loss: 0.5528 - mse: 0.3080 - mae: 0.5528 - mape: 104.6192\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 141us/sample - loss: 0.5524 - mse: 0.3075 - mae: 0.5524 - mape: 104.5389\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 147us/sample - loss: 0.5520 - mse: 0.3070 - mae: 0.5520 - mape: 104.4583\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 291us/sample - loss: 0.5515 - mse: 0.3066 - mae: 0.5515 - mape: 104.3777\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 201us/sample - loss: 0.5511 - mse: 0.3061 - mae: 0.5511 - mape: 104.2975\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 183us/sample - loss: 0.5507 - mse: 0.3057 - mae: 0.5507 - mape: 104.2168\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 145us/sample - loss: 0.5503 - mse: 0.3052 - mae: 0.5503 - mape: 104.1365\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 340us/sample - loss: 0.5498 - mse: 0.3047 - mae: 0.5498 - mape: 104.0555\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 156us/sample - loss: 0.5494 - mse: 0.3043 - mae: 0.5494 - mape: 103.9749\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 156us/sample - loss: 0.5490 - mse: 0.3038 - mae: 0.5490 - mape: 103.8938\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 194us/sample - loss: 0.5486 - mse: 0.3033 - mae: 0.5486 - mape: 103.8127\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 115us/sample - loss: 0.5481 - mse: 0.3029 - mae: 0.5481 - mape: 103.7316\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 147us/sample - loss: 0.5477 - mse: 0.3024 - mae: 0.5477 - mape: 103.6504\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 223us/sample - loss: 0.5473 - mse: 0.3019 - mae: 0.5473 - mape: 103.5692\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 163us/sample - loss: 0.5469 - mse: 0.3015 - mae: 0.5469 - mape: 103.4879\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 160us/sample - loss: 0.5464 - mse: 0.3010 - mae: 0.5464 - mape: 103.4064\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 149us/sample - loss: 0.5460 - mse: 0.3005 - mae: 0.5460 - mape: 103.3249\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 133us/sample - loss: 0.5456 - mse: 0.3001 - mae: 0.5456 - mape: 103.2436\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 141us/sample - loss: 0.5452 - mse: 0.2996 - mae: 0.5452 - mape: 103.1621\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 309us/sample - loss: 0.5447 - mse: 0.2991 - mae: 0.5447 - mape: 103.0807\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 130us/sample - loss: 0.5443 - mse: 0.2987 - mae: 0.5443 - mape: 102.9986\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 186us/sample - loss: 0.5439 - mse: 0.2982 - mae: 0.5439 - mape: 102.9167\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 165us/sample - loss: 0.5434 - mse: 0.2977 - mae: 0.5434 - mape: 102.8347\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 129us/sample - loss: 0.5430 - mse: 0.2973 - mae: 0.5430 - mape: 102.7524\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 148us/sample - loss: 0.5426 - mse: 0.2968 - mae: 0.5426 - mape: 102.6704\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 143us/sample - loss: 0.5421 - mse: 0.2963 - mae: 0.5421 - mape: 102.5875\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 170us/sample - loss: 0.5417 - mse: 0.2958 - mae: 0.5417 - mape: 102.5054\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 154us/sample - loss: 0.5413 - mse: 0.2954 - mae: 0.5413 - mape: 102.4227\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 154us/sample - loss: 0.5408 - mse: 0.2949 - mae: 0.5408 - mape: 102.3397\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 233us/sample - loss: 0.5404 - mse: 0.2944 - mae: 0.5404 - mape: 102.2570\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 168us/sample - loss: 0.5400 - mse: 0.2940 - mae: 0.5400 - mape: 102.1740\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 190us/sample - loss: 0.5395 - mse: 0.2935 - mae: 0.5395 - mape: 102.0908\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 157us/sample - loss: 0.5391 - mse: 0.2930 - mae: 0.5391 - mape: 102.0079\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 130us/sample - loss: 0.5387 - mse: 0.2926 - mae: 0.5387 - mape: 101.9242\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 153us/sample - loss: 0.5382 - mse: 0.2921 - mae: 0.5382 - mape: 101.8408\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 244us/sample - loss: 0.5378 - mse: 0.2916 - mae: 0.5378 - mape: 101.7572\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 169us/sample - loss: 0.5373 - mse: 0.2911 - mae: 0.5373 - mape: 101.6737\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 160us/sample - loss: 0.5369 - mse: 0.2907 - mae: 0.5369 - mape: 101.5898\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 264us/sample - loss: 0.5365 - mse: 0.2902 - mae: 0.5365 - mape: 101.5058\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 167us/sample - loss: 0.5360 - mse: 0.2897 - mae: 0.5360 - mape: 101.4217\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 162us/sample - loss: 0.5356 - mse: 0.2893 - mae: 0.5356 - mape: 101.3372\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 245us/sample - loss: 0.5351 - mse: 0.2888 - mae: 0.5351 - mape: 101.2530\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 163us/sample - loss: 0.5347 - mse: 0.2883 - mae: 0.5347 - mape: 101.1685\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 151us/sample - loss: 0.5342 - mse: 0.2878 - mae: 0.5342 - mape: 101.0836\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 142us/sample - loss: 0.5338 - mse: 0.2874 - mae: 0.5338 - mape: 100.9985\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 132us/sample - loss: 0.5334 - mse: 0.2869 - mae: 0.5334 - mape: 100.9131\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 132us/sample - loss: 0.5329 - mse: 0.2864 - mae: 0.5329 - mape: 100.8284\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 133us/sample - loss: 0.5325 - mse: 0.2859 - mae: 0.5325 - mape: 100.7429\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 133us/sample - loss: 0.5320 - mse: 0.2854 - mae: 0.5320 - mape: 100.6574\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 130us/sample - loss: 0.5316 - mse: 0.2850 - mae: 0.5316 - mape: 100.5718\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 129us/sample - loss: 0.5311 - mse: 0.2845 - mae: 0.5311 - mape: 100.4859\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 165us/sample - loss: 0.5307 - mse: 0.2840 - mae: 0.5307 - mape: 100.4001\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 226us/sample - loss: 0.5302 - mse: 0.2835 - mae: 0.5302 - mape: 100.3140\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 154us/sample - loss: 0.5298 - mse: 0.2830 - mae: 0.5298 - mape: 100.2273\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 146us/sample - loss: 0.5293 - mse: 0.2826 - mae: 0.5293 - mape: 100.1411\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 164us/sample - loss: 0.5289 - mse: 0.2821 - mae: 0.5289 - mape: 100.0543\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 137us/sample - loss: 0.5284 - mse: 0.2816 - mae: 0.5284 - mape: 99.9676\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 137us/sample - loss: 0.5279 - mse: 0.2811 - mae: 0.5279 - mape: 99.8808\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 136us/sample - loss: 0.5275 - mse: 0.2806 - mae: 0.5275 - mape: 99.7937\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 169us/sample - loss: 0.5270 - mse: 0.2802 - mae: 0.5270 - mape: 99.7061\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 200us/sample - loss: 0.5266 - mse: 0.2797 - mae: 0.5266 - mape: 99.6185\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 211us/sample - loss: 0.5261 - mse: 0.2792 - mae: 0.5261 - mape: 99.5312\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/4Total Parts.\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 4ms/sample - loss: 0.6127 - mse: 0.3777 - mae: 0.6127 - mape: 94.4309\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.6124 - mse: 0.3774 - mae: 0.6124 - mape: 94.3854\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.6121 - mse: 0.3770 - mae: 0.6121 - mape: 94.3392\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.6118 - mse: 0.3766 - mae: 0.6118 - mape: 94.2931\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6115 - mse: 0.3763 - mae: 0.6115 - mape: 94.2471\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6113 - mse: 0.3759 - mae: 0.6113 - mape: 94.2010\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6110 - mse: 0.3756 - mae: 0.6110 - mape: 94.1551\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 198us/sample - loss: 0.6107 - mse: 0.3752 - mae: 0.6107 - mape: 94.1090\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6104 - mse: 0.3748 - mae: 0.6104 - mape: 94.0630\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6101 - mse: 0.3745 - mae: 0.6101 - mape: 94.0166\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.6098 - mse: 0.3741 - mae: 0.6098 - mape: 93.9707\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.6095 - mse: 0.3737 - mae: 0.6095 - mape: 93.9247\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 219us/sample - loss: 0.6092 - mse: 0.3734 - mae: 0.6092 - mape: 93.8785\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6089 - mse: 0.3730 - mae: 0.6089 - mape: 93.8325\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6086 - mse: 0.3727 - mae: 0.6086 - mape: 93.7866\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.6083 - mse: 0.3723 - mae: 0.6083 - mape: 93.7405\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 0.6080 - mse: 0.3719 - mae: 0.6080 - mape: 93.6944\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6077 - mse: 0.3716 - mae: 0.6077 - mape: 93.6484\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.6074 - mse: 0.3712 - mae: 0.6074 - mape: 93.6023\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6071 - mse: 0.3709 - mae: 0.6071 - mape: 93.5560\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.6068 - mse: 0.3705 - mae: 0.6068 - mape: 93.5102\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6065 - mse: 0.3701 - mae: 0.6065 - mape: 93.4639\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6062 - mse: 0.3698 - mae: 0.6062 - mape: 93.4179\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6059 - mse: 0.3694 - mae: 0.6059 - mape: 93.3717\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.6056 - mse: 0.3691 - mae: 0.6056 - mape: 93.3255\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6053 - mse: 0.3687 - mae: 0.6053 - mape: 93.2795\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.6050 - mse: 0.3683 - mae: 0.6050 - mape: 93.2335\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.6047 - mse: 0.3680 - mae: 0.6047 - mape: 93.1871\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 0.6044 - mse: 0.3676 - mae: 0.6044 - mape: 93.1410\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.6041 - mse: 0.3673 - mae: 0.6041 - mape: 93.0945\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.6038 - mse: 0.3669 - mae: 0.6038 - mape: 93.0486\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6035 - mse: 0.3665 - mae: 0.6035 - mape: 93.0025\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.6032 - mse: 0.3662 - mae: 0.6032 - mape: 92.9563\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 280us/sample - loss: 0.6029 - mse: 0.3658 - mae: 0.6029 - mape: 92.9099\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 183us/sample - loss: 0.6026 - mse: 0.3655 - mae: 0.6026 - mape: 92.8637\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.6023 - mse: 0.3651 - mae: 0.6023 - mape: 92.8174\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 174us/sample - loss: 0.6020 - mse: 0.3648 - mae: 0.6020 - mape: 92.7710\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 183us/sample - loss: 0.6017 - mse: 0.3644 - mae: 0.6017 - mape: 92.7247\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.6014 - mse: 0.3640 - mae: 0.6014 - mape: 92.6783\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.6011 - mse: 0.3637 - mae: 0.6011 - mape: 92.6321\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 0.6008 - mse: 0.3633 - mae: 0.6008 - mape: 92.5857\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 243us/sample - loss: 0.6005 - mse: 0.3630 - mae: 0.6005 - mape: 92.5392\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6003 - mse: 0.3626 - mae: 0.6003 - mape: 92.4930\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6000 - mse: 0.3622 - mae: 0.6000 - mape: 92.4461\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.5997 - mse: 0.3619 - mae: 0.5997 - mape: 92.3999\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.5994 - mse: 0.3615 - mae: 0.5994 - mape: 92.3531\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5991 - mse: 0.3612 - mae: 0.5991 - mape: 92.3069\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.5988 - mse: 0.3608 - mae: 0.5988 - mape: 92.2602\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.5985 - mse: 0.3604 - mae: 0.5985 - mape: 92.2135\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.5982 - mse: 0.3601 - mae: 0.5982 - mape: 92.1671\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.5979 - mse: 0.3597 - mae: 0.5979 - mape: 92.1203\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.5976 - mse: 0.3594 - mae: 0.5976 - mape: 92.0734\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.5973 - mse: 0.3590 - mae: 0.5973 - mape: 92.0269\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.5969 - mse: 0.3587 - mae: 0.5969 - mape: 91.9802\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.5966 - mse: 0.3583 - mae: 0.5966 - mape: 91.9333\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.5963 - mse: 0.3579 - mae: 0.5963 - mape: 91.8864\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 173us/sample - loss: 0.5960 - mse: 0.3576 - mae: 0.5960 - mape: 91.8397\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 0.5957 - mse: 0.3572 - mae: 0.5957 - mape: 91.7929\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.5954 - mse: 0.3569 - mae: 0.5954 - mape: 91.7458\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.5951 - mse: 0.3565 - mae: 0.5951 - mape: 91.6989\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.5948 - mse: 0.3561 - mae: 0.5948 - mape: 91.6518\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5945 - mse: 0.3558 - mae: 0.5945 - mape: 91.6048\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.5942 - mse: 0.3554 - mae: 0.5942 - mape: 91.5579\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 220us/sample - loss: 0.5939 - mse: 0.3551 - mae: 0.5939 - mape: 91.5105\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 180us/sample - loss: 0.5936 - mse: 0.3547 - mae: 0.5936 - mape: 91.4633\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.5933 - mse: 0.3543 - mae: 0.5933 - mape: 91.4164\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.5930 - mse: 0.3540 - mae: 0.5930 - mape: 91.3690\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.5927 - mse: 0.3536 - mae: 0.5927 - mape: 91.3216\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5924 - mse: 0.3533 - mae: 0.5924 - mape: 91.2742\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5921 - mse: 0.3529 - mae: 0.5921 - mape: 91.2272\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.5918 - mse: 0.3525 - mae: 0.5918 - mape: 91.1797\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5915 - mse: 0.3522 - mae: 0.5915 - mape: 91.1326\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.5912 - mse: 0.3518 - mae: 0.5912 - mape: 91.0845\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.5909 - mse: 0.3515 - mae: 0.5909 - mape: 91.0370\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 230us/sample - loss: 0.5906 - mse: 0.3511 - mae: 0.5906 - mape: 90.9897\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5903 - mse: 0.3507 - mae: 0.5903 - mape: 90.9421\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 171us/sample - loss: 0.5900 - mse: 0.3504 - mae: 0.5900 - mape: 90.8944\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 176us/sample - loss: 0.5897 - mse: 0.3500 - mae: 0.5897 - mape: 90.8467\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.5893 - mse: 0.3496 - mae: 0.5893 - mape: 90.7989\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.5890 - mse: 0.3493 - mae: 0.5890 - mape: 90.7511\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.5887 - mse: 0.3489 - mae: 0.5887 - mape: 90.7033\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 178us/sample - loss: 0.5884 - mse: 0.3486 - mae: 0.5884 - mape: 90.6553\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.5881 - mse: 0.3482 - mae: 0.5881 - mape: 90.6074\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.5878 - mse: 0.3478 - mae: 0.5878 - mape: 90.5595\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.5875 - mse: 0.3475 - mae: 0.5875 - mape: 90.5112\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.5872 - mse: 0.3471 - mae: 0.5872 - mape: 90.4630\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.5869 - mse: 0.3467 - mae: 0.5869 - mape: 90.4149\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.5866 - mse: 0.3464 - mae: 0.5866 - mape: 90.3666\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.5862 - mse: 0.3460 - mae: 0.5862 - mape: 90.3185\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.5859 - mse: 0.3456 - mae: 0.5859 - mape: 90.2699\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.5856 - mse: 0.3453 - mae: 0.5856 - mape: 90.2215\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5853 - mse: 0.3449 - mae: 0.5853 - mape: 90.1732\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.5850 - mse: 0.3445 - mae: 0.5850 - mape: 90.1246\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5847 - mse: 0.3442 - mae: 0.5847 - mape: 90.0760\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.5844 - mse: 0.3438 - mae: 0.5844 - mape: 90.0275\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.5841 - mse: 0.3434 - mae: 0.5841 - mape: 89.9785\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.5837 - mse: 0.3431 - mae: 0.5837 - mape: 89.9296\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5834 - mse: 0.3427 - mae: 0.5834 - mape: 89.8809\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.5831 - mse: 0.3423 - mae: 0.5831 - mape: 89.8321\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.5828 - mse: 0.3420 - mae: 0.5828 - mape: 89.7830\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 3/4Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 77 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 5ms/sample - loss: 0.5512 - mse: 0.3280 - mae: 0.5512 - mape: 113.0502\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 243us/sample - loss: 0.5509 - mse: 0.3276 - mae: 0.5509 - mape: 112.9817\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 166us/sample - loss: 0.5506 - mse: 0.3273 - mae: 0.5506 - mape: 112.9121\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 198us/sample - loss: 0.5503 - mse: 0.3269 - mae: 0.5503 - mape: 112.8434\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 226us/sample - loss: 0.5500 - mse: 0.3266 - mae: 0.5500 - mape: 112.7734\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 150us/sample - loss: 0.5497 - mse: 0.3262 - mae: 0.5497 - mape: 112.7048\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 166us/sample - loss: 0.5494 - mse: 0.3259 - mae: 0.5494 - mape: 112.6349\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 168us/sample - loss: 0.5490 - mse: 0.3256 - mae: 0.5490 - mape: 112.5654\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 161us/sample - loss: 0.5487 - mse: 0.3252 - mae: 0.5487 - mape: 112.4978\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 155us/sample - loss: 0.5484 - mse: 0.3249 - mae: 0.5484 - mape: 112.4272\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 142us/sample - loss: 0.5481 - mse: 0.3245 - mae: 0.5481 - mape: 112.3587\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 137us/sample - loss: 0.5478 - mse: 0.3242 - mae: 0.5478 - mape: 112.2894\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 144us/sample - loss: 0.5475 - mse: 0.3238 - mae: 0.5475 - mape: 112.2197\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 148us/sample - loss: 0.5472 - mse: 0.3235 - mae: 0.5472 - mape: 112.1513\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 126us/sample - loss: 0.5468 - mse: 0.3231 - mae: 0.5468 - mape: 112.0823\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 153us/sample - loss: 0.5465 - mse: 0.3228 - mae: 0.5465 - mape: 112.0131\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 216us/sample - loss: 0.5462 - mse: 0.3225 - mae: 0.5462 - mape: 111.9441\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 166us/sample - loss: 0.5459 - mse: 0.3221 - mae: 0.5459 - mape: 111.8744\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 135us/sample - loss: 0.5456 - mse: 0.3218 - mae: 0.5456 - mape: 111.8059\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 155us/sample - loss: 0.5453 - mse: 0.3214 - mae: 0.5453 - mape: 111.7357\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 158us/sample - loss: 0.5450 - mse: 0.3211 - mae: 0.5450 - mape: 111.6680\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 145us/sample - loss: 0.5446 - mse: 0.3207 - mae: 0.5446 - mape: 111.5979\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 144us/sample - loss: 0.5443 - mse: 0.3204 - mae: 0.5443 - mape: 111.5297\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 138us/sample - loss: 0.5440 - mse: 0.3201 - mae: 0.5440 - mape: 111.4605\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 136us/sample - loss: 0.5437 - mse: 0.3197 - mae: 0.5437 - mape: 111.3919\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 235us/sample - loss: 0.5434 - mse: 0.3194 - mae: 0.5434 - mape: 111.3208\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 162us/sample - loss: 0.5431 - mse: 0.3190 - mae: 0.5431 - mape: 111.2523\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 152us/sample - loss: 0.5427 - mse: 0.3187 - mae: 0.5427 - mape: 111.1829\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 154us/sample - loss: 0.5424 - mse: 0.3184 - mae: 0.5424 - mape: 111.1129\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 132us/sample - loss: 0.5421 - mse: 0.3180 - mae: 0.5421 - mape: 111.0446\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 129us/sample - loss: 0.5418 - mse: 0.3177 - mae: 0.5418 - mape: 110.9741\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 140us/sample - loss: 0.5415 - mse: 0.3173 - mae: 0.5415 - mape: 110.9061\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 173us/sample - loss: 0.5412 - mse: 0.3170 - mae: 0.5412 - mape: 110.8357\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 218us/sample - loss: 0.5409 - mse: 0.3167 - mae: 0.5409 - mape: 110.7668\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 159us/sample - loss: 0.5405 - mse: 0.3163 - mae: 0.5405 - mape: 110.6970\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 156us/sample - loss: 0.5402 - mse: 0.3160 - mae: 0.5402 - mape: 110.6277\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 160us/sample - loss: 0.5399 - mse: 0.3156 - mae: 0.5399 - mape: 110.5589\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 160us/sample - loss: 0.5396 - mse: 0.3153 - mae: 0.5396 - mape: 110.4887\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 135us/sample - loss: 0.5393 - mse: 0.3150 - mae: 0.5393 - mape: 110.4193\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 138us/sample - loss: 0.5390 - mse: 0.3146 - mae: 0.5390 - mape: 110.3497\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 133us/sample - loss: 0.5386 - mse: 0.3143 - mae: 0.5386 - mape: 110.2803\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 136us/sample - loss: 0.5383 - mse: 0.3139 - mae: 0.5383 - mape: 110.2100\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 142us/sample - loss: 0.5380 - mse: 0.3136 - mae: 0.5380 - mape: 110.1408\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 130us/sample - loss: 0.5377 - mse: 0.3133 - mae: 0.5377 - mape: 110.0714\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.5374 - mse: 0.3129 - mae: 0.5374 - mape: 110.0004\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 203us/sample - loss: 0.5371 - mse: 0.3126 - mae: 0.5371 - mape: 109.9318\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.5367 - mse: 0.3122 - mae: 0.5367 - mape: 109.8604\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 130us/sample - loss: 0.5364 - mse: 0.3119 - mae: 0.5364 - mape: 109.7913\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 161us/sample - loss: 0.5361 - mse: 0.3116 - mae: 0.5361 - mape: 109.7214\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 172us/sample - loss: 0.5358 - mse: 0.3112 - mae: 0.5358 - mape: 109.6520\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 138us/sample - loss: 0.5355 - mse: 0.3109 - mae: 0.5355 - mape: 109.5813\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 135us/sample - loss: 0.5351 - mse: 0.3105 - mae: 0.5351 - mape: 109.5116\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 139us/sample - loss: 0.5348 - mse: 0.3102 - mae: 0.5348 - mape: 109.4414\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 140us/sample - loss: 0.5345 - mse: 0.3098 - mae: 0.5345 - mape: 109.3716\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 134us/sample - loss: 0.5342 - mse: 0.3095 - mae: 0.5342 - mape: 109.3002\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 150us/sample - loss: 0.5339 - mse: 0.3092 - mae: 0.5339 - mape: 109.2298\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 204us/sample - loss: 0.5335 - mse: 0.3088 - mae: 0.5335 - mape: 109.1605\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.5332 - mse: 0.3085 - mae: 0.5332 - mape: 109.0893\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 156us/sample - loss: 0.5329 - mse: 0.3081 - mae: 0.5329 - mape: 109.0191\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 154us/sample - loss: 0.5326 - mse: 0.3078 - mae: 0.5326 - mape: 108.9484\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 165us/sample - loss: 0.5323 - mse: 0.3075 - mae: 0.5323 - mape: 108.8779\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 145us/sample - loss: 0.5319 - mse: 0.3071 - mae: 0.5319 - mape: 108.8069\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 127us/sample - loss: 0.5316 - mse: 0.3068 - mae: 0.5316 - mape: 108.7361\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 118us/sample - loss: 0.5313 - mse: 0.3064 - mae: 0.5313 - mape: 108.6657\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 140us/sample - loss: 0.5310 - mse: 0.3061 - mae: 0.5310 - mape: 108.5942\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 132us/sample - loss: 0.5306 - mse: 0.3058 - mae: 0.5306 - mape: 108.5231\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 148us/sample - loss: 0.5303 - mse: 0.3054 - mae: 0.5303 - mape: 108.4523\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 256us/sample - loss: 0.5300 - mse: 0.3051 - mae: 0.5300 - mape: 108.3809\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 166us/sample - loss: 0.5297 - mse: 0.3047 - mae: 0.5297 - mape: 108.3091\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 153us/sample - loss: 0.5293 - mse: 0.3044 - mae: 0.5293 - mape: 108.2380\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 152us/sample - loss: 0.5290 - mse: 0.3040 - mae: 0.5290 - mape: 108.1663\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 156us/sample - loss: 0.5287 - mse: 0.3037 - mae: 0.5287 - mape: 108.0944\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 127us/sample - loss: 0.5284 - mse: 0.3034 - mae: 0.5284 - mape: 108.0231\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 134us/sample - loss: 0.5280 - mse: 0.3030 - mae: 0.5280 - mape: 107.9511\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 147us/sample - loss: 0.5277 - mse: 0.3027 - mae: 0.5277 - mape: 107.8797\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 187us/sample - loss: 0.5274 - mse: 0.3023 - mae: 0.5274 - mape: 107.8075\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 149us/sample - loss: 0.5271 - mse: 0.3020 - mae: 0.5271 - mape: 107.7359\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 149us/sample - loss: 0.5267 - mse: 0.3016 - mae: 0.5267 - mape: 107.6626\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 153us/sample - loss: 0.5264 - mse: 0.3013 - mae: 0.5264 - mape: 107.5918\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 166us/sample - loss: 0.5261 - mse: 0.3009 - mae: 0.5261 - mape: 107.5197\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 129us/sample - loss: 0.5257 - mse: 0.3006 - mae: 0.5257 - mape: 107.4465\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 127us/sample - loss: 0.5254 - mse: 0.3003 - mae: 0.5254 - mape: 107.3739\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 0s 130us/sample - loss: 0.5251 - mse: 0.2999 - mae: 0.5251 - mape: 107.3019\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 134us/sample - loss: 0.5247 - mse: 0.2996 - mae: 0.5247 - mape: 107.2287\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 170us/sample - loss: 0.5244 - mse: 0.2992 - mae: 0.5244 - mape: 107.1566\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 182us/sample - loss: 0.5241 - mse: 0.2989 - mae: 0.5241 - mape: 107.0826\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 175us/sample - loss: 0.5238 - mse: 0.2985 - mae: 0.5238 - mape: 107.0098\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 161us/sample - loss: 0.5234 - mse: 0.2982 - mae: 0.5234 - mape: 106.9367\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 182us/sample - loss: 0.5231 - mse: 0.2978 - mae: 0.5231 - mape: 106.8628\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 158us/sample - loss: 0.5228 - mse: 0.2975 - mae: 0.5228 - mape: 106.7908\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 129us/sample - loss: 0.5224 - mse: 0.2971 - mae: 0.5224 - mape: 106.7166\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 115us/sample - loss: 0.5221 - mse: 0.2968 - mae: 0.5221 - mape: 106.6436\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 117us/sample - loss: 0.5217 - mse: 0.2964 - mae: 0.5217 - mape: 106.5689\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 132us/sample - loss: 0.5214 - mse: 0.2961 - mae: 0.5214 - mape: 106.4961\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 236us/sample - loss: 0.5211 - mse: 0.2957 - mae: 0.5211 - mape: 106.4214\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 140us/sample - loss: 0.5207 - mse: 0.2954 - mae: 0.5207 - mape: 106.3473\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 145us/sample - loss: 0.5204 - mse: 0.2950 - mae: 0.5204 - mape: 106.2731\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 155us/sample - loss: 0.5201 - mse: 0.2947 - mae: 0.5201 - mape: 106.1991\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 149us/sample - loss: 0.5197 - mse: 0.2943 - mae: 0.5197 - mape: 106.1259\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 118us/sample - loss: 0.5194 - mse: 0.2940 - mae: 0.5194 - mape: 106.0496\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 1ms/sample - loss: 0.6138 - accuracy: 0.7500\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.976312  6.317764           1600  3201.158  4.135         4\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.5\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 5.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 82 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 5ms/sample - loss: 0.6517 - mse: 0.4406 - mae: 0.6517 - mape: 117.1763\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 121us/sample - loss: 0.6514 - mse: 0.4402 - mae: 0.6514 - mape: 117.1166\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 130us/sample - loss: 0.6511 - mse: 0.4397 - mae: 0.6511 - mape: 117.0569\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 159us/sample - loss: 0.6507 - mse: 0.4393 - mae: 0.6507 - mape: 116.9973\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 199us/sample - loss: 0.6504 - mse: 0.4389 - mae: 0.6504 - mape: 116.9367\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 147us/sample - loss: 0.6501 - mse: 0.4385 - mae: 0.6501 - mape: 116.8766\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 143us/sample - loss: 0.6498 - mse: 0.4381 - mae: 0.6498 - mape: 116.8166\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 169us/sample - loss: 0.6495 - mse: 0.4376 - mae: 0.6495 - mape: 116.7564\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 142us/sample - loss: 0.6491 - mse: 0.4372 - mae: 0.6491 - mape: 116.6968\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 132us/sample - loss: 0.6488 - mse: 0.4368 - mae: 0.6488 - mape: 116.6367\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 159us/sample - loss: 0.6485 - mse: 0.4364 - mae: 0.6485 - mape: 116.5770\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 212us/sample - loss: 0.6482 - mse: 0.4360 - mae: 0.6482 - mape: 116.5167\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6478 - mse: 0.4355 - mae: 0.6478 - mape: 116.4572\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 149us/sample - loss: 0.6475 - mse: 0.4351 - mae: 0.6475 - mape: 116.3966\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 191us/sample - loss: 0.6472 - mse: 0.4347 - mae: 0.6472 - mape: 116.3373\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 129us/sample - loss: 0.6469 - mse: 0.4343 - mae: 0.6469 - mape: 116.2768\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 136us/sample - loss: 0.6466 - mse: 0.4339 - mae: 0.6466 - mape: 116.2166\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6462 - mse: 0.4335 - mae: 0.6462 - mape: 116.1570\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 215us/sample - loss: 0.6459 - mse: 0.4330 - mae: 0.6459 - mape: 116.0963\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 141us/sample - loss: 0.6456 - mse: 0.4326 - mae: 0.6456 - mape: 116.0364\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 154us/sample - loss: 0.6453 - mse: 0.4322 - mae: 0.6453 - mape: 115.9759\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 158us/sample - loss: 0.6449 - mse: 0.4318 - mae: 0.6449 - mape: 115.9158\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 160us/sample - loss: 0.6446 - mse: 0.4314 - mae: 0.6446 - mape: 115.8559\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 193us/sample - loss: 0.6443 - mse: 0.4310 - mae: 0.6443 - mape: 115.7957\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 160us/sample - loss: 0.6440 - mse: 0.4305 - mae: 0.6440 - mape: 115.7357\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 139us/sample - loss: 0.6436 - mse: 0.4301 - mae: 0.6436 - mape: 115.6746\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 142us/sample - loss: 0.6433 - mse: 0.4297 - mae: 0.6433 - mape: 115.6147\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 126us/sample - loss: 0.6430 - mse: 0.4293 - mae: 0.6430 - mape: 115.5546\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 151us/sample - loss: 0.6427 - mse: 0.4289 - mae: 0.6427 - mape: 115.4941\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 192us/sample - loss: 0.6424 - mse: 0.4285 - mae: 0.6424 - mape: 115.4338\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 156us/sample - loss: 0.6420 - mse: 0.4280 - mae: 0.6420 - mape: 115.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 150us/sample - loss: 0.6417 - mse: 0.4276 - mae: 0.6417 - mape: 115.3128\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 155us/sample - loss: 0.6414 - mse: 0.4272 - mae: 0.6414 - mape: 115.2530\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 149us/sample - loss: 0.6411 - mse: 0.4268 - mae: 0.6411 - mape: 115.1923\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 130us/sample - loss: 0.6407 - mse: 0.4264 - mae: 0.6407 - mape: 115.1317\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 135us/sample - loss: 0.6404 - mse: 0.4260 - mae: 0.6404 - mape: 115.0714\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 126us/sample - loss: 0.6401 - mse: 0.4255 - mae: 0.6401 - mape: 115.0112\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 150us/sample - loss: 0.6398 - mse: 0.4251 - mae: 0.6398 - mape: 114.9499\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 218us/sample - loss: 0.6394 - mse: 0.4247 - mae: 0.6394 - mape: 114.8900\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 139us/sample - loss: 0.6391 - mse: 0.4243 - mae: 0.6391 - mape: 114.8289\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 185us/sample - loss: 0.6388 - mse: 0.4239 - mae: 0.6388 - mape: 114.7679\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 151us/sample - loss: 0.6385 - mse: 0.4235 - mae: 0.6385 - mape: 114.7075\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 129us/sample - loss: 0.6381 - mse: 0.4230 - mae: 0.6381 - mape: 114.6465\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.6378 - mse: 0.4226 - mae: 0.6378 - mape: 114.5858\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 176us/sample - loss: 0.6375 - mse: 0.4222 - mae: 0.6375 - mape: 114.5251\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6371 - mse: 0.4218 - mae: 0.6371 - mape: 114.4647\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 153us/sample - loss: 0.6368 - mse: 0.4214 - mae: 0.6368 - mape: 114.4034\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 159us/sample - loss: 0.6365 - mse: 0.4210 - mae: 0.6365 - mape: 114.3422\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 148us/sample - loss: 0.6362 - mse: 0.4205 - mae: 0.6362 - mape: 114.2820\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 127us/sample - loss: 0.6358 - mse: 0.4201 - mae: 0.6358 - mape: 114.2208\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 119us/sample - loss: 0.6355 - mse: 0.4197 - mae: 0.6355 - mape: 114.1593\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.6352 - mse: 0.4193 - mae: 0.6352 - mape: 114.0989\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 187us/sample - loss: 0.6349 - mse: 0.4189 - mae: 0.6349 - mape: 114.0375\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 133us/sample - loss: 0.6345 - mse: 0.4185 - mae: 0.6345 - mape: 113.9761\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 150us/sample - loss: 0.6342 - mse: 0.4180 - mae: 0.6342 - mape: 113.9142\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 162us/sample - loss: 0.6339 - mse: 0.4176 - mae: 0.6339 - mape: 113.8536\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 122us/sample - loss: 0.6335 - mse: 0.4172 - mae: 0.6335 - mape: 113.7919\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 142us/sample - loss: 0.6332 - mse: 0.4168 - mae: 0.6332 - mape: 113.7305\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.6329 - mse: 0.4164 - mae: 0.6329 - mape: 113.6688\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.6325 - mse: 0.4159 - mae: 0.6325 - mape: 113.6073\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 118us/sample - loss: 0.6322 - mse: 0.4155 - mae: 0.6322 - mape: 113.5454\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 145us/sample - loss: 0.6319 - mse: 0.4151 - mae: 0.6319 - mape: 113.4838\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6316 - mse: 0.4147 - mae: 0.6316 - mape: 113.4224\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 130us/sample - loss: 0.6312 - mse: 0.4143 - mae: 0.6312 - mape: 113.3611\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 132us/sample - loss: 0.6309 - mse: 0.4138 - mae: 0.6309 - mape: 113.2992\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 153us/sample - loss: 0.6306 - mse: 0.4134 - mae: 0.6306 - mape: 113.2372\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 127us/sample - loss: 0.6302 - mse: 0.4130 - mae: 0.6302 - mape: 113.1751\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 129us/sample - loss: 0.6299 - mse: 0.4126 - mae: 0.6299 - mape: 113.1131\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6296 - mse: 0.4122 - mae: 0.6296 - mape: 113.0507\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 192us/sample - loss: 0.6292 - mse: 0.4117 - mae: 0.6292 - mape: 112.9892\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 154us/sample - loss: 0.6289 - mse: 0.4113 - mae: 0.6289 - mape: 112.9269\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 150us/sample - loss: 0.6286 - mse: 0.4109 - mae: 0.6286 - mape: 112.8642\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 152us/sample - loss: 0.6282 - mse: 0.4105 - mae: 0.6282 - mape: 112.8020\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 154us/sample - loss: 0.6279 - mse: 0.4101 - mae: 0.6279 - mape: 112.7398\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6275 - mse: 0.4096 - mae: 0.6275 - mape: 112.6767\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 147us/sample - loss: 0.6272 - mse: 0.4092 - mae: 0.6272 - mape: 112.6139\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 132us/sample - loss: 0.6269 - mse: 0.4088 - mae: 0.6269 - mape: 112.5517\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 121us/sample - loss: 0.6265 - mse: 0.4084 - mae: 0.6265 - mape: 112.4889\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.6262 - mse: 0.4079 - mae: 0.6262 - mape: 112.4267\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 131us/sample - loss: 0.6259 - mse: 0.4075 - mae: 0.6259 - mape: 112.3628\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 118us/sample - loss: 0.6255 - mse: 0.4071 - mae: 0.6255 - mape: 112.3006\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 153us/sample - loss: 0.6252 - mse: 0.4067 - mae: 0.6252 - mape: 112.2374\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 175us/sample - loss: 0.6249 - mse: 0.4063 - mae: 0.6249 - mape: 112.1750\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.6245 - mse: 0.4058 - mae: 0.6245 - mape: 112.1109\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 125us/sample - loss: 0.6242 - mse: 0.4054 - mae: 0.6242 - mape: 112.0476\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 138us/sample - loss: 0.6238 - mse: 0.4050 - mae: 0.6238 - mape: 111.9851\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 129us/sample - loss: 0.6235 - mse: 0.4046 - mae: 0.6235 - mape: 111.9214\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 120us/sample - loss: 0.6231 - mse: 0.4041 - mae: 0.6231 - mape: 111.8580\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 164us/sample - loss: 0.6228 - mse: 0.4037 - mae: 0.6228 - mape: 111.7936\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 194us/sample - loss: 0.6225 - mse: 0.4033 - mae: 0.6225 - mape: 111.7302\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 134us/sample - loss: 0.6221 - mse: 0.4029 - mae: 0.6221 - mape: 111.6669\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 128us/sample - loss: 0.6218 - mse: 0.4024 - mae: 0.6218 - mape: 111.6026\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 129us/sample - loss: 0.6214 - mse: 0.4020 - mae: 0.6214 - mape: 111.5386\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 144us/sample - loss: 0.6211 - mse: 0.4016 - mae: 0.6211 - mape: 111.4748\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 126us/sample - loss: 0.6208 - mse: 0.4011 - mae: 0.6208 - mape: 111.4108\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 120us/sample - loss: 0.6204 - mse: 0.4007 - mae: 0.6204 - mape: 111.3466\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 119us/sample - loss: 0.6201 - mse: 0.4003 - mae: 0.6201 - mape: 111.2825\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 130us/sample - loss: 0.6197 - mse: 0.3999 - mae: 0.6197 - mape: 111.2178\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 214us/sample - loss: 0.6194 - mse: 0.3994 - mae: 0.6194 - mape: 111.1538\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 150us/sample - loss: 0.6190 - mse: 0.3990 - mae: 0.6190 - mape: 111.0890\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 45 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 9ms/sample - loss: 0.8310 - mse: 0.6910 - mae: 0.8310 - mape: 93.9905\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 190us/sample - loss: 0.8308 - mse: 0.6907 - mae: 0.8308 - mape: 93.9700\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 266us/sample - loss: 0.8306 - mse: 0.6904 - mae: 0.8306 - mape: 93.9494\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 182us/sample - loss: 0.8304 - mse: 0.6901 - mae: 0.8304 - mape: 93.9290\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 143us/sample - loss: 0.8302 - mse: 0.6898 - mae: 0.8302 - mape: 93.9084\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 189us/sample - loss: 0.8300 - mse: 0.6895 - mae: 0.8300 - mape: 93.8879\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 255us/sample - loss: 0.8299 - mse: 0.6892 - mae: 0.8299 - mape: 93.8674\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 169us/sample - loss: 0.8297 - mse: 0.6889 - mae: 0.8297 - mape: 93.8469\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 160us/sample - loss: 0.8295 - mse: 0.6886 - mae: 0.8295 - mape: 93.8263\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 172us/sample - loss: 0.8293 - mse: 0.6883 - mae: 0.8293 - mape: 93.8058\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 148us/sample - loss: 0.8291 - mse: 0.6880 - mae: 0.8291 - mape: 93.7853\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 172us/sample - loss: 0.8290 - mse: 0.6877 - mae: 0.8290 - mape: 93.7648\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 189us/sample - loss: 0.8288 - mse: 0.6874 - mae: 0.8288 - mape: 93.7443\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 148us/sample - loss: 0.8286 - mse: 0.6871 - mae: 0.8286 - mape: 93.7237\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 200us/sample - loss: 0.8284 - mse: 0.6868 - mae: 0.8284 - mape: 93.7032\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 183us/sample - loss: 0.8282 - mse: 0.6865 - mae: 0.8282 - mape: 93.6826\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 165us/sample - loss: 0.8281 - mse: 0.6862 - mae: 0.8281 - mape: 93.6621\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 177us/sample - loss: 0.8279 - mse: 0.6859 - mae: 0.8279 - mape: 93.6416\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 338us/sample - loss: 0.8277 - mse: 0.6856 - mae: 0.8277 - mape: 93.6211\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 183us/sample - loss: 0.8275 - mse: 0.6853 - mae: 0.8275 - mape: 93.6006\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 184us/sample - loss: 0.8273 - mse: 0.6850 - mae: 0.8273 - mape: 93.5800\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 177us/sample - loss: 0.8271 - mse: 0.6847 - mae: 0.8271 - mape: 93.5595\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 221us/sample - loss: 0.8270 - mse: 0.6844 - mae: 0.8270 - mape: 93.5390\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 174us/sample - loss: 0.8268 - mse: 0.6841 - mae: 0.8268 - mape: 93.5185\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 175us/sample - loss: 0.8266 - mse: 0.6838 - mae: 0.8266 - mape: 93.4979\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 163us/sample - loss: 0.8264 - mse: 0.6835 - mae: 0.8264 - mape: 93.4774\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 280us/sample - loss: 0.8262 - mse: 0.6832 - mae: 0.8262 - mape: 93.4568\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 185us/sample - loss: 0.8261 - mse: 0.6829 - mae: 0.8261 - mape: 93.4363\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 211us/sample - loss: 0.8259 - mse: 0.6826 - mae: 0.8259 - mape: 93.4158\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 204us/sample - loss: 0.8257 - mse: 0.6823 - mae: 0.8257 - mape: 93.3952\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 182us/sample - loss: 0.8255 - mse: 0.6820 - mae: 0.8255 - mape: 93.3747\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 199us/sample - loss: 0.8253 - mse: 0.6817 - mae: 0.8253 - mape: 93.3541\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 183us/sample - loss: 0.8251 - mse: 0.6814 - mae: 0.8251 - mape: 93.3336\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 154us/sample - loss: 0.8250 - mse: 0.6811 - mae: 0.8250 - mape: 93.3130\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 166us/sample - loss: 0.8248 - mse: 0.6808 - mae: 0.8248 - mape: 93.2925\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 248us/sample - loss: 0.8246 - mse: 0.6805 - mae: 0.8246 - mape: 93.2719\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 352us/sample - loss: 0.8244 - mse: 0.6802 - mae: 0.8244 - mape: 93.2513\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 246us/sample - loss: 0.8242 - mse: 0.6799 - mae: 0.8242 - mape: 93.2308\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 232us/sample - loss: 0.8241 - mse: 0.6796 - mae: 0.8241 - mape: 93.2103\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 207us/sample - loss: 0.8239 - mse: 0.6793 - mae: 0.8239 - mape: 93.1897\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 186us/sample - loss: 0.8237 - mse: 0.6790 - mae: 0.8237 - mape: 93.1691\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 175us/sample - loss: 0.8235 - mse: 0.6787 - mae: 0.8235 - mape: 93.1485\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 191us/sample - loss: 0.8233 - mse: 0.6784 - mae: 0.8233 - mape: 93.1279\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 148us/sample - loss: 0.8232 - mse: 0.6781 - mae: 0.8232 - mape: 93.1074\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 168us/sample - loss: 0.8230 - mse: 0.6778 - mae: 0.8230 - mape: 93.0868\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 187us/sample - loss: 0.8228 - mse: 0.6775 - mae: 0.8228 - mape: 93.0661\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 148us/sample - loss: 0.8226 - mse: 0.6772 - mae: 0.8226 - mape: 93.0456\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 182us/sample - loss: 0.8224 - mse: 0.6769 - mae: 0.8224 - mape: 93.0250\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 188us/sample - loss: 0.8222 - mse: 0.6766 - mae: 0.8222 - mape: 93.0044\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 145us/sample - loss: 0.8221 - mse: 0.6763 - mae: 0.8221 - mape: 92.9838\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 177us/sample - loss: 0.8219 - mse: 0.6760 - mae: 0.8219 - mape: 92.9632\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 199us/sample - loss: 0.8217 - mse: 0.6758 - mae: 0.8217 - mape: 92.9425\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 290us/sample - loss: 0.8215 - mse: 0.6755 - mae: 0.8215 - mape: 92.9219\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 183us/sample - loss: 0.8213 - mse: 0.6752 - mae: 0.8213 - mape: 92.9013\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 173us/sample - loss: 0.8211 - mse: 0.6749 - mae: 0.8211 - mape: 92.8806\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 206us/sample - loss: 0.8210 - mse: 0.6746 - mae: 0.8210 - mape: 92.8600\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 200us/sample - loss: 0.8208 - mse: 0.6743 - mae: 0.8208 - mape: 92.8394\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 190us/sample - loss: 0.8206 - mse: 0.6740 - mae: 0.8206 - mape: 92.8187\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 178us/sample - loss: 0.8204 - mse: 0.6737 - mae: 0.8204 - mape: 92.7980\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 185us/sample - loss: 0.8202 - mse: 0.6734 - mae: 0.8202 - mape: 92.7774\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 174us/sample - loss: 0.8201 - mse: 0.6731 - mae: 0.8201 - mape: 92.7567\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 193us/sample - loss: 0.8199 - mse: 0.6728 - mae: 0.8199 - mape: 92.7360\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 275us/sample - loss: 0.8197 - mse: 0.6725 - mae: 0.8197 - mape: 92.7154\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 196us/sample - loss: 0.8195 - mse: 0.6722 - mae: 0.8195 - mape: 92.6947\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 189us/sample - loss: 0.8193 - mse: 0.6719 - mae: 0.8193 - mape: 92.6740\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 162us/sample - loss: 0.8191 - mse: 0.6716 - mae: 0.8191 - mape: 92.6533\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 214us/sample - loss: 0.8190 - mse: 0.6713 - mae: 0.8190 - mape: 92.6326\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 216us/sample - loss: 0.8188 - mse: 0.6710 - mae: 0.8188 - mape: 92.6119\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 151us/sample - loss: 0.8186 - mse: 0.6707 - mae: 0.8186 - mape: 92.5911\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 168us/sample - loss: 0.8184 - mse: 0.6704 - mae: 0.8184 - mape: 92.5704\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 180us/sample - loss: 0.8182 - mse: 0.6701 - mae: 0.8182 - mape: 92.5497\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 154us/sample - loss: 0.8180 - mse: 0.6698 - mae: 0.8180 - mape: 92.5289\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 168us/sample - loss: 0.8179 - mse: 0.6695 - mae: 0.8179 - mape: 92.5082\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 218us/sample - loss: 0.8177 - mse: 0.6692 - mae: 0.8177 - mape: 92.4875\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 150us/sample - loss: 0.8175 - mse: 0.6689 - mae: 0.8175 - mape: 92.4667\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 187us/sample - loss: 0.8173 - mse: 0.6686 - mae: 0.8173 - mape: 92.4460\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 218us/sample - loss: 0.8171 - mse: 0.6683 - mae: 0.8171 - mape: 92.4252\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 305us/sample - loss: 0.8169 - mse: 0.6680 - mae: 0.8169 - mape: 92.4044\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 187us/sample - loss: 0.8168 - mse: 0.6677 - mae: 0.8168 - mape: 92.3836\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 179us/sample - loss: 0.8166 - mse: 0.6674 - mae: 0.8166 - mape: 92.3628\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 184us/sample - loss: 0.8164 - mse: 0.6671 - mae: 0.8164 - mape: 92.3420\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 197us/sample - loss: 0.8162 - mse: 0.6668 - mae: 0.8162 - mape: 92.3212\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 175us/sample - loss: 0.8160 - mse: 0.6665 - mae: 0.8160 - mape: 92.3003\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 156us/sample - loss: 0.8158 - mse: 0.6662 - mae: 0.8158 - mape: 92.2795\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 161us/sample - loss: 0.8157 - mse: 0.6659 - mae: 0.8157 - mape: 92.2587\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 143us/sample - loss: 0.8155 - mse: 0.6656 - mae: 0.8155 - mape: 92.2378\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 179us/sample - loss: 0.8153 - mse: 0.6653 - mae: 0.8153 - mape: 92.2170\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 176us/sample - loss: 0.8151 - mse: 0.6650 - mae: 0.8151 - mape: 92.1962\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 328us/sample - loss: 0.8149 - mse: 0.6647 - mae: 0.8149 - mape: 92.1753\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 171us/sample - loss: 0.8147 - mse: 0.6644 - mae: 0.8147 - mape: 92.1544\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 221us/sample - loss: 0.8145 - mse: 0.6641 - mae: 0.8145 - mape: 92.1336\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 213us/sample - loss: 0.8144 - mse: 0.6638 - mae: 0.8144 - mape: 92.1126\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 199us/sample - loss: 0.8142 - mse: 0.6635 - mae: 0.8142 - mape: 92.0917\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 163us/sample - loss: 0.8140 - mse: 0.6632 - mae: 0.8140 - mape: 92.0708\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 136us/sample - loss: 0.8138 - mse: 0.6629 - mae: 0.8138 - mape: 92.0499\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 326us/sample - loss: 0.8136 - mse: 0.6626 - mae: 0.8136 - mape: 92.0289\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 199us/sample - loss: 0.8134 - mse: 0.6623 - mae: 0.8134 - mape: 92.0080\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 204us/sample - loss: 0.8133 - mse: 0.6620 - mae: 0.8133 - mape: 91.9871\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 150us/sample - loss: 0.8131 - mse: 0.6617 - mae: 0.8131 - mape: 91.9661\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 188us/sample - loss: 0.8129 - mse: 0.6614 - mae: 0.8129 - mape: 91.9451\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 56 samples\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 0s 7ms/sample - loss: 0.6191 - mse: 0.3837 - mae: 0.6191 - mape: 95.5038\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 252us/sample - loss: 0.6189 - mse: 0.3834 - mae: 0.6189 - mape: 95.4732\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 175us/sample - loss: 0.6187 - mse: 0.3832 - mae: 0.6187 - mape: 95.4428\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 160us/sample - loss: 0.6185 - mse: 0.3829 - mae: 0.6185 - mape: 95.4121\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 171us/sample - loss: 0.6183 - mse: 0.3827 - mae: 0.6183 - mape: 95.3816\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 153us/sample - loss: 0.6181 - mse: 0.3825 - mae: 0.6181 - mape: 95.3511\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 178us/sample - loss: 0.6179 - mse: 0.3822 - mae: 0.6179 - mape: 95.3205\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 154us/sample - loss: 0.6177 - mse: 0.3820 - mae: 0.6177 - mape: 95.2899\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 130us/sample - loss: 0.6175 - mse: 0.3817 - mae: 0.6175 - mape: 95.2595\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 139us/sample - loss: 0.6173 - mse: 0.3815 - mae: 0.6173 - mape: 95.2289\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 162us/sample - loss: 0.6171 - mse: 0.3812 - mae: 0.6171 - mape: 95.1984\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 153us/sample - loss: 0.6169 - mse: 0.3810 - mae: 0.6169 - mape: 95.1678\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 135us/sample - loss: 0.6167 - mse: 0.3807 - mae: 0.6167 - mape: 95.1372\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 148us/sample - loss: 0.6165 - mse: 0.3805 - mae: 0.6165 - mape: 95.1067\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 203us/sample - loss: 0.6163 - mse: 0.3803 - mae: 0.6163 - mape: 95.0761\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 237us/sample - loss: 0.6161 - mse: 0.3800 - mae: 0.6161 - mape: 95.0457\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 184us/sample - loss: 0.6159 - mse: 0.3798 - mae: 0.6159 - mape: 95.0151\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 154us/sample - loss: 0.6157 - mse: 0.3795 - mae: 0.6157 - mape: 94.9845\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 141us/sample - loss: 0.6155 - mse: 0.3793 - mae: 0.6155 - mape: 94.9540\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 180us/sample - loss: 0.6153 - mse: 0.3790 - mae: 0.6153 - mape: 94.9235\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 191us/sample - loss: 0.6151 - mse: 0.3788 - mae: 0.6151 - mape: 94.8928\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 164us/sample - loss: 0.6149 - mse: 0.3786 - mae: 0.6149 - mape: 94.8624\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 133us/sample - loss: 0.6148 - mse: 0.3783 - mae: 0.6148 - mape: 94.8318\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 142us/sample - loss: 0.6146 - mse: 0.3781 - mae: 0.6146 - mape: 94.8014\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 165us/sample - loss: 0.6144 - mse: 0.3778 - mae: 0.6144 - mape: 94.7708\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 181us/sample - loss: 0.6142 - mse: 0.3776 - mae: 0.6142 - mape: 94.7401\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 143us/sample - loss: 0.6140 - mse: 0.3773 - mae: 0.6140 - mape: 94.7096\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 444us/sample - loss: 0.6138 - mse: 0.3771 - mae: 0.6138 - mape: 94.6791\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 175us/sample - loss: 0.6136 - mse: 0.3769 - mae: 0.6136 - mape: 94.6486\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 193us/sample - loss: 0.6134 - mse: 0.3766 - mae: 0.6134 - mape: 94.6180\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 194us/sample - loss: 0.6132 - mse: 0.3764 - mae: 0.6132 - mape: 94.5874\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 142us/sample - loss: 0.6130 - mse: 0.3761 - mae: 0.6130 - mape: 94.5569\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 149us/sample - loss: 0.6128 - mse: 0.3759 - mae: 0.6128 - mape: 94.5263\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 174us/sample - loss: 0.6126 - mse: 0.3756 - mae: 0.6126 - mape: 94.4958\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 160us/sample - loss: 0.6124 - mse: 0.3754 - mae: 0.6124 - mape: 94.4652\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 255us/sample - loss: 0.6122 - mse: 0.3752 - mae: 0.6122 - mape: 94.4346\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 137us/sample - loss: 0.6120 - mse: 0.3749 - mae: 0.6120 - mape: 94.4041\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 140us/sample - loss: 0.6118 - mse: 0.3747 - mae: 0.6118 - mape: 94.3736\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 189us/sample - loss: 0.6116 - mse: 0.3744 - mae: 0.6116 - mape: 94.3429\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 178us/sample - loss: 0.6114 - mse: 0.3742 - mae: 0.6114 - mape: 94.3123\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 157us/sample - loss: 0.6112 - mse: 0.3739 - mae: 0.6112 - mape: 94.2817\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 129us/sample - loss: 0.6110 - mse: 0.3737 - mae: 0.6110 - mape: 94.2511\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 169us/sample - loss: 0.6108 - mse: 0.3735 - mae: 0.6108 - mape: 94.2206\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 192us/sample - loss: 0.6106 - mse: 0.3732 - mae: 0.6106 - mape: 94.1900\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 254us/sample - loss: 0.6104 - mse: 0.3730 - mae: 0.6104 - mape: 94.1594\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 181us/sample - loss: 0.6102 - mse: 0.3727 - mae: 0.6102 - mape: 94.1289\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 156us/sample - loss: 0.6100 - mse: 0.3725 - mae: 0.6100 - mape: 94.0981\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 149us/sample - loss: 0.6098 - mse: 0.3723 - mae: 0.6098 - mape: 94.0676\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 181us/sample - loss: 0.6096 - mse: 0.3720 - mae: 0.6096 - mape: 94.0370\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 167us/sample - loss: 0.6094 - mse: 0.3718 - mae: 0.6094 - mape: 94.0063\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 127us/sample - loss: 0.6092 - mse: 0.3715 - mae: 0.6092 - mape: 93.9756\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 174us/sample - loss: 0.6090 - mse: 0.3713 - mae: 0.6090 - mape: 93.9450\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 185us/sample - loss: 0.6088 - mse: 0.3710 - mae: 0.6088 - mape: 93.9144\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 253us/sample - loss: 0.6086 - mse: 0.3708 - mae: 0.6086 - mape: 93.8838\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 166us/sample - loss: 0.6084 - mse: 0.3706 - mae: 0.6084 - mape: 93.8531\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 151us/sample - loss: 0.6082 - mse: 0.3703 - mae: 0.6082 - mape: 93.8224\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 149us/sample - loss: 0.6080 - mse: 0.3701 - mae: 0.6080 - mape: 93.7917\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 151us/sample - loss: 0.6078 - mse: 0.3698 - mae: 0.6078 - mape: 93.7610\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 159us/sample - loss: 0.6076 - mse: 0.3696 - mae: 0.6076 - mape: 93.7304\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 131us/sample - loss: 0.6074 - mse: 0.3694 - mae: 0.6074 - mape: 93.6997\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 118us/sample - loss: 0.6072 - mse: 0.3691 - mae: 0.6072 - mape: 93.6690\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 150us/sample - loss: 0.6070 - mse: 0.3689 - mae: 0.6070 - mape: 93.6383\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 158us/sample - loss: 0.6068 - mse: 0.3686 - mae: 0.6068 - mape: 93.6075\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 215us/sample - loss: 0.6066 - mse: 0.3684 - mae: 0.6066 - mape: 93.5769\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 158us/sample - loss: 0.6064 - mse: 0.3681 - mae: 0.6064 - mape: 93.5461\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 144us/sample - loss: 0.6062 - mse: 0.3679 - mae: 0.6062 - mape: 93.5154\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 145us/sample - loss: 0.6060 - mse: 0.3677 - mae: 0.6060 - mape: 93.4846\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 134us/sample - loss: 0.6058 - mse: 0.3674 - mae: 0.6058 - mape: 93.4538\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 157us/sample - loss: 0.6056 - mse: 0.3672 - mae: 0.6056 - mape: 93.4231\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 140us/sample - loss: 0.6054 - mse: 0.3669 - mae: 0.6054 - mape: 93.3923\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 129us/sample - loss: 0.6052 - mse: 0.3667 - mae: 0.6052 - mape: 93.3615\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 125us/sample - loss: 0.6050 - mse: 0.3665 - mae: 0.6050 - mape: 93.3308\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 125us/sample - loss: 0.6048 - mse: 0.3662 - mae: 0.6048 - mape: 93.2999\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 122us/sample - loss: 0.6046 - mse: 0.3660 - mae: 0.6046 - mape: 93.2691\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 143us/sample - loss: 0.6044 - mse: 0.3657 - mae: 0.6044 - mape: 93.2383\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 288us/sample - loss: 0.6042 - mse: 0.3655 - mae: 0.6042 - mape: 93.2074\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 151us/sample - loss: 0.6040 - mse: 0.3653 - mae: 0.6040 - mape: 93.1766\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 215us/sample - loss: 0.6038 - mse: 0.3650 - mae: 0.6038 - mape: 93.1458\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 285us/sample - loss: 0.6036 - mse: 0.3648 - mae: 0.6036 - mape: 93.1149\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 155us/sample - loss: 0.6034 - mse: 0.3645 - mae: 0.6034 - mape: 93.0840\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 132us/sample - loss: 0.6032 - mse: 0.3643 - mae: 0.6032 - mape: 93.0531\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 183us/sample - loss: 0.6030 - mse: 0.3640 - mae: 0.6030 - mape: 93.0222\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 171us/sample - loss: 0.6028 - mse: 0.3638 - mae: 0.6028 - mape: 92.9912\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 155us/sample - loss: 0.6026 - mse: 0.3636 - mae: 0.6026 - mape: 92.9603\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 118us/sample - loss: 0.6024 - mse: 0.3633 - mae: 0.6024 - mape: 92.9294\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 148us/sample - loss: 0.6022 - mse: 0.3631 - mae: 0.6022 - mape: 92.8985\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 130us/sample - loss: 0.6020 - mse: 0.3628 - mae: 0.6020 - mape: 92.8675\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 127us/sample - loss: 0.6018 - mse: 0.3626 - mae: 0.6018 - mape: 92.8365\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 155us/sample - loss: 0.6016 - mse: 0.3624 - mae: 0.6016 - mape: 92.8054\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 153us/sample - loss: 0.6014 - mse: 0.3621 - mae: 0.6014 - mape: 92.7745\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 195us/sample - loss: 0.6012 - mse: 0.3619 - mae: 0.6012 - mape: 92.7434\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 133us/sample - loss: 0.6010 - mse: 0.3616 - mae: 0.6010 - mape: 92.7124\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 168us/sample - loss: 0.6008 - mse: 0.3614 - mae: 0.6008 - mape: 92.6813\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 150us/sample - loss: 0.6006 - mse: 0.3611 - mae: 0.6006 - mape: 92.6503\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 154us/sample - loss: 0.6004 - mse: 0.3609 - mae: 0.6004 - mape: 92.6192\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 163us/sample - loss: 0.6002 - mse: 0.3607 - mae: 0.6002 - mape: 92.5882\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 145us/sample - loss: 0.6000 - mse: 0.3604 - mae: 0.6000 - mape: 92.5569\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 142us/sample - loss: 0.5998 - mse: 0.3602 - mae: 0.5998 - mape: 92.5258\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 122us/sample - loss: 0.5996 - mse: 0.3599 - mae: 0.5996 - mape: 92.4947\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 147us/sample - loss: 0.5994 - mse: 0.3597 - mae: 0.5994 - mape: 92.4635\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 3/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 67 samples\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 0s 6ms/sample - loss: 0.5369 - mse: 0.2896 - mae: 0.5369 - mape: 100.4693\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 138us/sample - loss: 0.5366 - mse: 0.2893 - mae: 0.5366 - mape: 100.4118\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 142us/sample - loss: 0.5363 - mse: 0.2889 - mae: 0.5363 - mape: 100.3543\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 154us/sample - loss: 0.5360 - mse: 0.2886 - mae: 0.5360 - mape: 100.2966\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 159us/sample - loss: 0.5357 - mse: 0.2883 - mae: 0.5357 - mape: 100.2390\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 157us/sample - loss: 0.5354 - mse: 0.2880 - mae: 0.5354 - mape: 100.1814\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 149us/sample - loss: 0.5351 - mse: 0.2876 - mae: 0.5351 - mape: 100.1240\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 207us/sample - loss: 0.5348 - mse: 0.2873 - mae: 0.5348 - mape: 100.0663\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 140us/sample - loss: 0.5345 - mse: 0.2870 - mae: 0.5345 - mape: 100.0089\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 157us/sample - loss: 0.5342 - mse: 0.2866 - mae: 0.5342 - mape: 99.9514\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 179us/sample - loss: 0.5339 - mse: 0.2863 - mae: 0.5339 - mape: 99.8939\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5336 - mse: 0.2860 - mae: 0.5336 - mape: 99.8363\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 164us/sample - loss: 0.5333 - mse: 0.2857 - mae: 0.5333 - mape: 99.7787\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 148us/sample - loss: 0.5329 - mse: 0.2853 - mae: 0.5329 - mape: 99.7212\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 132us/sample - loss: 0.5326 - mse: 0.2850 - mae: 0.5326 - mape: 99.6634\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 145us/sample - loss: 0.5323 - mse: 0.2847 - mae: 0.5323 - mape: 99.6060\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5320 - mse: 0.2844 - mae: 0.5320 - mape: 99.5483\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 247us/sample - loss: 0.5317 - mse: 0.2840 - mae: 0.5317 - mape: 99.4908\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 164us/sample - loss: 0.5314 - mse: 0.2837 - mae: 0.5314 - mape: 99.4330\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 177us/sample - loss: 0.5311 - mse: 0.2834 - mae: 0.5311 - mape: 99.3757\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 179us/sample - loss: 0.5308 - mse: 0.2831 - mae: 0.5308 - mape: 99.3182\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 160us/sample - loss: 0.5305 - mse: 0.2827 - mae: 0.5305 - mape: 99.2605\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 128us/sample - loss: 0.5302 - mse: 0.2824 - mae: 0.5302 - mape: 99.2030\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 150us/sample - loss: 0.5299 - mse: 0.2821 - mae: 0.5299 - mape: 99.1456\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 204us/sample - loss: 0.5296 - mse: 0.2818 - mae: 0.5296 - mape: 99.0877\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 183us/sample - loss: 0.5293 - mse: 0.2815 - mae: 0.5293 - mape: 99.0303\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 160us/sample - loss: 0.5290 - mse: 0.2811 - mae: 0.5290 - mape: 98.9724\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 171us/sample - loss: 0.5287 - mse: 0.2808 - mae: 0.5287 - mape: 98.9148\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 178us/sample - loss: 0.5284 - mse: 0.2805 - mae: 0.5284 - mape: 98.8571\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 172us/sample - loss: 0.5281 - mse: 0.2802 - mae: 0.5281 - mape: 98.7994\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 153us/sample - loss: 0.5277 - mse: 0.2798 - mae: 0.5277 - mape: 98.7414\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 209us/sample - loss: 0.5274 - mse: 0.2795 - mae: 0.5274 - mape: 98.6833\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 244us/sample - loss: 0.5271 - mse: 0.2792 - mae: 0.5271 - mape: 98.6255\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 181us/sample - loss: 0.5268 - mse: 0.2789 - mae: 0.5268 - mape: 98.5675\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 156us/sample - loss: 0.5265 - mse: 0.2785 - mae: 0.5265 - mape: 98.5095\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 166us/sample - loss: 0.5262 - mse: 0.2782 - mae: 0.5262 - mape: 98.4518\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 162us/sample - loss: 0.5259 - mse: 0.2779 - mae: 0.5259 - mape: 98.3937\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 151us/sample - loss: 0.5256 - mse: 0.2776 - mae: 0.5256 - mape: 98.3360\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 155us/sample - loss: 0.5253 - mse: 0.2772 - mae: 0.5253 - mape: 98.2779\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 149us/sample - loss: 0.5250 - mse: 0.2769 - mae: 0.5250 - mape: 98.2200\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 163us/sample - loss: 0.5247 - mse: 0.2766 - mae: 0.5247 - mape: 98.1621\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 240us/sample - loss: 0.5244 - mse: 0.2763 - mae: 0.5244 - mape: 98.1040\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 156us/sample - loss: 0.5241 - mse: 0.2760 - mae: 0.5241 - mape: 98.0457\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 157us/sample - loss: 0.5237 - mse: 0.2756 - mae: 0.5237 - mape: 97.9874\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 148us/sample - loss: 0.5234 - mse: 0.2753 - mae: 0.5234 - mape: 97.9293\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 174us/sample - loss: 0.5231 - mse: 0.2750 - mae: 0.5231 - mape: 97.8712\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 137us/sample - loss: 0.5228 - mse: 0.2747 - mae: 0.5228 - mape: 97.8130\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 132us/sample - loss: 0.5225 - mse: 0.2743 - mae: 0.5225 - mape: 97.7548\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 117us/sample - loss: 0.5222 - mse: 0.2740 - mae: 0.5222 - mape: 97.6963\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 145us/sample - loss: 0.5219 - mse: 0.2737 - mae: 0.5219 - mape: 97.6379\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 133us/sample - loss: 0.5216 - mse: 0.2734 - mae: 0.5216 - mape: 97.5795\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 153us/sample - loss: 0.5213 - mse: 0.2731 - mae: 0.5213 - mape: 97.5212\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 153us/sample - loss: 0.5210 - mse: 0.2727 - mae: 0.5210 - mape: 97.4628\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 183us/sample - loss: 0.5206 - mse: 0.2724 - mae: 0.5206 - mape: 97.4044\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 147us/sample - loss: 0.5203 - mse: 0.2721 - mae: 0.5203 - mape: 97.3459\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 155us/sample - loss: 0.5200 - mse: 0.2718 - mae: 0.5200 - mape: 97.2873\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 159us/sample - loss: 0.5197 - mse: 0.2714 - mae: 0.5197 - mape: 97.2286\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 160us/sample - loss: 0.5194 - mse: 0.2711 - mae: 0.5194 - mape: 97.1702\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 137us/sample - loss: 0.5191 - mse: 0.2708 - mae: 0.5191 - mape: 97.1116\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 134us/sample - loss: 0.5188 - mse: 0.2705 - mae: 0.5188 - mape: 97.0530\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 141us/sample - loss: 0.5185 - mse: 0.2701 - mae: 0.5185 - mape: 96.9938\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 146us/sample - loss: 0.5182 - mse: 0.2698 - mae: 0.5182 - mape: 96.9352\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 126us/sample - loss: 0.5178 - mse: 0.2695 - mae: 0.5178 - mape: 96.8765\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 167us/sample - loss: 0.5175 - mse: 0.2692 - mae: 0.5175 - mape: 96.8176\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 286us/sample - loss: 0.5172 - mse: 0.2689 - mae: 0.5172 - mape: 96.7589\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 160us/sample - loss: 0.5169 - mse: 0.2685 - mae: 0.5169 - mape: 96.6998\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 148us/sample - loss: 0.5166 - mse: 0.2682 - mae: 0.5166 - mape: 96.6405\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 159us/sample - loss: 0.5163 - mse: 0.2679 - mae: 0.5163 - mape: 96.5817\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 211us/sample - loss: 0.5160 - mse: 0.2676 - mae: 0.5160 - mape: 96.5222\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 146us/sample - loss: 0.5157 - mse: 0.2672 - mae: 0.5157 - mape: 96.4629\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 144us/sample - loss: 0.5153 - mse: 0.2669 - mae: 0.5153 - mape: 96.4038\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 154us/sample - loss: 0.5150 - mse: 0.2666 - mae: 0.5150 - mape: 96.3443\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 188us/sample - loss: 0.5147 - mse: 0.2663 - mae: 0.5147 - mape: 96.2851\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 184us/sample - loss: 0.5144 - mse: 0.2659 - mae: 0.5144 - mape: 96.2252\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 145us/sample - loss: 0.5141 - mse: 0.2656 - mae: 0.5141 - mape: 96.1659\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 156us/sample - loss: 0.5138 - mse: 0.2653 - mae: 0.5138 - mape: 96.1062\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 188us/sample - loss: 0.5134 - mse: 0.2650 - mae: 0.5134 - mape: 96.0464\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 166us/sample - loss: 0.5131 - mse: 0.2646 - mae: 0.5131 - mape: 95.9867\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 166us/sample - loss: 0.5128 - mse: 0.2643 - mae: 0.5128 - mape: 95.9267\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 190us/sample - loss: 0.5125 - mse: 0.2640 - mae: 0.5125 - mape: 95.8667\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 255us/sample - loss: 0.5122 - mse: 0.2637 - mae: 0.5122 - mape: 95.8066\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 185us/sample - loss: 0.5118 - mse: 0.2633 - mae: 0.5118 - mape: 95.7464\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 181us/sample - loss: 0.5115 - mse: 0.2630 - mae: 0.5115 - mape: 95.6861\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5112 - mse: 0.2627 - mae: 0.5112 - mape: 95.6258\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 175us/sample - loss: 0.5109 - mse: 0.2623 - mae: 0.5109 - mape: 95.5655\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 158us/sample - loss: 0.5106 - mse: 0.2620 - mae: 0.5106 - mape: 95.5052\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5102 - mse: 0.2617 - mae: 0.5102 - mape: 95.4445\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 320us/sample - loss: 0.5099 - mse: 0.2614 - mae: 0.5099 - mape: 95.3839\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 164us/sample - loss: 0.5096 - mse: 0.2610 - mae: 0.5096 - mape: 95.3234\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5093 - mse: 0.2607 - mae: 0.5093 - mape: 95.2624\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 165us/sample - loss: 0.5090 - mse: 0.2604 - mae: 0.5090 - mape: 95.2018\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 167us/sample - loss: 0.5086 - mse: 0.2601 - mae: 0.5086 - mape: 95.1409\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 145us/sample - loss: 0.5083 - mse: 0.2597 - mae: 0.5083 - mape: 95.0803\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 140us/sample - loss: 0.5080 - mse: 0.2594 - mae: 0.5080 - mape: 95.0192\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 155us/sample - loss: 0.5077 - mse: 0.2591 - mae: 0.5077 - mape: 94.9581\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 150us/sample - loss: 0.5073 - mse: 0.2587 - mae: 0.5073 - mape: 94.8969\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 136us/sample - loss: 0.5070 - mse: 0.2584 - mae: 0.5070 - mape: 94.8353\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 136us/sample - loss: 0.5067 - mse: 0.2581 - mae: 0.5067 - mape: 94.7743\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 152us/sample - loss: 0.5064 - mse: 0.2578 - mae: 0.5064 - mape: 94.7125\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 170us/sample - loss: 0.5060 - mse: 0.2574 - mae: 0.5060 - mape: 94.6515\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 4/5Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 89 samples\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 0s 5ms/sample - loss: 0.5473 - mse: 0.3232 - mae: 0.5473 - mape: 112.1514\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 142us/sample - loss: 0.5470 - mse: 0.3229 - mae: 0.5470 - mape: 112.0801\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 200us/sample - loss: 0.5467 - mse: 0.3225 - mae: 0.5467 - mape: 112.0079\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 132us/sample - loss: 0.5464 - mse: 0.3222 - mae: 0.5464 - mape: 111.9358\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5460 - mse: 0.3219 - mae: 0.5460 - mape: 111.8652\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 138us/sample - loss: 0.5457 - mse: 0.3215 - mae: 0.5457 - mape: 111.7942\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 128us/sample - loss: 0.5454 - mse: 0.3212 - mae: 0.5454 - mape: 111.7228\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 150us/sample - loss: 0.5451 - mse: 0.3208 - mae: 0.5451 - mape: 111.6514\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 183us/sample - loss: 0.5448 - mse: 0.3205 - mae: 0.5448 - mape: 111.5791\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 141us/sample - loss: 0.5445 - mse: 0.3202 - mae: 0.5445 - mape: 111.5080\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5441 - mse: 0.3198 - mae: 0.5441 - mape: 111.4372\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 134us/sample - loss: 0.5438 - mse: 0.3195 - mae: 0.5438 - mape: 111.3653\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5435 - mse: 0.3191 - mae: 0.5435 - mape: 111.2934\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 110us/sample - loss: 0.5432 - mse: 0.3188 - mae: 0.5432 - mape: 111.2220\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5429 - mse: 0.3185 - mae: 0.5429 - mape: 111.1499\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 119us/sample - loss: 0.5425 - mse: 0.3181 - mae: 0.5425 - mape: 111.0796\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5422 - mse: 0.3178 - mae: 0.5422 - mape: 111.0069\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 181us/sample - loss: 0.5419 - mse: 0.3174 - mae: 0.5419 - mape: 110.9352\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 145us/sample - loss: 0.5416 - mse: 0.3171 - mae: 0.5416 - mape: 110.8647\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5413 - mse: 0.3168 - mae: 0.5413 - mape: 110.7932\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 154us/sample - loss: 0.5409 - mse: 0.3164 - mae: 0.5409 - mape: 110.7203\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5406 - mse: 0.3161 - mae: 0.5406 - mape: 110.6496\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5403 - mse: 0.3158 - mae: 0.5403 - mape: 110.5775\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 120us/sample - loss: 0.5400 - mse: 0.3154 - mae: 0.5400 - mape: 110.5058\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 109us/sample - loss: 0.5397 - mse: 0.3151 - mae: 0.5397 - mape: 110.4344\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 120us/sample - loss: 0.5394 - mse: 0.3147 - mae: 0.5394 - mape: 110.3630\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 127us/sample - loss: 0.5390 - mse: 0.3144 - mae: 0.5390 - mape: 110.2900\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5387 - mse: 0.3141 - mae: 0.5387 - mape: 110.2175\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 198us/sample - loss: 0.5384 - mse: 0.3137 - mae: 0.5384 - mape: 110.1458\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5381 - mse: 0.3134 - mae: 0.5381 - mape: 110.0749\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 160us/sample - loss: 0.5377 - mse: 0.3131 - mae: 0.5377 - mape: 110.0014\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 139us/sample - loss: 0.5374 - mse: 0.3127 - mae: 0.5374 - mape: 109.9305\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5371 - mse: 0.3124 - mae: 0.5371 - mape: 109.8579\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5368 - mse: 0.3120 - mae: 0.5368 - mape: 109.7871\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5365 - mse: 0.3117 - mae: 0.5365 - mape: 109.7142\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 125us/sample - loss: 0.5361 - mse: 0.3114 - mae: 0.5361 - mape: 109.6430\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 132us/sample - loss: 0.5358 - mse: 0.3110 - mae: 0.5358 - mape: 109.5702\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 151us/sample - loss: 0.5355 - mse: 0.3107 - mae: 0.5355 - mape: 109.4972\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 206us/sample - loss: 0.5352 - mse: 0.3103 - mae: 0.5352 - mape: 109.4255\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5349 - mse: 0.3100 - mae: 0.5349 - mape: 109.3531\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5345 - mse: 0.3097 - mae: 0.5345 - mape: 109.2808\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 150us/sample - loss: 0.5342 - mse: 0.3093 - mae: 0.5342 - mape: 109.2068\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 124us/sample - loss: 0.5339 - mse: 0.3090 - mae: 0.5339 - mape: 109.1360\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5336 - mse: 0.3087 - mae: 0.5336 - mape: 109.0628\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 244us/sample - loss: 0.5332 - mse: 0.3083 - mae: 0.5332 - mape: 108.9897\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 141us/sample - loss: 0.5329 - mse: 0.3080 - mae: 0.5329 - mape: 108.9180\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 140us/sample - loss: 0.5326 - mse: 0.3076 - mae: 0.5326 - mape: 108.8451\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 135us/sample - loss: 0.5323 - mse: 0.3073 - mae: 0.5323 - mape: 108.7710\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5319 - mse: 0.3070 - mae: 0.5319 - mape: 108.6987\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 124us/sample - loss: 0.5316 - mse: 0.3066 - mae: 0.5316 - mape: 108.6254\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 210us/sample - loss: 0.5313 - mse: 0.3063 - mae: 0.5313 - mape: 108.5526\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5310 - mse: 0.3059 - mae: 0.5310 - mape: 108.4792\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 129us/sample - loss: 0.5306 - mse: 0.3056 - mae: 0.5306 - mape: 108.4062\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 136us/sample - loss: 0.5303 - mse: 0.3053 - mae: 0.5303 - mape: 108.3341\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 141us/sample - loss: 0.5300 - mse: 0.3049 - mae: 0.5300 - mape: 108.2615\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 132us/sample - loss: 0.5297 - mse: 0.3046 - mae: 0.5297 - mape: 108.1869\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 121us/sample - loss: 0.5293 - mse: 0.3042 - mae: 0.5293 - mape: 108.1128\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5290 - mse: 0.3039 - mae: 0.5290 - mape: 108.0389\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5287 - mse: 0.3036 - mae: 0.5287 - mape: 107.9653\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 220us/sample - loss: 0.5284 - mse: 0.3032 - mae: 0.5284 - mape: 107.8927\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 136us/sample - loss: 0.5280 - mse: 0.3029 - mae: 0.5280 - mape: 107.8172\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 144us/sample - loss: 0.5277 - mse: 0.3025 - mae: 0.5277 - mape: 107.7442\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5274 - mse: 0.3022 - mae: 0.5274 - mape: 107.6709\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 186us/sample - loss: 0.5270 - mse: 0.3019 - mae: 0.5270 - mape: 107.5963\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 142us/sample - loss: 0.5267 - mse: 0.3015 - mae: 0.5267 - mape: 107.5217\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 148us/sample - loss: 0.5264 - mse: 0.3012 - mae: 0.5264 - mape: 107.4465\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 209us/sample - loss: 0.5260 - mse: 0.3008 - mae: 0.5260 - mape: 107.3737\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5257 - mse: 0.3005 - mae: 0.5257 - mape: 107.2996\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 147us/sample - loss: 0.5254 - mse: 0.3002 - mae: 0.5254 - mape: 107.2254\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 152us/sample - loss: 0.5251 - mse: 0.2998 - mae: 0.5251 - mape: 107.1494\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 133us/sample - loss: 0.5247 - mse: 0.2995 - mae: 0.5247 - mape: 107.0740\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 130us/sample - loss: 0.5244 - mse: 0.2991 - mae: 0.5244 - mape: 106.9987\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5241 - mse: 0.2988 - mae: 0.5241 - mape: 106.9234\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 123us/sample - loss: 0.5237 - mse: 0.2984 - mae: 0.5237 - mape: 106.8497\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 106us/sample - loss: 0.5234 - mse: 0.2981 - mae: 0.5234 - mape: 106.7736\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5231 - mse: 0.2978 - mae: 0.5231 - mape: 106.6990\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 121us/sample - loss: 0.5227 - mse: 0.2974 - mae: 0.5227 - mape: 106.6233\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 147us/sample - loss: 0.5224 - mse: 0.2971 - mae: 0.5224 - mape: 106.5492\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 208us/sample - loss: 0.5220 - mse: 0.2967 - mae: 0.5220 - mape: 106.4736\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 165us/sample - loss: 0.5217 - mse: 0.2964 - mae: 0.5217 - mape: 106.3989\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 177us/sample - loss: 0.5214 - mse: 0.2960 - mae: 0.5214 - mape: 106.3213\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 155us/sample - loss: 0.5210 - mse: 0.2957 - mae: 0.5210 - mape: 106.2455\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 131us/sample - loss: 0.5207 - mse: 0.2954 - mae: 0.5207 - mape: 106.1710\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5204 - mse: 0.2950 - mae: 0.5204 - mape: 106.0936\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 138us/sample - loss: 0.5200 - mse: 0.2947 - mae: 0.5200 - mape: 106.0184\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 129us/sample - loss: 0.5197 - mse: 0.2943 - mae: 0.5197 - mape: 105.9415\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 0s 197us/sample - loss: 0.5193 - mse: 0.2940 - mae: 0.5193 - mape: 105.8653\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 137us/sample - loss: 0.5190 - mse: 0.2936 - mae: 0.5190 - mape: 105.7876\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 144us/sample - loss: 0.5187 - mse: 0.2933 - mae: 0.5187 - mape: 105.7118\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 147us/sample - loss: 0.5183 - mse: 0.2929 - mae: 0.5183 - mape: 105.6355\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 115us/sample - loss: 0.5180 - mse: 0.2926 - mae: 0.5180 - mape: 105.5571\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 115us/sample - loss: 0.5176 - mse: 0.2922 - mae: 0.5176 - mape: 105.4811\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 125us/sample - loss: 0.5173 - mse: 0.2919 - mae: 0.5173 - mape: 105.4060\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 126us/sample - loss: 0.5169 - mse: 0.2915 - mae: 0.5169 - mape: 105.3266\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 121us/sample - loss: 0.5166 - mse: 0.2912 - mae: 0.5166 - mape: 105.2490\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 0s 154us/sample - loss: 0.5163 - mse: 0.2909 - mae: 0.5163 - mape: 105.1722\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 196us/sample - loss: 0.5159 - mse: 0.2905 - mae: 0.5159 - mape: 105.0947\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 143us/sample - loss: 0.5156 - mse: 0.2902 - mae: 0.5156 - mape: 105.0177\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 140us/sample - loss: 0.5152 - mse: 0.2898 - mae: 0.5152 - mape: 104.9396\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 142us/sample - loss: 0.5149 - mse: 0.2895 - mae: 0.5149 - mape: 104.8601\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 1ms/sample - loss: 0.5894 - accuracy: 0.7538\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  2.369627  7.022293           1800  3601.158  4.201         5\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training classifier and generating partition!\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.625\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 6.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/6Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 44 samples\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 10ms/sample - loss: 0.3807 - mse: 0.1451 - mae: 0.3807 - mape: 95.4881\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 0.3805 - mse: 0.1450 - mae: 0.3805 - mape: 95.4355\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 195us/sample - loss: 0.3803 - mse: 0.1448 - mae: 0.3803 - mape: 95.3829\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 178us/sample - loss: 0.3800 - mse: 0.1446 - mae: 0.3800 - mape: 95.3304\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 265us/sample - loss: 0.3798 - mse: 0.1445 - mae: 0.3798 - mape: 95.2779\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 214us/sample - loss: 0.3796 - mse: 0.1443 - mae: 0.3796 - mape: 95.2253\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 191us/sample - loss: 0.3794 - mse: 0.1442 - mae: 0.3794 - mape: 95.1727\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 264us/sample - loss: 0.3792 - mse: 0.1440 - mae: 0.3792 - mape: 95.1202\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 233us/sample - loss: 0.3790 - mse: 0.1438 - mae: 0.3790 - mape: 95.0676\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 164us/sample - loss: 0.3788 - mse: 0.1437 - mae: 0.3788 - mape: 95.0151\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 153us/sample - loss: 0.3786 - mse: 0.1435 - mae: 0.3786 - mape: 94.9625\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 184us/sample - loss: 0.3784 - mse: 0.1434 - mae: 0.3784 - mape: 94.9099\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 182us/sample - loss: 0.3782 - mse: 0.1432 - mae: 0.3782 - mape: 94.8577\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 170us/sample - loss: 0.3779 - mse: 0.1431 - mae: 0.3779 - mape: 94.8048\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 344us/sample - loss: 0.3777 - mse: 0.1429 - mae: 0.3777 - mape: 94.7525\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 214us/sample - loss: 0.3775 - mse: 0.1427 - mae: 0.3775 - mape: 94.6999\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 183us/sample - loss: 0.3773 - mse: 0.1426 - mae: 0.3773 - mape: 94.6473\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 208us/sample - loss: 0.3771 - mse: 0.1424 - mae: 0.3771 - mape: 94.5949\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 221us/sample - loss: 0.3769 - mse: 0.1423 - mae: 0.3769 - mape: 94.5425\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 152us/sample - loss: 0.3767 - mse: 0.1421 - mae: 0.3767 - mape: 94.4899\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 168us/sample - loss: 0.3765 - mse: 0.1419 - mae: 0.3765 - mape: 94.4374\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 181us/sample - loss: 0.3763 - mse: 0.1418 - mae: 0.3763 - mape: 94.3850\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 180us/sample - loss: 0.3761 - mse: 0.1416 - mae: 0.3761 - mape: 94.3325\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 153us/sample - loss: 0.3759 - mse: 0.1415 - mae: 0.3759 - mape: 94.2800\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 215us/sample - loss: 0.3757 - mse: 0.1413 - mae: 0.3757 - mape: 94.2274\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 212us/sample - loss: 0.3754 - mse: 0.1412 - mae: 0.3754 - mape: 94.1749\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 260us/sample - loss: 0.3752 - mse: 0.1410 - mae: 0.3752 - mape: 94.1224\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 218us/sample - loss: 0.3750 - mse: 0.1408 - mae: 0.3750 - mape: 94.0700\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 169us/sample - loss: 0.3748 - mse: 0.1407 - mae: 0.3748 - mape: 94.0176\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 198us/sample - loss: 0.3746 - mse: 0.1405 - mae: 0.3746 - mape: 93.9650\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 201us/sample - loss: 0.3744 - mse: 0.1404 - mae: 0.3744 - mape: 93.9127\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 185us/sample - loss: 0.3742 - mse: 0.1402 - mae: 0.3742 - mape: 93.8601\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 176us/sample - loss: 0.3740 - mse: 0.1401 - mae: 0.3740 - mape: 93.8076\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 188us/sample - loss: 0.3738 - mse: 0.1399 - mae: 0.3738 - mape: 93.7551\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 173us/sample - loss: 0.3736 - mse: 0.1398 - mae: 0.3736 - mape: 93.7025\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 176us/sample - loss: 0.3734 - mse: 0.1396 - mae: 0.3734 - mape: 93.6502\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 186us/sample - loss: 0.3731 - mse: 0.1394 - mae: 0.3731 - mape: 93.5976\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 157us/sample - loss: 0.3729 - mse: 0.1393 - mae: 0.3729 - mape: 93.5451\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 181us/sample - loss: 0.3727 - mse: 0.1391 - mae: 0.3727 - mape: 93.4926\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 212us/sample - loss: 0.3725 - mse: 0.1390 - mae: 0.3725 - mape: 93.4401\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 360us/sample - loss: 0.3723 - mse: 0.1388 - mae: 0.3723 - mape: 93.3875\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 228us/sample - loss: 0.3721 - mse: 0.1387 - mae: 0.3721 - mape: 93.3351\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 209us/sample - loss: 0.3719 - mse: 0.1385 - mae: 0.3719 - mape: 93.2824\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 194us/sample - loss: 0.3717 - mse: 0.1384 - mae: 0.3717 - mape: 93.2300\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 191us/sample - loss: 0.3715 - mse: 0.1382 - mae: 0.3715 - mape: 93.1773\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 188us/sample - loss: 0.3713 - mse: 0.1380 - mae: 0.3713 - mape: 93.1247\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 227us/sample - loss: 0.3711 - mse: 0.1379 - mae: 0.3711 - mape: 93.0722\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 181us/sample - loss: 0.3708 - mse: 0.1377 - mae: 0.3708 - mape: 93.0197\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 178us/sample - loss: 0.3706 - mse: 0.1376 - mae: 0.3706 - mape: 92.9669\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 173us/sample - loss: 0.3704 - mse: 0.1374 - mae: 0.3704 - mape: 92.9143\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 182us/sample - loss: 0.3702 - mse: 0.1373 - mae: 0.3702 - mape: 92.8618\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 150us/sample - loss: 0.3700 - mse: 0.1371 - mae: 0.3700 - mape: 92.8089\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 200us/sample - loss: 0.3698 - mse: 0.1370 - mae: 0.3698 - mape: 92.7562\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 192us/sample - loss: 0.3696 - mse: 0.1368 - mae: 0.3696 - mape: 92.7037\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 207us/sample - loss: 0.3694 - mse: 0.1366 - mae: 0.3694 - mape: 92.6509\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 243us/sample - loss: 0.3692 - mse: 0.1365 - mae: 0.3692 - mape: 92.5984\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 177us/sample - loss: 0.3690 - mse: 0.1363 - mae: 0.3690 - mape: 92.5455\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 199us/sample - loss: 0.3687 - mse: 0.1362 - mae: 0.3687 - mape: 92.4927\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 200us/sample - loss: 0.3685 - mse: 0.1360 - mae: 0.3685 - mape: 92.4401\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 179us/sample - loss: 0.3683 - mse: 0.1359 - mae: 0.3683 - mape: 92.3873\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 160us/sample - loss: 0.3681 - mse: 0.1357 - mae: 0.3681 - mape: 92.3343\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 187us/sample - loss: 0.3679 - mse: 0.1356 - mae: 0.3679 - mape: 92.2817\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 171us/sample - loss: 0.3677 - mse: 0.1354 - mae: 0.3677 - mape: 92.2287\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 152us/sample - loss: 0.3675 - mse: 0.1353 - mae: 0.3675 - mape: 92.1760\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 185us/sample - loss: 0.3673 - mse: 0.1351 - mae: 0.3673 - mape: 92.1231\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 160us/sample - loss: 0.3671 - mse: 0.1349 - mae: 0.3671 - mape: 92.0701\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 164us/sample - loss: 0.3669 - mse: 0.1348 - mae: 0.3669 - mape: 92.0172\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 191us/sample - loss: 0.3666 - mse: 0.1346 - mae: 0.3666 - mape: 91.9643\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 139us/sample - loss: 0.3664 - mse: 0.1345 - mae: 0.3664 - mape: 91.9113\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 208us/sample - loss: 0.3662 - mse: 0.1343 - mae: 0.3662 - mape: 91.8584\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 332us/sample - loss: 0.3660 - mse: 0.1342 - mae: 0.3660 - mape: 91.8054\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 228us/sample - loss: 0.3658 - mse: 0.1340 - mae: 0.3658 - mape: 91.7522\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 198us/sample - loss: 0.3656 - mse: 0.1339 - mae: 0.3656 - mape: 91.6993\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 178us/sample - loss: 0.3654 - mse: 0.1337 - mae: 0.3654 - mape: 91.6462\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 174us/sample - loss: 0.3652 - mse: 0.1336 - mae: 0.3652 - mape: 91.5932\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 209us/sample - loss: 0.3650 - mse: 0.1334 - mae: 0.3650 - mape: 91.5399\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 169us/sample - loss: 0.3647 - mse: 0.1332 - mae: 0.3647 - mape: 91.4868\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 172us/sample - loss: 0.3645 - mse: 0.1331 - mae: 0.3645 - mape: 91.4336\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 187us/sample - loss: 0.3643 - mse: 0.1329 - mae: 0.3643 - mape: 91.3804\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 316us/sample - loss: 0.3641 - mse: 0.1328 - mae: 0.3641 - mape: 91.3272\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 249us/sample - loss: 0.3639 - mse: 0.1326 - mae: 0.3639 - mape: 91.2739\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 196us/sample - loss: 0.3637 - mse: 0.1325 - mae: 0.3637 - mape: 91.2207\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 171us/sample - loss: 0.3635 - mse: 0.1323 - mae: 0.3635 - mape: 91.1673\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 205us/sample - loss: 0.3633 - mse: 0.1322 - mae: 0.3633 - mape: 91.1140\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 210us/sample - loss: 0.3630 - mse: 0.1320 - mae: 0.3630 - mape: 91.0606\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 168us/sample - loss: 0.3628 - mse: 0.1319 - mae: 0.3628 - mape: 91.0070\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 156us/sample - loss: 0.3626 - mse: 0.1317 - mae: 0.3626 - mape: 90.9537\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 221us/sample - loss: 0.3624 - mse: 0.1315 - mae: 0.3624 - mape: 90.9002\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 162us/sample - loss: 0.3622 - mse: 0.1314 - mae: 0.3622 - mape: 90.8468\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 162us/sample - loss: 0.3620 - mse: 0.1312 - mae: 0.3620 - mape: 90.7933\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 224us/sample - loss: 0.3618 - mse: 0.1311 - mae: 0.3618 - mape: 90.7395\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 244us/sample - loss: 0.3616 - mse: 0.1309 - mae: 0.3616 - mape: 90.6860\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 446us/sample - loss: 0.3613 - mse: 0.1308 - mae: 0.3613 - mape: 90.6325\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 195us/sample - loss: 0.3611 - mse: 0.1306 - mae: 0.3611 - mape: 90.5786\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 204us/sample - loss: 0.3609 - mse: 0.1305 - mae: 0.3609 - mape: 90.5250\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 219us/sample - loss: 0.3607 - mse: 0.1303 - mae: 0.3607 - mape: 90.4713\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 197us/sample - loss: 0.3605 - mse: 0.1302 - mae: 0.3605 - mape: 90.4174\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 159us/sample - loss: 0.3603 - mse: 0.1300 - mae: 0.3603 - mape: 90.3637\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 179us/sample - loss: 0.3601 - mse: 0.1298 - mae: 0.3601 - mape: 90.3098\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 217us/sample - loss: 0.3598 - mse: 0.1297 - mae: 0.3598 - mape: 90.2559\n"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "# q_implicit_N_parts_possibilities = np.linspace(min_parts_threshold,max_parts_threshold,N_plot_finess)\n",
    "N_parts_possibilities = np.unique(np.round(np.linspace(N_min_parts,N_max_plots,num=N_plot_finess))).astype(int)\n",
    "# Custom: N_parts_possibilities = np.array([1,2,3,4,5,8]); N_plot_finess = len(N_parts_possibilities)\n",
    "\n",
    "# Get Performance Metric\n",
    "for inplicit_N_parts_loop in range(len(N_parts_possibilities)):\n",
    "    ### UPDATE USER ###\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    print('Ablation Completion Percentage:',(inplicit_N_parts_loop/N_plot_finess))\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    \n",
    "    # Implicitly Set: Current Number of Parts\n",
    "#     q_implicit_N_parts_loop = q_implicit_N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    N_parts_possibilities_loop = N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    # Run Algos. 1+2\n",
    "    performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop, N_neurons_subPatterns_loop, N_neurons_deep_Zero_Sets_loop, height_mean_loop, performance_PCNN_ffNN_logistic_loop, N_params_PCNN_logistic_loop = get_PCNNs(N_parts_possibilities_loop,X_train,y_train,X_test,y_test)\n",
    "#     performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop, height_mean_loop = Ablate_PCNNs(q_implicit_N_parts_loop,data_y,X_train,X_test,y_test)\n",
    "    # Reshape\n",
    "    performance_Architope_loop = performance_Architope_loop.to_numpy().reshape([3,2,1])\n",
    "    Architope_Model_Complexity_full_loop = Architope_Model_Complexity_full_loop.to_numpy().reshape([1,6,1])\n",
    "    performance_PCNN_ffNN_logistic_loop = performance_PCNN_ffNN_logistic_loop.to_numpy().reshape([3,2,1])\n",
    "    # Record\n",
    "    if inplicit_N_parts_loop == 0:\n",
    "        # Don't count partitioner if only one parts is active!\n",
    "        if N_parts_possibilities_loop <= 1:\n",
    "            Architope_Model_Complexity_full_loop[:,1] = Architope_Model_Complexity_full_loop[:,0]\n",
    "            N_neurons_deep_Zero_Sets_loop = 0\n",
    "        # Record Model Complexities Otherwise    \n",
    "        performance_Architope_history = performance_Architope_loop\n",
    "        Architope_Model_Complexity_history = Architope_Model_Complexity_full_loop\n",
    "        N_parts_Generated_by_Algo_2_history = N_parts_Generated_by_Algo_2_loop\n",
    "        N_params_subPatterns_hist = N_neurons_subPatterns_loop\n",
    "        N_neurons_deep_Zero_Sets_hist = N_neurons_deep_Zero_Sets_loop\n",
    "        N_params_architope_hist = N_neurons_deep_Zero_Sets_loop + N_neurons_subPatterns_loop\n",
    "        height_mean_hist = height_mean_loop\n",
    "        N_neurons_per_input = N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))\n",
    "        ### BENCHMARKs\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = performance_PCNN_ffNN_logistic_loop\n",
    "        N_params_PCNN_logistic_hist = N_params_PCNN_logistic_loop\n",
    "    else:\n",
    "        performance_Architope_history = np.concatenate((performance_Architope_history,performance_Architope_loop),axis=2)\n",
    "        Architope_Model_Complexity_history = np.concatenate((Architope_Model_Complexity_history,Architope_Model_Complexity_full_loop),axis=2)\n",
    "        N_parts_Generated_by_Algo_2_history = np.append(N_parts_Generated_by_Algo_2_history,N_parts_Generated_by_Algo_2_loop)\n",
    "        N_params_architope_hist = np.append(N_params_architope_hist,N_params_architope_loop)\n",
    "        N_params_subPatterns_hist = np.append(N_params_subPatterns_hist,N_neurons_subPatterns_loop)\n",
    "        N_neurons_deep_Zero_Sets_hist = np.append(N_neurons_deep_Zero_Sets_hist,N_neurons_deep_Zero_Sets_loop)\n",
    "        height_mean_hist = np.append(height_mean_hist,height_mean_loop)\n",
    "        N_neurons_per_input = np.append(N_neurons_per_input,(N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))))\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = np.concatenate((performance_PCNN_ffNN_logistic_hist,\n",
    "                                                              performance_PCNN_ffNN_logistic_loop),\n",
    "                                                             axis=2)\n",
    "        N_params_PCNN_logistic_hist = np.append(N_params_PCNN_logistic_hist,N_params_PCNN_logistic_loop)\n",
    "\n",
    "# Cleanup\n",
    "## Randomization may produce duplicates; we remove these with the following snippet:\n",
    "get_unique_entries = np.unique(N_parts_Generated_by_Algo_2_history, return_index=True)[1]\n",
    "N_parts_Generated_by_Algo_2_history_report = N_parts_Generated_by_Algo_2_history[get_unique_entries]\n",
    "\n",
    "# Write\n",
    "## Prediction Qualities\n",
    "performance_Architope_history_report_MAE_train = (performance_Architope_history[0,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MAE_test = (performance_Architope_history[0,1,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_train = (performance_Architope_history[1,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_test = (performance_Architope_history[1,1,:])[get_unique_entries]\n",
    "## Model Complexities\n",
    "L_Times = (Architope_Model_Complexity_history[:,1].reshape(-1,))[get_unique_entries]\n",
    "P_Times = (Architope_Model_Complexity_history[:,0].reshape(-1,))[get_unique_entries]\n",
    "N_Params = (N_params_architope_hist.reshape(-1,))[get_unique_entries]\n",
    "mean_subpattern_widths_hist = (height_mean_hist.reshape(-1,))[get_unique_entries]\n",
    "AIC_Like = (Architope_Model_Complexity_history[:,3].reshape(-1,))[get_unique_entries]\n",
    "Eff = (Architope_Model_Complexity_history[:,4].reshape(-1,))[get_unique_entries]\n",
    "N_neurons_per_input = (N_neurons_per_input.reshape(-1,))[get_unique_entries]\n",
    "\n",
    "# Record Benchmark Complexities\n",
    "performance_PCNN_ffNN_logistic_report_MAE_train = (performance_PCNN_ffNN_logistic_hist[0,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MAE_test = (performance_PCNN_ffNN_logistic_hist[0,1,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MSE_train = (performance_PCNN_ffNN_logistic_hist[1,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_logistic_report_MSE_test = (performance_PCNN_ffNN_logistic_hist[1,1,:])[get_unique_entries]\n",
    "N_params_PCNN_logistic_hist = N_params_PCNN_logistic_hist[get_unique_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feedforward Neural Network (ffNN) Benchmark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Model complexities for ffNNs\n",
    "P_time_ffNN = P_Times[0]\n",
    "L_time_ffNN = P_Times[0]\n",
    "Width_ffNN = height_mean_hist[0]\n",
    "# For: Plots\n",
    "MAE_ffNN = np.repeat(performance_Architope_history_report_MAE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "MSE_ffNN = np.repeat(performance_Architope_history_report_MSE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "L_times_ffNN_plot = np.repeat(L_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "P_times_ffNN_plot = np.repeat(P_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_per_input_ffNN = np.repeat(N_neurons_per_input[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "Width_neurons_ffNN = np.repeat(mean_subpattern_widths_hist[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_ffNN = np.repeat(N_Params[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "# Record in Table\n",
    "ffNN_Model_Complexity = pd.DataFrame({'L-time': [L_time_ffNN],\n",
    "                                               'P-time':[P_time_ffNN],\n",
    "                                               'N_params_expt': [N_neurons_ffNN],\n",
    "                                               'AIC-like': [0],\n",
    "                                               'Eff': [0],\n",
    "                                               'N. Parts':[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MSE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MSE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MSE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MSE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "# Add Legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MSE_test___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MAE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MAE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MAE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MAE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MAE___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"L-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"L-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_L_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"P-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"P-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_P_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"N. Params\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"N. Params\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_Params,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_N_Params___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Active Neurons Per Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Active Neurons per. Input\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Active Neurons per. Input\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_per_input,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Active_Neurons_per_input___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Widths for Sub-Pattern Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Mean Subpattern Widths\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Mean Subpattern Widths\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         mean_subpattern_widths_hist,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         Width_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Mean_Widths___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
