{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Semi-Supervised Architope - for Reviews\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"PC-NNs\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1-(1/24)\n",
    "min_width = 100\n",
    "min_epochs = 100\n",
    "# Ablation Finess\n",
    "N_plot_finess = 10\n",
    "# min_parts_threshold = .001; max_parts_threshold = 0.9\n",
    "N_min_parts = 1; N_max_plots = 20\n",
    "Tied_Neurons_Q = True\n",
    "# Partition with Inputs (determine parts with domain) or outputs (determine parts with image)\n",
    "Partition_using_Inputs = True\n",
    "# Cuttoff Level\n",
    "gamma = .5\n",
    "# Softmax Layer instead of sigmoid\n",
    "softmax_layer = False #<- Just out of curiosity...but it doesn't perform many better IRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 10**4\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return np.exp(-x)\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "1\n",
      "Training Data size:  416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Financial_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# exec(open('Prepare_Data_California_Housing.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]\n",
    "sns.set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Partion Builder:\n",
    "Implements exactly Algorithm 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(X_in,\n",
    "                               y_in,\n",
    "                               N_parts_to_get=4):\n",
    "\n",
    "    # Compute Size of each part\n",
    "    size_part_reference = int(round(X_in.shape[0]/N_parts_to_get))\n",
    "\n",
    "    # Apply random bijection #\n",
    "    #------------------------#\n",
    "    ## Get random bijection indices\n",
    "    random_bijection_indices = np.random.choice(range(X_in.shape[0]),size=X_in.shape[0], replace=False)\n",
    "    ## Apply random bijections\n",
    "    X_in_shuffled = X_in[random_bijection_indices,:]\n",
    "    y_in_shuffled = y_in[random_bijection_indices,:]\n",
    "\n",
    "    # Initialize Lists #\n",
    "    #------------------#\n",
    "    X_parts = []\n",
    "    y_parts = []\n",
    "\n",
    "    for i_th_part_to_get in range(N_parts_to_get):\n",
    "        # Build random balls #\n",
    "        #--------------------#\n",
    "        ## Sample random radius\n",
    "        size_part = int(np.maximum(1,np.round(size_part_reference*np.random.uniform(low=.5,high=1.5,size=1)[0])))\n",
    "        ## Sample random point\n",
    "        X_center_loop_index = np.random.choice(range(X_in_shuffled.shape[0]),size=1, replace=False)\n",
    "        X_center_loop = X_in_shuffled[X_center_loop_index,:]\n",
    "        ## Compute Typical Distances from Center\n",
    "        distances_loop = X_center_loop-X_in_shuffled\n",
    "        distances_loop = np.linalg.norm(distances_loop, axis=1)\n",
    "\n",
    "        # Remove Random Ball from Dataset\n",
    "        if size_part <= len(distances_loop):\n",
    "            ## Identify indices\n",
    "            indices_smallest_to_random_ball = np.argsort(distances_loop)[:size_part]\n",
    "        else:\n",
    "            print('Final Loop')\n",
    "            indices_smallest_to_random_ball = np.array(range(X_in_shuffled.shape[0]))\n",
    "        ## Extract Parts\n",
    "        X_current_part_loop = X_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        y_current_part_loop = y_in_shuffled[indices_smallest_to_random_ball,:]\n",
    "        ## Append to List of Parts\n",
    "        X_parts.append(X_current_part_loop)\n",
    "        y_parts.append(y_current_part_loop)\n",
    "\n",
    "        # Remove Selected Entries From Array #\n",
    "        #------------------------------------#\n",
    "        X_in_shuffled = np.delete(X_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "        y_in_shuffled = np.delete(y_in_shuffled,indices_smallest_to_random_ball,axis=0)\n",
    "\n",
    "        # Failsafe if procedure has terminated\n",
    "        if X_in_shuffled.shape[0] == 0:\n",
    "            print('breaking early')\n",
    "            break\n",
    "    # Count Number of Parts Generated        \n",
    "    N_parts_generated = len(X_parts)\n",
    "    # Output Parts\n",
    "    return X_parts, y_parts, N_parts_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCNNs(N_parts,X_train,y_train,X_test,y_test):\n",
    "\n",
    "    # Initialization(s) #\n",
    "    #-------------------#\n",
    "    N_neurons = 0\n",
    "    L_timer = 0\n",
    "    P_timer = 0\n",
    "    Mean_Width_Subnetworks = 0\n",
    "\n",
    "    # Partitioner Begin #\n",
    "    #-------------------#\n",
    "    import time\n",
    "    partitioning_time_begin = time.time()\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Randomly Initialized Parts - Via Randomized Algorithm 2')\n",
    "    print('-------------------------------------------------------')\n",
    "    if Partition_using_Inputs == True:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(X_train.to_numpy(),\n",
    "                                                                                             y_train.reshape(-1,1),\n",
    "                                                                                             N_parts)\n",
    "    else:\n",
    "        X_parts_list, y_parts_list, N_parts_Generated_by_Algo_2 = Random_Lipschitz_Partioner(y_train.reshape(-1,1),\n",
    "                                                                                             X_train.to_numpy(),\n",
    "                                                                                             N_parts)\n",
    "    partitioning_time = time.time() - partitioning_time_begin\n",
    "    print('The_parts_listhe number of parts are: ' + str(N_parts_Generated_by_Algo_2)+'.')\n",
    "    ############# Partitioner End ########\n",
    "\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Training Sub-Networks on Each Randomly Generated Part')\n",
    "    print('-----------------------------------------------------')\n",
    "    # Time-Elapse (Start) for Training on Each Part #\n",
    "    PCNN_timer = time.time(); PCNN_timer = -math.inf; N_params_Architope = 0; N_params_tally = 0\n",
    "    # Remove Eager Execution Error(s)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Automatically Initialize Correct Input/Output Dimension(s)\n",
    "    param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]; param_grid_Vanilla_Nets['output_dim'] = [1]\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    # Decide if/or not to tie neuron numbers of sub-patterns together\n",
    "    if Tied_Neurons_Q == True:\n",
    "        param_grid_Vanilla_Nets['height'] = [int(np.maximum(round(param_grid_Vanilla_Nets['height'][0]/N_parts),min_width))]\n",
    "        param_grid_Vanilla_Nets['epochs'] = [int(np.maximum(round(param_grid_Vanilla_Nets['epochs'][0]/int(round(np.sqrt(N_parts)))),min_epochs))]\n",
    "#         param_grid_Deep_Classifier['height'] = [int(np.maximum(round(param_grid_Deep_Classifier['height'][0]/N_parts),min_width))]\n",
    "\n",
    "    for current_part in range(N_parts_Generated_by_Algo_2):\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('-----------------------------------------------------------')\n",
    "        print('Currently Training Part: '+str(current_part)+'/'+str(N_parts_Generated_by_Algo_2 )+'Total Parts.')\n",
    "        print('-----------------------------------------------------------')\n",
    "\n",
    "        # Timer for Part\n",
    "        part_training_timer = time.time()\n",
    "        # Get Data for Sub-Pattern\n",
    "        X_loop = pd.DataFrame(X_parts_list[current_part])\n",
    "        y_loop = (y_parts_list[current_part]).reshape(-1,)\n",
    "        # Train ffNN\n",
    "        y_hat_part_loop, y_hat_part_loop_test, N_neurons_PCNN_loop = build_ffNN(n_folds = 4, \n",
    "                                                                              n_jobs = n_jobs,\n",
    "                                                                              n_iter = n_iter, \n",
    "                                                                              param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                              X_train= X_loop, \n",
    "                                                                              y_train=y_loop,\n",
    "                                                                              X_test_partial=X_train,\n",
    "                                                                              X_test=X_test,\n",
    "                                                                              NOCV=True)\n",
    "        # Reshape y\n",
    "        ## Training\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop.shape = (y_hat_part_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        ## Testing\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_part_loop_test.shape = (y_hat_part_loop_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_part_loop-y_train)).reshape(y_hat_part_loop.shape[0],1)\n",
    "\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_part_loop.reshape(y_hat_part_loop.shape[0],1)\n",
    "            predictions_test = y_hat_part_loop_test.reshape(y_hat_part_loop_test.shape[0],1)\n",
    "\n",
    "\n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "        # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_part_loop.reshape(predictions_train.shape[0],1)\n",
    "            predictions_train = np.append(predictions_train,y_hat_train_loop,axis=1)\n",
    "            y_hat_test_loop = y_hat_part_loop_test.reshape(predictions_test.shape[0],1)\n",
    "            predictions_test = np.append(predictions_test,y_hat_test_loop,axis=1)\n",
    "\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            training_quality = np.append(training_quality,prediction_errors.reshape(training_quality.shape[0],1),axis=1)\n",
    "\n",
    "        #==============================#\n",
    "        # Update Performance Metric(s) #\n",
    "        #==============================#\n",
    "        part_training_timer = time.time() - part_training_timer\n",
    "        # L-Time\n",
    "        L_timer += partitioning_time\n",
    "        # P-Time\n",
    "        P_timer = max(P_timer,part_training_timer)\n",
    "        # N. Params\n",
    "        N_neurons += N_neurons_PCNN_loop\n",
    "        # Mean Width for Sub-Network(s)\n",
    "        Mean_Width_Subnetworks += param_grid_Vanilla_Nets['height'][0]\n",
    "\n",
    "    # Take Mean of Width(s)\n",
    "    Mean_Width_Subnetworks = Mean_Width_Subnetworks/N_parts_Generated_by_Algo_2\n",
    "    print('-----------------------')\n",
    "    print('Training Deep Zero-Sets')\n",
    "    print('-----------------------')\n",
    "\n",
    "\n",
    "    # Time Elapsed for Training Deep Zero-Sets\n",
    "    Deep_Zero_Sets_timer = time.time()\n",
    "\n",
    "    ## Initialize Classes Labels\n",
    "    if softmax_layer == False:\n",
    "        # No pooling (classical)\n",
    "        partition_labels_training_integers = np.argmin(training_quality,axis=-1)\n",
    "    else:\n",
    "        # Max Pooling\n",
    "#         partition_labels_training_integers = (training_quality == training_quality.min(axis=1)[:,None]).astype(int)\n",
    "        partition_labels_training_integers = np.apply_along_axis(softminn, 1, training_quality).astype(int)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    ## Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    ## Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    ## Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train.values, \n",
    "                                                                                                        y_train = partition_labels_training.values,\n",
    "                                                                                                        X_test = X_test.values)\n",
    "    # Get Binary Classes (Discontinuous Unit)\n",
    "    ## Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>gamma)*1).astype(int)\n",
    "    ## Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > gamma)*1).astype(int)\n",
    "    # Get PC-NN Prediction(s)\n",
    "    ## Train\n",
    "    PCNN_prediction_y_train = (predictions_train*predicted_classes_train).sum(axis=1)\n",
    "    ## Test\n",
    "    PCNN_prediction_y_test = (predictions_test*predicted_classes_test).sum(axis=1)\n",
    "\n",
    "    # End Timer\n",
    "    Deep_Zero_Sets_timer = time.time() - Deep_Zero_Sets_timer\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print('Computing Final Performance Metrics')\n",
    "    print('-----------------------------------')\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "\n",
    "    # Update Times\n",
    "    L_timer +=Deep_Zero_Sets_timer\n",
    "    P_timer +=Deep_Zero_Sets_timer\n",
    "    # Update Number of Neurons Used\n",
    "    N_neurons_subPatterns = N_neurons\n",
    "    N_neurons_deep_Zero_Sets = (param_grid_Deep_Classifier['height'][0])*(param_grid_Deep_Classifier['depth'][0])\n",
    "    N_neurons = N_neurons_deep_Zero_Sets + N_neurons_subPatterns\n",
    "\n",
    "\n",
    "\n",
    "    # Compute Peformance\n",
    "    performance_PCNN = reporter(y_train_hat_in=PCNN_prediction_y_train,y_test_hat_in=PCNN_prediction_y_test,\n",
    "                                y_train_in=y_train,\n",
    "                                y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_PCNN.to_latex((results_tables_path+\"PCNN_full_performance.tex\"))\n",
    "\n",
    "    # Update User\n",
    "    print(performance_PCNN)\n",
    "\n",
    "    ### Model Complexity/Efficiency Metrics\n",
    "    # Build AIC-like Metric #\n",
    "    #-----------------------#\n",
    "    AIC_like = 2*(N_neurons - np.log((performance_PCNN['test']['MAE'])))\n",
    "    AIC_like = np.round(AIC_like,3)\n",
    "    Efficiency = np.log(N_neurons) *(performance_PCNN['test']['MAE'])\n",
    "    Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "    # Build Table #\n",
    "    #-------------#\n",
    "    PCNN_Model_Complexity = pd.DataFrame({'L-time': [L_timer],\n",
    "                                               'P-time':[P_timer],\n",
    "                                               'N_params_expt': [N_neurons],\n",
    "                                               'AIC-like': [AIC_like],\n",
    "                                               'Eff': [Efficiency],\n",
    "                                               'N. Parts':[N_parts_Generated_by_Algo_2]})\n",
    "\n",
    "\n",
    "    # Write Required Training Time(s)\n",
    "    PCNN_Model_Complexity.to_latex((results_tables_path+\"PCNN_full_model_complexities.tex\"))\n",
    "\n",
    "    #--------------======---------------#\n",
    "    # Display Required Training Time(s) #\n",
    "    #--------------======---------------#\n",
    "    print(PCNN_Model_Complexity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    print('# ---- Getting Benchmarks ---- #')\n",
    "    #########################################\n",
    "    for j in range(10):\n",
    "        print('#------------------------------#')\n",
    "    #########################################\n",
    "    print('Training PCNN-lgt')\n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training_begin = time.time()\n",
    "    if N_parts > 1:\n",
    "        parameters = {'penalty': ['none'], 'C': [0.1]}\n",
    "        lr = LogisticRegression(random_state=2020)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=CV_folds, \n",
    "                                     n_repeats=n_iter, random_state=0)\n",
    "        classifier = RandomizedSearchCV(lr, \n",
    "                                        parameters, \n",
    "                                        random_state=2020)\n",
    "\n",
    "        # Initialize Classes Labels\n",
    "        partition_labels_training = np.argmin(training_quality,axis=-1)\n",
    "        # Train Logistic Classifier #\n",
    "        #---------------------------#\n",
    "        # Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Train Classifier\n",
    "        classifier.fit(X_train, partition_labels_training)\n",
    "    if N_parts >1 :\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "        Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "        # Testing Set\n",
    "        predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "        Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, \n",
    "                                                                     predicted_classes_test_logistic_BM[:,None], \n",
    "                                                                     axis=1)\n",
    "    else:\n",
    "        #### Write Predicted Class(es)\n",
    "        # Training Set\n",
    "        Architope_prediction_y_train_logistic_BM = predictions_train\n",
    "        # Testing Set\n",
    "        Architope_prediction_y_test_logistic_BM = predictions_test    \n",
    "    # Extract Number of Parameters Logistic Regressor\n",
    "    if N_parts > 1:\n",
    "        N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)\n",
    "    else:\n",
    "        N_params_best_logistic = 1\n",
    "    N_params_best_logistic = N_params_best_logistic + N_neurons_subPatterns*N_parts    \n",
    "    # Time-Elapsed Training linear classifier\n",
    "    Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin\n",
    "    #### Compute Performance\n",
    "    # Compute Peformance\n",
    "    performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                        y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                        y_train_in=y_train,\n",
    "                                        y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "    \n",
    "    ##### --- #####\n",
    "    print('Training PCNN-Bagged')\n",
    "    ##### --- #####\n",
    "    # Time for Bagging\n",
    "    Bagging_ffNN_bagging_time_begin = time.time()\n",
    "    # Train Bagging Weights in-sample\n",
    "    bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "    # Predict Bagging Weights out-of-sample\n",
    "    bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "    bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "    # Write number of trainable bagging parameters\n",
    "    N_bagged_parameters = len(bagging_coefficients.coef_) + 1\n",
    "    # Time for Bagging\n",
    "    Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin\n",
    "    # Compute Peformance\n",
    "    performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                        y_test_hat_in=bagged_prediction_test,\n",
    "                                        y_train_in=y_train,\n",
    "                                        y_test_in=y_test)\n",
    "    # Write Performance\n",
    "    performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "    \n",
    "    for jj in range(5):\n",
    "        print('-----------------------')\n",
    "    print('...Returning Results...')\n",
    "    for jj in range(5):\n",
    "        print('-----------------------')\n",
    "    # Return Output(s)\n",
    "    return performance_PCNN, PCNN_Model_Complexity, N_parts_Generated_by_Algo_2, N_neurons, N_neurons_subPatterns,N_neurons_deep_Zero_Sets, Mean_Width_Subnetworks, performance_architope_ffNN_logistic, N_params_best_logistic, performance_bagged_ffNN, Bagging_ffNN_bagging_time, Architope_logistic_classifier_training, Deep_Zero_Sets_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform Ablation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.0\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 1.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/1Total Parts.\n",
      "-----------------------------------------------------------\n",
      "WARNING:tensorflow:From /Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 299 samples\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 0s 1ms/sample - loss: 0.6005 - mse: 0.3760 - mae: 0.6005 - mape: 110.5991\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 403us/sample - loss: 0.5642 - mse: 0.3342 - mae: 0.5642 - mape: 103.5004\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 396us/sample - loss: 0.5280 - mse: 0.2953 - mae: 0.5280 - mape: 96.3587\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 415us/sample - loss: 0.4917 - mse: 0.2584 - mae: 0.4917 - mape: 89.3451\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 599us/sample - loss: 0.4554 - mse: 0.2243 - mae: 0.4554 - mape: 82.2371\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 493us/sample - loss: 0.4188 - mse: 0.1930 - mae: 0.4188 - mape: 75.0936\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 502us/sample - loss: 0.3822 - mse: 0.1643 - mae: 0.3822 - mape: 67.8845\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 422us/sample - loss: 0.3454 - mse: 0.1382 - mae: 0.3454 - mape: 60.6578\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 438us/sample - loss: 0.3084 - mse: 0.1144 - mae: 0.3084 - mape: 53.4198\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 407us/sample - loss: 0.2711 - mse: 0.0937 - mae: 0.2711 - mape: 46.0670\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 429us/sample - loss: 0.2338 - mse: 0.0753 - mae: 0.2338 - mape: 38.7948\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 460us/sample - loss: 0.2013 - mse: 0.0601 - mae: 0.2013 - mape: 32.7629\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 439us/sample - loss: 0.1811 - mse: 0.0490 - mae: 0.1811 - mape: 29.6455\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 451us/sample - loss: 0.1675 - mse: 0.0412 - mae: 0.1675 - mape: 27.8559\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 503us/sample - loss: 0.1575 - mse: 0.0359 - mae: 0.1575 - mape: 26.6492\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 543us/sample - loss: 0.1491 - mse: 0.0319 - mae: 0.1491 - mape: 25.6911\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 471us/sample - loss: 0.1421 - mse: 0.0287 - mae: 0.1421 - mape: 25.0136\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 526us/sample - loss: 0.1368 - mse: 0.0265 - mae: 0.1368 - mape: 24.5257\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 495us/sample - loss: 0.1328 - mse: 0.0249 - mae: 0.1328 - mape: 24.1934\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 455us/sample - loss: 0.1301 - mse: 0.0239 - mae: 0.1301 - mape: 24.0712\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 658us/sample - loss: 0.1279 - mse: 0.0230 - mae: 0.1279 - mape: 23.9951\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 481us/sample - loss: 0.1261 - mse: 0.0223 - mae: 0.1261 - mape: 23.9096\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 637us/sample - loss: 0.1245 - mse: 0.0218 - mae: 0.1245 - mape: 23.7939\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 485us/sample - loss: 0.1235 - mse: 0.0215 - mae: 0.1235 - mape: 23.7266\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 456us/sample - loss: 0.1224 - mse: 0.0211 - mae: 0.1224 - mape: 23.6247\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 642us/sample - loss: 0.1213 - mse: 0.0207 - mae: 0.1213 - mape: 23.4585\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 498us/sample - loss: 0.1202 - mse: 0.0204 - mae: 0.1202 - mape: 23.2809\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 454us/sample - loss: 0.1192 - mse: 0.0201 - mae: 0.1192 - mape: 23.0996\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 484us/sample - loss: 0.1182 - mse: 0.0198 - mae: 0.1182 - mape: 22.8575\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 508us/sample - loss: 0.1170 - mse: 0.0195 - mae: 0.1170 - mape: 22.6015\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 414us/sample - loss: 0.1160 - mse: 0.0192 - mae: 0.1160 - mape: 22.3841\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 416us/sample - loss: 0.1149 - mse: 0.0189 - mae: 0.1149 - mape: 22.1783\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 378us/sample - loss: 0.1138 - mse: 0.0186 - mae: 0.1138 - mape: 21.9465\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 411us/sample - loss: 0.1127 - mse: 0.0183 - mae: 0.1127 - mape: 21.6905\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 402us/sample - loss: 0.1115 - mse: 0.0180 - mae: 0.1115 - mape: 21.4447\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 429us/sample - loss: 0.1104 - mse: 0.0178 - mae: 0.1104 - mape: 21.2438\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 382us/sample - loss: 0.1092 - mse: 0.0175 - mae: 0.1092 - mape: 21.0127\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 379us/sample - loss: 0.1081 - mse: 0.0172 - mae: 0.1081 - mape: 20.8504\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.1070 - mse: 0.0169 - mae: 0.1070 - mape: 20.7007\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 395us/sample - loss: 0.1058 - mse: 0.0166 - mae: 0.1058 - mape: 20.4402\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.1047 - mse: 0.0164 - mae: 0.1047 - mape: 20.1723\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 501us/sample - loss: 0.1035 - mse: 0.0162 - mae: 0.1035 - mape: 19.9098\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 426us/sample - loss: 0.1022 - mse: 0.0158 - mae: 0.1022 - mape: 19.6930\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 393us/sample - loss: 0.1012 - mse: 0.0156 - mae: 0.1012 - mape: 19.5815\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 424us/sample - loss: 0.1000 - mse: 0.0154 - mae: 0.1000 - mape: 19.3413\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 385us/sample - loss: 0.0988 - mse: 0.0152 - mae: 0.0988 - mape: 18.9873\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 407us/sample - loss: 0.0976 - mse: 0.0150 - mae: 0.0976 - mape: 18.7235\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 485us/sample - loss: 0.0963 - mse: 0.0147 - mae: 0.0963 - mape: 18.5337\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 385us/sample - loss: 0.0952 - mse: 0.0144 - mae: 0.0952 - mape: 18.3898\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 413us/sample - loss: 0.0940 - mse: 0.0142 - mae: 0.0940 - mape: 18.1869\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 461us/sample - loss: 0.0927 - mse: 0.0140 - mae: 0.0927 - mape: 17.8824\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.0915 - mse: 0.0139 - mae: 0.0915 - mape: 17.5679\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 416us/sample - loss: 0.0903 - mse: 0.0137 - mae: 0.0903 - mape: 17.3032\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 521us/sample - loss: 0.0890 - mse: 0.0135 - mae: 0.0890 - mape: 17.0770\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 431us/sample - loss: 0.0878 - mse: 0.0133 - mae: 0.0878 - mape: 16.8746\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.0865 - mse: 0.0131 - mae: 0.0865 - mape: 16.6258\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 391us/sample - loss: 0.0853 - mse: 0.0130 - mae: 0.0853 - mape: 16.3858\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 397us/sample - loss: 0.0840 - mse: 0.0128 - mae: 0.0840 - mape: 16.1289\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 448us/sample - loss: 0.0828 - mse: 0.0127 - mae: 0.0828 - mape: 15.8837\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 379us/sample - loss: 0.0817 - mse: 0.0125 - mae: 0.0817 - mape: 15.7186\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.0802 - mse: 0.0124 - mae: 0.0802 - mape: 15.3903\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 385us/sample - loss: 0.0792 - mse: 0.0125 - mae: 0.0792 - mape: 15.0384\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 398us/sample - loss: 0.0778 - mse: 0.0123 - mae: 0.0778 - mape: 14.8256\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 401us/sample - loss: 0.0765 - mse: 0.0121 - mae: 0.0765 - mape: 14.6635\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 382us/sample - loss: 0.0752 - mse: 0.0120 - mae: 0.0752 - mape: 14.4063\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 400us/sample - loss: 0.0740 - mse: 0.0120 - mae: 0.0740 - mape: 14.1217\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 415us/sample - loss: 0.0726 - mse: 0.0119 - mae: 0.0726 - mape: 13.8446\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 387us/sample - loss: 0.0714 - mse: 0.0118 - mae: 0.0714 - mape: 13.6277\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 361us/sample - loss: 0.0700 - mse: 0.0117 - mae: 0.0700 - mape: 13.3453\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 438us/sample - loss: 0.0687 - mse: 0.0117 - mae: 0.0687 - mape: 13.0722\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 424us/sample - loss: 0.0674 - mse: 0.0117 - mae: 0.0674 - mape: 12.8319\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 427us/sample - loss: 0.0662 - mse: 0.0116 - mae: 0.0662 - mape: 12.5970\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 446us/sample - loss: 0.0648 - mse: 0.0116 - mae: 0.0648 - mape: 12.3065\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 418us/sample - loss: 0.0636 - mse: 0.0117 - mae: 0.0636 - mape: 11.9914\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 399us/sample - loss: 0.0623 - mse: 0.0116 - mae: 0.0623 - mape: 11.8146\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 437us/sample - loss: 0.0610 - mse: 0.0116 - mae: 0.0610 - mape: 11.5971\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 455us/sample - loss: 0.0596 - mse: 0.0116 - mae: 0.0596 - mape: 11.3278\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 361us/sample - loss: 0.0583 - mse: 0.0116 - mae: 0.0583 - mape: 11.1173\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 384us/sample - loss: 0.0570 - mse: 0.0116 - mae: 0.0570 - mape: 10.8910\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 390us/sample - loss: 0.0556 - mse: 0.0116 - mae: 0.0556 - mape: 10.6199\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 392us/sample - loss: 0.0544 - mse: 0.0117 - mae: 0.0544 - mape: 10.3560\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 377us/sample - loss: 0.0530 - mse: 0.0118 - mae: 0.0530 - mape: 10.0929\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.0516 - mse: 0.0118 - mae: 0.0516 - mape: 9.8853\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 386us/sample - loss: 0.0505 - mse: 0.0118 - mae: 0.0505 - mape: 9.7619\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 361us/sample - loss: 0.0491 - mse: 0.0120 - mae: 0.0491 - mape: 9.4553\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 380us/sample - loss: 0.0481 - mse: 0.0120 - mae: 0.0481 - mape: 9.3756\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 410us/sample - loss: 0.0475 - mse: 0.0120 - mae: 0.0475 - mape: 9.2933\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 428us/sample - loss: 0.0471 - mse: 0.0121 - mae: 0.0471 - mape: 9.2611\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 372us/sample - loss: 0.0469 - mse: 0.0121 - mae: 0.0469 - mape: 9.3160\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 421us/sample - loss: 0.0469 - mse: 0.0122 - mae: 0.0469 - mape: 9.2678\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 409us/sample - loss: 0.0470 - mse: 0.0121 - mae: 0.0470 - mape: 9.4135\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 435us/sample - loss: 0.0467 - mse: 0.0123 - mae: 0.0467 - mape: 9.3040\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 407us/sample - loss: 0.0465 - mse: 0.0122 - mae: 0.0465 - mape: 9.3182\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 414us/sample - loss: 0.0463 - mse: 0.0123 - mae: 0.0463 - mape: 9.2877\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 361us/sample - loss: 0.0465 - mse: 0.0124 - mae: 0.0465 - mape: 9.3104\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 408us/sample - loss: 0.0465 - mse: 0.0123 - mae: 0.0465 - mape: 9.3723\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 405us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.3441\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 389us/sample - loss: 0.0463 - mse: 0.0124 - mae: 0.0463 - mape: 9.3633\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 369us/sample - loss: 0.0464 - mse: 0.0124 - mae: 0.0464 - mape: 9.4086\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 418us/sample - loss: 0.0462 - mse: 0.0124 - mae: 0.0462 - mape: 9.3418\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 765us/sample - loss: 0.5006 - accuracy: 0.9231\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "          train       test\n",
      "MAE    0.114847   0.121532\n",
      "MSE    0.056335   0.060995\n",
      "MAPE  16.387137  17.621219\n",
      "     L-time     P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.120582  16.035375           2400  4804.215  0.946         1\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training PCNN-lgt\n",
      "Training PCNN-Bagged\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "...Returning Results...\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.3333333333333333\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "The_parts_listhe number of parts are: 2.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/2Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 168 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "168/168 [==============================] - 0s 2ms/sample - loss: 0.4283 - mse: 0.1969 - mae: 0.4283 - mape: 85.3972\n",
      "Epoch 2/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.4223 - mse: 0.1918 - mae: 0.4223 - mape: 84.1342\n",
      "Epoch 3/100\n",
      "168/168 [==============================] - 0s 262us/sample - loss: 0.4163 - mse: 0.1868 - mae: 0.4163 - mape: 82.8600\n",
      "Epoch 4/100\n",
      "168/168 [==============================] - 0s 234us/sample - loss: 0.4103 - mse: 0.1819 - mae: 0.4103 - mape: 81.5863\n",
      "Epoch 5/100\n",
      "168/168 [==============================] - 0s 263us/sample - loss: 0.4043 - mse: 0.1770 - mae: 0.4043 - mape: 80.3210\n",
      "Epoch 6/100\n",
      "168/168 [==============================] - 0s 224us/sample - loss: 0.3982 - mse: 0.1721 - mae: 0.3982 - mape: 79.0514\n",
      "Epoch 7/100\n",
      "168/168 [==============================] - 0s 206us/sample - loss: 0.3922 - mse: 0.1674 - mae: 0.3922 - mape: 77.7617\n",
      "Epoch 8/100\n",
      "168/168 [==============================] - 0s 265us/sample - loss: 0.3861 - mse: 0.1628 - mae: 0.3861 - mape: 76.4801\n",
      "Epoch 9/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.3801 - mse: 0.1581 - mae: 0.3801 - mape: 75.2044\n",
      "Epoch 10/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.3740 - mse: 0.1536 - mae: 0.3740 - mape: 73.9148\n",
      "Epoch 11/100\n",
      "168/168 [==============================] - 0s 257us/sample - loss: 0.3679 - mse: 0.1491 - mae: 0.3679 - mape: 72.6304\n",
      "Epoch 12/100\n",
      "168/168 [==============================] - 0s 248us/sample - loss: 0.3617 - mse: 0.1447 - mae: 0.3617 - mape: 71.3261\n",
      "Epoch 13/100\n",
      "168/168 [==============================] - 0s 222us/sample - loss: 0.3556 - mse: 0.1403 - mae: 0.3556 - mape: 70.0380\n",
      "Epoch 14/100\n",
      "168/168 [==============================] - 0s 235us/sample - loss: 0.3495 - mse: 0.1360 - mae: 0.3495 - mape: 68.7337\n",
      "Epoch 15/100\n",
      "168/168 [==============================] - 0s 250us/sample - loss: 0.3433 - mse: 0.1318 - mae: 0.3433 - mape: 67.4276\n",
      "Epoch 16/100\n",
      "168/168 [==============================] - 0s 227us/sample - loss: 0.3371 - mse: 0.1276 - mae: 0.3371 - mape: 66.1050\n",
      "Epoch 17/100\n",
      "168/168 [==============================] - 0s 814us/sample - loss: 0.3308 - mse: 0.1235 - mae: 0.3308 - mape: 64.7942\n",
      "Epoch 18/100\n",
      "168/168 [==============================] - 0s 868us/sample - loss: 0.3246 - mse: 0.1194 - mae: 0.3246 - mape: 63.4790\n",
      "Epoch 19/100\n",
      "168/168 [==============================] - 0s 251us/sample - loss: 0.3183 - mse: 0.1154 - mae: 0.3183 - mape: 62.1347\n",
      "Epoch 20/100\n",
      "168/168 [==============================] - 0s 219us/sample - loss: 0.3120 - mse: 0.1114 - mae: 0.3120 - mape: 60.8091\n",
      "Epoch 21/100\n",
      "168/168 [==============================] - 0s 206us/sample - loss: 0.3056 - mse: 0.1075 - mae: 0.3056 - mape: 59.4713\n",
      "Epoch 22/100\n",
      "168/168 [==============================] - 0s 256us/sample - loss: 0.2992 - mse: 0.1038 - mae: 0.2992 - mape: 58.1093\n",
      "Epoch 23/100\n",
      "168/168 [==============================] - 0s 236us/sample - loss: 0.2928 - mse: 0.1000 - mae: 0.2928 - mape: 56.7469\n",
      "Epoch 24/100\n",
      "168/168 [==============================] - 0s 202us/sample - loss: 0.2863 - mse: 0.0963 - mae: 0.2863 - mape: 55.3914\n",
      "Epoch 25/100\n",
      "168/168 [==============================] - 0s 257us/sample - loss: 0.2799 - mse: 0.0927 - mae: 0.2799 - mape: 54.0260\n",
      "Epoch 26/100\n",
      "168/168 [==============================] - 0s 223us/sample - loss: 0.2734 - mse: 0.0891 - mae: 0.2734 - mape: 52.6486\n",
      "Epoch 27/100\n",
      "168/168 [==============================] - 0s 211us/sample - loss: 0.2668 - mse: 0.0856 - mae: 0.2668 - mape: 51.2622\n",
      "Epoch 28/100\n",
      "168/168 [==============================] - 0s 253us/sample - loss: 0.2602 - mse: 0.0822 - mae: 0.2602 - mape: 49.8641\n",
      "Epoch 29/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.2536 - mse: 0.0788 - mae: 0.2536 - mape: 48.4562\n",
      "Epoch 30/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.2469 - mse: 0.0755 - mae: 0.2469 - mape: 47.0577\n",
      "Epoch 31/100\n",
      "168/168 [==============================] - 0s 281us/sample - loss: 0.2402 - mse: 0.0723 - mae: 0.2402 - mape: 45.6264\n",
      "Epoch 32/100\n",
      "168/168 [==============================] - 0s 236us/sample - loss: 0.2334 - mse: 0.0692 - mae: 0.2334 - mape: 44.1899\n",
      "Epoch 33/100\n",
      "168/168 [==============================] - 0s 217us/sample - loss: 0.2266 - mse: 0.0660 - mae: 0.2266 - mape: 42.7612\n",
      "Epoch 34/100\n",
      "168/168 [==============================] - 0s 230us/sample - loss: 0.2197 - mse: 0.0631 - mae: 0.2197 - mape: 41.3030\n",
      "Epoch 35/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.2128 - mse: 0.0601 - mae: 0.2128 - mape: 39.8460\n",
      "Epoch 36/100\n",
      "168/168 [==============================] - 0s 211us/sample - loss: 0.2059 - mse: 0.0572 - mae: 0.2059 - mape: 38.3877\n",
      "Epoch 37/100\n",
      "168/168 [==============================] - 0s 247us/sample - loss: 0.1989 - mse: 0.0545 - mae: 0.1989 - mape: 36.8924\n",
      "Epoch 38/100\n",
      "168/168 [==============================] - 0s 216us/sample - loss: 0.1918 - mse: 0.0518 - mae: 0.1918 - mape: 35.4124\n",
      "Epoch 39/100\n",
      "168/168 [==============================] - 0s 213us/sample - loss: 0.1847 - mse: 0.0491 - mae: 0.1847 - mape: 33.9163\n",
      "Epoch 40/100\n",
      "168/168 [==============================] - 0s 250us/sample - loss: 0.1776 - mse: 0.0466 - mae: 0.1776 - mape: 32.3989\n",
      "Epoch 41/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.1704 - mse: 0.0442 - mae: 0.1704 - mape: 30.8843\n",
      "Epoch 42/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.1632 - mse: 0.0418 - mae: 0.1632 - mape: 29.3496\n",
      "Epoch 43/100\n",
      "168/168 [==============================] - 0s 201us/sample - loss: 0.1559 - mse: 0.0395 - mae: 0.1559 - mape: 27.8052\n",
      "Epoch 44/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 0.1486 - mse: 0.0373 - mae: 0.1486 - mape: 26.2894\n",
      "Epoch 45/100\n",
      "168/168 [==============================] - 0s 236us/sample - loss: 0.1420 - mse: 0.0353 - mae: 0.1420 - mape: 24.9178\n",
      "Epoch 46/100\n",
      "168/168 [==============================] - 0s 217us/sample - loss: 0.1366 - mse: 0.0335 - mae: 0.1366 - mape: 23.8563\n",
      "Epoch 47/100\n",
      "168/168 [==============================] - 0s 252us/sample - loss: 0.1322 - mse: 0.0318 - mae: 0.1322 - mape: 23.0432\n",
      "Epoch 48/100\n",
      "168/168 [==============================] - 0s 223us/sample - loss: 0.1282 - mse: 0.0304 - mae: 0.1282 - mape: 22.2842\n",
      "Epoch 49/100\n",
      "168/168 [==============================] - 0s 211us/sample - loss: 0.1245 - mse: 0.0291 - mae: 0.1245 - mape: 21.6154\n",
      "Epoch 50/100\n",
      "168/168 [==============================] - 0s 253us/sample - loss: 0.1215 - mse: 0.0279 - mae: 0.1215 - mape: 21.0910\n",
      "Epoch 51/100\n",
      "168/168 [==============================] - 0s 223us/sample - loss: 0.1189 - mse: 0.0269 - mae: 0.1189 - mape: 20.6488\n",
      "Epoch 52/100\n",
      "168/168 [==============================] - 0s 208us/sample - loss: 0.1166 - mse: 0.0259 - mae: 0.1166 - mape: 20.2809\n",
      "Epoch 53/100\n",
      "168/168 [==============================] - 0s 249us/sample - loss: 0.1147 - mse: 0.0251 - mae: 0.1147 - mape: 19.9750\n",
      "Epoch 54/100\n",
      "168/168 [==============================] - 0s 230us/sample - loss: 0.1131 - mse: 0.0244 - mae: 0.1131 - mape: 19.7509\n",
      "Epoch 55/100\n",
      "168/168 [==============================] - 0s 208us/sample - loss: 0.1115 - mse: 0.0237 - mae: 0.1115 - mape: 19.5333\n",
      "Epoch 56/100\n",
      "168/168 [==============================] - 0s 318us/sample - loss: 0.1103 - mse: 0.0231 - mae: 0.1103 - mape: 19.3752\n",
      "Epoch 57/100\n",
      "168/168 [==============================] - 0s 233us/sample - loss: 0.1091 - mse: 0.0225 - mae: 0.1091 - mape: 19.2244\n",
      "Epoch 58/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.1080 - mse: 0.0220 - mae: 0.1080 - mape: 19.0714\n",
      "Epoch 59/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.1072 - mse: 0.0216 - mae: 0.1072 - mape: 19.0068\n",
      "Epoch 60/100\n",
      "168/168 [==============================] - 0s 279us/sample - loss: 0.1062 - mse: 0.0211 - mae: 0.1062 - mape: 18.8834\n",
      "Epoch 61/100\n",
      "168/168 [==============================] - 0s 222us/sample - loss: 0.1054 - mse: 0.0208 - mae: 0.1054 - mape: 18.7899\n",
      "Epoch 62/100\n",
      "168/168 [==============================] - 0s 238us/sample - loss: 0.1047 - mse: 0.0204 - mae: 0.1047 - mape: 18.7251\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 231us/sample - loss: 0.1042 - mse: 0.0201 - mae: 0.1042 - mape: 18.6890\n",
      "Epoch 64/100\n",
      "168/168 [==============================] - 0s 219us/sample - loss: 0.1038 - mse: 0.0199 - mae: 0.1038 - mape: 18.6646\n",
      "Epoch 65/100\n",
      "168/168 [==============================] - 0s 256us/sample - loss: 0.1034 - mse: 0.0196 - mae: 0.1034 - mape: 18.6380\n",
      "Epoch 66/100\n",
      "168/168 [==============================] - 0s 218us/sample - loss: 0.1030 - mse: 0.0194 - mae: 0.1030 - mape: 18.6110\n",
      "Epoch 67/100\n",
      "168/168 [==============================] - 0s 218us/sample - loss: 0.1028 - mse: 0.0193 - mae: 0.1028 - mape: 18.6010\n",
      "Epoch 68/100\n",
      "168/168 [==============================] - 0s 273us/sample - loss: 0.1025 - mse: 0.0191 - mae: 0.1025 - mape: 18.5831\n",
      "Epoch 69/100\n",
      "168/168 [==============================] - 0s 209us/sample - loss: 0.1023 - mse: 0.0190 - mae: 0.1023 - mape: 18.5822\n",
      "Epoch 70/100\n",
      "168/168 [==============================] - 0s 244us/sample - loss: 0.1021 - mse: 0.0188 - mae: 0.1021 - mape: 18.5779\n",
      "Epoch 71/100\n",
      "168/168 [==============================] - 0s 216us/sample - loss: 0.1018 - mse: 0.0187 - mae: 0.1018 - mape: 18.5725\n",
      "Epoch 72/100\n",
      "168/168 [==============================] - 0s 206us/sample - loss: 0.1016 - mse: 0.0185 - mae: 0.1016 - mape: 18.5617\n",
      "Epoch 73/100\n",
      "168/168 [==============================] - 0s 240us/sample - loss: 0.1014 - mse: 0.0183 - mae: 0.1014 - mape: 18.5722\n",
      "Epoch 74/100\n",
      "168/168 [==============================] - 0s 231us/sample - loss: 0.1011 - mse: 0.0182 - mae: 0.1011 - mape: 18.5616\n",
      "Epoch 75/100\n",
      "168/168 [==============================] - 0s 211us/sample - loss: 0.1009 - mse: 0.0181 - mae: 0.1009 - mape: 18.5477\n",
      "Epoch 76/100\n",
      "168/168 [==============================] - 0s 278us/sample - loss: 0.1007 - mse: 0.0179 - mae: 0.1007 - mape: 18.5413\n",
      "Epoch 77/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.1005 - mse: 0.0178 - mae: 0.1005 - mape: 18.5375\n",
      "Epoch 78/100\n",
      "168/168 [==============================] - 0s 221us/sample - loss: 0.1003 - mse: 0.0177 - mae: 0.1003 - mape: 18.5263\n",
      "Epoch 79/100\n",
      "168/168 [==============================] - 0s 246us/sample - loss: 0.1001 - mse: 0.0176 - mae: 0.1001 - mape: 18.5202\n",
      "Epoch 80/100\n",
      "168/168 [==============================] - 0s 242us/sample - loss: 0.0998 - mse: 0.0175 - mae: 0.0998 - mape: 18.5063\n",
      "Epoch 81/100\n",
      "168/168 [==============================] - 0s 229us/sample - loss: 0.0996 - mse: 0.0174 - mae: 0.0996 - mape: 18.4980\n",
      "Epoch 82/100\n",
      "168/168 [==============================] - 0s 283us/sample - loss: 0.0994 - mse: 0.0173 - mae: 0.0994 - mape: 18.4890\n",
      "Epoch 83/100\n",
      "168/168 [==============================] - 0s 258us/sample - loss: 0.0992 - mse: 0.0172 - mae: 0.0992 - mape: 18.4803\n",
      "Epoch 84/100\n",
      "168/168 [==============================] - 0s 284us/sample - loss: 0.0990 - mse: 0.0171 - mae: 0.0990 - mape: 18.4852\n",
      "Epoch 85/100\n",
      "168/168 [==============================] - 0s 303us/sample - loss: 0.0987 - mse: 0.0170 - mae: 0.0987 - mape: 18.4613\n",
      "Epoch 86/100\n",
      "168/168 [==============================] - 0s 248us/sample - loss: 0.0985 - mse: 0.0170 - mae: 0.0985 - mape: 18.4532\n",
      "Epoch 87/100\n",
      "168/168 [==============================] - 0s 268us/sample - loss: 0.0983 - mse: 0.0169 - mae: 0.0983 - mape: 18.4385\n",
      "Epoch 88/100\n",
      "168/168 [==============================] - 0s 368us/sample - loss: 0.0981 - mse: 0.0168 - mae: 0.0981 - mape: 18.4290\n",
      "Epoch 89/100\n",
      "168/168 [==============================] - 0s 370us/sample - loss: 0.0979 - mse: 0.0167 - mae: 0.0979 - mape: 18.4175\n",
      "Epoch 90/100\n",
      "168/168 [==============================] - 0s 385us/sample - loss: 0.0976 - mse: 0.0166 - mae: 0.0976 - mape: 18.4161\n",
      "Epoch 91/100\n",
      "168/168 [==============================] - 0s 446us/sample - loss: 0.0974 - mse: 0.0165 - mae: 0.0974 - mape: 18.4203\n",
      "Epoch 92/100\n",
      "168/168 [==============================] - 0s 402us/sample - loss: 0.0971 - mse: 0.0164 - mae: 0.0971 - mape: 18.4188\n",
      "Epoch 93/100\n",
      "168/168 [==============================] - 0s 571us/sample - loss: 0.0968 - mse: 0.0163 - mae: 0.0968 - mape: 18.3980\n",
      "Epoch 94/100\n",
      "168/168 [==============================] - 0s 296us/sample - loss: 0.0966 - mse: 0.0162 - mae: 0.0966 - mape: 18.3982\n",
      "Epoch 95/100\n",
      "168/168 [==============================] - 0s 312us/sample - loss: 0.0963 - mse: 0.0162 - mae: 0.0963 - mape: 18.3949\n",
      "Epoch 96/100\n",
      "168/168 [==============================] - 0s 408us/sample - loss: 0.0960 - mse: 0.0161 - mae: 0.0960 - mape: 18.3836\n",
      "Epoch 97/100\n",
      "168/168 [==============================] - 0s 408us/sample - loss: 0.0958 - mse: 0.0160 - mae: 0.0958 - mape: 18.3721\n",
      "Epoch 98/100\n",
      "168/168 [==============================] - 0s 486us/sample - loss: 0.0957 - mse: 0.0160 - mae: 0.0957 - mape: 18.3767\n",
      "Epoch 99/100\n",
      "168/168 [==============================] - 0s 314us/sample - loss: 0.0955 - mse: 0.0159 - mae: 0.0955 - mape: 18.3634\n",
      "Epoch 100/100\n",
      "168/168 [==============================] - 0s 238us/sample - loss: 0.0953 - mse: 0.0159 - mae: 0.0953 - mape: 18.3456\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/2Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 134 samples\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.5844 - mse: 0.3551 - mae: 0.5844 - mape: 97.1429\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 233us/sample - loss: 0.5798 - mse: 0.3498 - mae: 0.5798 - mape: 96.3446\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 222us/sample - loss: 0.5753 - mse: 0.3445 - mae: 0.5753 - mape: 95.5455\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 221us/sample - loss: 0.5707 - mse: 0.3393 - mae: 0.5707 - mape: 94.7403\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.5662 - mse: 0.3342 - mae: 0.5662 - mape: 93.9336\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 226us/sample - loss: 0.5616 - mse: 0.3290 - mae: 0.5616 - mape: 93.1364\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 249us/sample - loss: 0.5571 - mse: 0.3239 - mae: 0.5571 - mape: 92.3378\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 276us/sample - loss: 0.5525 - mse: 0.3189 - mae: 0.5525 - mape: 91.5277\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 229us/sample - loss: 0.5480 - mse: 0.3139 - mae: 0.5480 - mape: 90.7110\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 237us/sample - loss: 0.5434 - mse: 0.3089 - mae: 0.5434 - mape: 89.9162\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 271us/sample - loss: 0.5388 - mse: 0.3039 - mae: 0.5388 - mape: 89.1145\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 318us/sample - loss: 0.5342 - mse: 0.2990 - mae: 0.5342 - mape: 88.2985\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 361us/sample - loss: 0.5296 - mse: 0.2941 - mae: 0.5296 - mape: 87.5017\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 318us/sample - loss: 0.5251 - mse: 0.2893 - mae: 0.5251 - mape: 86.6804\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 260us/sample - loss: 0.5204 - mse: 0.2845 - mae: 0.5204 - mape: 85.8719\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 220us/sample - loss: 0.5158 - mse: 0.2797 - mae: 0.5158 - mape: 85.0538\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 255us/sample - loss: 0.5112 - mse: 0.2749 - mae: 0.5112 - mape: 84.2396\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 435us/sample - loss: 0.5066 - mse: 0.2702 - mae: 0.5066 - mape: 83.4223\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 432us/sample - loss: 0.5019 - mse: 0.2655 - mae: 0.5019 - mape: 82.5965\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 280us/sample - loss: 0.4973 - mse: 0.2609 - mae: 0.4973 - mape: 81.7797\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 264us/sample - loss: 0.4926 - mse: 0.2563 - mae: 0.4926 - mape: 80.9479\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 298us/sample - loss: 0.4879 - mse: 0.2517 - mae: 0.4879 - mape: 80.1231\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 250us/sample - loss: 0.4832 - mse: 0.2471 - mae: 0.4832 - mape: 79.3013\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 247us/sample - loss: 0.4785 - mse: 0.2425 - mae: 0.4785 - mape: 78.4708\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.4738 - mse: 0.2381 - mae: 0.4738 - mape: 77.6277\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 453us/sample - loss: 0.4690 - mse: 0.2336 - mae: 0.4690 - mape: 76.7962\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 452us/sample - loss: 0.4642 - mse: 0.2291 - mae: 0.4642 - mape: 75.9538\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 300us/sample - loss: 0.4595 - mse: 0.2247 - mae: 0.4595 - mape: 75.1031\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 299us/sample - loss: 0.4547 - mse: 0.2203 - mae: 0.4547 - mape: 74.2702\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 311us/sample - loss: 0.4498 - mse: 0.2160 - mae: 0.4498 - mape: 73.4138\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 279us/sample - loss: 0.4450 - mse: 0.2117 - mae: 0.4450 - mape: 72.5605\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 245us/sample - loss: 0.4402 - mse: 0.2073 - mae: 0.4402 - mape: 71.7195\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 295us/sample - loss: 0.4353 - mse: 0.2031 - mae: 0.4353 - mape: 70.8583\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 246us/sample - loss: 0.4304 - mse: 0.1988 - mae: 0.4304 - mape: 69.9932\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 251us/sample - loss: 0.4255 - mse: 0.1946 - mae: 0.4255 - mape: 69.1226\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 240us/sample - loss: 0.4205 - mse: 0.1905 - mae: 0.4205 - mape: 68.2431\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 263us/sample - loss: 0.4156 - mse: 0.1863 - mae: 0.4156 - mape: 67.3768\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 297us/sample - loss: 0.4106 - mse: 0.1823 - mae: 0.4106 - mape: 66.4906\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.4056 - mse: 0.1782 - mae: 0.4056 - mape: 65.6074\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.4006 - mse: 0.1741 - mae: 0.4006 - mape: 64.7332\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 332us/sample - loss: 0.3956 - mse: 0.1701 - mae: 0.3956 - mape: 63.8438\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 258us/sample - loss: 0.3905 - mse: 0.1661 - mae: 0.3905 - mape: 62.9463\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 276us/sample - loss: 0.3854 - mse: 0.1622 - mae: 0.3854 - mape: 62.0543\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.3803 - mse: 0.1582 - mae: 0.3803 - mape: 61.1530\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.3752 - mse: 0.1544 - mae: 0.3752 - mape: 60.2424\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 235us/sample - loss: 0.3700 - mse: 0.1505 - mae: 0.3700 - mape: 59.3323\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 223us/sample - loss: 0.3648 - mse: 0.1467 - mae: 0.3648 - mape: 58.4132\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 233us/sample - loss: 0.3596 - mse: 0.1430 - mae: 0.3596 - mape: 57.4907\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 326us/sample - loss: 0.3544 - mse: 0.1392 - mae: 0.3544 - mape: 56.5772\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.3491 - mse: 0.1355 - mae: 0.3491 - mape: 55.6394\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 254us/sample - loss: 0.3438 - mse: 0.1319 - mae: 0.3438 - mape: 54.7104\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.3385 - mse: 0.1282 - mae: 0.3385 - mape: 53.7717\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.3331 - mse: 0.1246 - mae: 0.3331 - mape: 52.8392\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 281us/sample - loss: 0.3278 - mse: 0.1211 - mae: 0.3278 - mape: 51.8751\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 244us/sample - loss: 0.3223 - mse: 0.1176 - mae: 0.3223 - mape: 50.9227\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.3169 - mse: 0.1141 - mae: 0.3169 - mape: 49.9644\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 301us/sample - loss: 0.3114 - mse: 0.1107 - mae: 0.3114 - mape: 48.9970\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 266us/sample - loss: 0.3060 - mse: 0.1073 - mae: 0.3060 - mape: 48.0400\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.3004 - mse: 0.1039 - mae: 0.3004 - mape: 47.0670\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 300us/sample - loss: 0.2949 - mse: 0.1006 - mae: 0.2949 - mape: 46.1027\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.2898 - mse: 0.0974 - mae: 0.2898 - mape: 45.2579\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 260us/sample - loss: 0.2850 - mse: 0.0943 - mae: 0.2850 - mape: 44.5247\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 227us/sample - loss: 0.2804 - mse: 0.0913 - mae: 0.2804 - mape: 43.8168\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 296us/sample - loss: 0.2762 - mse: 0.0885 - mae: 0.2762 - mape: 43.2426\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 240us/sample - loss: 0.2721 - mse: 0.0857 - mae: 0.2721 - mape: 42.6735\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 250us/sample - loss: 0.2680 - mse: 0.0831 - mae: 0.2680 - mape: 42.0759\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 305us/sample - loss: 0.2641 - mse: 0.0806 - mae: 0.2641 - mape: 41.5477\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 259us/sample - loss: 0.2601 - mse: 0.0781 - mae: 0.2601 - mape: 40.9733\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 232us/sample - loss: 0.2561 - mse: 0.0757 - mae: 0.2561 - mape: 40.4143\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 214us/sample - loss: 0.2521 - mse: 0.0733 - mae: 0.2521 - mape: 39.8507\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 281us/sample - loss: 0.2481 - mse: 0.0709 - mae: 0.2481 - mape: 39.2794\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 247us/sample - loss: 0.2440 - mse: 0.0685 - mae: 0.2440 - mape: 38.7162\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 215us/sample - loss: 0.2398 - mse: 0.0662 - mae: 0.2398 - mape: 38.1187\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 234us/sample - loss: 0.2356 - mse: 0.0639 - mae: 0.2356 - mape: 37.5278\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 224us/sample - loss: 0.2314 - mse: 0.0616 - mae: 0.2314 - mape: 36.9397\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 314us/sample - loss: 0.2271 - mse: 0.0593 - mae: 0.2271 - mape: 36.3278\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 238us/sample - loss: 0.2226 - mse: 0.0571 - mae: 0.2226 - mape: 35.6976\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 282us/sample - loss: 0.2184 - mse: 0.0549 - mae: 0.2184 - mape: 35.1127\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 229us/sample - loss: 0.2138 - mse: 0.0527 - mae: 0.2138 - mape: 34.4638\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 235us/sample - loss: 0.2094 - mse: 0.0506 - mae: 0.2094 - mape: 33.8410\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 300us/sample - loss: 0.2049 - mse: 0.0485 - mae: 0.2049 - mape: 33.2017\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 269us/sample - loss: 0.2004 - mse: 0.0465 - mae: 0.2004 - mape: 32.5818\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 269us/sample - loss: 0.1958 - mse: 0.0445 - mae: 0.1958 - mape: 31.9320\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 394us/sample - loss: 0.1912 - mse: 0.0426 - mae: 0.1912 - mape: 31.2898\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 309us/sample - loss: 0.1868 - mse: 0.0407 - mae: 0.1868 - mape: 30.6722\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 298us/sample - loss: 0.1822 - mse: 0.0390 - mae: 0.1822 - mape: 30.0193\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 493us/sample - loss: 0.1777 - mse: 0.0372 - mae: 0.1777 - mape: 29.4002\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 363us/sample - loss: 0.1730 - mse: 0.0355 - mae: 0.1730 - mape: 28.7290\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 297us/sample - loss: 0.1682 - mse: 0.0339 - mae: 0.1682 - mape: 28.0350\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 297us/sample - loss: 0.1635 - mse: 0.0323 - mae: 0.1635 - mape: 27.4001\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 251us/sample - loss: 0.1588 - mse: 0.0307 - mae: 0.1588 - mape: 26.7401\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 252us/sample - loss: 0.1540 - mse: 0.0293 - mae: 0.1540 - mape: 26.0613\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 341us/sample - loss: 0.1491 - mse: 0.0278 - mae: 0.1491 - mape: 25.3600\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 280us/sample - loss: 0.1442 - mse: 0.0265 - mae: 0.1442 - mape: 24.6762\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 233us/sample - loss: 0.1393 - mse: 0.0251 - mae: 0.1393 - mape: 23.9875\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 379us/sample - loss: 0.1348 - mse: 0.0239 - mae: 0.1348 - mape: 23.3842\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 332us/sample - loss: 0.1305 - mse: 0.0228 - mae: 0.1305 - mape: 22.8150\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 260us/sample - loss: 0.1261 - mse: 0.0216 - mae: 0.1261 - mape: 22.2251\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 390us/sample - loss: 0.1225 - mse: 0.0208 - mae: 0.1225 - mape: 21.7408\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.1194 - mse: 0.0199 - mae: 0.1194 - mape: 21.3685\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 1s 1ms/sample - loss: 0.6932 - accuracy: 0.5000\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.698843  8.185952           2400  4801.158  4.363         2\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training PCNN-lgt\n",
      "Training PCNN-Bagged\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "...Returning Results...\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Ablation Completion Percentage: 0.6666666666666666\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "-------------------------------------------------------\n",
      "Randomly Initialized Parts - Via Randomized Algorithm 2\n",
      "-------------------------------------------------------\n",
      "Final Loop\n",
      "breaking early\n",
      "The_parts_listhe number of parts are: 3.\n",
      "-----------------------------------------------------\n",
      "Training Sub-Networks on Each Randomly Generated Part\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 0/3Total Parts.\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/kratsi0000/opt/anaconda3/envs/bpcnn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174 samples\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 0s 2ms/sample - loss: 0.4759 - mse: 0.2396 - mae: 0.4759 - mape: 94.9109\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 0s 162us/sample - loss: 0.4749 - mse: 0.2387 - mae: 0.4749 - mape: 94.7065\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 0s 163us/sample - loss: 0.4739 - mse: 0.2378 - mae: 0.4739 - mape: 94.5031\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 0s 164us/sample - loss: 0.4729 - mse: 0.2369 - mae: 0.4729 - mape: 94.2988\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 0s 209us/sample - loss: 0.4720 - mse: 0.2360 - mae: 0.4720 - mape: 94.0971\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 0s 487us/sample - loss: 0.4710 - mse: 0.2351 - mae: 0.4710 - mape: 93.8900\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 0s 198us/sample - loss: 0.4700 - mse: 0.2341 - mae: 0.4700 - mape: 93.6850\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 0s 184us/sample - loss: 0.4690 - mse: 0.2332 - mae: 0.4690 - mape: 93.4832\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 0s 220us/sample - loss: 0.4681 - mse: 0.2323 - mae: 0.4681 - mape: 93.2754\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 0s 240us/sample - loss: 0.4671 - mse: 0.2314 - mae: 0.4671 - mape: 93.0707\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 0s 432us/sample - loss: 0.4661 - mse: 0.2305 - mae: 0.4661 - mape: 92.8665\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 0s 214us/sample - loss: 0.4651 - mse: 0.2296 - mae: 0.4651 - mape: 92.6599\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 0s 467us/sample - loss: 0.4641 - mse: 0.2287 - mae: 0.4641 - mape: 92.4522\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 0s 184us/sample - loss: 0.4632 - mse: 0.2278 - mae: 0.4632 - mape: 92.2441\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 0s 189us/sample - loss: 0.4622 - mse: 0.2269 - mae: 0.4622 - mape: 92.0378\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 0s 138us/sample - loss: 0.4612 - mse: 0.2259 - mae: 0.4612 - mape: 91.8303\n",
      "Epoch 17/100\n",
      "174/174 [==============================] - 0s 312us/sample - loss: 0.4602 - mse: 0.2250 - mae: 0.4602 - mape: 91.6225\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 0s 282us/sample - loss: 0.4592 - mse: 0.2241 - mae: 0.4592 - mape: 91.4138\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 0s 207us/sample - loss: 0.4582 - mse: 0.2232 - mae: 0.4582 - mape: 91.2031\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 0s 333us/sample - loss: 0.4572 - mse: 0.2223 - mae: 0.4572 - mape: 90.9949\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 0s 283us/sample - loss: 0.4562 - mse: 0.2214 - mae: 0.4562 - mape: 90.7844\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 0s 212us/sample - loss: 0.4552 - mse: 0.2205 - mae: 0.4552 - mape: 90.5734\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 0s 225us/sample - loss: 0.4542 - mse: 0.2196 - mae: 0.4542 - mape: 90.3608\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 0s 176us/sample - loss: 0.4532 - mse: 0.2186 - mae: 0.4532 - mape: 90.1485\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 0s 305us/sample - loss: 0.4521 - mse: 0.2177 - mae: 0.4521 - mape: 89.9378\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 0s 217us/sample - loss: 0.4511 - mse: 0.2168 - mae: 0.4511 - mape: 89.7232\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 0s 227us/sample - loss: 0.4501 - mse: 0.2159 - mae: 0.4501 - mape: 89.5097\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 0s 189us/sample - loss: 0.4491 - mse: 0.2150 - mae: 0.4491 - mape: 89.2935\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 0s 188us/sample - loss: 0.4481 - mse: 0.2141 - mae: 0.4481 - mape: 89.0780\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 0s 175us/sample - loss: 0.4470 - mse: 0.2132 - mae: 0.4470 - mape: 88.8613\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 0s 313us/sample - loss: 0.4460 - mse: 0.2122 - mae: 0.4460 - mape: 88.6464\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 0s 170us/sample - loss: 0.4450 - mse: 0.2113 - mae: 0.4450 - mape: 88.4283\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 0s 177us/sample - loss: 0.4439 - mse: 0.2104 - mae: 0.4439 - mape: 88.2104\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 0s 157us/sample - loss: 0.4429 - mse: 0.2095 - mae: 0.4429 - mape: 87.9912\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 0s 213us/sample - loss: 0.4418 - mse: 0.2085 - mae: 0.4418 - mape: 87.7711\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 0s 159us/sample - loss: 0.4408 - mse: 0.2076 - mae: 0.4408 - mape: 87.5504\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 0s 161us/sample - loss: 0.4397 - mse: 0.2067 - mae: 0.4397 - mape: 87.3270\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 0s 138us/sample - loss: 0.4386 - mse: 0.2058 - mae: 0.4386 - mape: 87.1055\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 0s 176us/sample - loss: 0.4376 - mse: 0.2048 - mae: 0.4376 - mape: 86.8801\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 0s 153us/sample - loss: 0.4365 - mse: 0.2039 - mae: 0.4365 - mape: 86.6558\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 0s 137us/sample - loss: 0.4354 - mse: 0.2030 - mae: 0.4354 - mape: 86.4306\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 0s 133us/sample - loss: 0.4344 - mse: 0.2021 - mae: 0.4344 - mape: 86.2023\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 0s 117us/sample - loss: 0.4333 - mse: 0.2011 - mae: 0.4333 - mape: 85.9792\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 0s 162us/sample - loss: 0.4322 - mse: 0.2002 - mae: 0.4322 - mape: 85.7485\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 0s 200us/sample - loss: 0.4311 - mse: 0.1992 - mae: 0.4311 - mape: 85.5188\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 0s 178us/sample - loss: 0.4300 - mse: 0.1983 - mae: 0.4300 - mape: 85.2901\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.4289 - mse: 0.1974 - mae: 0.4289 - mape: 85.0578\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 0s 141us/sample - loss: 0.4278 - mse: 0.1964 - mae: 0.4278 - mape: 84.8261\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 0s 181us/sample - loss: 0.4267 - mse: 0.1955 - mae: 0.4267 - mape: 84.5947\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 0s 134us/sample - loss: 0.4256 - mse: 0.1945 - mae: 0.4256 - mape: 84.3616\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 0s 166us/sample - loss: 0.4244 - mse: 0.1936 - mae: 0.4244 - mape: 84.1220\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 0s 152us/sample - loss: 0.4233 - mse: 0.1926 - mae: 0.4233 - mape: 83.8871\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 0s 189us/sample - loss: 0.4222 - mse: 0.1917 - mae: 0.4222 - mape: 83.6484\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 0s 144us/sample - loss: 0.4211 - mse: 0.1907 - mae: 0.4211 - mape: 83.4118\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 0s 152us/sample - loss: 0.4199 - mse: 0.1898 - mae: 0.4199 - mape: 83.1722\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 0s 137us/sample - loss: 0.4188 - mse: 0.1888 - mae: 0.4188 - mape: 82.9328\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 0s 248us/sample - loss: 0.4176 - mse: 0.1878 - mae: 0.4176 - mape: 82.6909\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 0s 139us/sample - loss: 0.4165 - mse: 0.1869 - mae: 0.4165 - mape: 82.4491\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 0s 145us/sample - loss: 0.4153 - mse: 0.1859 - mae: 0.4153 - mape: 82.2039\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 0s 138us/sample - loss: 0.4141 - mse: 0.1850 - mae: 0.4141 - mape: 81.9588\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.4130 - mse: 0.1840 - mae: 0.4130 - mape: 81.7139\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.4118 - mse: 0.1830 - mae: 0.4118 - mape: 81.4641\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 143us/sample - loss: 0.4106 - mse: 0.1821 - mae: 0.4106 - mape: 81.2177\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 0s 145us/sample - loss: 0.4094 - mse: 0.1811 - mae: 0.4094 - mape: 80.9679\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.4082 - mse: 0.1801 - mae: 0.4082 - mape: 80.7161\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 0s 132us/sample - loss: 0.4070 - mse: 0.1791 - mae: 0.4070 - mape: 80.4626\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 0s 149us/sample - loss: 0.4058 - mse: 0.1782 - mae: 0.4058 - mape: 80.2097\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 0s 123us/sample - loss: 0.4046 - mse: 0.1772 - mae: 0.4046 - mape: 79.9542\n",
      "Epoch 69/100\n",
      "174/174 [==============================] - 0s 126us/sample - loss: 0.4034 - mse: 0.1762 - mae: 0.4034 - mape: 79.6999\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 0s 112us/sample - loss: 0.4021 - mse: 0.1752 - mae: 0.4021 - mape: 79.4419\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 0s 119us/sample - loss: 0.4009 - mse: 0.1742 - mae: 0.4009 - mape: 79.1813\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 0s 150us/sample - loss: 0.3997 - mse: 0.1733 - mae: 0.3997 - mape: 78.9207\n",
      "Epoch 73/100\n",
      "174/174 [==============================] - 0s 125us/sample - loss: 0.3984 - mse: 0.1723 - mae: 0.3984 - mape: 78.6592\n",
      "Epoch 74/100\n",
      "174/174 [==============================] - 0s 138us/sample - loss: 0.3972 - mse: 0.1713 - mae: 0.3972 - mape: 78.3963\n",
      "Epoch 75/100\n",
      "174/174 [==============================] - 0s 113us/sample - loss: 0.3959 - mse: 0.1703 - mae: 0.3959 - mape: 78.1334\n",
      "Epoch 76/100\n",
      "174/174 [==============================] - 0s 118us/sample - loss: 0.3946 - mse: 0.1693 - mae: 0.3946 - mape: 77.8656\n",
      "Epoch 77/100\n",
      "174/174 [==============================] - 0s 121us/sample - loss: 0.3933 - mse: 0.1683 - mae: 0.3933 - mape: 77.5970\n",
      "Epoch 78/100\n",
      "174/174 [==============================] - 0s 190us/sample - loss: 0.3921 - mse: 0.1673 - mae: 0.3921 - mape: 77.3293\n",
      "Epoch 79/100\n",
      "174/174 [==============================] - 0s 157us/sample - loss: 0.3908 - mse: 0.1663 - mae: 0.3908 - mape: 77.0575\n",
      "Epoch 80/100\n",
      "174/174 [==============================] - 0s 125us/sample - loss: 0.3895 - mse: 0.1653 - mae: 0.3895 - mape: 76.7863\n",
      "Epoch 81/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.3882 - mse: 0.1643 - mae: 0.3882 - mape: 76.5139\n",
      "Epoch 82/100\n",
      "174/174 [==============================] - 0s 122us/sample - loss: 0.3869 - mse: 0.1633 - mae: 0.3869 - mape: 76.2397\n",
      "Epoch 83/100\n",
      "174/174 [==============================] - 0s 120us/sample - loss: 0.3856 - mse: 0.1622 - mae: 0.3856 - mape: 75.9624\n",
      "Epoch 84/100\n",
      "174/174 [==============================] - 0s 155us/sample - loss: 0.3842 - mse: 0.1612 - mae: 0.3842 - mape: 75.6826\n",
      "Epoch 85/100\n",
      "174/174 [==============================] - 0s 145us/sample - loss: 0.3829 - mse: 0.1602 - mae: 0.3829 - mape: 75.4045\n",
      "Epoch 86/100\n",
      "174/174 [==============================] - 0s 148us/sample - loss: 0.3816 - mse: 0.1592 - mae: 0.3816 - mape: 75.1220\n",
      "Epoch 87/100\n",
      "174/174 [==============================] - 0s 121us/sample - loss: 0.3802 - mse: 0.1582 - mae: 0.3802 - mape: 74.8428\n",
      "Epoch 88/100\n",
      "174/174 [==============================] - 0s 117us/sample - loss: 0.3789 - mse: 0.1572 - mae: 0.3789 - mape: 74.5548\n",
      "Epoch 89/100\n",
      "174/174 [==============================] - 0s 116us/sample - loss: 0.3775 - mse: 0.1561 - mae: 0.3775 - mape: 74.2693\n",
      "Epoch 90/100\n",
      "174/174 [==============================] - 0s 127us/sample - loss: 0.3761 - mse: 0.1551 - mae: 0.3761 - mape: 73.9826\n",
      "Epoch 91/100\n",
      "174/174 [==============================] - 0s 158us/sample - loss: 0.3747 - mse: 0.1541 - mae: 0.3747 - mape: 73.6913\n",
      "Epoch 92/100\n",
      "174/174 [==============================] - 0s 131us/sample - loss: 0.3734 - mse: 0.1531 - mae: 0.3734 - mape: 73.3995\n",
      "Epoch 93/100\n",
      "174/174 [==============================] - 0s 124us/sample - loss: 0.3720 - mse: 0.1520 - mae: 0.3720 - mape: 73.1089\n",
      "Epoch 94/100\n",
      "174/174 [==============================] - 0s 116us/sample - loss: 0.3706 - mse: 0.1510 - mae: 0.3706 - mape: 72.8119\n",
      "Epoch 95/100\n",
      "174/174 [==============================] - 0s 124us/sample - loss: 0.3691 - mse: 0.1499 - mae: 0.3691 - mape: 72.5182\n",
      "Epoch 96/100\n",
      "174/174 [==============================] - 0s 116us/sample - loss: 0.3677 - mse: 0.1489 - mae: 0.3677 - mape: 72.2195\n",
      "Epoch 97/100\n",
      "174/174 [==============================] - 0s 122us/sample - loss: 0.3663 - mse: 0.1479 - mae: 0.3663 - mape: 71.9229\n",
      "Epoch 98/100\n",
      "174/174 [==============================] - 0s 147us/sample - loss: 0.3649 - mse: 0.1468 - mae: 0.3649 - mape: 71.6179\n",
      "Epoch 99/100\n",
      "174/174 [==============================] - 0s 140us/sample - loss: 0.3634 - mse: 0.1458 - mae: 0.3634 - mape: 71.3158\n",
      "Epoch 100/100\n",
      "174/174 [==============================] - 0s 122us/sample - loss: 0.3620 - mse: 0.1447 - mae: 0.3620 - mape: 71.0106\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 1/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 145 samples\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 0s 2ms/sample - loss: 0.5439 - mse: 0.3198 - mae: 0.5439 - mape: 96.1029\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 178us/sample - loss: 0.5431 - mse: 0.3190 - mae: 0.5431 - mape: 95.9517\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 138us/sample - loss: 0.5423 - mse: 0.3181 - mae: 0.5423 - mape: 95.8030\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 151us/sample - loss: 0.5416 - mse: 0.3173 - mae: 0.5416 - mape: 95.6491\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 128us/sample - loss: 0.5408 - mse: 0.3165 - mae: 0.5408 - mape: 95.4967\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 189us/sample - loss: 0.5400 - mse: 0.3156 - mae: 0.5400 - mape: 95.3470\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5393 - mse: 0.3148 - mae: 0.5393 - mape: 95.1940\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 178us/sample - loss: 0.5385 - mse: 0.3140 - mae: 0.5385 - mape: 95.0449\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 138us/sample - loss: 0.5377 - mse: 0.3132 - mae: 0.5377 - mape: 94.8890\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 131us/sample - loss: 0.5370 - mse: 0.3123 - mae: 0.5370 - mape: 94.7348\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 129us/sample - loss: 0.5362 - mse: 0.3115 - mae: 0.5362 - mape: 94.5867\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 133us/sample - loss: 0.5354 - mse: 0.3107 - mae: 0.5354 - mape: 94.4323\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 126us/sample - loss: 0.5347 - mse: 0.3099 - mae: 0.5347 - mape: 94.2804\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 194us/sample - loss: 0.5339 - mse: 0.3090 - mae: 0.5339 - mape: 94.1282\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 175us/sample - loss: 0.5331 - mse: 0.3082 - mae: 0.5331 - mape: 93.9754\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 168us/sample - loss: 0.5324 - mse: 0.3074 - mae: 0.5324 - mape: 93.8254\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 174us/sample - loss: 0.5316 - mse: 0.3066 - mae: 0.5316 - mape: 93.6722\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 154us/sample - loss: 0.5308 - mse: 0.3058 - mae: 0.5308 - mape: 93.5195\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 215us/sample - loss: 0.5301 - mse: 0.3050 - mae: 0.5301 - mape: 93.3666\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 174us/sample - loss: 0.5293 - mse: 0.3041 - mae: 0.5293 - mape: 93.2137\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.5285 - mse: 0.3033 - mae: 0.5285 - mape: 93.0643\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 161us/sample - loss: 0.5278 - mse: 0.3025 - mae: 0.5278 - mape: 92.9089\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 138us/sample - loss: 0.5270 - mse: 0.3017 - mae: 0.5270 - mape: 92.7539\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 165us/sample - loss: 0.5262 - mse: 0.3009 - mae: 0.5262 - mape: 92.6018\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 173us/sample - loss: 0.5255 - mse: 0.3001 - mae: 0.5255 - mape: 92.4471\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 130us/sample - loss: 0.5247 - mse: 0.2993 - mae: 0.5247 - mape: 92.2917\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 142us/sample - loss: 0.5239 - mse: 0.2984 - mae: 0.5239 - mape: 92.1397\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 127us/sample - loss: 0.5231 - mse: 0.2976 - mae: 0.5231 - mape: 91.9862\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 156us/sample - loss: 0.5224 - mse: 0.2968 - mae: 0.5224 - mape: 91.8326\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 208us/sample - loss: 0.5216 - mse: 0.2960 - mae: 0.5216 - mape: 91.6791\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 149us/sample - loss: 0.5208 - mse: 0.2952 - mae: 0.5208 - mape: 91.5232\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 148us/sample - loss: 0.5200 - mse: 0.2944 - mae: 0.5200 - mape: 91.3689\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.5192 - mse: 0.2936 - mae: 0.5192 - mape: 91.2138\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 141us/sample - loss: 0.5185 - mse: 0.2927 - mae: 0.5185 - mape: 91.0601\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.5177 - mse: 0.2919 - mae: 0.5177 - mape: 90.9015\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 127us/sample - loss: 0.5169 - mse: 0.2911 - mae: 0.5169 - mape: 90.7451\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 0s 179us/sample - loss: 0.5161 - mse: 0.2903 - mae: 0.5161 - mape: 90.5891\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 202us/sample - loss: 0.5153 - mse: 0.2895 - mae: 0.5153 - mape: 90.4296\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 160us/sample - loss: 0.5145 - mse: 0.2887 - mae: 0.5145 - mape: 90.2753\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 0s 130us/sample - loss: 0.5137 - mse: 0.2879 - mae: 0.5137 - mape: 90.1206\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 0s 122us/sample - loss: 0.5129 - mse: 0.2871 - mae: 0.5129 - mape: 89.9605\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 158us/sample - loss: 0.5122 - mse: 0.2862 - mae: 0.5122 - mape: 89.8040\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 0s 139us/sample - loss: 0.5114 - mse: 0.2854 - mae: 0.5114 - mape: 89.6465\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 0s 145us/sample - loss: 0.5106 - mse: 0.2846 - mae: 0.5106 - mape: 89.4875\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 154us/sample - loss: 0.5098 - mse: 0.2838 - mae: 0.5098 - mape: 89.3274\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 146us/sample - loss: 0.5090 - mse: 0.2830 - mae: 0.5090 - mape: 89.1677\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 209us/sample - loss: 0.5082 - mse: 0.2821 - mae: 0.5082 - mape: 89.0104\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 0s 142us/sample - loss: 0.5073 - mse: 0.2813 - mae: 0.5073 - mape: 88.8498\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 173us/sample - loss: 0.5065 - mse: 0.2805 - mae: 0.5065 - mape: 88.6881\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 190us/sample - loss: 0.5057 - mse: 0.2797 - mae: 0.5057 - mape: 88.5290\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 0s 150us/sample - loss: 0.5049 - mse: 0.2789 - mae: 0.5049 - mape: 88.3667\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 128us/sample - loss: 0.5041 - mse: 0.2780 - mae: 0.5041 - mape: 88.2044\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 121us/sample - loss: 0.5033 - mse: 0.2772 - mae: 0.5033 - mape: 88.0420\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.5025 - mse: 0.2764 - mae: 0.5025 - mape: 87.8811\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 172us/sample - loss: 0.5017 - mse: 0.2756 - mae: 0.5017 - mape: 87.7164\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 194us/sample - loss: 0.5008 - mse: 0.2747 - mae: 0.5008 - mape: 87.5551\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 137us/sample - loss: 0.5000 - mse: 0.2739 - mae: 0.5000 - mape: 87.3889\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 145us/sample - loss: 0.4992 - mse: 0.2731 - mae: 0.4992 - mape: 87.2265\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 131us/sample - loss: 0.4984 - mse: 0.2723 - mae: 0.4984 - mape: 87.0663\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.4975 - mse: 0.2714 - mae: 0.4975 - mape: 86.8986\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 168us/sample - loss: 0.4967 - mse: 0.2706 - mae: 0.4967 - mape: 86.7351\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 141us/sample - loss: 0.4959 - mse: 0.2698 - mae: 0.4959 - mape: 86.5660\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.4950 - mse: 0.2689 - mae: 0.4950 - mape: 86.4010\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.4942 - mse: 0.2681 - mae: 0.4942 - mape: 86.2299\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 130us/sample - loss: 0.4933 - mse: 0.2673 - mae: 0.4933 - mape: 86.0664\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 159us/sample - loss: 0.4925 - mse: 0.2665 - mae: 0.4925 - mape: 85.8986\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 137us/sample - loss: 0.4917 - mse: 0.2656 - mae: 0.4917 - mape: 85.7267\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.4908 - mse: 0.2648 - mae: 0.4908 - mape: 85.5616\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 151us/sample - loss: 0.4900 - mse: 0.2639 - mae: 0.4900 - mape: 85.3911\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 121us/sample - loss: 0.4891 - mse: 0.2631 - mae: 0.4891 - mape: 85.2204\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.4882 - mse: 0.2623 - mae: 0.4882 - mape: 85.0526\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 167us/sample - loss: 0.4874 - mse: 0.2614 - mae: 0.4874 - mape: 84.8775\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 129us/sample - loss: 0.4865 - mse: 0.2606 - mae: 0.4865 - mape: 84.7057\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 129us/sample - loss: 0.4857 - mse: 0.2597 - mae: 0.4857 - mape: 84.5381\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 116us/sample - loss: 0.4848 - mse: 0.2589 - mae: 0.4848 - mape: 84.3632\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 120us/sample - loss: 0.4839 - mse: 0.2581 - mae: 0.4839 - mape: 84.1882\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.4830 - mse: 0.2572 - mae: 0.4830 - mape: 84.0159\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 123us/sample - loss: 0.4822 - mse: 0.2563 - mae: 0.4822 - mape: 83.8454\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 131us/sample - loss: 0.4813 - mse: 0.2555 - mae: 0.4813 - mape: 83.6653\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 178us/sample - loss: 0.4804 - mse: 0.2547 - mae: 0.4804 - mape: 83.4883\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 132us/sample - loss: 0.4795 - mse: 0.2538 - mae: 0.4795 - mape: 83.3142\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 142us/sample - loss: 0.4786 - mse: 0.2529 - mae: 0.4786 - mape: 83.1390\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 119us/sample - loss: 0.4777 - mse: 0.2521 - mae: 0.4777 - mape: 82.9602\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 169us/sample - loss: 0.4768 - mse: 0.2512 - mae: 0.4768 - mape: 82.7822\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 199us/sample - loss: 0.4759 - mse: 0.2504 - mae: 0.4759 - mape: 82.6058\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 172us/sample - loss: 0.4750 - mse: 0.2495 - mae: 0.4750 - mape: 82.4274\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 155us/sample - loss: 0.4741 - mse: 0.2486 - mae: 0.4741 - mape: 82.2441\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.4732 - mse: 0.2478 - mae: 0.4732 - mape: 82.0641\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 116us/sample - loss: 0.4723 - mse: 0.2469 - mae: 0.4723 - mape: 81.8803\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 144us/sample - loss: 0.4714 - mse: 0.2460 - mae: 0.4714 - mape: 81.6972\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 180us/sample - loss: 0.4705 - mse: 0.2452 - mae: 0.4705 - mape: 81.5167\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 130us/sample - loss: 0.4695 - mse: 0.2443 - mae: 0.4695 - mape: 81.3343\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 140us/sample - loss: 0.4686 - mse: 0.2434 - mae: 0.4686 - mape: 81.1496\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 134us/sample - loss: 0.4677 - mse: 0.2426 - mae: 0.4677 - mape: 80.9622\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 133us/sample - loss: 0.4667 - mse: 0.2417 - mae: 0.4667 - mape: 80.7769\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 137us/sample - loss: 0.4658 - mse: 0.2408 - mae: 0.4658 - mape: 80.5922\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 153us/sample - loss: 0.4649 - mse: 0.2399 - mae: 0.4649 - mape: 80.4045\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 221us/sample - loss: 0.4639 - mse: 0.2390 - mae: 0.4639 - mape: 80.2170\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 152us/sample - loss: 0.4630 - mse: 0.2382 - mae: 0.4630 - mape: 80.0281\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 158us/sample - loss: 0.4620 - mse: 0.2373 - mae: 0.4620 - mape: 79.8406\n",
      "-----------------------------------------------------------\n",
      "Currently Training Part: 2/3Total Parts.\n",
      "-----------------------------------------------------------\n",
      "Train on 97 samples\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 0s 3ms/sample - loss: 0.7524 - mse: 0.6941 - mae: 0.7524 - mape: 407.3248\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 135us/sample - loss: 0.7518 - mse: 0.6932 - mae: 0.7518 - mape: 405.2774\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.7512 - mse: 0.6923 - mae: 0.7512 - mape: 403.3290\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 212us/sample - loss: 0.7506 - mse: 0.6914 - mae: 0.7506 - mape: 400.9820\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 168us/sample - loss: 0.7500 - mse: 0.6905 - mae: 0.7500 - mape: 398.9821\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 158us/sample - loss: 0.7494 - mse: 0.6896 - mae: 0.7494 - mape: 396.7017\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 149us/sample - loss: 0.7488 - mse: 0.6887 - mae: 0.7488 - mape: 394.7632\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 140us/sample - loss: 0.7482 - mse: 0.6878 - mae: 0.7482 - mape: 392.7074\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 172us/sample - loss: 0.7476 - mse: 0.6870 - mae: 0.7476 - mape: 391.0882\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 179us/sample - loss: 0.7470 - mse: 0.6860 - mae: 0.7470 - mape: 389.1441\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 223us/sample - loss: 0.7464 - mse: 0.6852 - mae: 0.7464 - mape: 387.1084\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 188us/sample - loss: 0.7458 - mse: 0.6843 - mae: 0.7458 - mape: 385.4952\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 175us/sample - loss: 0.7452 - mse: 0.6834 - mae: 0.7452 - mape: 382.7997\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 154us/sample - loss: 0.7446 - mse: 0.6825 - mae: 0.7446 - mape: 381.5034\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 144us/sample - loss: 0.7440 - mse: 0.6816 - mae: 0.7440 - mape: 378.7982\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 141us/sample - loss: 0.7434 - mse: 0.6807 - mae: 0.7434 - mape: 376.5455\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 142us/sample - loss: 0.7428 - mse: 0.6798 - mae: 0.7428 - mape: 375.2170\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 152us/sample - loss: 0.7422 - mse: 0.6789 - mae: 0.7422 - mape: 372.8982\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 182us/sample - loss: 0.7417 - mse: 0.6781 - mae: 0.7417 - mape: 371.5708\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 161us/sample - loss: 0.7411 - mse: 0.6772 - mae: 0.7411 - mape: 369.2870\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 174us/sample - loss: 0.7405 - mse: 0.6763 - mae: 0.7405 - mape: 367.6436\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 164us/sample - loss: 0.7399 - mse: 0.6754 - mae: 0.7399 - mape: 365.7072\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 135us/sample - loss: 0.7393 - mse: 0.6745 - mae: 0.7393 - mape: 363.3391\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 141us/sample - loss: 0.7387 - mse: 0.6736 - mae: 0.7387 - mape: 361.7007\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 155us/sample - loss: 0.7381 - mse: 0.6727 - mae: 0.7381 - mape: 359.7107\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 251us/sample - loss: 0.7375 - mse: 0.6719 - mae: 0.7375 - mape: 357.7156\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 172us/sample - loss: 0.7369 - mse: 0.6710 - mae: 0.7369 - mape: 355.7197\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 179us/sample - loss: 0.7363 - mse: 0.6701 - mae: 0.7363 - mape: 353.0476\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 198us/sample - loss: 0.7357 - mse: 0.6692 - mae: 0.7357 - mape: 351.7443\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 178us/sample - loss: 0.7351 - mse: 0.6683 - mae: 0.7351 - mape: 349.4382\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 235us/sample - loss: 0.7345 - mse: 0.6674 - mae: 0.7345 - mape: 347.7968\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 234us/sample - loss: 0.7339 - mse: 0.6666 - mae: 0.7339 - mape: 345.1042\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.7333 - mse: 0.6657 - mae: 0.7333 - mape: 343.0814\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 213us/sample - loss: 0.7327 - mse: 0.6648 - mae: 0.7327 - mape: 341.8436\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 191us/sample - loss: 0.7321 - mse: 0.6639 - mae: 0.7321 - mape: 339.7547\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 146us/sample - loss: 0.7315 - mse: 0.6630 - mae: 0.7315 - mape: 337.8338\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 146us/sample - loss: 0.7309 - mse: 0.6621 - mae: 0.7309 - mape: 335.4044\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 148us/sample - loss: 0.7303 - mse: 0.6613 - mae: 0.7303 - mape: 333.4202\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 137us/sample - loss: 0.7297 - mse: 0.6604 - mae: 0.7297 - mape: 331.4514\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 141us/sample - loss: 0.7291 - mse: 0.6595 - mae: 0.7291 - mape: 329.7842\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 160us/sample - loss: 0.7285 - mse: 0.6586 - mae: 0.7285 - mape: 327.7500\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 236us/sample - loss: 0.7279 - mse: 0.6577 - mae: 0.7279 - mape: 325.3731\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.7272 - mse: 0.6568 - mae: 0.7272 - mape: 323.1026\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 151us/sample - loss: 0.7266 - mse: 0.6559 - mae: 0.7266 - mape: 321.4106\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 152us/sample - loss: 0.7260 - mse: 0.6551 - mae: 0.7260 - mape: 319.3643\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 173us/sample - loss: 0.7254 - mse: 0.6542 - mae: 0.7254 - mape: 316.9769\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 147us/sample - loss: 0.7248 - mse: 0.6533 - mae: 0.7248 - mape: 315.3168\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 149us/sample - loss: 0.7242 - mse: 0.6524 - mae: 0.7242 - mape: 313.3790\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 138us/sample - loss: 0.7236 - mse: 0.6516 - mae: 0.7236 - mape: 311.6041\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 178us/sample - loss: 0.7230 - mse: 0.6507 - mae: 0.7230 - mape: 309.2351\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 223us/sample - loss: 0.7224 - mse: 0.6498 - mae: 0.7224 - mape: 307.6255\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 187us/sample - loss: 0.7218 - mse: 0.6489 - mae: 0.7218 - mape: 304.8828\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 165us/sample - loss: 0.7212 - mse: 0.6480 - mae: 0.7212 - mape: 303.5381\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 153us/sample - loss: 0.7205 - mse: 0.6471 - mae: 0.7205 - mape: 301.0908\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 150us/sample - loss: 0.7199 - mse: 0.6462 - mae: 0.7199 - mape: 298.8140\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 130us/sample - loss: 0.7193 - mse: 0.6453 - mae: 0.7193 - mape: 296.7439\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 132us/sample - loss: 0.7187 - mse: 0.6445 - mae: 0.7187 - mape: 294.6388\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 129us/sample - loss: 0.7181 - mse: 0.6436 - mae: 0.7181 - mape: 292.9911\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 123us/sample - loss: 0.7175 - mse: 0.6427 - mae: 0.7175 - mape: 291.2342\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 132us/sample - loss: 0.7169 - mse: 0.6418 - mae: 0.7169 - mape: 288.4678\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 134us/sample - loss: 0.7162 - mse: 0.6409 - mae: 0.7162 - mape: 287.1610\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 151us/sample - loss: 0.7156 - mse: 0.6400 - mae: 0.7156 - mape: 284.4261\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 179us/sample - loss: 0.7150 - mse: 0.6391 - mae: 0.7150 - mape: 282.4075\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 147us/sample - loss: 0.7144 - mse: 0.6382 - mae: 0.7144 - mape: 280.2797\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 0s 156us/sample - loss: 0.7138 - mse: 0.6373 - mae: 0.7138 - mape: 278.9684\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 0s 170us/sample - loss: 0.7131 - mse: 0.6364 - mae: 0.7131 - mape: 276.5209\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 0s 162us/sample - loss: 0.7125 - mse: 0.6355 - mae: 0.7125 - mape: 274.1338\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 0s 180us/sample - loss: 0.7119 - mse: 0.6347 - mae: 0.7119 - mape: 272.0009\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 0s 277us/sample - loss: 0.7113 - mse: 0.6338 - mae: 0.7113 - mape: 270.2833\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 0s 193us/sample - loss: 0.7106 - mse: 0.6329 - mae: 0.7106 - mape: 268.1573\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 0s 191us/sample - loss: 0.7100 - mse: 0.6320 - mae: 0.7100 - mape: 265.7386\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 0s 221us/sample - loss: 0.7094 - mse: 0.6311 - mae: 0.7094 - mape: 264.0268\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 0s 258us/sample - loss: 0.7087 - mse: 0.6302 - mae: 0.7087 - mape: 261.5339\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 0s 173us/sample - loss: 0.7081 - mse: 0.6293 - mae: 0.7081 - mape: 260.2079\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 0s 182us/sample - loss: 0.7075 - mse: 0.6284 - mae: 0.7075 - mape: 257.3747\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 0s 303us/sample - loss: 0.7068 - mse: 0.6275 - mae: 0.7068 - mape: 255.2765\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 0s 179us/sample - loss: 0.7062 - mse: 0.6266 - mae: 0.7062 - mape: 253.5209\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 0s 187us/sample - loss: 0.7056 - mse: 0.6257 - mae: 0.7056 - mape: 251.0680\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 0s 193us/sample - loss: 0.7049 - mse: 0.6248 - mae: 0.7049 - mape: 249.2850\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 0s 159us/sample - loss: 0.7043 - mse: 0.6238 - mae: 0.7043 - mape: 246.8311\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6930 - mse: 0.6096 - mae: 0.6930 - mape: 450.94 - 0s 149us/sample - loss: 0.7036 - mse: 0.6230 - mae: 0.7036 - mape: 245.3993\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 0s 147us/sample - loss: 0.7030 - mse: 0.6221 - mae: 0.7030 - mape: 243.2665\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 0s 143us/sample - loss: 0.7023 - mse: 0.6212 - mae: 0.7023 - mape: 241.1238\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 0s 147us/sample - loss: 0.7017 - mse: 0.6203 - mae: 0.7017 - mape: 238.6255\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 0s 154us/sample - loss: 0.7011 - mse: 0.6193 - mae: 0.7011 - mape: 236.8343\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 0s 220us/sample - loss: 0.7004 - mse: 0.6184 - mae: 0.7004 - mape: 233.9201\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 0s 149us/sample - loss: 0.6998 - mse: 0.6175 - mae: 0.6998 - mape: 232.5853\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 0s 155us/sample - loss: 0.6991 - mse: 0.6166 - mae: 0.6991 - mape: 230.0432\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 0s 160us/sample - loss: 0.6985 - mse: 0.6157 - mae: 0.6985 - mape: 227.8548\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 0s 143us/sample - loss: 0.6978 - mse: 0.6148 - mae: 0.6978 - mape: 225.7039\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 0s 137us/sample - loss: 0.6971 - mse: 0.6138 - mae: 0.6971 - mape: 223.9272\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 0s 159us/sample - loss: 0.6965 - mse: 0.6129 - mae: 0.6965 - mape: 221.7064\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 0s 142us/sample - loss: 0.6958 - mse: 0.6120 - mae: 0.6958 - mape: 219.1177\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 0s 151us/sample - loss: 0.6952 - mse: 0.6111 - mae: 0.6952 - mape: 217.0199\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 0s 180us/sample - loss: 0.6945 - mse: 0.6102 - mae: 0.6945 - mape: 214.8367\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 0s 169us/sample - loss: 0.6939 - mse: 0.6092 - mae: 0.6939 - mape: 212.9571\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 0s 145us/sample - loss: 0.6932 - mse: 0.6083 - mae: 0.6932 - mape: 210.0082\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 0s 181us/sample - loss: 0.6925 - mse: 0.6074 - mae: 0.6925 - mape: 208.1557\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 0s 195us/sample - loss: 0.6919 - mse: 0.6065 - mae: 0.6919 - mape: 205.6023\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 0s 161us/sample - loss: 0.6912 - mse: 0.6056 - mae: 0.6912 - mape: 204.1000\n",
      "-----------------------\n",
      "Training Deep Zero-Sets\n",
      "-----------------------\n",
      "Train on 416 samples\n",
      "416/416 [==============================] - 0s 928us/sample - loss: 0.6564 - accuracy: 0.6410\n",
      "-----------------------------------\n",
      "Computing Final Performance Metrics\n",
      "-----------------------------------\n",
      "         train      test\n",
      "MAE   0.559773  0.560526\n",
      "MSE   0.360984  0.364207\n",
      "MAPE       inf       inf\n",
      "     L-time    P-time  N_params_expt  AIC-like    Eff  N. Parts\n",
      "0  1.627204  6.744359           1598  3197.158  4.135         3\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "# ---- Getting Benchmarks ---- #\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "#------------------------------#\n",
      "Training PCNN-lgt\n",
      "Training PCNN-Bagged\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "...Returning Results...\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "# q_implicit_N_parts_possibilities = np.linspace(min_parts_threshold,max_parts_threshold,N_plot_finess)\n",
    "N_parts_possibilities = np.unique(np.round(np.linspace(N_min_parts,N_max_plots,num=N_plot_finess))).astype(int)\n",
    "# Custom: N_parts_possibilities = np.array([1,2,3,4,5,8]); N_plot_finess = len(N_parts_possibilities)\n",
    "\n",
    "# Get Performance Metric\n",
    "for inplicit_N_parts_loop in range(len(N_parts_possibilities)):\n",
    "    ### UPDATE USER ###\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    print('Ablation Completion Percentage:',(inplicit_N_parts_loop/N_plot_finess))\n",
    "    for k in range(10):\n",
    "        print('--------------------------------------')\n",
    "    \n",
    "    # Implicitly Set: Current Number of Parts\n",
    "#     q_implicit_N_parts_loop = q_implicit_N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    N_parts_possibilities_loop = N_parts_possibilities[inplicit_N_parts_loop]\n",
    "    # Run Algos. 1+2\n",
    "    performance_Architope_loop, Architope_Model_Complexity_full_loop, N_parts_Generated_by_Algo_2_loop, N_params_architope_loop, N_neurons_subPatterns_loop, N_neurons_deep_Zero_Sets_loop, height_mean_loop, performance_PCNN_ffNN_logistic_loop, N_params_PCNN_logistic_loop,performance_bagged_ffNN_loop, baggin_time_loop, logistic_time_loop, Deep_Zero_Sets_timer_loop = get_PCNNs(N_parts_possibilities_loop,X_train,y_train,X_test,y_test)\n",
    "    # Reshape\n",
    "    performance_Architope_loop = performance_Architope_loop.to_numpy().reshape([3,2,1])\n",
    "    Architope_Model_Complexity_full_loop = Architope_Model_Complexity_full_loop.to_numpy().reshape([1,6,1])\n",
    "    performance_PCNN_ffNN_logistic_loop = performance_PCNN_ffNN_logistic_loop.to_numpy().reshape([3,2,1])\n",
    "    performance_bagged_ffNN_loop = performance_bagged_ffNN_loop.to_numpy().reshape([3,2,1])\n",
    "    # Record\n",
    "    if inplicit_N_parts_loop == 0:\n",
    "        # Don't count partitioner if only one parts is active!\n",
    "        if N_parts_possibilities_loop <= 1:\n",
    "            Architope_Model_Complexity_full_loop[:,1] = Architope_Model_Complexity_full_loop[:,0]\n",
    "            N_neurons_deep_Zero_Sets_loop = 0\n",
    "        # Record Model Complexities Otherwise    \n",
    "        performance_Architope_history = performance_Architope_loop\n",
    "        Architope_Model_Complexity_history = Architope_Model_Complexity_full_loop\n",
    "        N_parts_Generated_by_Algo_2_history = N_parts_Generated_by_Algo_2_loop\n",
    "        N_params_subPatterns_hist = N_neurons_subPatterns_loop\n",
    "        N_neurons_deep_Zero_Sets_hist = N_neurons_deep_Zero_Sets_loop\n",
    "        N_params_architope_hist = N_neurons_deep_Zero_Sets_loop + N_neurons_subPatterns_loop\n",
    "        height_mean_hist = height_mean_loop\n",
    "        N_neurons_per_input = N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))\n",
    "        ### BENCHMARKs\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = performance_PCNN_ffNN_logistic_loop\n",
    "        N_params_PCNN_logistic_hist = N_params_PCNN_logistic_loop\n",
    "        logistic_time_hist =  logistic_time_loop\n",
    "        baggin_time_hist = baggin_time_loop\n",
    "        ### Bagged PCNNs\n",
    "        performance_bagged_ffNN_hist = performance_bagged_ffNN_loop\n",
    "        ### Misc\n",
    "        Deep_Zero_Sets_timer_hist = Deep_Zero_Sets_timer_loop\n",
    "    else:\n",
    "        performance_Architope_history = np.concatenate((performance_Architope_history,performance_Architope_loop),axis=2)\n",
    "        Architope_Model_Complexity_history = np.concatenate((Architope_Model_Complexity_history,Architope_Model_Complexity_full_loop),axis=2)\n",
    "        N_parts_Generated_by_Algo_2_history = np.append(N_parts_Generated_by_Algo_2_history,N_parts_Generated_by_Algo_2_loop)\n",
    "        N_params_architope_hist = np.append(N_params_architope_hist,N_params_architope_loop)\n",
    "        N_params_subPatterns_hist = np.append(N_params_subPatterns_hist,N_neurons_subPatterns_loop)\n",
    "        N_neurons_deep_Zero_Sets_hist = np.append(N_neurons_deep_Zero_Sets_hist,N_neurons_deep_Zero_Sets_loop)\n",
    "        height_mean_hist = np.append(height_mean_hist,height_mean_loop)\n",
    "        N_neurons_per_input = np.append(N_neurons_per_input,(N_neurons_deep_Zero_Sets_loop + int(round(N_neurons_subPatterns_loop/N_parts_possibilities_loop))))\n",
    "        ### Logistic PCNN\n",
    "        performance_PCNN_ffNN_logistic_hist = np.concatenate((performance_PCNN_ffNN_logistic_hist,\n",
    "                                                              performance_PCNN_ffNN_logistic_loop),\n",
    "                                                             axis=2)\n",
    "        N_params_PCNN_logistic_hist = np.append(N_params_PCNN_logistic_hist,N_params_PCNN_logistic_loop)\n",
    "        logistic_time_hist = np.append(logistic_time_hist,logistic_time_loop)\n",
    "        ### Bagged Performance\n",
    "        performance_bagged_ffNN_hist = np.concatenate((performance_bagged_ffNN_hist,\n",
    "                                                       performance_bagged_ffNN_loop),\n",
    "                                                      axis=2)\n",
    "        baggin_time_hist = np.append(baggin_time_hist,baggin_time_loop)\n",
    "        ### Misc\n",
    "        Deep_Zero_Sets_timer_hist = np.append(Deep_Zero_Sets_timer_hist,Deep_Zero_Sets_timer_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "## Randomization may produce duplicates; we remove these with the following snippet:\n",
    "get_unique_entries = np.unique(N_parts_Generated_by_Algo_2_history, return_index=True)[1]\n",
    "N_parts_Generated_by_Algo_2_history_report = N_parts_Generated_by_Algo_2_history[get_unique_entries]\n",
    "\n",
    "# Write\n",
    "## Prediction Qualities\n",
    "performance_Architope_history_report_MAE_train = (performance_Architope_history[0,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MAE_test = (performance_Architope_history[0,1,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_train = (performance_Architope_history[1,0,:])[get_unique_entries]\n",
    "performance_Architope_history_report_MSE_test = (performance_Architope_history[1,1,:])[get_unique_entries]\n",
    "## Model Complexities\n",
    "L_Times = (Architope_Model_Complexity_history[:,1].reshape(-1,))[get_unique_entries]\n",
    "P_Times = (Architope_Model_Complexity_history[:,0].reshape(-1,))[get_unique_entries]\n",
    "N_Params = (N_params_architope_hist.reshape(-1,))[get_unique_entries]\n",
    "mean_subpattern_widths_hist = (height_mean_hist.reshape(-1,))[get_unique_entries]\n",
    "AIC_Like = (Architope_Model_Complexity_history[:,3].reshape(-1,))[get_unique_entries]\n",
    "Eff = (Architope_Model_Complexity_history[:,4].reshape(-1,))[get_unique_entries]\n",
    "N_neurons_per_input = (N_neurons_per_input.reshape(-1,))[get_unique_entries]\n",
    "## Misc\n",
    "Deep_Zero_Sets_timer_hist = Deep_Zero_Sets_timer_hist[get_unique_entries]\n",
    "\n",
    "# Record Benchmark Complexities\n",
    "## PCNN-lgt\n",
    "performance_bagged_ffNN_report_MAE_train = (performance_PCNN_ffNN_logistic_hist[0,0,:])[get_unique_entries]\n",
    "performance_bagged_ffNN_report_MAE_test = (performance_PCNN_ffNN_logistic_hist[0,1,:])[get_unique_entries]\n",
    "performance_bagged_ffNN_report_MSE_train = (performance_PCNN_ffNN_logistic_hist[1,0,:])[get_unique_entries]\n",
    "performance_bagged_ffNN_report_MSE_test = (performance_PCNN_ffNN_logistic_hist[1,1,:])[get_unique_entries]\n",
    "N_params_PCNN_logistic_hist = (N_params_subPatterns_hist + N_parts_Generated_by_Algo_2_history_report)[get_unique_entries]\n",
    "N_params_PCNN_logistic_hist_per_input = N_parts_Generated_by_Algo_2_history_report + N_params_subPatterns_hist[get_unique_entries]\n",
    "P_time_PCNN_lgt = logistic_time_hist[get_unique_entries] + P_Times - Deep_Zero_Sets_timer_hist\n",
    "L_time_PCNN_lgt = logistic_time_hist[get_unique_entries] + L_Times - Deep_Zero_Sets_timer_hist\n",
    "## PCNN-bag\n",
    "performance_PCNN_ffNN_bag_report_MAE_train = (performance_bagged_ffNN_hist[0,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_bag_report_MAE_test = (performance_bagged_ffNN_hist[0,1,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_bag_report_MSE_train = (performance_bagged_ffNN_hist[1,0,:])[get_unique_entries]\n",
    "performance_PCNN_ffNN_bag_report_MSE_test = (performance_bagged_ffNN_hist[1,1,:])[get_unique_entries]\n",
    "N_params_PCNN_ffNN_bag = (N_params_subPatterns_hist*N_parts_Generated_by_Algo_2_history_report)[get_unique_entries]\n",
    "N_params_PCNN_ffNN_bag_per_input = N_params_PCNN_ffNN_bag\n",
    "P_time_PCNN_bag = baggin_time_hist[get_unique_entries] + P_Times - Deep_Zero_Sets_timer_hist\n",
    "L_time_PCNN_bag = baggin_time_hist[get_unique_entries] + L_Times - Deep_Zero_Sets_timer_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get Best PCNN\n",
    "This is identified as the PCNN with the smallest training MAE.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_N_parts = np.argmin(performance_Architope_history_report_MAE_train)\n",
    "# Get PCNN Performance Metrics\n",
    "PCNN_MAE_train = performance_Architope_history_report_MAE_train[best_N_parts]\n",
    "PCNN_MAE_test = performance_Architope_history_report_MAE_test[best_N_parts]\n",
    "PCNN_MSE_train = performance_Architope_history_report_MSE_train[best_N_parts]\n",
    "PCNN_MSE_test = performance_Architope_history_report_MSE_test[best_N_parts]\n",
    "PCNN_performance_all = performance_Architope_history[:,:,best_N_parts]\n",
    "## Model Complexities\n",
    "PCNN_L_time = L_Times[best_N_parts]\n",
    "PCNN_P_time = P_Times[best_N_parts]\n",
    "PCNN_subpattern_widths_hist = mean_subpattern_widths_hist[best_N_parts]\n",
    "PCNN_AIC_Like = AIC_Like[best_N_parts]\n",
    "PCNN_Eff = Eff[best_N_parts]\n",
    "PCNN_N_neurons_per_input = N_neurons_per_input[best_N_parts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get Other Benchmark(s)\n",
    "## Feedforward Neural Network (ffNN) Benchmark\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Model complexities for ffNNs\n",
    "P_time_ffNN = P_Times[0]\n",
    "L_time_ffNN = P_Times[0]\n",
    "Width_ffNN = height_mean_hist[0]\n",
    "# For: Plots\n",
    "MAE_ffNN = np.repeat(performance_Architope_history_report_MAE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "MSE_ffNN = np.repeat(performance_Architope_history_report_MSE_test[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "L_times_ffNN_plot = np.repeat(L_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "P_times_ffNN_plot = np.repeat(P_time_ffNN,len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_per_input_ffNN = np.repeat(N_neurons_per_input[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "Width_neurons_ffNN = np.repeat(mean_subpattern_widths_hist[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "N_neurons_ffNN = np.repeat(N_Params[0],len(N_parts_Generated_by_Algo_2_history_report))\n",
    "# Record in Table\n",
    "ffNN_Model_Complexity = pd.DataFrame({'L-time': [L_time_ffNN],\n",
    "                                               'P-time':[P_time_ffNN],\n",
    "                                               'N_params_expt': [N_neurons_ffNN],\n",
    "                                               'AIC-like': [0],\n",
    "                                               'Eff': [0],\n",
    "                                               'N. Parts':[1]})\n",
    "# Misc\n",
    "ffNN_performance_all = performance_Architope_history[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Random Forest Regressor (GBRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Random Forest: In-progress...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gradient Boosted Trees Model - Done CV!\n",
      "Random Forest Regressor uses: 70 parameters.\n",
      "          train       test\n",
      "MAE    0.114654   0.115841\n",
      "MSE    0.018530   0.018903\n",
      "MAPE  22.799543  23.422860\n",
      "Training of Gradient-Boosted Random Forest: Complete!\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing Table: Required Training Times\n"
     ]
    }
   ],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'ffNN': [round(L_Times[0],3)],\n",
    "                                       'GBRF': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'ffNN-Bag': [round(L_time_PCNN_bag[best_N_parts],3)],\n",
    "                                       'ffNN-log': [round(L_time_PCNN_lgt[best_N_parts],3)],\n",
    "                                       'PCNN': [round(PCNN_L_time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'ffNN': ['-'],\n",
    "                                       'GBRF': ['-'],\n",
    "                                       'ffNN-Bag': [round(L_time_PCNN_bag[best_N_parts],3)],\n",
    "                                       'ffNN-log': [round(L_time_PCNN_lgt[best_N_parts],3)],\n",
    "                                       'PCNN': [round(PCNN_L_time,3)]\n",
    "                                      },index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE       MAPE\n",
      "ffNN  0.114847  0.056335  16.387137\n",
      "GBRF  0.114654  0.018530  22.799543\n",
      "PCNN  0.114847  0.056335  16.387137\n"
     ]
    }
   ],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': ffNN_performance_all[:,0],\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "#                                                 'ffNN-bag': performance_bagged_ffNN.train,\n",
    "#                                                 'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'PCNN': PCNN_performance_all[:,0]})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': ffNN_performance_all[:,1],\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "#                                             'ffNN-bag': performance_bagged_ffNN.test,\n",
    "#                                             'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'PCNN': PCNN_performance_all[:,1]})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MSE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MSE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MSE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MSE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "# Add Legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MSE_test___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"MAE\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_Architope_history_report_MAE_test,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         MAE_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         performance_PCNN_ffNN_logistic_report_MAE_test,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_MAE___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"L-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"L-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         L_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_L_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"P-Time\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"P-Time\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_Times,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         P_times_ffNN_plot,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_P_Time___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"N. Params\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"N. Params\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_Params,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_params_PCNN_logistic_hist,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_N_Params___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Active Neurons Per Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Active Neurons per. Input\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Active Neurons per. Input\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_per_input,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         N_params_PCNN_logistic_hist_per_input,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Active_Neurons_per_input___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Widths for Sub-Pattern Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.title(\"Mean Subpattern Widths\")\n",
    "plt.xlabel(\"N. Parts\")\n",
    "plt.ylabel(\"Mean Subpattern Widths\")\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         mean_subpattern_widths_hist,\n",
    "         label = 'PCNN-lgt',\n",
    "         color='red',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         mean_subpattern_widths_hist,\n",
    "         label = 'PCNN',\n",
    "         color='seagreen',\n",
    "         linewidth=2.5)\n",
    "plt.plot(N_parts_Generated_by_Algo_2_history_report,\n",
    "         Width_neurons_ffNN,\n",
    "         label = 'ffNN',\n",
    "         color='darkmagenta',\n",
    "         linewidth=2.5)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/Ablation_Mean_Widths___'+str(Option_Function)+'__Fix_Neurons_Q'+str(Tied_Neurons_Q)+'.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "---------------------\n",
      "---------------------\n",
      "Prediction Metric(s)\n",
      "---------------------\n",
      "---------------------\n",
      "---------------------\n",
      "           MAE       MSE       MAPE\n",
      "ffNN  0.114847  0.056335  16.387137\n",
      "GBRF  0.114654  0.018530  22.799543\n",
      "PCNN  0.114847  0.056335  16.387137\n",
      " \n",
      " \n",
      " \n",
      "---------------------\n",
      "---------------------\n",
      "---------------------\n",
      "Model Complexitie(s)\n",
      "---------------------\n",
      "---------------------\n",
      "---------------------\n",
      "                   ffNN   GBRF  ffNN-Bag  ffNN-log   PCNN\n",
      "In-Line (L-Time)  1.121  1.249     0.001     0.001  1.121\n",
      "                  ffNN GBRF  ffNN-Bag  ffNN-log   PCNN\n",
      "Parallel (P-Time)    -    -     0.001     0.001  1.121\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "    print('---------------------')\n",
    "print('Prediction Metric(s)')\n",
    "for j in range(3):\n",
    "    print('---------------------')\n",
    "print(predictive_performance_training)\n",
    "for j in range(3):\n",
    "    print(' ')\n",
    "for j in range(3):\n",
    "    print('---------------------')\n",
    "print('Model Complexitie(s)')\n",
    "for j in range(3):\n",
    "    print('---------------------')\n",
    "print(training_times_In_Line)\n",
    "print(training_times_Parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
